ClientProtocol in MR incorrectly uses the DelegationTokenSelector in hdfs due to a wrong import. It should use the DelegationTokenSelector in mapreduce.,0
"Rumen tries to match the end of a value string through indexOf(""\""""). It does not take into account the case when an escaped '""' in the value string. This leads to the incorrect parsing the remaining key=value properties in the same line.",0
"Short description:

Enhance the org.apache.hadoop.mrunit.mapreduce.MapDriver, ReduceDriver, and MapReduceDriver unit test driver classes to contain ""setConfiguration"" and ""withConfiguration"" methods for passing in user-supplied org.apache.hadoop.conf.Configuration objects, and have those configuration objects eventually get passed on to the Context objects that are passed in to the mapper/reducer ""setup"" methods.  (Rather than passing in an empty Configuration object, as is being done now.)


Long description:

The MRUnit driver classes (i.e., MapDriver, ReduceDriver, and MapReduceDriver) ought to be enhanced to contain methods for setting a Configuration object to be used by the mapper/reducer being tested - i.e., setConfiguration() and withConfiguration().

The only way to effectively pass parameters into a mapper or reducer is by setting properties on a configuration object, which the mapper/reducer can then retrieve in their ""setup"" step, and use to customize its operation.  As a result, specific mappers/reducers may require the presence of specific configuration properties/parameters in order to function correctly (or at all).  (I am currently coding such a reducer right now.)

Testing such a mapper/reducer thus requires that the unit testing framework used provide the ability to pass in user-supplied Configuration objects to them so that they can be tested with appropriate parameter values.  However, MRUnit currently does not provide this ability.  (All mappers/reducers are always passed an empty configuration object.)  And there is not even currently any (easy) way for the end-user to fix this problem by creating a simple sub-class that supplies this functionality, as such subclasses would require a substantial reimplementation/override of several MRUnit framework classes.

I believe this something that is not too difficult to fix in the MRUnit framework code, however, and would greatly help the usability of MRUnit.


Although I don't have time to code this enhancement right now, if needed/preferred I could squeeze out some time to code up a patch for this.  If that's needed, please let me know.
",0
"Gridmix throws Exceptions (including those that come from mapreduce jobs) when there are some issues like
(1) ioPath already exists and -generate option is given
(2) when -generate option is given, ioPath (a) doesn't exist (b) exists but with wrong permissions
(3) gridmix.output.directory path already exists
(4) gridmix.min.file.size is > the size specified as option to -generate
etc.

These can be validated early and provide proper error messages to the user of gridmix.",0
"Suppose if user submit a GridMix job in a cluster. However, there are no task trackers running in the cluster, in this case the GridMix is hanging forever at JobMonitor. Please make sure to exit the job with appropriate message after specified amount of time instead of waiting forever.",0
nan,0
"Gridmix always throws an FileAlreadyExistsException even ouput directory is not available in HDFS. Actually I was launching the Gridmix in a command line for generating the data, before launching I just make sure the output directory is not available in the HDFS by deleting the folder if already exists.However, I could see output directory already exists exception every time. Please see the attached logs for more information.",0
"GridMix throws an ArithmeticException error when tasktracker count is zero. In generating data, while calculating the bytes per task tracker in getSplit method, throws an exception if tasktracker count is zero. Actually bytes are calculating by dividing the number of task trackers in the cluster. So we need to build the better exception handling for these kinds of cases. Should add a condition (count should be >0) for tasktracker count before calculating the bytes per tasktracker. 

10/08/12 08:33:34 INFO gridmix.JobSubmitter:  Job org.apache.hadoop.mapreduce.Job@18a8ce2 submission failed 
java.lang.ArithmeticException: / by zero
        at org.apache.hadoop.mapred.gridmix.GenerateData$GenDataFormat.getSplits(GenerateData.java:161)
        at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:902)
        at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:919)
        at org.apache.hadoop.mapred.JobClient.access$5(JobClient.java:913)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:838)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:1)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1021)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:792)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:465)
        at org.apache.hadoop.mapred.gridmix.GenerateData$1.run(GenerateData.java:116)
        at org.apache.hadoop.mapred.gridmix.GenerateData$1.run(GenerateData.java:101)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1021)
        at org.apache.hadoop.mapred.gridmix.GenerateData.call(GenerateData.java:101)
        at org.apache.hadoop.mapred.gridmix.GenerateData.call(GenerateData.java:57)
        at org.apache.hadoop.mapred.gridmix.JobSubmitter$SubmitTask.run(JobSubmitter.java:106)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
",0
"Exceptions are thrown while computing splits near the end of file - typically when the number of bytes read is smaller than RECORD_LENGTH

10/08/17 22:44:17 WARN conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
10/08/17 22:44:17 INFO input.FileInputFormat: Total input paths to process : 1
Spent 19ms computing base-splits.
Spent 2ms computing TeraScheduler splits.
Computing input splits took 22ms
Sampling 1 splits of 1
Got an exception while reading splits java.io.EOFException: read past eof
        at org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.java:267)
        at org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:181)

TeraInoutFormat I believe assumes the file sizes are exact multiples of RECORD_LENGTH

",0
"CombineFileInputFormat.getSplits creates splits with duplicate locations. It adds locations of the files in the split to an ArrayList; if all the files are on same location, the location is added again and again. Instead, it should add it to a Set instead of List to avoid duplicates.",0
"Trunk compilation fails with following errors:
    [javac] /home/amarsri/workspace/trunk/src/test/mapred/org/apache/hadoop/mapred/TestSubmitJob.java:267: getListing(java.lang.String,byte[],boolean) in org.apache.hadoop.hdfs.protocol.ClientProtocol cannot be applied to (java.lang.String,byte[])
    [javac]         client.getListing(
    [javac]               ^
    [javac] /home/amarsri/workspace/trunk/src/test/mapred/org/apache/hadoop/mapred/TestSubmitJob.java:281: getListing(java.lang.String,byte[],boolean) in org.apache.hadoop.hdfs.protocol.ClientProtocol cannot be applied to (java.lang.String,byte[])
    [javac]         client.getListing(
    [javac]               ^

This is due to commit of HDFS-202",0
TestDFSIO's read test may read less bytes than specified when reading large files.,0
"When DistributedRaidFileSystem.close() is called, it does not remove itself from the FileSystem cache, but it does close the underlying filesystem, e.g. DFS.

Because the DRFS with the closed DFS is still in the cache, calling FileSystem.get() returns a stale DRFS that throws 'filesystem closed' exceptions.",0
"Gridmix throws an IOException while submitting the Gridmix jobs consecutively through ToolRunner. For first job its works fine and for next job onwards, it throws the below exception.

    [junit] java.io.IOException: Stream closed
    [junit]     at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:145)
    [junit]     at java.io.BufferedInputStream.read(BufferedInputStream.java:308)
    [junit]     at org.codehaus.jackson.impl.ByteSourceBootstrapper.ensureLoaded(ByteSourceBootstrapper.java:338)
    [junit]     at org.codehaus.jackson.impl.ByteSourceBootstrapper.detectEncoding(ByteSourceBootstrapper.java:116)
    [junit]     at org.codehaus.jackson.impl.ByteSourceBootstrapper.constructParser(ByteSourceBootstrapper.java:205)
    [junit]     at org.codehaus.jackson.JsonFactory._createJsonParser(JsonFactory.java:298)
    [junit]     at org.codehaus.jackson.JsonFactory.createJsonParser(JsonFactory.java:251)
    [junit]     at org.apache.hadoop.tools.rumen.JsonObjectMapperParser.<init>(JsonObjectMapperParser.java:72)
    [junit]     at org.apache.hadoop.tools.rumen.JobTraceReader.<init>(JobTraceReader.java:49)
    [junit]     at org.apache.hadoop.tools.rumen.ZombieJobProducer.<init>(ZombieJobProducer.java:94)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.createJobFactory(Gridmix.java:212)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.startThreads(Gridmix.java:181)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.start(Gridmix.java:291)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.runJob(Gridmix.java:273)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.access$000(Gridmix.java:55)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix$1.run(Gridmix.java:227)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix$1.run(Gridmix.java:225)
    [junit]     at java.security.AccessController.doPrivileged(Native Method)
    [junit]     at javax.security.auth.Subject.doAs(Subject.java:396)
    [junit]     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1021)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.run(Gridmix.java:225)
    [junit]     at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
    [junit]     at org.apache.hadoop.mapred.gridmix.TestGridMixDataGeneration.testGenerateDataWithREPLAYSubmission(TestGridMixDataGeneration.java:173)
    [junit]     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    [junit]     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    [junit]     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    [junit]     at java.lang.reflect.Method.invoke(Method.java:597)
    [junit]     at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
    [junit]     at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
    [junit]     at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
    [junit]     at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
    [junit]     at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
    [junit]     at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
    [junit]     at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:73)
    [junit]     at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:46)
    [junit]     at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:180)
    [junit]     at org.junit.runners.ParentRunner.access$000(ParentRunner.java:41)
    [junit]     at org.junit.runners.ParentRunner$1.evaluate(ParentRunner.java:173)
    [junit]     at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
    [junit]     at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
    [junit]     at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
    [junit]     at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
    [junit] 10/08/25 07:05:13 ERROR gridmix.Gridmix: Startup failed
    [junit] java.io.IOException: java.io.IOException: Stream closed
",0
"TestJobOutputCommitter fails in a ""ant test"" run with following exception :
{noformat}
Output directory /home/amarsri/mapred/build/test/data/test-job-cleanup/output-2 already exists
org.apache.hadoop.fs.FileAlreadyExistsException: Output directory /home/amarsri/mapred/build/test/data/test-job-cleanup/output-2 already exists
        at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:141)
        at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:391)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:350)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1037)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1034)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1093)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1034)
        at org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter.testKilledJob(TestJobOutputCommitter.java:192)
        at org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter.testDefaultCleanupAndAbort(TestJobOutputCommitter.java:232)
{noformat}
But it passes when it is run individually.",0
"TestSubmitJob.testSecureJobExecution catches any IOException and assumes a permissions error has been caught. In fact, it was passing an invalid path name to the NameNode and triggering an NPE, not a Permission denied error, in one case, but the test was not specific enough to detect this.",0
"TaskRunner's prepareLogFiles() warns on mkdirs() failures but ignores them.  It also fails even to check the return value of setPermissions().  Either one can fail (e.g., on NFS, where there appears to be a TOCTOU-style race, except with C = ""creation""), in which case the subsequent creation of job-acl.xml in writeJobACLs() will also fail, killing the task:

{noformat}
2010-08-26 20:18:10,334 INFO  mapred.TaskInProgress (TaskInProgress.java:updateStatus(591)) - Error from attempt_20100826201758813_0001_m_000001_0 on tracker_host2.rack.com:rh45-64/127.0.0.1:35112: java.lang.Throwable: Child Error
    at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:229)
Caused by: java.io.FileNotFoundException: /home/<username>/grid/trunk/hadoop-mapreduce/build/test/logs/userlogs/job_20100826201758813_0001/attempt_20100826201758813_0001_m_000001_0/job-acl.xml (No such file or directory)
    at java.io.FileOutputStream.open(Native Method)
    at java.io.FileOutputStream.<init>(FileOutputStream.java:179)
    at java.io.FileOutputStream.<init>(FileOutputStream.java:131)
    at org.apache.hadoop.mapred.TaskRunner.writeJobACLs(TaskRunner.java:307)
    at org.apache.hadoop.mapred.TaskRunner.prepareLogFiles(TaskRunner.java:290)
    at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:199)
{noformat}

This in turn causes TestTrackerBlacklistAcrossJobs to fail sporadically; the job-acl.xml failure always seems to affect host2 - and to do so more quickly than the intentional exception on host1 - which triggers an assertion failure due to the wrong host being job-blacklisted.
",0
"MRAsyncDiskService fails when it's given local dirs it can't create or write. Per MAPREDUCE-1213 this conflicts with the previous behavior. The TTs will no longer start on hosts where the config has localdirs that can not be created (ie if some hosts don't have the same local mounts).  

The TT and JT should prune out invalid local dirs (ones that fail checkLocalDirs ie that it can not create) before giving them to MRAsyncDiskService and using them otherwise.

Also mapred-default.xml states that mapred.local.dir that do not exist are ignored, this should be updated as directories that don't exist are created (if possible), they're only ignored if they can not be created. 

",0
Queue names were returned from the queue manager as an immutable set after the hierarchical queuname feature which breaks the dynamic priority scheduler,0
"HADOOP-1622 was apparently broken in refactoring (I think in the refactoring that removed JobShell) a few releases ago. e.g., running

hadoop -libjars lib.jar main.jar Class 

now tries to run -libjars as a library.

It would be nice to fix this regression.
",0
"As far as I can tell, where the NameNode, in validating the dfs.hosts and dfs.hosts.exclude files uses the source IP address for the RPC connection, the JobTracker appears to use the presented hostname (set via slave.host.name or the standard hostname-search semantics) from the TaskTracker. Obviously this is a security bug as in a production environment it could allow rogue machines to present the hostname of a real TaskTracker and take over that role, but it also turns up as a configuration bug because it means that you can set up a (multi-homed, natch) environment where the same set of files work for the NameNode, but don't for the JobTracker or vice versa - with the same binding hostname for fs.default.name and mapred.job.tracker.",0
"When I contact the jobtracker web interface prior to the job tracker being fully initialized (say, if hdfs is still in safe mode), I get the following error:

10/09/09 18:06:02 ERROR mortbay.log: /jobtracker.jsp
java.lang.NullPointerException
        at org.apache.hadoop.mapred.FairScheduler.getJobs(FairScheduler.java:909)
        at org.apache.hadoop.mapred.JobTracker.getJobsFromQueue(JobTracker.java:4357)
        at org.apache.hadoop.mapred.JobTracker.getQueueInfoArray(JobTracker.java:4334)
        at org.apache.hadoop.mapred.JobTracker.getRootQueues(JobTracker.java:4295)
        at org.apache.hadoop.mapred.jobtracker_jsp.generateSummaryTable(jobtracker_jsp.java:44)
        at org.apache.hadoop.mapred.jobtracker_jsp._jspService(jobtracker_jsp.java:176)
        at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1124)
        at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:857)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1115)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:361)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:324)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)
",0
"The jobtracker is treating the file 'jobtracker.info' in the system data directory as a job to be recovered, resulting in the following:

10/09/09 18:06:02 WARN mapred.JobTracker: Failed to add the job jobtracker.info
java.lang.IllegalArgumentException: JobId string : jobtracker.info is not properly formed
        at org.apache.hadoop.mapreduce.JobID.forName(JobID.java:158)
        at org.apache.hadoop.mapred.JobID.forName(JobID.java:84)
        at org.apache.hadoop.mapred.JobTracker$RecoveryManager.addJobForRecovery(JobTracker.java:1057)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1565)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:275)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:267)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:262)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4256)
",0
"I get the following strange error on the jobtracker when attempting to submit a job:

10/09/09 20:31:35 INFO ipc.Server: IPC Server handler 7 on 31000, call submitJob(job_201009092028_0001, hdfs://hns4.sea1.qc:21000/tmp/hadoop-mr20/mapred/staging/dadkins/.staging/job_201009092028_0001, org.apache.hadoop.security.Credentials@20c87621) from 10.128.130.145:49253: error: java.io.IOException: Filesystem closed
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:307)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:1212)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:494)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1491)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:395)
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3078)
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3014)
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:2996)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:349)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1380)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1376)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1105)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1374)
",0
"The function canBeSpeculated has subtle bugs that cause too much speculation in certain cases.

- it compares the current progress of the task with the last observed mean of all the tasks. if only one task is in question - then the progress rate decays as time progresses (in the absence of updates) and std-dev is zero. So a job with a single reducer or mapper is almost always speculated.
- is only a single task has reported progress - then the stddev is zero. so other tasks may be speculated aggressively.
- several tasks take a while to report progress initially. they seem to get speculated as soon as speculative-lag is over. the lag should be configurable at the minimum.
",0
MR portion of HADOOP-6951.,0
Likely has to do with the fact that PipesReducer starts the application with a Null reporter in the close method.,0
nan,0
"If I pass an invalid symlink as   -Dmapred.cache.files=/user/knoguchi/onerecord.txt#abc/abc

Task only reports a WARN and goes on.

{noformat} 
2010-09-16 21:38:49,782 INFO org.apache.hadoop.mapred.TaskRunner: Creating symlink: /0/tmp/mapred-local/taskTracker/knoguchi/distcache/-5031501808205559510_-128488332_1354038698/abc-nn1.def.com/user/knoguchi/onerecord.txt <- /0/tmp/mapred-local/taskTracker/knoguchi/jobcache/job_201008310107_15105/attempt_201008310107_15105_m_000000_0/work/./abc/abc
2010-09-16 21:38:49,789 WARN org.apache.hadoop.mapred.TaskRunner: Failed to create symlink: /0/tmp/mapred-local/taskTracker/knoguchi/distcache/-5031501808205559510_-128488332_1354038698/abc-nn1.def.com/user/knoguchi/onerecord.txt <- /0/tmp/mapred-local/taskTracker/knoguchi/jobcache/job_201008310107_15105/attempt_201008310107_15105_m_000000_0/work/./abc/abc
{noformat} 

I believe we should fail the task at this point.",0
"Name clash compile error in the deprecated org.apache.hadoop.util.MemoryCalculatorPlugin due to JLS3 8.4.8.3 (cf. http://bugs.sun.com/view_bug.do?bug_id=6182950)

The bug doesn't manifest in jdk 1.6 up to 20, but shows up in NetBeans 6.9+ due to its bundled (conforming) compiler. Fix is trivial: just remove the offending method in the deprecated subclass as its equivalent erasure is inherited from the parent class anyway.",0
"We use cdh3b2

After reducer took more than 600 seconds to report to tasktracker, tasktracker tried to kill it.
However reducer JVM process hung.

Attaching stack trace of reducer.",0
"In Application.java, when jobtoken password file is written, there is a race condition because the file is written in job's work directory. The file should rather be written in the task's working directory.",0
"I'm currently running a map reduce job in which the reducer inserts data into HBase. It is a long running job dealing with hundreds of GB of map output data and 9 out of 10 reducers are currently showing 110+% progress (i.e. the total job reduce progress is 100% but clickig through to the reducer list shows reducers with percentages over 100%). 

The number of reduce input records is 4,299,991,005

While keeping an eye on it through the job detail page of the JobTracker web gui, the Jobtracker started generating exceptions every 30 seconds which turned out to be generated by the TaskGrapServlet that displays reducer progress. The stacktrace also showed up in the web gui in the area that normally holds the reducer progress graph. 30 seconds is of course the refresh rate of the status page.

I guess the root cause here is progress percentages being greater than 100%. I found issue HADOOP-5210 which reports a cause for progress crossing 100% but it is marked as fixed in 0.20.1 and I'm running 0.20.2.

One thing that might impact the progress percentages is the fact that we LZO compress our map outputs. For the above job uncompressed output (""Map output bytes"") was 2,462,412,228,874 which compressed to 694,405,054,632 (FILE_BYTES_WRITTEN/map).

Here's the exception:

2010-09-23 18:03:05,484 ERROR org.mortbay.log: /taskgraph
java.lang.ArrayIndexOutOfBoundsException: 3
	at org.apache.hadoop.mapred.TaskGraphServlet.getReduceAvarageProgresses(TaskGraphServlet.java:199)
	at org.apache.hadoop.mapred.TaskGraphServlet.doGet(TaskGraphServlet.java:131)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:324)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)



",0
"The Compilation (the ANT clean and tar directives) of the Map/Reduce  Project works fine, but the test-core directive fails because the smoke tests are missing. This is the tail of the build log:

    [junit] Running org.apache.hadoop.mapreduce.TestMapReduceLocal
    [junit] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 57.962 sec
    [junit] Running org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat
    [junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 1.839 sec
    [junit] Running org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter
    [junit] Tests run: 3, Failures: 0, Errors: 0, Time elapsed: 0.866 sec

checkfailure:

run-smoke-test:
   [delete] Deleting directory /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build/test/data
    [mkdir] Created dir: /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build/test/data
   [delete] Deleting directory /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build/test/logs
    [mkdir] Created dir: /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build/test/logs

BUILD FAILED
/home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build.xml:749: The following error occurred while executing this line:
/home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build.xml:658: Excludesfile /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/src/test/smoke-tests not found.

The fastest way to reproduce this error is to run : ""ant run-test-mapred-excluding-commit-and-smoke""
",0
"This JIRA is to contribute a patch developed on the private security@ mailing list.

The vulnerability is that MR daemons occasionally open files that are located in a path where the user has write access. A malicious user may place a symlink in place of the expected file in order to cause the daemon to instead read another file on the system -- one which the attacker may not naturally be able to access. This includes delegation tokens belong to other users, log files, keytabs, etc.",0
"While executing hive query ""select count(*) from table "" , i got this error message 
Ended Job = job_201009291356_0003 with errors
FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask

On investigating task tracker logs , i found out

2010-09-29 14:31:46,839 WARN org.apache.hadoop.conf.Configuration: /home/hadoop/mapred/local/taskTracker/jobcache/job_201009291356_0003/attempt_201009291356_0003_r_000000_3/job.xml:a attempt to override final parameter: mapred.local.dir;  Ignoring.
2010-09-29 14:31:46,862 WARN org.apache.hadoop.conf.Configuration: /home/hadoop/mapred/local/taskTracker/jobcache/job_201009291356_0003/attempt_201009291356_0003_r_000000_3/job.xml:a attempt to override final parameter: mapred.job.tracker;  Ignoring.
2010-09-29 14:31:46,943 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=SHUFFLE, sessionId=
2010-09-29 14:31:47,133 WARN org.apache.hadoop.conf.Configuration: /home/hadoop/mapred/local/taskTracker/jobcache/job_201009291356_0003/attempt_201009291356_0003_r_000000_3/job.xml:a attempt to override final parameter: mapred.local.dir;  Ignoring.
2010-09-29 14:31:47,133 WARN org.apache.hadoop.conf.Configuration: /home/hadoop/mapred/local/taskTracker/jobcache/job_201009291356_0003/attempt_201009291356_0003_r_000000_3/job.xml:a attempt to override final parameter: dfs.data.dir;  Ignoring.
2010-09-29 14:31:47,143 WARN org.apache.hadoop.conf.Configuration: /home/hadoop/mapred/local/taskTracker/jobcache/job_201009291356_0003/attempt_201009291356_0003_r_000000_3/job.xml:a attempt to override final parameter: mapred.job.tracker;  Ignoring.
2010-09-29 14:31:47,143 WARN org.apache.hadoop.conf.Configuration: /home/hadoop/mapred/local/taskTracker/jobcache/job_201009291356_0003/attempt_201009291356_0003_r_000000_3/job.xml:a attempt to override final parameter: dfs.name.dir;  Ignoring.
2010-09-29 14:31:47,209 INFO org.apache.hadoop.mapred.ReduceTask: ShuffleRamManager: MemoryLimit=141387360, MaxSingleShuffleLimit=35346840
2010-09-29 14:31:47,219 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201009291356_0003_r_000000_3 Thread started: Thread for merging on-disk files
2010-09-29 14:31:47,220 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201009291356_0003_r_000000_3 Thread waiting: Thread for merging on-disk files
2010-09-29 14:31:47,222 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201009291356_0003_r_000000_3 Thread started: Thread for merging in memory files
2010-09-29 14:31:47,223 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201009291356_0003_r_000000_3 Need another 17 map output(s) where 0 is already in progress
2010-09-29 14:31:47,224 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201009291356_0003_r_000000_3 Scheduled 0 outputs (0 slow hosts and0 dup hosts)
2010-09-29 14:31:47,224 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201009291356_0003_r_000000_3 Thread started: Thread for polling Map Completion Events
2010-09-29 14:31:47,233 FATAL org.apache.hadoop.mapred.TaskRunner: attempt_201009291356_0003_r_000000_3 GetMapEventsThread Ignoring exception : java.lang.NullPointerException
	at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:768)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$GetMapEventsThread.getMapCompletionEvents(ReduceTask.java:2683)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$GetMapEventsThread.run(ReduceTask.java:2605)



ReduceTask.java:2683 is :  List<MapOutputLocation> loc = mapLocations.get(host)

where host is:-URI u = URI.create(event.getTaskTrackerHttp());  host = u.getHost() ;

What's the fix??",0
"The task-controller currently checks that ""other"" users don't have read permissions. This is unnecessary - we just need to make it's not executable. The debian policy manual explains it well:
Setuid and setgid executables should be mode 4755 or 2755 respectively, and owned by the appropriate user or group. They should not be made unreadable (modes like 4711 or 2711 or even 4111); doing so achieves no extra security, because anyone can find the binary in the freely available Debian package; it is merely inconvenient. For the same reason you should not restrict read or execute permissions on non-set-id executables.
Some setuid programs need to be restricted to particular sets of users, using file permissions. In this case they should be owned by the uid to which they are set-id, and by the group which should be allowed to execute them. They should have mode 4754; again there is no point in making them unreadable to those users who must not be allowed to execute them.",0
"TestControlledMapReduceJob times out on trunk. Logs show the following ArrayIndexOutOfBoundsException:
{noformat} 
java.lang.ArrayIndexOutOfBoundsException: 0
    [junit]     at org.apache.hadoop.mapred.ControlledMapReduceJob.map(ControlledMapReduceJob.java:302)
    [junit]     at org.apache.hadoop.mapred.ControlledMapReduceJob.map(ControlledMapReduceJob.java:60)
    [junit]     at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
    [junit]     at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:397)
    [junit]     at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
    [junit]     at org.apache.hadoop.mapred.Child$4.run(Child.java:223)
    [junit]     at java.security.AccessController.doPrivileged(Native Method)
    [junit]     at javax.security.auth.Subject.doAs(Subject.java:396)
    [junit]     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1114)
    [junit]     at org.apache.hadoop.mapred.Child.main(Child.java:217)
{noformat}",0
Job may hang at RUNNING state if mapreduce.job.committer.setup.cleanup.needed=false and mapreduce.map/reduce.failures.maxpercent>0. It happens when some tasks fail but havent reached failures.maxpercent.,0
"Consider a trace file ""trace1"" obtained by running Rumen on a set of MR jobs' history logs. When gridmix runs simulated jobs from ""trace1"", it may skip some of the jobs from the trace file for some reason like out-of-order-jobs. Now use Rumen to generate trace2 from the history logs of gridmix's simulated jobs.
Now, to compare and analyze the gridmix's simulated jobs with original MR jobs, we need a mapping between them.",0
nan,0
"taskLauncher thread exits on interruptedException and on Interrupt conditions without checking for any shutdown flag:

     while (!Thread.interrupted()) {
        ...
        } catch (InterruptedException e) { 
          return; // ALL DONE                                                                                                                      
        }
     }

If the interrupt happened because of reasons other than TaskTracker.close() - then the TaskTracker will look functional - but will not be able to schedule tasks anymore. worse - some tasks (that are in the launch queue) will hang indefinitely un UNASSIGNED state (the JobTracker will not even time them out). We have seen this cause jobs to hang indefinitely.

It seems that the interrupted condition can be set by log4j (of which there are many calls inside TaskLauncher). See or instance: http://logging.apache.org/log4j/1.2/xref/org/apache/log4j/AsyncAppender.html
",0
nan,0
"the new speculation code only speculates tasks whose progress rate deviates from the mean progress rate of a job by more than some multiple (typically 1.0) of stddev. stddev can be larger than mean. which means that if we ever get into a situation where this condition holds true - then a task with even 0 progress rate will not be speculated.

it's not clear that this condition is self-correcting. if a job has thousands of tasks - then one laggard task, inspite of not being speculated for a long time, may not be able to fix the condition of stddev > mean.

we have seen jobs where tasks have not been speculated for hours and this seems one explanation why this may have happened. here's an example job with stddev > mean:

DataStatistics: count is 6, sum is 1.7141054797775723E-8, sumSquares is 2.9381575958035014E-16 mean is 2.8568424662959537E-9 std() is 6.388093955645905E-9
",0
TestBlockFixer sometimes fails in reportCorruptBlocks because a corrupt block is deleted before in.readFully is called. This causes a BlockMissingException instead of the expected ChecksumException.,0
"When considering task speculation - the job's overall progress rate for the given task type and the individual task's progress rate are compared. When doing so - the task's current progress rate is considered. However the job's overall progress rate is only only updated when a task's progress report is received.

This causes weirdness if a particular task does not report for a while. The job's progress rate is not updated - but the task's progress rate decays. For single task jobs - it causes speculation almost inevitably. 

We need to update the job's overall progress rate as the task's progress rate changes.",0
"We sometimes saw maptask timeout in cdh3b2. Here is log from one of the maptasks:

2010-11-04 10:34:23,820 INFO org.apache.hadoop.mapred.MapTask: Spilling map output: buffer full= true
2010-11-04 10:34:23,820 INFO org.apache.hadoop.mapred.MapTask: bufstart = 119534169; bufend = 59763857; bufvoid = 298844160

2010-11-04 10:34:23,820 INFO org.apache.hadoop.mapred.MapTask: kvstart = 438913; kvend = 585320; length = 983040
2010-11-04 10:34:41,615 INFO org.apache.hadoop.mapred.MapTask: Finished spill 3
2010-11-04 10:35:45,352 INFO org.apache.hadoop.mapred.MapTask: Spilling map output: buffer full= true

2010-11-04 10:35:45,547 INFO org.apache.hadoop.mapred.MapTask: bufstart = 59763857; bufend = 298837899; bufvoid = 298844160
2010-11-04 10:35:45,547 INFO org.apache.hadoop.mapred.MapTask: kvstart = 585320; kvend = 731585; length = 983040

2010-11-04 10:45:41,289 INFO org.apache.hadoop.mapred.MapTask: Finished spill 4

Note how long the last spill took.

In MapTask.java, the following code waits for spill to finish:
while (kvstart != kvend) { reporter.progress(); spillDone.await(); }

In trunk code, code is similar.

There is no timeout mechanism for Condition.await(). In case the SpillThread takes long before calling spillDone.signal(), we would see timeout.
Condition.awaitNanos(long nanosTimeout) should be called.",0
"The linux-task-controller executable currently traverses a directory heirarchy and calls chown/chmod on the files inside. There is a race condition here which can be exploited by an attacker, causing the task-controller to improprly chown an arbitrary target file (via a symlink) to the user running a MR job. This can be exploited to escalate to root.

[this issue was raised and discussed on the security@ list over the last couple of months]",0
"This is caused by a missing block in HDFS. So the block's locations are empty. The following code adds the block to blockToNodes map but not to rackToBlocks map. Later on when generating splits, only blocks in rackToBlocks are removed from blockToNodes map. So blockToNodes map can never become empty therefore causing infinite loop

{code}
          // add this block to the block --> node locations map
          blockToNodes.put(oneblock, oneblock.hosts);

          // add this block to the rack --> block map
          for (int j = 0; j < oneblock.racks.length; j++) {
             ..
          }
{code}",0
nan,0
"If a job's jar file is very large, e.g 200m+, the TaskTracker's heartbeat hang for several minutes when localizing the job. The jstack of related threads are as follows:
{code:borderStyle=solid}
""TaskLauncher for task"" daemon prio=10 tid=0x0000002b05ee5000 nid=0x1adf runnable [0x0000000042e56000]
   java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
        - locked <0x0000002afc892ec8> (a sun.nio.ch.Util$1)
        - locked <0x0000002afc892eb0> (a java.util.Collections$UnmodifiableSet)
        - locked <0x0000002afc8927d8> (a sun.nio.ch.EPollSelectorImpl)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
        at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:260)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:155)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:237)
        - locked <0x0000002afce26158> (a java.io.BufferedInputStream)
        at java.io.DataInputStream.readShort(DataInputStream.java:295)
        at org.apache.hadoop.hdfs.DFSClient$BlockReader.newBlockReader(DFSClient.java:1304)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1556)
        - locked <0x0000002afce26218> (a org.apache.hadoop.hdfs.DFSClient$DFSInputStream)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1673)
        - locked <0x0000002afce26218> (a org.apache.hadoop.hdfs.DFSClient$DFSInputStream)
        at java.io.DataInputStream.read(DataInputStream.java:83)
        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:209)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:142)
        at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1214)
        at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1195)
        at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:824)
        - locked <0x0000002afce2d260> (a org.apache.hadoop.mapred.TaskTracker$RunningJob)
        at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:1745)
        at org.apache.hadoop.mapred.TaskTracker.access$1200(TaskTracker.java:103)
        at org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1710)

""Map-events fetcher for all reduce tasks on tracker_r01a08025:localhost/127.0.0.1:50050"" daemon prio=10 tid=0x0000002b05ef8000 
nid=0x1ada waiting for monitor entry [0x0000000042d55000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.mapred.TaskTracker$MapEventsFetcherThread.reducesInShuffle(TaskTracker.java:582)
        - waiting to lock <0x0000002afce2d260> (a org.apache.hadoop.mapred.TaskTracker$RunningJob)
        at org.apache.hadoop.mapred.TaskTracker$MapEventsFetcherThread.run(TaskTracker.java:617)
        - locked <0x0000002a9eefe1f8> (a java.util.TreeMap)


""IPC Server handler 2 on 50050"" daemon prio=10 tid=0x0000002b050eb000 nid=0x1ab0 waiting for monitor entry [0x000000004234b000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.mapred.TaskTracker.getMapCompletionEvents(TaskTracker.java:2684)
        - waiting to lock <0x0000002a9eefe1f8> (a java.util.TreeMap)
        - locked <0x0000002a9eac1de8> (a org.apache.hadoop.mapred.TaskTracker)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:894)

""main"" prio=10 tid=0x0000000040113800 nid=0x197d waiting for monitor entry [0x000000004022a000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.mapred.TaskTracker.transmitHeartBeat(TaskTracker.java:1196)
        - waiting to lock <0x0000002a9eac1de8> (a org.apache.hadoop.mapred.TaskTracker)
        at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1068)
        at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:1799)
        at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:2898)
{code}",0
"The ExpireLaunchingTask thread kills the task that are scheduled but not responded.
Currently if a task is scheduled on tasktracker and for some reason tasktracker cannot put it to RUNNING.
The task will just hang in the UNASSIGNED status and JobTracker will keep waiting for it.

JobTracker.ExpireLaunchingTask should be able to kill this task.",0
JvmManager.JvmManagerForType has several HashMap members that are inconsistently synchronized. I've seen sporadic NPEs in the 0.20 version of this code which has similar bugs.,0
nan,0
"Currently it's not possible to get at the original InputSplits when using MultipleInputs. This is because TaggedInputSplit (used by DelegatingInputFormat used by MultipleInputs) is not public. This means things like the following do not work:
public void map(...) {
  FileSplit fis = (FileSplit)((TaggedInputSplit) reporter.getInputSplit()).getInputSplit();
  Path p = fis.getPath();
}
This prevents users from getting at input split specific data.",0
nan,0
"When the LinuxTaskController is incorrectly configured (eg wrong permissions or path) an NPE is thrown when it tries to kill the failed tasks, since there is no known pid.",0
nan,0
"There is a genaral problem in JobTracker.java code: it's using ""this"" synchronization everywhere so only one method could be executed at one moment. When the job submit rate is low (lower then one job in several seconds) tracker's working without a problem. When the job rate is high the following problem occurs:

Inside submitJob() JT copies job jar + xml to local filesystem. After that it's doing ""chmod"" on those files. Hadoop does chmod  by spawning child process. When JT heap is big (like several gigabytes) spawning child process takes a lot of time (because java calls fork()) 鈥?in our case it's about 1-2 seconds. So job tracker can't handle high frequency job submits.

Except of that, as heartbeat() method is also synchronized JT stops to process heart-beat as ""this"" monitor is being held by submit job. That makes JT thins that a lot of TaskTrackers are down.

Following solution could help:

""chmod"" is being called from submitJob() method under following line:

JobInProgress job = new JobInProgress(jobId, this, this.conf);

This block could be taken away from synchronized code:

public JobStatus submitJob(JobID jobId) throws IOException {
    synchronized (this) {
        .... the rest
    }

    //here we're leaving this line outside syncronized code as it doesn't relate
    //on state of JobTracker. Also this line

    JobInProgress job = new JobInProgress(jobId, this, this.conf);

    synchronized (this) {
         .... the rest
    }",0
"If the attempts is configured to use Integer.MAX_VALUE, an overflow occurs inside TaskInProgress, and thereby no task is attempted by the cluster and the map tasks stay in pending state forever.

For example, here's a job driver that causes this:
{code}
import java.io.IOException;

import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapred.FileInputFormat;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.TextInputFormat;
import org.apache.hadoop.mapred.lib.IdentityMapper;
import org.apache.hadoop.mapred.lib.NullOutputFormat;


@SuppressWarnings(""deprecation"")
public class IntegerOverflow {

	/**
	 * @param args
	 * @throws IOException 
	 */
	@SuppressWarnings(""deprecation"")
	public static void main(String[] args) throws IOException {
		JobConf conf = new JobConf();
		
		Path inputPath = new Path(""ignore"");
		FileSystem fs = FileSystem.get(conf);
		if (!fs.exists(inputPath)) {
			FSDataOutputStream out = fs.create(inputPath);
			out.writeChars(""Test"");
			out.close();
		}
		
		conf.setInputFormat(TextInputFormat.class);
		conf.setOutputFormat(NullOutputFormat.class);
		FileInputFormat.addInputPath(conf, inputPath);
		
		conf.setMapperClass(IdentityMapper.class);
		conf.setNumMapTasks(1);
		// Problem inducing line follows.
		conf.setMaxMapAttempts(Integer.MAX_VALUE);
		
		// No reducer in this test, although setMaxReduceAttempts leads to the same problem.
		conf.setNumReduceTasks(0);
		
		JobClient.runJob(conf);
	}

}
{code}

The above code will not let any map task run. Additionally, a log would be created inside JobTracker logs with the following information that clearly shows the overflow:
{code}
2010-12-30 00:59:07,836 WARN org.apache.hadoop.mapred.TaskInProgress: Exceeded limit of -2147483648 (plus 0 killed) attempts for the tip 'task_201012300058_0001_m_000000'
{code}

The issue lies inside the TaskInProgress class (/o/a/h/mapred/TaskInProgress.java), at line 1018 (trunk), part of the getTaskToRun(String taskTracker) method.
{code}
  public Task getTaskToRun(String taskTracker) throws IOException {   
    // Create the 'taskid'; do not count the 'killed' tasks against the job!
    TaskAttemptID taskid = null;
    /* ============ THIS LINE v ====================================== */
    if (nextTaskId < (MAX_TASK_EXECS + maxTaskAttempts + numKilledTasks)) {
    /* ============ THIS LINE ^====================================== */
      // Make sure that the attempts are unqiue across restarts
      int attemptId = job.getNumRestarts() * NUM_ATTEMPTS_PER_RESTART + nextTaskId;
      taskid = new TaskAttemptID( id, attemptId);
      ++nextTaskId;
    } else {
      LOG.warn(""Exceeded limit of "" + (MAX_TASK_EXECS + maxTaskAttempts) +
              "" (plus "" + numKilledTasks + "" killed)""  + 
              "" attempts for the tip '"" + getTIPId() + ""'"");
      return null;
    }
{code}

Since all three variables being added are integer in type, one of them being Integer.MAX_VALUE makes the condition fail with an overflow, thereby logging and returning a null as the result is negative.

One solution would be to make one of these variables into a long, so the addition does not overflow?",0
"The MR hudson job is failing, looks like it's due to a test chmod'ing a build directory so the checkout can't clean the build dir.

https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk/549/console

Building remotely on hadoop7
hudson.util.IOException2: remote file operation failed: /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk at hudson.remoting.Channel@2545938c:hadoop7
	at hudson.FilePath.act(FilePath.java:749)
	at hudson.FilePath.act(FilePath.java:735)
	at hudson.scm.SubversionSCM.checkout(SubversionSCM.java:589)
	at hudson.scm.SubversionSCM.checkout(SubversionSCM.java:537)
	at hudson.model.AbstractProject.checkout(AbstractProject.java:1116)
	at hudson.model.AbstractBuild$AbstractRunner.checkout(AbstractBuild.java:479)
	at hudson.model.AbstractBuild$AbstractRunner.run(AbstractBuild.java:411)
	at hudson.model.Run.run(Run.java:1324)
	at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:46)
	at hudson.model.ResourceController.execute(ResourceController.java:88)
	at hudson.model.Executor.run(Executor.java:139)
Caused by: java.io.IOException: Unable to delete /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build/test/logs/userlogs/job_20101230131139886_0001/attempt_20101230131139886_0001_m_000000_0",0
"LinuxTaskController currently just writes ""export FOO=bar"" pairs into taskjvm.sh, which fails if the value has multiple words or contains a space. This is causing TestDebugScriptWithLinuxTaskController among others to fail on trunk with the following message:
{code}
export: 1: -Dhadoop.tasklog.iscleanup: bad variable name
{code}
since it generated a taskjvm.sh including the following:
{code}
export HADOOP_CLIENT_OPTS=-Dhadoop.tasklog.taskid=attempt_20110104180935141_0001_m_000001_0 -Dhadoop.tasklog.iscleanup=false -Dhadoop.tasklog.totalLogFileSize=0
{code}",0
MAPREDUCE-2224 introduced a change such that the Linux Task Controller no longer will kill descendant processes of a successful child JVM. This is causing TestKillSubProcessesWithLinuxTaskController to fail.,0
"Scenarios:
You have a cluster with 600 map slots and 3 pools.  Fairshare for each pool is 200 to start with.  Fairsharepreemption timeout is 5 mins.
1)  Pool1 schedules 300 map tasks first
2)  Pool2 then schedules another 300 map tasks
3)  Pool3 demands 300 map tasks but doesn't get any slot as all slots are taken.
4)  After 5 mins pool3 should preempt 200 map-slots.  Instead of peempting 100 slots each from pool1 and pool2, the bug would cause it to preempt all 200 slots from pool2 (last started) causing it to go below fairshare.  This is happening because the preemptTask method is not reducing the tasks left from a pool while preempting the tasks.  

The above scenario could be an extreme case but some amount of excess preemption would happen because of this bug.

The patch I created was for 0.22.0 but the code fix should work on 0.21  as well as looks like it has the same bug.",0
"In IFile.Reader.close(), we return the decompressor to the pool and then call close() on the input stream. This is backwards and causes a rare race in the case of LzopCodec, since LzopInputStream makes a few calls on the decompressor object inside close(). If another thread pulls the decompressor out of the pool and starts to use it in the meantime, the first thread's close() will cause the second thread to potentially miss pieces of data.",0
"Currently the ivy.xml file for the capacity scheduler doesn't include the commons-cli, leading to class not found exceptions.",0
"In JvmManager, when a Jvm exits, it tries to delete the workdir for {{initalContext.task}} which is null, hence throwing NPE. Currently this NPE is swallowed into the abyss.

We should catch exceptions out of the JvmRunner thread, add a test case that verifies this functionality, and fix this code to properly grab the last task.",0
"Rumen's TopologyBuilder component attempts to build up a view of a complete cluster over time by processing many jobs' history files (per discussion with Dick King).  It appears to be designed to take a greedy approach to this, pulling hostnames and rack info out of any JobHistory events that have them.

In particular, it pulls split locations out of TaskStartedEvent and hostnames out of TaskAttemptUnsuccessfulCompletionEvent (used for all task types) and TaskAttemptFinishedEvent (used only for setup and cleanup task attempts).  It omits hostnames in TaskAttemptStartedEvents produced by map attempts (perhaps intentional given the split info from TaskStartedEvents?) and in ReduceAttemptFinishedEvents (apparently unintentional).  The latter resulted in an empty topology and an ArrayIndexOutOfBoundsException in a reduce-only unit test (TestTaskPerformanceSplitTranscription modified for an upcoming feature).

I'm not sure if this is intended behavior or a bug; feel free to close if the former.  It seemed like TaskAttemptFinishedEvent might have been mistakenly believed to cover REDUCE_ATTEMPT_FINISHED.  (If so, the fix to TopologyBuilder.java is trivial.)",0
"Sometimes the testJobTrackerIntegration test fails on my Hudson. It seems the issue is that it doesn't ever wait for the first job to complete before checking its success status. Since the two jobs are in different queues, the first job may complete after the second job.",0
"I've observed the following race condition in TestFairSchedulerSystem which uses a MiniMRCluster on top of RawLocalFileSystem:
- two threads call getStagingDir at the same time
- Thread A checks fs.exists(stagingArea) and sees false
-- Calls mkdirs(stagingArea, JOB_DIR_PERMISSIONS)
--- mkdirs calls the Java mkdir API which makes the file with umask-based permissions
- Thread B runs, checks fs.exists(stagingArea) and sees true
-- checks permissions, sees the default permissions, and throws IOE
- Thread A resumes and sets correct permissions",0
"If you have any process listening on port 9001 (the default hsqldb port) then TestDataDrivenDBInputFormat will fail with:

Connection is broken: java.io.EOFException
java.sql.SQLException: Connection is broken: java.io.EOFException
        at org.hsqldb.jdbc.Util.sqlException(Unknown Source)

in the logs you see:
[Server@42704baa]: [Thread[HSQLDB Server @42704baa,5,main]]: run()/openServerSocket():
java.net.BindException: Address already in use
",0
"If we try to start the job tracker with fair scheduler using the default configuration, It is giving the below exception.


{code:xml} 
2010-07-03 10:18:27,142 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9001: starting
2010-07-03 10:18:28,037 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/linux172.site
2010-07-03 10:18:28,090 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/linux177.site
2010-07-03 10:18:40,074 ERROR org.apache.hadoop.mapred.PoolManager: Failed to reload allocations file - will use existing allocations.
java.lang.NullPointerException
at java.io.File.<init>(File.java:222)
at org.apache.hadoop.mapred.PoolManager.reloadAllocsIfNecessary(PoolManager.java:127)
at org.apache.hadoop.mapred.FairScheduler.assignTasks(FairScheduler.java:234)
at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2785)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:513)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:984)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:980)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:978)
{code} ",0
"There are some instances where opened streams are not closed, leading to a file descriptor leak.",0
"While we are trying to run hadoop archive tool in widows using this way, it is giving the below exception.

java org.apache.hadoop.tools.HadoopArchives -archiveName temp.har D:/test/in E:/temp

{code:xml} 

java.lang.NullPointerException
	at org.apache.hadoop.tools.HadoopArchives.writeTopLevelDirs(HadoopArchives.java:320)
	at org.apache.hadoop.tools.HadoopArchives.archive(HadoopArchives.java:386)
	at org.apache.hadoop.tools.HadoopArchives.run(HadoopArchives.java:725)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
	at org.apache.hadoop.tools.HadoopArchives.main(HadoopArchives.java:739)

{code} 

I see the code flow to handle this feature in windows also, 

{code:title=Path.java|borderStyle=solid}

/** Returns the parent of a path or null if at root. */
  public Path getParent() {
    String path = uri.getPath();
    int lastSlash = path.lastIndexOf('/');
    int start = hasWindowsDrive(path, true) ? 3 : 0;
    if ((path.length() == start) ||               // empty path
        (lastSlash == start && path.length() == start+1)) { // at root
      return null;
    }
    String parent;
    if (lastSlash==-1) {
      parent = CUR_DIR;
    } else {
      int end = hasWindowsDrive(path, true) ? 3 : 0;
      parent = path.substring(0, lastSlash==end?end+1:lastSlash);
    }
    return new Path(uri.getScheme(), uri.getAuthority(), parent);
  }

{code} ",0
"When security is enabled, the TT requires SecureIO JNI extensions to be available. Currently the user doesn't notice this until jobs start failing with mysterious fetch failures and exceptions spew all over the log. Instead the TT should check that the JNI library is available and fail to start if it's not.",0
"If there's a reduce task that needs more disk space than is available on any mapred.local.dir in the cluster, that task will stay pending forever. For example, we produced this in a QA cluster by accidentally running terasort with one reducer - since no mapred.local.dir had 1T free, the job remained in pending state for several days. The reason for the ""stuck"" task wasn't clear from a user perspective until we looked at the JT logs.

Probably better to just fail the job if a reduce task goes through all TTs and finds that there isn't enough space.",0
RAID BlockFixer should exclude files matching the pattern ^/tmp/.*,0
"Description:
 When launching Mapreduce application, the property *mapred.job.reuse.jvm.num.tasks* has been set to *0*, as a result the task JVM(MAP or Reduce JVM) is hanging indefinitely and finally being killed by Tasktracker.

Steps to Reproduce
------------------
1) Set the *mapred.job.reuse.jvm.num.tasks* property in mapred-site.xml to 0
2) Execute the wordcount example, child JVM is hanging indefinitely and finally killed by Tasktracker
",0
"Description:

* Submit a job to the job tracker and let the job complete its execution through one of the job client's submitJob APIs. 
* Jobclient returns a handle to the job, in the form of a RunningJob object. Client can use this object to check whether job is sucessful or whether job is completed.
* Reduce the following property *mapred.jobtracker.retirejob.interval*.By default this value is 1 day. I reduced it to 5 min.
* Set the property *mapred.job.tracker.persist.jobstatus.active* to {color:blue}*false*{color}.
* Call either isComplete or isSuccessful APIs, after *mapred.jobtracker.retirejob.interval* time period, previously mentioned APIs throw NPE.

Below I am attaching stack trace
{code:xml} 

java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobClient$NetworkedJob.isSuccessful(JobClient.java:330)
	at com.huawei.isap.hdp.mapreduce.test.TestJobClient.testjobClientForNULL(TestJobClient.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:164)
	at junit.framework.TestCase.runBare(TestCase.java:130)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:120)
	at junit.framework.TestSuite.runTest(TestSuite.java:230)
	at junit.framework.TestSuite.run(TestSuite.java:225)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
{code} 
",0
There is a deadlock while localizing resources on the TaskTracker.,0
nan,0
nan,0
"Some very small percentage of tasks fail with a ""Text file busy"" error.

The following was the original diagnosis:
{quote}
Our use of PrintWriter in TaskController.writeCommand is unsafe, since that class swallows all IO exceptions. We're not currently checking for errors, which I'm seeing result in occasional task failures with the message ""Text file busy"" - assumedly because the close() call is failing silently for some reason.
{quote}
.. but turned out to be another issue as well (see below)",0
"To reproduce, have a mapred.local.dir property set to a few directories. Before starting up the JT, set one of these directories' permission as 'd---------', and then start the JT/TT. The JT, although it tries to ignore this directory, fails with an odd and misleading message claiming that its configured address in use.

Fixing the permission clears this issue!

This was also reported in the mailing lists by Ted Yu, quite a few months ago. But I had forgotten about filing a bug for it here. Still seems to happen. A log is attached below.

{code}
2011-03-17 00:40:32,321 WARN org.apache.hadoop.mapred.JobTracker: Error starting tracker: java.io.IOException: Cannot create toBeDeleted in /home/hack/.tmplocalz/2
        at org.apache.hadoop.util.MRAsyncDiskService.<init>(MRAsyncDiskService.java:86)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2189)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2022)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:276)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:268)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4712)

2011-03-17 00:40:33,322 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2011-03-17 00:40:33,322 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2011-03-17 00:40:33,322 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2011-03-17 00:40:33,322 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2011-03-17 00:40:33,322 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-03-17 00:40:33,350 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hack
2011-03-17 00:40:33,351 FATAL org.apache.hadoop.mapred.JobTracker: java.net.BindException: Problem binding to localhost/127.0.0.1:8021 : Address already in use
        at org.apache.hadoop.ipc.Server.bind(Server.java:227)
        at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:314)
        at org.apache.hadoop.ipc.Server.<init>(Server.java:1411)
        at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:510)
        at org.apache.hadoop.ipc.RPC.getServer(RPC.java:471)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2112)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2022)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:276)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:268)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4712)
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:126)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
        at org.apache.hadoop.ipc.Server.bind(Server.java:225)
        ... 9 more

2011-03-17 00:40:33,352 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at QDuo/127.0.0.1
************************************************************/
{code}

The list conversation in context, at {{search-hadoop.com}}:
http://search-hadoop.com/m/FzN7iqreL/problem+starting+cdh3b2+jobtracker&subj=problem+starting+cdh3b2+jobtracker

I'll try to investigate and post the exact problem / solution soon.",0
"If a 'global' file is specified as a 'file' by one job - subsequent jobs cannot override this source file to be an 'archive' (until the TT cleans up it's cache or a TT restart).
The other way around as well -> 'archive' to 'file'

In case of an accidental submission using the wrong type - some of the tasks for the second job will end up seeing the source file as an archive, others as a file.",0
nan,0
nan,0
The math around the slot usage when maximum-capacity=-1 appears to be faulty.  See comments.,0
nan,0
"Until Hadoop 0.20, the JobClient was injecting the property 'group.name' on the JobConf submitted to the JobTracker.

Since Hadoop 0.21, due to security related changes, this is not done anymore.

This breaks backwards compatibility for jobs/components that expect the 'group.name' to be automatically set at submission time.

An example of a component being affected by this change is the FairScheduler where it is common to use the group.name as pool name. Different from other properties, a special characteristic of the group.name is that its value cannot be tampered by a user.

For security reasons this should not be done (as it was done before) in the JobClient side. Instead, it should be done in the JobTracker when the JobConf is received.
",0
"This is running in a Java daemon that is used as an interface (Thrift) to get information and data from MR Jobs. Using JobClient.getJob(JobID) I successfully get a RunningJob object (I'm checking for NULL), and then rarely I get an NPE when I do RunningJob.getCounters(). This seems to occur after the daemon has been up and running for a while, and in the event of an Exception, I close the JobClient, set it to NULL, and a new one should then be created on the next request for data. Yet, I still seem to be unable to fetch the Counters. Below is the stack trace.


java.lang.NullPointerException
            at org.apache.hadoop.mapred.Counters.downgrade(Counters.java:77)
            at org.apache.hadoop.mapred.JobClient$NetworkedJob.getCounters(JobClient.java:381)
            at com.telescope.HadoopThrift.service.ServiceImpl.getReportResults(ServiceImpl.java:350)
            at com.telescope.HadoopThrift.gen.HadoopThrift$Processor$getReportResults.process(HadoopThrift.java:545)
            at com.telescope.HadoopThrift.gen.HadoopThrift$Processor.process(HadoopThrift.java:421)
            at org.apache.thrift.server.TNonblockingServer$FrameBuffer.invoke(TNonblockingServer.java:697)
            at org.apache.thrift.server.THsHaServer$Invocation.run(THsHaServer.java:317)
            at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
            at java.lang.Thread.run(Thread.java:619)
",0
nan,0
"We saw an issue where a custom InputSplit was returning invalid hostnames for the splits that were then causing the JobTracker to attempt to excessively resolve host names.  This caused a major slowdown for the JobTracker.  We should prevent invalid InputSplit hostnames from affecting everyone else.

I propose we implement some verification for the hostnames to try to ensure that we only do DNS lookups on valid hostnames (and fail otherwise).  We could also fail the job after a certain number of failures in the resolve.",0
Job submission (specifically TaskTracker#localizeJobJarFile) fails if {{mapreduce.cluster.local.dir}} has a URI with a scheme (eg file:///home/eli/hadoop-dirs1/mr1) vs just the path component. MR configuration parameters should accept full URIs to be consistent with common and HDFS.,0
"The condition to stop the eventHandling thread currently requires it to be 'stopped' AND interrupted. If an interrupt arrives after a take, but before handleEvent is called - the interrupt status ends up being handled by hadoop.util.Shell.runCommand() - which ignores it (and in the process resets the flag).
The eventHandling thread subsequently hangs on eventQueue.take()
This currently randomly fails unit tests - and can hang MR AMs.",0
nan,0
"The heuristics for failing maps when we get map output fetch failures during the shuffle is pretty conservative in 20. Backport the heuristics from trunk which are more aggressive, simpler, and configurable.",0
"We are seeing many instances of the Jetty-1342 (http://jira.codehaus.org/browse/JETTY-1342). The bug doesn't cause Jetty to stop responding altogether, some fetches go through but a lot of them throw exceptions and eventually fail. The only way we have found to get the TT out of this state is to restart the TT.  This jira is to catch this particular exception (or perhaps a configurable regex) and handle it in an automated way to either blacklist or shutdown the TT after seeing it a configurable number of them.
",0
"When calling JobClient.getMapTaskReports for a retired job this results in a NPE.  In the 0.20.* version an empty TaskReport array was returned instead.

Caused by: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobClient.getMapTaskReports(JobClient.java:588)
        at org.apache.pig.tools.pigstats.JobStats.addMapReduceStatistics(JobStats.java:388)
......",0
"The race condition goes like this:
Thread1: readIndexFileToCache()  totalMemoryUsed.addAndGet(newInd.getSize())
Thread2: removeMap() totalMemoryUsed.addAndGet(-info.getSize());
When SpillRecord is being read from fileSystem, client kills the job, info.getSize() equals 0, so in fact totalMemoryUsed is not reduced, but after thread1 finished reading SpillRecord, it adds the real index size to totalMemoryUsed, which makes the value of totalMemoryUsed wrong(larger).
When this value(totalMemoryUsed) exceeds totalMemoryAllowed (this usually happens when a vary large job with vary large reduce number is killed by the user, probably because the user sets a wrong reduce number by mistake), and actually indexCache has not cache anything, freeIndexInformation() will throw exception constantly.

A quick fix for this issue is to make removeMap() do nothing, let freeIndexInformation() do this job only.
",0
"It is throwing NullPointerException in job tracker logs when job tracker is started without NameNode.

{code:title=Bar.java|borderStyle=solid}
2011-06-03 01:50:04,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.225:9000. Already tried 7 time(s).
2011-06-03 01:50:05,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.225:9000. Already tried 8 time(s).
2011-06-03 01:50:06,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.225:9000. Already tried 9 time(s).
2011-06-03 01:50:21,243 FATAL org.apache.hadoop.mapred.JobTracker: java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1635)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:287)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:279)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:274)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4312)
{code} ",0
YarnConfiguration(conf) uses the ctor Configuration(conf) which is effectively a clone. If the configuration object is created before YarnConfiguration has been loaded - yarn-site.xml will not be available to the configuration.,0
YarnConfiguration(conf) uses the ctor Configuration(conf) which is effectively a clone. If the configuration object is created before YarnConfiguration has been loaded - yarn-site.xml will not be available to the configuration.,0
"The getSplits methods of 
  org.apache.hadoop.mapred.lib.CombineFileInputFormat 
not work.

...mapred.lib.CombineFileInputFormat(0.20-style) is a proxy for ...mapreduce.lib.input.CombineFileInputFormat(0.21-style)

The 0.21-style getSplits returns ArrayList<...mapreduce.lib.input.CombineFileSplit>
and the 0.20-style delegation calls toArray(...mapred.InputSplit[])

The ...mapreduce.lib.input.CombineFileSplit is based on ...mapreduce.InputSplit
and ...mapred.InputSplit is a interface, not a super-class of ...mapreduce.InputSplit

",0
"In Gridmix high ram emulation enable by default.Because of this feature, some of the gridmix system tests are hanging for some time and then failing after timeout. Actually the failure case was occurring whenever reserved slot capacity exceeds the cluster slot capacity.So for fixing the issue by disabling the high ram emulation in the tests which are using the normal mr jobs in the traces.",0
"A 0 map, 0 reduce job fails with an NPE. This case works fine on hadoop-0.20.x. The job should succeed and run setup/cleanup code - with no tasks.  Below is the stacktrace:

11/06/05 19:35:37 WARN mapred.ClientServiceDelegate:
 StackTrace: java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getTaskAttemptCompletionEvents(JobImpl.java:498)
        at
org.apache.hadoop.mapreduce.v2.app.client.MRClientService$MRClientProtocolHandler.getTaskAttemptCompletionEvents(MRClientService.java:290)
        at
org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBServiceImpl.java:139)
        at
org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:195)
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$TunnelResponder.call(ProtoOverHadoopRpcEngine.java:168)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:420)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1406)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1402)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1094)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1400)",0
"Running the following example hangs the child job indefinitely.

public class HaltCluster
{

  public static void main(String[] args) throws IOException
  {
    JobConf jobConf = new JobConf();
    prepareConf(jobConf);
    if (args != null && args.length > 0)
    {
      jobConf.set(""callonceagain"", args[0]);
      jobConf.setMaxMapAttempts(1);
      jobConf.setJobName(""ParentJob"");

    }
    JobClient.runJob(jobConf);

  }

  public static void prepareConf(JobConf jobConf)
  {
    jobConf.setJarByClass(HaltCluster.class);
    jobConf.set(""mapred.job.tracker"", ""<<jobtracker>>"");
    jobConf.set(""fs.default.name"", ""<<hdfs>>"");
    MultipleInputs.addInputPath(jobConf, new Path(""/ignore"" + System.currentTimeMillis()), MyInputFormat.class);
    jobConf.setJobName(""ChildJob"");
    jobConf.setMapperClass(MyMapper.class);
    jobConf.setOutputFormat(NullOutputFormat.class);
    jobConf.setNumReduceTasks(0);
  }

}

public class MyMapper implements Mapper<IntWritable, Text, NullWritable, NullWritable>
{
  JobConf myConf = null;

  @Override
  public void map(IntWritable arg0, Text arg1, OutputCollector<NullWritable, NullWritable> arg2, Reporter arg3) throws IOException
  {
    if (myConf != null && ""true"".equals(myConf.get(""callonceagain"")))
    {
      startBackGroundReporting(arg3);
      HaltCluster.main(new String[] {});
    }

    throw new RuntimeException(""Throwing exception"");
  }

  private void startBackGroundReporting(final Reporter arg3)
  {
    Thread t = new Thread()
    {
      @Override
      public void run()
      {
        while (true)
        {
          arg3.setStatus(""Reporting to be alive at "" + System.currentTimeMillis());
        }
      }
    };
    t.setDaemon(true);
    t.start();
  }

  @Override
  public void configure(JobConf arg0)
  {
    myConf = arg0;

  }

  @Override
  public void close() throws IOException
  {
    // TODO Auto-generated method stub

  }

}

run using the following command

java -cp <<classpath>> HaltCluster true

But if only one job is triggered as java -cp <<classpath>> HaltCluster
it fails to max number of attempts and quits as expected.


Also, when the jobs hang, running the child job once again, makes it come out of deadlock and completes the three jobs.

",0
"If the yarn configuration does not explicitly specify a value for the yarn.server.nodemanager.log.dir property, container allocation will fail on the NodeManager w/an NPE when the LocalDirAllocator goes to create the temp directory. In most of the code, we handle this by defaulting to /tmp/logs, but we cannot do this in the LocalDirAllocator context, so we need to set the default value explicitly in the Configuration.

Marking this as major b/c it's annoying to bump into it when you're getting your first MRv2 cluster up and running. :)",0
Currently AM can assign a container given by RM to any map or reduce. However RM allocates for a particular priority. This leads to AM and RM data structures going out of sync.,0
"Dev had seen the attempt directory permission getting set to 000 or 111 in the CI builds and tests run on dev desktops with 0.20-security.
MAPREDUCE-2238 reported and fixed the issue for 0.22.0, back-port to 0.20-security is needed.
",0
There is a rare race condition in linux task controller when concurrent task processes tries to create job log directory at the same time. ,0
"Currently in MR-279 the Auxiliary services, like ShuffleHandler, have no way to communicate information back to the applications.  Because of this the Map Reduce Application Master has hardcoded in a port of 8080 for shuffle.  This prevents the configuration ""mapreduce.shuffle.port"" form ever being set to anything but 8080.  The code should be updated to allow this information to be returned to the application master.  Also the data needs to be persisted to the task log so that on restart the data is not lost.",0
nan,0
"Following the installation instructions at: https://svn.apache.org/repos/asf/hadoop/common/branches/MR-279/mapreduce/INSTALL
the randomwriter example runs successfully. However, other full map & reduce jobs (e.g. wordcount) fail with the error:

java.lang.UnsupportedOperationException: Incompatible with LocalRunner
	at org.apache.hadoop.mapred.YarnOutputFiles.getInputFile(YarnOutputFiles.java:200)
	at org.apache.hadoop.mapred.ReduceTask.getMapFiles(ReduceTask.java:223)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:412)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1094)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:143)

The ReduceTask evaluates the isLocal flag based on the property ""mapreduce.jobtracker.address"", the default value for this property in mapred-default.xml is 'local' and this is the cause of the problem.

Setting ""mapreduce.jobtracker.address"" in the mapred-site.xml to something other than ""local"" seems to solve the problem. ",0
"In branch MR-279, org.apache.hadoop.mapred.getSplits() throws RuntimeException:ArrayStoreException 

The following code in trunk:
{noformat}
  public InputSplit[] getSplits(JobConf job, int numSplits) 
    throws IOException {
    List<org.apache.hadoop.mapreduce.InputSplit> newStyleSplits =
      super.getSplits(new Job(job));
    InputSplit[] ret = new InputSplit[newStyleSplits.size()];
    for(int pos = 0; pos < newStyleSplits.size(); ++pos) {
      org.apache.hadoop.mapreduce.lib.input.CombineFileSplit newStyleSplit = 
        (org.apache.hadoop.mapreduce.lib.input.CombineFileSplit) newStyleSplits.get(pos);
      ret[pos] = new CombineFileSplit(job, newStyleSplit.getPaths(),
        newStyleSplit.getStartOffsets(), newStyleSplit.getLengths(),
        newStyleSplit.getLocations());
    }
    return ret;
  }
{noformat}

got changed to

{noformat}
  public InputSplit[] getSplits(JobConf job, int numSplits) 
    throws IOException {
    return super.getSplits(new Job(job)).toArray(new InputSplit[0]);
  }
{noformat}

Code in trunk works fine. We should change the code in MR-279 to the same in trunk.",0
nan,0
"the mapred job -kill command doesn't seem to fully clean up the application.

If you kill a job and run mapred job -list again it still shows up as running:

mapred job -kill job_1310072430717_0003
Killed job job_1310072430717_0003

 mapred job -list
Total jobs:1
JobId   State   StartTime       UserName        Queue   Priority        SchedulingInfo
job_1310072430717_0003  RUNNING 0       tgraves default NORMAL  98.139.92.22:19888/yarn/job/job_1310072430717_3_3

Running kill again will error out.

It also still shows up in the RM Applications UI as running with a note of: Kill Job received from client
job_1310072430717_0003 Job received Kill while in RUNNING state.",0
"If mapreduce.reduce.input.limit is mis-configured or if a cluster is just running low on disk space in general then reduces with large a input may never get scheduled causing the Job to never fail and never succeed, just starve until the job is killed.

The JobInProgess tries to guess at the size of the input to all reducers in a job.  If the size is over mapreduce.reduce.input.limit then the job is killed.  If it is not then findNewReduceTask() checks to see if the estimated size is too big to fit on the node currently looking for work.  If it is not then it will let some other task have a chance at the slot.

The idea is to keep track of how often it happens that a Reduce Slot is rejected because of the lack of space vs how often it succeeds and then guess if the reduce tasks will ever be scheduled.

So I would like some feedback on this.

1) How should we guess.  Someone who found the bug here suggested P1 + (P2 * S), where S is the number of successful assignments.  Possibly P1 = 20 and P2 = 2.0.  I am not really sure.
2) What should we do when we guess that it will never get a slot?  Should we fail the job or do we say, even though it might fail, well lets just schedule the it and see if it really will fail.",0
"Apps of non superuser fail to succeed in both secure and non-secure environment. Only the superuser(i.e. one who started/owns the mrv2 cluster) is able to launch apps successfully. However, when a normal user submits a job, the job fails.",0
"The following exception in AM of an application at the top of queue causes this. Once this happens, AM keeps obtaining
containers from RM and simply loses them. Eventually on a cluster with multiple jobs, no more scheduling happens
because of these lost containers.

It happens when there are blacklisted nodes at the app level in AM. A bug in AM
(RMContainerRequestor.containerFailedOnHost(hostName)) is causing this - nodes are simply getting removed from the
request-table. We should make sure RM also knows about this update.

========================================================================
11/06/17 06:11:18 INFO rm.RMContainerAllocator: Assigned based on host match 98.138.163.34
11/06/17 06:11:18 INFO rm.RMContainerRequestor: BEFORE decResourceRequest: applicationId=30 priority=20
resourceName=... numContainers=4978 #asks=5
11/06/17 06:11:18 INFO rm.RMContainerRequestor: AFTER decResourceRequest: applicationId=30 priority=20
resourceName=... numContainers=4977 #asks=5
11/06/17 06:11:18 INFO rm.RMContainerRequestor: BEFORE decResourceRequest: applicationId=30 priority=20
resourceName=... numContainers=1540 #asks=5
11/06/17 06:11:18 INFO rm.RMContainerRequestor: AFTER decResourceRequest: applicationId=30 priority=20
resourceName=... numContainers=1539 #asks=6
11/06/17 06:11:18 ERROR rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.decResourceRequest(RMContainerRequestor.java:246)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.decContainerReq(RMContainerRequestor.java:198)
        at
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(RMContainerAllocator.java:523)
        at
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.access$200(RMContainerAllocator.java:433)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:151)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:220)
        at java.lang.Thread.run(Thread.java:619)",0
"CombineFileInputFormat constructs new Path objects by converting an existing path to a URI, and then only pulling out the ""path"" part of it. This drops the scheme and host, which makes CombineFileInputFormat fail if the paths are on a filesystem other than the default one.",0
"ProtoOverHadoopRpcEngine is introduced in MR-279, which uses TunnelProtocol over WritableRpcEngine. This jira removes the tunnel protocol and lets ProtoOverHadoopRpcEngine directly interact with ipc.Client and ipc.Server.",0
{{DFSClient.stringifyToken(..)}} was removed by HDFS-2161.  {{JobSubmitter.printTokens(..)}} won't be compiled.,0
{{TestBlockPlacementPolicyRaid}} access internal {{FSNamesystem}} directly.  It cannot be compiled after HDFS-2147.,0
"After MAPREDUCE-130, the job's conf copy will be deleted from the log directory of the JobTracker when the job is retired. However, it just works if the job is retired by _RetireJobs_ thread of JobTracker. If a job is retired by the same user's another job, its conf copy will not be deleted. This kind of retire happens in _JobTracker::finalizeJob(job)_, when JobTracker maintains more than _MAX_COMPLETE_USER_JOBS_IN_MEMORY_ jobs information in memory for a given user.",0
nan,0
"When the count is 0 for mappers or reducers, a divide-by-zero exception is thrown.  There are existing checks to error out when count < 0, which obviously doesn't handle the 0 case.  This is causing the MRReliabilityTest to fail.",0
When an application finishes it should be added to an application summary log for historical purposes.  jira MAPREDUCE-2649 is going to start purging applications from RM when certain limits are hit which makes this more critical. We also need to save the information early enough after the app finishes so we don't lose the info if the RM does get restarted.,0
"Right now none of the tokens and secret-keys have an expiry interval. This needs to be fixed.
This ticket should also handle how to renew the tickets when necessary.",0
"Because of this problem, till now, we've been testing YARN+MR with hadoop.security.authorization set to false. We need to register yarn communication protocols in the implementation of the authorization related PolicyProvider (MapReducePolicyProvider.java).
Devaraj Das also found this issue independently.",0
"This is similar to [MAPREDUCE-103] . We should pass a whitelisted set of environment variables from NM env to the container. By default, we should pass HADOOP_* variables. This can be a simple configuration key that NodeManager reads.

Today, we already either pass the following correctly or assume that it works but doesn't
 - YARN_HOME: ContainerLaunch#writeLaunchEnv
 - HADOOP_CLIENT_OPTS: MapReduceChildJVM#setVMEnv
 - JAVA_HOME: TaskAttemptImpl#createContainerLaunchContext - Works by shell-expansion.
 - LD_LIBRARY_PATH: Assumed to work via shell-expansion but doesn't.",0
"There is absolutely no need for NM to start ContainerManager on a standard port, it should bind to an ephemeral port. Binding on ephemeral ports will help us start multiple NMs on a single node without any issues.

The same holds for the ResourceLocalizationService's server port and NM Http server's port. ",0
"This ticket is about app-only files which should be cleaned after app-finish.

I see these undeleted after app-finish:
/tmp/nm-local-dir/0/nmPrivate/application_1305091029545_0001/*
/tmp/nm-local-dir/0/nmPrivate/container_1305019205843_0001_000002/*
/tmp/nm-local-dir/0/usercache/nobody/appcache/application_1305091029545_0001/*

We should check for other left-over files too, if any.",0
"If you run a pig job with UDFs that has not been recompiled for MRV2.  There are situations where pig will fail with an error message stating that Hadoop failed and did not give a reason.  There is even the possibility of deadlock if an Error is thrown and the JobControl thread dies.
",0
"After MAPREDUCE-2178, TaskController assumes that pids are always available. The shell executor object that's used to launch a JVM isn't retained, but rather the pid is set when the task heartbeats. On Windows, there are no pids, and since the ShellCommandExecutor object is no longer around, we can't call process.destroy(). So, the TaskController doesn't work on Cygwin anymore.",0
"The files created under the staging dir have to be deleted after job completion. Currently, all job.* files remain forever in the ${yarn.apps.stagingDir}",0
"There's a potential security hole in the task-controller as it stands. Based on the discussion on general@, removing task-controller from the 0.22 branch will pave way for 0.22.0 release. (This was done for the 0.21.0 release as well: see MAPREDUCE-2014.) We can roll a 0.22.1 release with the task-controller when it is fixed.",0
A Nodemanager which is decommissioned by an admin via refreshnodes does not automatically shutdown. ,0
nan,0
"We use cascading MultiInputFormat. MultiInputFormat sometimes generates big job.split used internally by hadoop, sometimes it can go beyond 2GB.

In JobSplitWriter.java, the function that generates such file uses 32bit signed integer to compute offset into job.split.


writeNewSplits
...
        int prevCount = out.size();
...
        int currCount = out.size();

writeOldSplits
...
      long offset = out.size();
...
      int currLen = out.size();
",0
"The job history/application tracking url handling during kill is not consistent. Currently if you kill a job that was running the tracking url points to job history, but job history server doesn't have the job.  ",0
The assignContainer() method in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue can cause the scheduler to crash if the ResourseRequest capability memory == 0 (divide by zero).,0
"Currently, all the logs, UI, CLI have IP addresses of the NM/RM, which are difficult to manage. It will be useful to have hostnames like in 0.20.x for easier debugging and maintenance purpose. ",0
"AvailableGB per queue is not the same as AvailableGB per queue per user when the user limit is set to 100%.
i.e. if the total available GB of the cluster is 60, and queue ""default"" has 92% capacity with 100% as the user limit, AvailableGB per queue default = 55 (i.e. 0.92*60) whereas AvailableGB per queue for user ramya is 56 (however it should be 55 = 0.92*60*1) 

Also, unlike the AvailableGB/queue, AvailableGB/queue/user is not decremented when user ramya is running apps on the ""default"" queue.",0
"The start time for all the apps in the output of ""job -list"" is set to 0",0
"When the Load job's tasks are emulating cpu/memory, the task-tracker kills the emulating task due to lack of status updates. Load job has its own status reporter which dies too soon.",0
"The type check like:
if (key.getClass() != keyClass)
        throw new IOException(""wrong key class: ""+key.getClass().getName()
                              +"" is not ""+keyClass);
if (val.getClass() != valClass)
        throw new IOException(""wrong value class: ""+val.getClass().getName()
                              +"" is not ""+valClass);
is used a lot when a type check is needed. 
I found their uses in org.apache.hadoop.io.SequenceFile, org.apache.hadoop.mapred.IFile, org.apache.hadoop.mapred.MapTask. Because i search with(key.getClass() != keyClass), so these codes may also appear in other classes.
I suggest we can relax the strict type check by using 
if (key.getClass().isAssignableFrom(keyClass))
The error in my situation is listed below:
java.io.IOException: Type mismatch in value from map: expected cn.ac.ict.vega.type.Type, recieved cn.ac.ict.vega.type.Type$Float
at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:553)
at cn.ac.ict.vega.parse.mapreduce.block.FilterColumnBlockMapper.map(FilterColumnBlockMapper.java:77)
at cn.ac.ict.vega.parse.mapreduce.block.BlockMapRunner.run(BlockMapRunner.java:33)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:332)
at org.apache.hadoop.mapred.Child.main(Child.java:155)
Float is a sub class of Type. I wish it can pass the check. I use Type instead of Float is because i can not determint exactly whether it is Float, String or some others.",0
"In some environments, it might be desirable to explicitly specify the fair scheduler pools and to explicitly fail jobs that are not submitted to any of the pools. 
Current behavior of the fair scheduler is to submit jobs to a default pool if a pool name isn't specified or to create a pool with the new name if the pool name doesn't already exist. There should be a configuration option for the fair scheduler that causes it to noisily fail the job if it's submitted to a pool that isn't pre-specified or if the specified pool doesn't exist.",0
"After upgrading our test 0.20.203 grid to 0.20.204-rc2, we ran terasort to verify operation.  While the job completed successfully, approx 10% of the tasks failed with task runner execution errors and the inability to create symlinks for attempt logs.",0
"In MRv2, while the system servers (ResourceManager (RM), NodeManager (NM) and NameNode (NN)) run as ""trusted""
system users, the application masters (AM) run as users who submit the application. While this offers great flexibility
to run multiple version of mapreduce frameworks (including their UI) on the same Hadoop cluster, it has significant
implication for the security of webapps (Please do not discuss company specific vulnerabilities here).
Requirements:
Secure authentication for AM (for app/job level ACLs).
Webapp security should be optional via site configuration.
Support existing pluggable single sign on mechanisms.
Should not require per app/user configuration for deployment.
Should not require special site-wide DNS configuration for deployment.
This the top jira for webapp security. A design doc/notes of threat-modeling and counter measures will be posted on the wiki.",0
"Hi, we met the infinite loop on CombineFileInputFormat#getMoreSplits().

At first, we lost some blocks by mis-operation :-(. Then, one job tried to use these missing blocks. At that time getMoreSplits() goes into the infinite loop.

From our investigation, this List could be an empty array.
> https://github.com/apache/hadoop-mapreduce/blob/trunk/src/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java#L363

Then 'for' loop just after that line does nothing, and entry is not removed from 'blockToNodes'.

Finally this line goes into the infinite loop.
> https://github.com/apache/hadoop-mapreduce/blob/trunk/src/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java#L348

We're now creating the patch against this problem...",0
"[ivy:resolve] 	found com.cenqua.clover#clover;3.0.2 in fs
[ivy:resolve] 
[ivy:resolve] :: problems summary ::
[ivy:resolve] :::: ERRORS
[ivy:resolve] 	impossible to get artifacts when data has not been loaded. IvyNode = log4j#log4j;1.2.16
[ivy:resolve] 
[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS

BUILD FAILED
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/build.xml:451: The following error occurred while executing this line:
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/src/contrib/build.xml:30: The following error occurred while executing this line:
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/src/contrib/build-contrib.xml:511: impossible to resolve dependencies:
	java.lang.IllegalStateException: impossible to get artifacts when data has not been loaded. IvyNode = log4j#log4j;1.2.16
",0
"We encountered a situation where in the same cluster, large jobs benefit from mapred.fairscheduler.assignmultiple, but small jobs with small numbers of mappers do not: the mappers all clump to fully occupy just a few nodes, which causes those nodes to saturate and bottleneck. The desired behavior is to spread the job across more nodes so that a relatively small job doesn't saturate any node in the cluster.

Testing has shown that setting mapred.fairscheduler.assignmultiple to false gives the desired behavior for small jobs, but is unnecessary for large jobs. However, since this is a cluster-wide setting, we can't properly tune.

It'd be nice if jobs can set a param similar to mapred.fairscheduler.assignmultiple on submission to better control the task distribution of a particular job.",0
"When a job is submitted, LinuxTaskController launches the native task-controller binary for job initialization. The native program does a series of prep work and call execv() to run JobLocalizer.  It was observed that JobLocalizer does fails to run when JniBasedUnixGroupsNetgroupMapping or JniBasedUnixGroupsMapping is enabled, resulting in 100% job failures.

JobLocalizer normally does not need the native library (libhadoop) for its functioning, but enabling a JNI user-to-group mapping function cause it to load the library. However, JobLocalizer cannot locate the library since ""java.library.path"" is not set.

The proposed solution is to pass the java.library.path property through task-controller. LinuxTaskController already does it when launching the task log truncater.",0
"Saw a corner case in container reservations where the node on which the AM is running was reserved, and hence never fulfilled leaving the application hanging.",0
"This below message is coming continuously on the console.

{code:xml}
11/09/02 16:00:00 INFO mapred.ClientServiceDelegate: Failed to contact AM for job job_1314955256658_0009  Will retry..
11/09/02 16:00:00 INFO mapred.ClientServiceDelegate: Application state is completed. Redirecting to job history server null
11/09/02 16:00:00 INFO mapred.ClientServiceDelegate: Failed to contact AM for job job_1314955256658_0009  Will retry..
11/09/02 16:00:00 INFO mapred.ClientServiceDelegate: Application state is completed. Redirecting to job history server null
{code}
",0
CompletedJob.isUber on the MR-279 branch returns jobInfo.getIsUber() but got turned into an exception when MR-279 was merged to trunk. SVN Revision 1159166.,0
"Per the implementation of the TaskTracker instrumentation plugin implementation (from 2008), a ClassNotFoundException during loading up of an configured TaskTracker instrumentation class shouldn't have hampered TT start up at all.

But, there is one class-fetching call outside try/catch, which makes TT fall down with a RuntimeException if there's a class not found. Would be good to include this line into the try/catch itself.

Strace would appear as:

{code}
2011-08-25 11:45:38,470 ERROR org.apache.hadoop.mapred.TaskTracker: Can not start task tracker because java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: org.apache.hadoop.mapred.CustomInstPlugin 
at org.apache.hadoop.conf.Configuration.getClass(Configuration.java) 
at org.apache.hadoop.mapred.TaskTracker.getInstrumentationClass(TaskTracker.java) 
at org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java) 
{code}",0
"This is failing right after the MAPREDUCE-2655 commit, but Jenkins did report a success when that patch was submitted.

{code}
Standard Output

2011-09-07 07:12:52,785 INFO  ipc.Server (Server.java:run(349)) - Starting Socket Reader #1 for port 33000
2011-09-07 07:12:52,787 INFO  ipc.Server (WritableRpcEngine.java:registerProtocolAndImpl(399)) - ProtocolImpl=org.apache.hadoop.yarn.server.nodemanager.TestNMAuditLogger$MyTestRPCServer protocolClass=org.apache.hadoop.yarn.server.nodemanager.TestNMAuditLogger$MyTestRPCServer version=1
2011-09-07 07:12:52,788 INFO  ipc.Server (Server.java:run(642)) - IPC Server Responder: starting
2011-09-07 07:12:52,788 INFO  ipc.Server (Server.java:run(473)) - IPC Server listener on 33000: starting
2011-09-07 07:12:52,788 INFO  ipc.Server (Server.java:run(1459)) - IPC Server handler 0 on 33000: starting
2011-09-07 07:12:52,798 INFO  ipc.Server (Server.java:run(1497)) - IPC Server handler 0 on 33000, call: ping(), rpc version=2, client version=1, methodsFingerPrint=-1968962669 from 67.195.138.31:33806, error: 
java.io.IOException: java.io.IOException: Unknown protocol: org.apache.hadoop.ipc.TestRPC$TestProtocol
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:622)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)
{code}",0
"[~karams](the great man the world hardly knows about) found lots of failing tasks while running sort on a 350 node cluster. The failed tasks eventually failed the job and this happening consistently on the big cluster.
{quote}
Container launch failed for container_1315410418107_0002_01_002511 : RemoteTrace: java.lang.IllegalArgumentException at java.nio.Buffer.position(Buffer.java:218) at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:129) at java.nio.ByteBuffer.get(ByteBuffer.java:675) at com.google.protobuf.ByteString.copyFrom(ByteString.java:108) at com.google.protobuf.ByteString.copyFrom(ByteString.java:117) at org.apache.hadoop.yarn.util.ProtoUtils.convertToProtoFormat(ProtoUtils.java:97) at org.apache.hadoop.yarn.api.records.ProtoBase.convertToProtoFormat(ProtoBase.java:59) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.access$100(StartContainerResponsePBImpl.java:35) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl$1$1.next(StartContainerResponsePBImpl.java:134) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl$1$1.next(StartContainerResponsePBImpl.java:122) at com.google.protobuf.AbstractMessageLite$Builder.addAll(AbstractMessageLite.java:319) at org.apache.hadoop.yarn.proto.YarnServiceProtos$StartContainerResponseProto$Builder.addAllServiceResponse(YarnServiceProtos.java:12620) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.addServiceResponseToProto(StartContainerResponsePBImpl.java:144) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.mergeLocalToBuilder(StartContainerResponsePBImpl.java:60) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.mergeLocalToProto(StartContainerResponsePBImpl.java:68) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.getProto(StartContainerResponsePBImpl.java:52) at org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagerPBServiceImpl.startContainer(ContainerManagerPBServiceImpl.java:69) at org.apache.hadoop.yarn.proto.ContainerManager$ContainerManagerService$2.callBlockingMethod(ContainerManager.java:83) at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:337) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1496) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1492) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1490) at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:151) at $Proxy20.startContainer(Unknown Source) at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:81) at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:215) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:619) 
{quote}",0
"When a service startup fails at the Nodemanager, the Nodemanager JVM doesnot exit as the following threads are still running.

Daemon Thread [Timer for 'NodeManager' metrics system] (Running)	
Thread [pool-1-thread-1] (Running)	
Thread [Thread-11] (Running)	
Thread [DestroyJavaVM] (Running).

As a result, the NodeManager keeps running even though no services are started.",0
"When Container crashes, the reason for failures isn't propagated because of a bug in _RMAppAttemptImpl.AMContainerCrashedTransition_ which simply discards the diagnostics of the container. Also RMAppAttemptImpl.diagnostics is never consumed.",0
"[~Karams] ran into this multiple times. MR JobClient crashes immediately.

{code}
11/09/08 10:52:35 INFO mapreduce.JobSubmitter: number of splits:2094
11/09/08 10:52:36 INFO mapred.YARNRunner: AppMaster capability = memory: 2048,
11/09/08 10:52:36 INFO mapred.YARNRunner: Command to launch container for ApplicationMaster is : $JAVA_HOME/bin/java -Dhadoop.root.logger=INFO,console -Xmx1536m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1315478927026 1 <FAILCOUNT> 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr
11/09/08 10:52:36 INFO mapred.ResourceMgrDelegate: Submitted application application_1315478927026_1 to ResourceManager
11/09/08 10:52:36 INFO mapreduce.JobSubmitter: Cleaning up the staging area /user/gridperf/.staging/job_1315478927026_0001
RemoteTrace:
 at Local Trace:
        org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: failed to run job
        at org.apache.hadoop.yarn.factories.impl.pb.YarnRemoteExceptionFactoryPBImpl.createYarnRemoteException(YarnRemoteExceptionFactoryPBImpl.java:39)
        at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:47)
        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:250)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:377)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1072)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1069)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1069)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1089)
        at org.apache.hadoop.examples.RandomWriter.run(RandomWriter.java:283)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.examples.RandomWriter.main(RandomWriter.java:294)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
}
{code}

The client crashes due to a race in RM.

Because the client fails, it immediately removes the staged files which in turn makes the MR AM itself to crash due to failed localization on the NM.",0
"Found this:
{code}
Java stack information for the threads listed above:
===================================================
""Thread-45"":
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.getApplicationId(ApplicationAttemptIdPBImpl.java:101)
        - waiting to lock <0xb6a43ba0> (a org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl)
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.compareTo(ApplicationAttemptIdPBImpl.java:144)
        - locked <0xb6a443a0> (a org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl)
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.compareTo(ApplicationAttemptIdPBImpl.java:31)
        at org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl.compareTo(ContainerIdPBImpl.java:215)
        at org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl.compareTo(ContainerIdPBImpl.java:34)
        at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:797)
        at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1640)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:360)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:355)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:113)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:619)
""Thread-30"":
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.getApplicationId(ApplicationAttemptIdPBImpl.java:101)
        - waiting to lock <0xb6a443a0> (a org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl)
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.compareTo(ApplicationAttemptIdPBImpl.java:144)
        - locked <0xb6a43ba0> (a org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl)
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.compareTo(ApplicationAttemptIdPBImpl.java:31)
        at org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl.compareTo(ContainerIdPBImpl.java:215)
        at org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl.compareTo(ContainerIdPBImpl.java:34)
        at java.util.concurrent.ConcurrentSkipListMap.doRemove(ConcurrentSkipListMap.java:1078)
        at java.util.concurrent.ConcurrentSkipListMap.remove(ConcurrentSkipListMap.java:1673)
        at java.util.concurrent.ConcurrentSkipListMap$Iter.remove(ConcurrentSkipListMap.java:2256)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getNodeStatus(NodeStatusUpdaterImpl.java:223)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.access$300(NodeStatusUpdaterImpl.java:62)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl$1.run(NodeStatusUpdaterImpl.java:262)
Found 1 deadlock.
{code}",0
Right now if one of the services fails to stop in the CompositeServices it just quits.  It should continue and try to stop all the services so it shuts down as clean as possible.,0
nan,0
"I have been running wordcount out of the 23 examples jar.  It says it succeeds but doesn't actually output a file.

hadoop jar examples/hadoop-mapreduce-0.23.0-SNAPSHOT/hadoop-mapreduce-examples-0.23.0-SNAPSHOT.jar wordcount input output2

input file is really basic:
fdksajl
dlkfsajlfljda;j
kldfsjallj
test
one
two
test",0
TestMRJobs is hanging waiting to connect to history server. I will post the logs next.,0
"{noformat}
compile-mapred-test:
    [mkdir] Created dir: /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/build/test/mapred/classes
....
  [javac] found   : org.apache.hadoop.mapred.IFile.Writer
    [javac] required: org.apache.hadoop.mapred.IFile.Writer<java.lang.String,java.lang.Integer>
    [javac]     Writer<String, Integer> mockWriter = mock(Writer.class);
    [javac]                                              ^
    [javac] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestCombineOutputCollector.java:128: warning: [unchecked] unchecked conversion
    [javac] found   : org.apache.hadoop.mapred.IFile.Writer
    [javac] required: org.apache.hadoop.mapred.IFile.Writer<java.lang.String,java.lang.Integer>
    [javac]     Writer<String, Integer> mockWriter = mock(Writer.class);
    [javac]                                              ^
    [javac] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestJvmManager.java:63: unreported exception java.io.IOException; must be caught or declared to be thrown
    [javac]     FileUtil.fullyDelete(TEST_DIR);
    [javac]                         ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 1 error
    [javac] 2 warnings

BUILD FAILED
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/build.xml:538: The following error occurred while executing this line:
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/build.xml:615: Compile failed; see the compiler error output for details.

{noformat}",0
"If mapreduce.framework.name property is not set in mapred-site.xml, Null pointer Exception is thrown.

java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.Cluster$1.run(Cluster.java:133)
	at org.apache.hadoop.mapreduce.Cluster$1.run(Cluster.java:1)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:131)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1067)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1089)
	at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:189)",0
"Running the ant target in the hadoop-mapreduce-project directory fails with:

[jsp-compile] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
    [javac] /home/tgraves/branch23/branch-0.23/hadoop-mapreduce-project/build.xml:398: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 50 source files to /home/tgraves/branch23/branch-0.23/hadoop-mapreduce-project/build/classes
    [javac] /home/tgraves/branch23/branch-0.23/hadoop-mapreduce-project/src/java/org/apache/hadoop/mapred/JobQueueClient.java:189: displayJobList(org.apache.hadoop.mapreduce.JobStatus[]) has protected access in org.apache.hadoop.mapreduce.tools.CLI
    [javac]       jc.displayJobList(jobs);
    [javac]         ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 1 error",0
"We use the capacity scheduler to enable jobs with large memory requirements to be run on our cluster. The individual tasks have a large initial overhead when they load cached data. Using the JVM reuse option ({{mapred.job.reuse.jvm.num.tasks}}) and by caching data in a static variable we can reduce the overhead. 

The current {{JvmManager}} implementation will prefer creating new JVMs to reusing existing ones if the number of already created JVMs is less than the maximum. In the extreme case where the capacity scheduler is used to limit the number of tasks on a node to 1, but the number of [map|reduce] tasks per node is set to say 16, then 16 JVMs will be created before one of them is reused. Obviously, if the amount of cached data in the memory of each JVM is large, then node can rapidly run out of memory! What should really happen in this case is that the first created JVM should be reused, and others should not be spawned.

To work-around this problem on our cluster, we have modified the logic in the {{reapJVM()}} method in {{JvmManager}} to prefer to reuse an existing JVM (idle & belonging to the same job) over starting a new JVM, or killing an existing idle JVM.

",0
MAPREDUCE-2937 accidentally changes ResourceMgrDelegate so that it does not pick up yarn-site.xml as a default resource. Will upload patch.,0
The JobTracker currently manages tokens for the applications and the resource manager needs the same functionality.,0
"It seems that hudson is not properly reporting findbug failures introduced by jiras. 

Here is an example where hudson gave the jira a +1 for findbugs but it really introduced a bug:
https://issues.apache.org/jira/browse/MAPREDUCE-2937

The actual findbugs report - you'll see there is 1:
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/662//artifact/trunk/hadoop-mapreduce-project/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-client-jobclient.html

Note that I had to enter in the extra path of hadoop-mapreduce-project to see the html file so perhaps the path it is using to do the diff is wrong.",0
"ClientProtocolProvider configuration exists under the job-client and core modules. It's really only required in job-client. The version in core points to JobTrackerClientProtocolProvider which causes

java.util.ServiceConfigurationError: org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider: Provider org.apache.hadoop.mapred.JobTrackerClientProtocolProvider not found
        at java.util.ServiceLoader.fail(ServiceLoader.java:214)
        at java.util.ServiceLoader.access$400(ServiceLoader.java:164)
        at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:350)
        at java.util.ServiceLoader$1.next(ServiceLoader.java:421)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:73)
        at org.apache.hadoop.mapreduce.Job.<init>(Job.java:133)
        at org.apache.hadoop.mapreduce.Job.<init>(Job.java:138)
        at org.apache.hadoop.examples.WordCount.main(WordCount.java:75)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)",0
"A lot of improvements have been made to the fair scheduler in 0.21, 0.22 and trunk, but have not been ported back to the new 0.20.20X releases that are currently considered the stable branch of Hadoop.",0
"{code:xml}
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.yarn.api.records.ContainerId.compareTo(ContainerId.java:97)
	at org.apache.hadoop.yarn.api.records.ContainerId.compareTo(ContainerId.java:23)
	at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:819)
	at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1640)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerPage$ContainerBlock.render(ContainerPage.java:70)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:64)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
	at org.apache.hadoop.yarn.webapp.View.render(View.java:210)
{code}

{code:xml}
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerPage$ContainerBlock.render(ContainerPage.java:71)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:64)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
	at org.apache.hadoop.yarn.webapp.View.render(View.java:210)
	at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:47)
	at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)
	at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:843)
	at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:54)
	at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:80)
	at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:210)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.NMController.container(NMController.java:62)
	... 30 more
{code}
",0
"All the pages of the UI, currently show ""Logged in as: null"" instead of the correct username",0
TestLinuxContainerExecutor is currently disabled completely.,0
"AM tries to launch containers on a faulty node which blocks several/all of the {{StartContainer}} requests. Eventually, RM expires the container-allocations, informs the AM about container-expiry. But AM crashes with an INTERNAL_ERROR as the event is unexpected.
{code}
11/09/12 14:11:38 ERROR impl.TaskAttemptImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_CONTAINER_COMPLETED at ASSIGNED
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:297)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:39)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:439)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:903)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:127)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:543)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:536)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:113)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:619)
{code}

Found this on a big cluster where [~karams] was trying to get sort running.",0
"Exception found on the AM web UI while the application is running:
{code}
Container launch failed for container_1315908079531_0002_01_000387 : java.lang.NullPointerException
  at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:162)
  at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:204)
  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
  at java.lang.Thread.run(Thread.java:619) 
{code}",0
"I am getting an exception frequently when running my jobs on a single-node cluster.  It happens with basically any job I run: sometimes the job will work, but most of the time I get this exception (in this case, I was running a simple wordcount from the examples jar - where I got the exception 4 times in a row, and then the job worked the fifth time I submitted it). 
Sometimes restarting the namenode, resourcemanager, and historyserver helps - but not always.  Several other developers have seen this problem.


11/09/12 17:17:50 INFO mapred.YARNRunner: AppMaster capability = memory: 2048, 
11/09/12 17:17:51 INFO mapred.YARNRunner: Command to launch container for ApplicationMaster is : $JAVA_HOME/bin/java -Dhadoop.root.logger=DEBUG,console -Xmx1536m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1315847180566 6 <FAILCOUNT> 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
11/09/12 17:17:51 INFO mapred.ResourceMgrDelegate: Submitted application application_1315847180566_6 to ResourceManager
11/09/12 17:17:51 INFO mapred.ClientCache: Connecting to HistoryServer at: 0.0.0.0:10020
11/09/12 17:17:51 INFO ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
11/09/12 17:17:51 INFO mapred.ClientCache: Connected to HistoryServer at: 0.0.0.0:10020
11/09/12 17:17:51 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.mapreduce.v2.api.MRClientProtocol
11/09/12 17:17:51 INFO mapreduce.Job: Running job: job_1315847180566_0006
11/09/12 17:17:52 INFO mapreduce.Job:  map 0% reduce 0%
11/09/12 17:18:00 INFO mapred.ClientServiceDelegate: Tracking Url of JOB is <IP-ADDRESS>:55361
11/09/12 17:18:00 INFO mapred.ClientServiceDelegate: Connecting to <IP-ADDRESS>:43465
11/09/12 17:18:00 INFO ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
11/09/12 17:18:00 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.mapreduce.v2.api.MRClientProtocol
11/09/12 17:18:01 INFO mapred.ClientServiceDelegate: Failed to contact AM/History for job job_1315847180566_0006  Will retry..
java.lang.reflect.UndeclaredThrowableException
    at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:179)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:237)
    at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:276)
    at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:547)
    at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:540)
    at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1144)
    at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1092)
    at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
    at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
    at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
Caused by: com.google.protobuf.ServiceException: java.io.IOException: Call to /<IP-ADDRESS>:43465 failed on local exception: java.io.EOFException
    at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:139)
    at $Proxy8.getTaskAttemptCompletionEvents(Unknown Source)
    at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:172)
    ... 23 more
Caused by: java.io.IOException: Call to /<IP-ADDRESS>:43465 failed on local exception: java.io.EOFException
    at org.apache.hadoop.ipc.Client.wrapException(Client.java:1119)
    at org.apache.hadoop.ipc.Client.call(Client.java:1087)
    at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:136)
    ... 25 more
Caused by: java.io.EOFException
    at java.io.DataInputStream.readInt(DataInputStream.java:375)
    at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:816)
    at org.apache.hadoop.ipc.Client$Connection.run(Client.java:754)
11/09/12 17:18:01 INFO mapreduce.Job: Job job_1315847180566_0006 failed with state FAILED
11/09/12 17:18:01 INFO mapreduce.Job: Counters: 0 

",0
"Log trace when running sort on a single node setup:

11/09/13 17:01:06 INFO mapreduce.Job:  map 100% reduce 0%
11/09/13 17:01:10 INFO mapreduce.Job: Task Id : attempt_1315949787252_0009_r_000000_0, Status : FAILED
java.lang.UnsupportedOperationException: Incompatible with LocalRunner
	at org.apache.hadoop.mapred.YarnOutputFiles.getInputFile(YarnOutputFiles.java:200)
	at org.apache.hadoop.mapred.ReduceTask.getMapFiles(ReduceTask.java:183)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:365)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:143)
",0
"The app hangs and it turns out to be a NPE in ResourceManager. This happened two of five times on [~karams]'s sort runs on a big cluster.
{code}
2011-09-12 15:02:33,715 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler
java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateNodeLocal(AppSchedulingInfo.java:244)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:206)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.allocate(SchedulerApp.java:230)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1120)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:961)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:933)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:725)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:577)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:509)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:579)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:620)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:75)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:266)
        at java.lang.Thread.run(Thread.java:619)
{code}",0
"[~Karams] was executing a sleep job with 100,000 tasks on a 350 node cluster to test MR AM's scalability and ran into this. The job ran successfully but the history was not available.

I debugged around and figured that the job is finishing prematurely before the JobHistory is written. In most of the cases, we don't see this bug as we have a 5 seconds sleep in AM towards the end.",0
"In secure mode, Jobclient cannot connect to HistoryServer. Thanks to Karam Singh for finding this out.
11/09/14 09:57:51 INFO mapred.ClientServiceDelegate: Application state is completed. Redirecting to job history server
11/09/14 09:57:51 INFO security.ApplicationTokenSelector: Looking for a token with service <history-server>:10020
11/09/14 09:57:51 INFO security.ApplicationTokenSelector: Token kind is YARN_APPLICATION_TOKEN and the token's service name is <Am-ip>:46257
11/09/14 09:57:51 INFO security.UserGroupInformation: Initiating logout for <user-principal>
11/09/14 09:57:51 INFO security.UserGroupInformation: Initiating re-login for <user-principal>
11/09/14 09:57:55 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
11/09/14 09:57:56 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
11/09/14 09:58:00 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
11/09/14 09:58:05 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
11/09/14 09:58:05 WARN ipc.Client: Couldn't setup connection for <user-principal> to null
11/09/14 09:58:05 INFO mapred.ClientServiceDelegate: Failed to contact AM/History for job job_1315993268700_0001  Will retry..
Am surprised no one working with YARN+MR ever ran into this!",0
"When User adds the hierarchical queues, and try to see them from the command line using 
mapred queue -list 
It returns Null Pointer Exception.",0
"Oozie primarily depends on  the job end notification to determine when the job finishes. In the current version,  job end notification is implemented in job tracker. Since job tracker will be removed in the upcoming hadoop release (.next), we wander where this support will move. I think this best effort notification could be implemented in the new Application Manager as one of the last step of job completion.

Whatever implementation will it be, Oozie badly needs this feature to be continued in next releases as well.

 

",0
"{code:title=Node Manager Logs|borderStyle=solid}
2011-09-19 13:39:29,816 INFO  webapp.WebApps (WebApps.java:start(162)) - Registered webapp guice modules
2011-09-19 13:39:29,817 INFO  service.AbstractService (AbstractService.java:start(61)) - Service:org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer is started.
2011-09-19 13:39:29,818 INFO  service.AbstractService (AbstractService.java:start(61)) - Service:Dispatcher is started.
2011-09-19 13:39:29,819 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:start(133)) - Configured ContainerManager Address is 10.18.52.124:45454
2011-09-19 13:39:29,819 INFO  ipc.YarnRPC (YarnRPC.java:create(47)) - Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2011-09-19 13:39:29,822 INFO  ipc.HadoopYarnRPC (HadoopYarnProtoRPC.java:getProxy(49)) - Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.server.api.ResourceTracker
2011-09-19 13:39:29,862 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:registerWithRM(165)) - Connected to ResourceManager at 0.0.0.0:8025
2011-09-19 13:39:30,369 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:registerWithRM(189)) - Registered with ResourceManager as 10.18.52.124:45454 with total resource of memory: 8192, 
2011-09-19 13:39:30,369 INFO  service.AbstractService (AbstractService.java:start(61)) - Service:org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl is started.
2011-09-19 13:39:30,371 INFO  service.AbstractService (AbstractService.java:start(61)) - Service:org.apache.hadoop.yarn.server.nodemanager.NodeManager is started.
{code}



{code:title=Resource Manager Logs|borderStyle=solid}
2011-09-19 14:01:03,238 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:04,240 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:05,242 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:06,244 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:07,246 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:08,247 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
{code}

Node Manager is registered with Resource manager and the for every heartbeat, it is printing the above message.",0
"Started a cluster. Submitted a sleep job with around 10000 maps and 1000 reduces.
Killed AM with kill -9 by which time already 7000 thousands maps got completed.

On the RM webUI, Application is stuck in Application.RUNNING state. And JobClient goes into an infinite loop as RM keeps telling the client that the application is running.",0
nan,0
"If mapreduce.jobtracker.address is not set in mapred-site.xml and mapreduce.framework.name is set yarn, job submission fails :

Tried to submit sleep job with maps 1 task. Job submission failed with following exception -:
{code}
11/09/19 13:19:20 INFO ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
11/09/19 13:19:20 INFO mapred.ResourceMgrDelegate: Connecting to ResourceManager at <RMHost>:8040
11/09/19 13:19:20 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ClientRMProtocol
11/09/19 13:19:20 INFO mapred.ResourceMgrDelegate: Connected to ResourceManager at <RMHost>:8040
11/09/19 13:19:21 INFO mapred.ResourceMgrDelegate: DEBUG --- getStagingAreaDir: dir=/user/<username>/.staging
11/09/19 13:19:21 INFO mapreduce.JobSubmitter: Cleaning up the staging area /user/<username>/.staging/job_1316435926198_0004
java.lang.RuntimeException: Not a host:port pair: local
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:132)
	at org.apache.hadoop.mapred.Master.getMasterAddress(Master.java:42)
	at org.apache.hadoop.mapred.Master.getMasterPrincipal(Master.java:47)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:104)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:90)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:83)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:346)
	at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1072)
	at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1069)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1069)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1089)
	at org.apache.hadoop.mapreduce.SleepJob.run(SleepJob.java:262)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
	at org.apache.hadoop.mapreduce.SleepJob.main(SleepJob.java:194)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
	at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:111)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
{code}",0
"RM sends a reboot command to NM in some cases, like when it gets lost and rejoins back. In such a case, NM should act on the command and reboot/reinitalize itself.

This is akin to TT reinitialize on order from JT. We will need to shutdown all the services properly and reinitialize - this should automatically take care of killing of containers, cleaning up local temporary files etc.",0
"Exception starting history server.


Sep 19, 2011 6:51:53 PM com.google.inject.MessageProcessor visit
INFO: An exception was caught and reported. Message: org.apache.hadoop.yarn.webapp.WebAppException: conf() not found in class org.apache.hadoop.mapreduce.v2.hs.webapp.HsController                                                                                 org.apache.hadoop.yarn.webapp.WebAppException: conf() not found in class org.apache.hadoop.mapreduce.v2.hs.webapp.HsController
    at org.apache.hadoop.yarn.webapp.Router.addController(Router.java:107)
    at org.apache.hadoop.yarn.webapp.Router.add(Router.java:83)
    at org.apache.hadoop.yarn.webapp.WebApp.route(WebApp.java:140)
    at org.apache.hadoop.yarn.webapp.WebApp.route(WebApp.java:146)
    at org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebApp.setup(HsWebApp.java:42)
    at org.apache.hadoop.yarn.webapp.WebApp.configureServlets(WebApp.java:121)
    at com.google.inject.servlet.ServletModule.configure(ServletModule.java:45)
    at com.google.inject.AbstractModule.configure(AbstractModule.java:59)
    at com.google.inject.spi.Elements$RecordingBinder.install(Elements.java:223)
    at com.google.inject.spi.Elements.getElements(Elements.java:101)
    at com.google.inject.InjectorShell$Builder.build(InjectorShell.java:135)
    at com.google.inject.InjectorBuilder.build(InjectorBuilder.java:102)
    at com.google.inject.Guice.createInjector(Guice.java:92)
    at com.google.inject.Guice.createInjector(Guice.java:69)
    at com.google.inject.Guice.createInjector(Guice.java:59)
    at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:166)
    at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService.initializeWebApp(HistoryClientService.java:138)
    at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService.start(HistoryClientService.java:109)
    at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
    at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:83)",0
"When I build and run YARN's RM, I get an invalid host:port exception.

Looks like there's a typo in the ResourceTrackerService.",0
"Found by Philip Su

The ""mapred job -kill"" command
appears to succeed, but listing the jobs again shows that the job supposedly killed is still there. 

{code}
mapred job -list
Total jobs:2
JobId   State   StartTime       UserName        Queue   Priority        SchedulingInfo
job_1316203984216_0002  PREP    1316204924937   hadoopqa        default NORMAL
job_1316203984216_0001  PREP    1316204031206   hadoopqa        default NORMAL

mapred job -kill job_1316203984216_0002
Killed job job_1316203984216_0002

mapred job -list
Total jobs:2
JobId   State   StartTime       UserName        Queue   Priority        SchedulingInfo
job_1316203984216_0002  PREP    1316204924937   hadoopqa        default NORMAL
job_1316203984216_0001  PREP    1316204031206   hadoopqa        default NORMAL
{code}",0
"MR cluster is started by the user 'root'. If any other users other than 'root' submit a job, it is failing always.

Find the conatiner logs in the comments section.",0
"History server was started with -Xmx10000m
Ran GridMix V3 with 1200 Jobs trace in STRESS mode on 350 nodes with each node 4 NMS.
All jobs finished as reported by RM Web UI and HADOOP_MAPRED_HOME/bin/mapred job -list all
But found that GridMix job client was stuck while trying connect to HistoryServer
Then tried to do HADOOP_MAPRED_HOME/bin/mapred job -status jobid
JobClient also got stuck while looking for token to connect to History server
Then looked at History Server logs and found History is trowing ""java.lang.OutOfMemoryError: GC overhead limit exceeded"" error.

With 10GB of Heap space and 1200 Jobs, History Server should not go out of memory .
No matter what are the type of jobs.



",0
"2011-09-21 10:21:41,932 FATAL resourcemanager.ResourceManager (ResourceManager.java:main(502)) - Error starting ResourceManager
java.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.admin.address
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:132)
	at org.apache.hadoop.yarn.server.resourcemanager.AdminService.init(AdminService.java:88)
	at org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.init(ResourceManager.java:191)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:497)

Another copy and paste issue. Similar to https://issues.apache.org/jira/browse/MAPREDUCE-3042.",0
"Please check conf.get() calls. Every time I svn up, I get one of these.


2011-09-21 15:36:33,534 INFO  service.AbstractService (AbstractService.java:stop(71)) - Service:org.apache.hadoop.yarn.server.nodemanager.DeletionService is stopped.
2011-09-21 15:36:33,534 FATAL nodemanager.NodeManager (NodeManager.java:main(204)) - Error starting NodeManager
org.apache.hadoop.yarn.YarnException: Failed to Start org.apache.hadoop.yarn.server.nodemanager.NodeManager
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:78)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:153)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:202)
Caused by: org.apache.avro.AvroRuntimeException: java.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.resource-tracker.address
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:141)
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
	... 2 more
Caused by: java.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.resource-tracker.address
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:132)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getRMClient(NodeStatusUpdaterImpl.java:154)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:164)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:137)
	... 3 more
2011-09-21 15:36:33,535 INFO  service.CompositeService (CompositeService.java:stop(97)) - Error stopping org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl
java.lang.IllegalStateException: For this operation, current State must be STARTED instead of INITED
	at org.apache.hadoop.yarn.service.AbstractService.ensureCurrentState(AbstractService.java:101)
	at org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:69)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.stop(NodeStatusUpdaterImpl.java:149)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:95)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:85)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:158)
	at org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:118)
2011-09-21 15:36:33,535 INFO  nodemanager.NodeManager (StringUtils.java:run(605)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at criccomi-ld/127.0.0.1
************************************************************/
2011-09-21 15:36:33,536 INFO  ipc.Server (Server.java:stop(1708)) - Stopping server on 45454
2011-09-21 15:36:33,536 INFO  logaggregation.LogAggregationService (LogAggregationService.java:stop(116)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService waiting for pending aggregation during exit
2011-09-21 15:36:33,536 INFO  ipc.Server (Server.java:stop(1708)) - Stopping server on 4344
2011-09-21 15:36:33,536 INFO  service.CompositeService (CompositeService.java:run(120)) - Error stopping org.apache.hadoop.yarn.server.nodemanager.NodeManager
java.lang.IllegalStateException: For this operation, current State must be STARTED instead of INITED
	at org.apache.hadoop.yarn.service.AbstractService.ensureCurrentState(AbstractService.java:101)
	at org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:69)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:87)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:158)
	at org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:118)
",0
"After stopping NM gracefully then starting NM, NM registration fails with RM with Duplicate registration from the node! error.


{noformat} 
2011-09-23 01:50:46,705 FATAL nodemanager.NodeManager (NodeManager.java:main(204)) - Error starting NodeManager
org.apache.hadoop.yarn.YarnException: Failed to Start org.apache.hadoop.yarn.server.nodemanager.NodeManager
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:78)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:153)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:202)
Caused by: org.apache.avro.AvroRuntimeException: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Duplicate registration from the node!
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:141)
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
	... 2 more
Caused by: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Duplicate registration from the node!
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:142)
	at $Proxy13.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:59)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:175)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:137)
	... 3 more
{noformat} 
",0
"Depending on when ContainersLaunch starts a container, {{KILL_CONTAINER}} when container state is {{LOCALIZED}} ({{LAUNCH_CONTAINER}} event already sent) can end up generating a {{CONTAINER_LAUNCHED}} event - which isn't handled by ContainerState: {{KILLING}}. Also, the launched container won't be killed since {{CLEANUP_CONTAINER}} would have already been processed.",0
nan,0
nan,0
nan,0
"When we set the value for the property *mapred.map.multithreadedrunner.class* as instance of MultithreadedMapper, using MultithreadedMapper.setMapperClass(), it simply throws IllegalArgumentException.
But when we set the same property, using job's conf object using job.getConfiguration().setClass(*mapred.map.multithreadedrunner.class*, MultithreadedMapper.class, Mapper.class), throws OOM.",0
"This is akin to MAPREDUCE-2413 but for YARN's NodeManager. We want to minimize the impact of transient/permanent disk failures on containers. With larger number of disks per node, the ability to continue to run containers on other disks is crucial.",0
"the following job throws an exception when you have the special characters in it.

hadoop jar hadoop-streaming.jar -Dmapreduce.job.acl-view-job=* -Dmapreduce.job.queuename=queue1 -files file:///homes/user/hadoop/Streaming/data/streaming-980//InputDir#testlink!@$&*()-_+= -input Streaming/streaming-980/input.txt  -mapper 'xargs cat' -reducer cat -output Streaming/streaming-980/Output -jobconf mapred.job.name=streamingTest-980 -jobconf mapreduce.job.acl-view-job=*

Exception:
2011-09-27 20:58:48,903 INFO org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: launchContainer:
[container-executor, hadoopuser, 1, application_1317077272567_0239,
container_1317077272567 0239_01_000001,
tmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001,
tmp/mapred-local/nmPrivate/application_1317077272567_0239/container_1317077272567_0239_01 000001/task.sh,
tmp/mapred-local/nmPrivate/container_1317077272567_0239_01_000001/container_1317077272567_0239_01_000001.tokens]1109221111-tests.jar:hadoop-mapreduce-p2011-09-27
20:58:48,944 WARN org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exit code from container is : 2    
                                                                                                           2011-09-27
20:58:48,946 WARN org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exception from container-launch :  
                                                                                                          
org.apache.hadoop.util.Shell$ExitCodeException:
/tmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001/task.sh:
line 26: syntax error near unexpected token `-_+='       
/tmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001/task.sh:
line 26: `ln -sf /tmp/mapred-local/usercache/hadoopqa/filecache/-1888139433818483070/InputDir test
ink!@$&*()-_+='kson-jaxrs-1.7.1.jar:/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.7.3/jackson-mapper-asl-1.7.3.jar:.m2/repository/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar:

     at org.apache.hadoop.util.Shell.runCommand(Shell.java:261)                                                        
                                                                                                                       
   at org.apache.hadoop.util.Shell.run(Shell.java:188)                                                                 
                                                                                                                       
 at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:381)                                          
                                                                                                                      
at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:174)   
                                                                                                                     
at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:197)  
                                                                                                                     
at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:62)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
2011-09-27 20:58:48,951 INFO org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor:
2011-09-27 20:58:48,951 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Processing
container_1317077272567_0239_01_000001 of type UPDATE_DIAGNOSTICS_MSG
2011-09-27 20:58:48,951 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch:
Container exited with a non-zero exit code 2


",0
"hadoop jar hadoop-mapreduce-examples-*.jar sort -Dmapreduce.job.acl-view
-job=* -Dmapreduce.map.output.compress=true 
-Dmapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.GzipCodec 
-Dmapreduce.output.fileoutputformat.compress=true  -Dmapreduce.output.fileoutputformat.compression.type=NONE -Dmap
reduce.output.fileoutputformat.compression.codec=org.apache.hadoop.io.compress.GzipCodec  -outKey
org.apache.hadoop.io.Text -outValue org.apache.hadoop.io.Text  Compression/textinput Compression/textoutput-1317315994

This will fail with native libs not found error unless -Dmapred.child.java.opts='-Djava.library.path=${HADOOP_COMMON_HOME}/lib/native/Linux-i386-32' is added.


The error in container log:


2011-09-29 17:06:56,787 DEBUG org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop
library...2011-09-29 17:06:56,787 DEBUG org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with
error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path2011-09-29 17:06:56,787 DEBUG
org.apache.hadoop.util.NativeCodeLoader:
java.library.path=/share/gridjdk-1.6.0_21/jre/lib/i386/server:/share/gridjdk-1.6.0_21/jre/lib/i386:/share/gridjdk-1.6.0_21/jre/../lib/i386:/tmp/mapred-local/usercache/hadoopqa/appcache/application_1317314754104_0012/container_1317314754104_0012_01_000002:/current/lib:/usr/java/packages/lib/i386:/lib:/usr/lib2011-09-29
17:06:56,787 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform...
using builtin-java classes where applicable


Also note that the error that shows up at the application master for this is terrible:

Container killed by the ApplicationMaster. Container killed on request. Exit code is 137 Too Many fetch failures.Failing the attempt 
",0
"The command in MAPREDUCE-3124 run and this job got hung with 1 Map task waiting for resources and 7 Reducers running (2 waiting).  The mapper got scheduler, then AM scheduled the reducers, the map task failed and tried to start a new attempt but reducers were using all the slots.   

I will try to add some more info from the logs.",0
"Setting the following property in yarn-site.xml with user ids to restrict ability to run
'rmadmin -refreshQueues is not honoured
<property>
<name>yarn.server.resourcemanager.admin.acls</name>
<value>hadoop1</value>
<description></description>
<final></final>
</property>
Should it be the same for rmadmin -refreshNodes?",0
The DefaultContainerExecutor currently has code that removes the application dir from appcache/ in the local directories on every task localization. This causes any concurrent executing tasks from the same job to fail.,0
"When I used the ""hadoop job"" command line to kill a running MR2 job, I got a bunch of error spew on the console, despite the kill actually taking effect.",0
"The file src/mapred/org/apache/hadoop/mapred/TaskTracker.java.orig was accidentally checked in as part of r1179465.  It is only in 0.20-security-205, not 0.20-security.  If there is a 0.20.205.1, remove it then.",0
"We are seeing the following Kerberos exception upon trying to run terasort on secure single and multi-node clusters using the latest build from branch 0.23.

java.io.IOException: Can't get JobTracker Kerberos principal for use as renewer
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:106)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:90)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:83)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:205)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:269)
        at org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(TeraInputFormat.java:318)
        at org.apache.hadoop.examples.terasort.TeraInputFormat.writePartitionFile(TeraInputFormat.java:169)
        at org.apache.hadoop.examples.terasort.TeraSort.run(TeraSort.java:306)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.examples.terasort.TeraSort.main(TeraSort.java:325)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)

Adding debug output shows that the job configuration is not loading up yarn-site.xml causing the above failure to happen.
",0
"If the resource manager is restarted while the job execution is in progress, the job is getting hanged.
UI shows the job as running.
In the RM log, it is throwing an error ""ERROR org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AppAttemptId doesnt exist in cache appattempt_1318579738195_0004_000001""
In the console MRAppMaster and Runjar processes are not getting killed",0
nan,0
"Using the FairScheduler with kerberos authentication does not appear to work with 0.20.205.0.  When submitting a job, execution fails when storing the delegation tokens for the job:

{noformat}
11/10/18 21:48:53 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 6 for hdfs on xxxx:8020
11/10/18 21:48:53 INFO security.TokenCache: Got dt for hdfs://xxxx/user/hdfs/.staging/job_201110182148_0001;uri=xxxx:8020;t.service=xxxx:8020
11/10/18 21:48:53 INFO mapred.FileInputFormat: Total input paths to process : 1
11/10/18 21:48:53 INFO mapred.JobClient: Running job: job_201110182148_0001
11/10/18 21:48:54 INFO mapred.JobClient:  map 0% reduce 0%
11/10/18 21:48:54 INFO mapred.JobClient: Job complete: job_201110182148_0001
11/10/18 21:48:54 INFO mapred.JobClient: Counters: 0
11/10/18 21:48:54 INFO mapred.JobClient: Job Failed: Job initialization failed:
java.io.IOException: Call to xxxx/xxxx:8020 failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Attempt to obtain new INITIATE credentials failed! (null))]
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1103)
	at org.apache.hadoop.ipc.Client.call(Client.java:1071)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy7.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:396)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:379)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:118)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:222)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:187)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:89)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1328)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:65)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:244)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
	at org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:175)
	at org.apache.hadoop.mapred.JobInProgress.generateAndStoreTokens(JobInProgress.java:3528)
	at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:696)
	at org.apache.hadoop.mapred.JobTracker.initJob(JobTracker.java:4207)
	at org.apache.hadoop.mapred.FairScheduler$JobInitializer$InitJob.run(FairScheduler.java:291)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Attempt to obtain new INITIATE credentials failed! (null))]
	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:539)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:484)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:586)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1202)
	at org.apache.hadoop.ipc.Client.call(Client.java:1046)
	... 21 more
Caused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Attempt to obtain new INITIATE credentials failed! (null))]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:194)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:134)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:381)
	at org.apache.hadoop.ipc.Client$Connection.access$1100(Client.java:184)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:579)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:576)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:575)
	... 24 more
Caused by: GSSException: No valid credentials provided (Mechanism level: Attempt to obtain new INITIATE credentials failed! (null))
	at sun.security.jgss.krb5.Krb5InitCredential.getTgt(Krb5InitCredential.java:333)
	at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:128)
	at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:106)
	at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:172)
	at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:209)
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:195)
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:162)
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:175)
	... 33 more
Caused by: javax.security.auth.login.LoginException: No LoginModules configured for 
	at javax.security.auth.login.LoginContext.init(LoginContext.java:256)
	at javax.security.auth.login.LoginContext.<init>(LoginContext.java:499)
	at sun.security.jgss.GSSUtil.login(GSSUtil.java:244)
	at sun.security.jgss.krb5.Krb5Util.getTicket(Krb5Util.java:136)
	at sun.security.jgss.krb5.Krb5InitCredential$1.run(Krb5InitCredential.java:328)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.security.jgss.krb5.Krb5InitCredential.getTgt(Krb5InitCredential.java:325)
	... 40 more
{noformat}

The problem seems to have been introduced by the backported changes in MAPREDUCE-2981, which shifted the execution of JobTracker.initJob(), and hence JobInProgress.generateAndStoreTokens(), to underneath the call path for the RPC invocation.  As a result, the DFS write in TokenStorage.writeTokenStorageFile() in done under a UGI.doAs() block as the RPC client remote user, without a TGT for negotiating the connection.

Does this analysis seem right?  Previously it seems that JobTracker.initJob() was only called in a separate thread so it was picking up the credentials obtained for the configured JobTracker kerberos principal.  The same job runs successfully in a build with MAPREDUCE-2981 reverted.",0
"In a gridmix run with ~1000 jobs, one job is getting stuck because of 2-3 hanging reducers. All of the them are stuck after downloading all map outputs and have the following thread dump.

{code}
""EventFetcher for fetching Map Completion Events"" daemon prio=10 tid=0xa325fc00 nid=0x1ca4 waiting on condition [0xa315c000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:71)

""main"" prio=10 tid=0x080ed400 nid=0x1c71 in Object.wait() [0xf73a2000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        - waiting on <0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)
        at java.lang.Thread.join(Thread.java:1143)
        - locked <0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)
        at java.lang.Thread.join(Thread.java:1196)
        at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:135)
        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:367)
        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)
{code}

Thanks to [~karams] for helping track this down.",0
"Found this on one of the gridmix runs, again. One of the nodes went real bad, the job had three containers running on the node. Eventually, AM marked the tasks as timedout and initiated cleanup of the failed containers via {{stopContainer()}}. The later got stuck at the faulty node, the tasks are stuck in FAIL_CONTAINER_CLEANUP stage and the job lies in there waiting for ever.

Thanks to [~Karams] for helping with this.",0
"I propose a stripped down JSON based protocol for creating safe user generate web pages. This JIRA is intended first of all as a place for a discussion about this proposal, and then if there are no serious objections this will be an Umbrella JIRA to implement the changes proposed.",0
"I tried to copy file from .20.204 to .20.205 by distcp over hdfs:// while using hadoop.security.token.service.use_ip=false in core-site.xml. The copy was successful but found error "" org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal:"" exception in .20.205 JT.


",0
"Can't find log4j logs in tests, all of them complain:

{noformat}
log4j:WARN No appenders could be found for logger (org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer).
log4j:WARN Please initialize the log4j system properly.
{noformat}

I suspect MAPREDUCE-3199.",0
nan,0
"I found that, even if the output of a map task fits entirely in its sort buffer, it was rewriting the output entirely rather than just renaming the first spill into place. This is due to RawLocalFileSystem.rename() falling back to a copy if renameTo() fails. The first rename attempt was failing because no one has called mkdir for the output directory yet.",0
"ClassNotFoundException: org.apache.hadoop.streaming.PipeMapRunner encountered while running streaming jobs. Stack trace in the next comment.
",0
"We already authenticate requests to NM from any AM. We also need to authorize the requests, otherwise a rogue AM, but with proper tokens and thus authenticated to talk to NM, could either launch or kill a container with different ContainerID. We have two options:
Remove the explicit passing of the ContainerId as part of the API and instead get it from the RPC layer. In this case, we will need a ContainerToken for each container.
Do explicit authorization checks without relying on getting ContainerID from the RPC.
One ContainerToken per container is a serious restriction. We anyways want to be able to use application-ACLS to, say, stop containers owned by others. So I am going to take the later route of explicit checks.",0
"This is like MAPREDUCE-3256, but for AM->RM protocol.",0
"As seen in MAPREDUCE-2915, java.library.path is not being passed when the LCE spawns a JVM for ContainerLocalizer. 

However, unlike branch-0.20-security, the task runtime in 0.23 is unaffected by this. This is because tasks' run-time environment is specified in the launch script by client. Setting LD_LIBRARY_PATH is the primary way of specifying the locations of required native library in this case. The config property, mapreduce.admin.user.env is always set in the job environment and the default value is to add the path to the hadoop native library to LD_LABRARY_PATH.

For JVM's being launched by the hadoop system scripts, java.library.path is set.",0
"Need to handle kill container event in localization failed state. 
Need to handle resource localized in localization failed state. ",0
"Currently in MR2 I have to manually specify mapreduce.job.user.name for each job. It's not picking it up from the security infrastructure, at least when running with DefaultContainerExecutor. This is obviously incorrect.",0
There appears to be a race condition in the MR App Master in relation to preempting reducers to let a mapper run.  In the particular case that I have been debugging a reducer was selected for preemption that did not have a container assigned to it yet. When the container became available that reduce started running and the previous TA_KILL event appears to have been ignored.,0
"MR AM reads the value for mapreduce.job.user.name from the configuration in several places. It should instead get the app-submitter name from the RM.

Once that is done, we can remove the default value for mapreduce.job.user.name from mapred-default.xml",0
"In secure mode, saw an app failure due to ""org.apache.hadoop.security.token.SecretManager$InvalidToken: token (HDFS_DELEGATION_TOKEN token <id> for <user>) can't be found in cache"" Exception in the next comment.",0
"Seeing this in NM logs when trying to run jobs.
{code}
2011-10-28 21:40:21,263 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Processing application_1319818154209_0001 of type APPLICATION_INITED
2011-10-28 21:40:21,264 FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread. Exiting..
java.util.NoSuchElementException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:796)
        at java.util.HashMap$ValueIterator.next(HashMap.java:822)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$AppInitDoneTransition.transition(ApplicationImpl.java:251)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$AppInitDoneTransition.transition(ApplicationImpl.java:245)
        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:385)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:407)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:399)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:116)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:662)
{code}",0
nan,0
"This is a follow on to MAPREDUCE-3274.  It is possible, although rare, for the MR AM to send a stop container before it sends a start container.  This needs to stop that from happening.  If a stop is found first it should prevent the start from being sent.  It tries to do this, but only if the stop is currently pending.",0
"Configure a cluster to use the capacity scheduler and then specifying a maximum-capacity < 100% for a queue.  If you go to the RM Web UI and hover over the queue, it always shows the max at 100%.",0
"When running mapred queue -list on a 0.23.0 cluster with capacity scheduler configured with child queues.  In my case I have queues default, test1, and test2.  test1 has subqueues of a1, a2.  test2 has subqueues of a3 and a4.

- the child queues do not show up
- The output of maximum capacity doesn't match the format of the current capacity and capacity.  the latter two use float while the maximum is specified as int:

Queue Name : default 
Queue State : running 
Scheduling Info : queueName: ""default"", capacity: 0.7, maximumCapacity: 90.0, currentCapacity: 0.0, state: Q_RUNNING,  
======================
Queue Name : test 
Queue State : running 
Scheduling Info : queueName: ""test"", capacity: 0.2, maximumCapacity: -1.0, currentCapacity: 0.0, state: Q_RUNNING,  
======================
Queue Name : test2 
Queue State : running 
Scheduling Info : queueName: ""test2"", capacity: 0.1, maximumCapacity: 5.0, currentCapacity: 0.0, state: Q_RUNNING,  
======================


here default is configured to have capacity=70% and maximum capacity = 90%",0
"When configuring the capacity scheduler capacity and maximum-capacity, it allows the maximum-capacity to be less then the capacity.  I did not test to see what true limit is, I assume maximum capacity.

output from mapred queue -list where capacity = 10%, max capacity = 5%.

Queue Name : test2 
Queue State : running 
Scheduling Info : queueName: ""test2"", capacity: 0.1, maximumCapacity: 5.0, currentCapacity: 0.0, state: Q_RUNNING,  
",0
"[~Karams] just found this. The usual sort job on a 350 node cluster hung due to OutOfMemory and eventually failed after an hour instead of the usual odd 20 minutes.
{code}
2011-11-02 11:40:36,438 ERROR [ContainerLauncher #258] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Container launch failed for container_1320233407485_0002
_01_001434 : java.lang.reflect.UndeclaredThrowableException
        at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:88)
        at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:290)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: com.google.protobuf.ServiceException: java.io.IOException: Failed on local exception: java.io.IOException: Couldn't set up IO streams; Host Details : local host is: ""gsbl91281.blue.ygrid.yahoo.com/98.137.101.189""; destination host is: """"gsbl91525.blue.ygrid.yahoo.com"":45450; 
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:139)
        at $Proxy20.startContainer(Unknown Source)
        at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:81)
        ... 4 more
Caused by: java.io.IOException: Failed on local exception: java.io.IOException: Couldn't set up IO streams; Host Details : local host is: ""gsbl91281.blue.ygrid.yahoo.com/98.137.101.189""; destination host is: """"gsbl91525.blue.ygrid.yahoo.com"":45450; 
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:655)
        at org.apache.hadoop.ipc.Client.call(Client.java:1089)
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:136)
        ... 6 more
Caused by: java.io.IOException: Couldn't set up IO streams
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:621)
        at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:205)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1195)
        at org.apache.hadoop.ipc.Client.call(Client.java:1065)
        ... 7 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
        at java.lang.Thread.start0(Native Method)
        at java.lang.Thread.start(Thread.java:597)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:614)
        ... 10 more
{code}",0
"I have only one NM running.
I have submitted a job and all the child processes on the NM got killed continuosly.This made the Job to hang indefinitely.

In the NM logs it is logging WARN message :org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Event EventType: KILL_CONTAINER sent to absent container container_1320301910500_0004_01_001359 ",0
"This Out of Memory happens when you run large number of jobs (using the distributed cache) on a TaskTracker. 

Seems the basic issue is with the distributedCacheManager (instance of TrackerDistributedCacheManager in TaskTracker.java), this gets created during TaskTracker.initialize(), and it keeps references to TaskDistributedCacheManager for every submitted job via the jobArchives Map, also references to CacheStatus via cachedArchives map. I am not seeing these cleaned up between jobs, so this can out of memory problems after really large number of jobs are submitted. We have seen this issue in a number of cases.",0
"0.21 mapreduce.Reducer introduced a blind cast to ReduceContext.ValueIterator. There should an instanceof check around this block to ensure we don't throw a CastClassException:
{code}
       // If a back up store is used, reset it
      ((ReduceContext.ValueIterator)
          (context.getValues().iterator())).resetBackupStore();
{code}",0
See https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1247//testReport/org.apache.hadoop.yarn.server/TestContainerManagerSecurity/testUnauthorizedUser/,0
JobHistoryServer belongs to mapreduce land.,0
"Another collaboration with [~karams]. Sort job hangs not so rarely on a 350 node cluster. Found this in AM logs:
{code}

Exception in thread ""ContainerLauncher #60"" org.apache.hadoop.yarn.YarnException: java.lang.InterruptedException
            at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:170)
            at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:379)
            at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
            at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.InterruptedException
            at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1199)
            at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:312)
            at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:294)
            at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:168)
            ... 4 more

Exception in thread ""ContainerLauncher #53"" org.apache.hadoop.yarn.YarnException: java.lang.InterruptedException
            at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:170)
            at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.sendContainerLaunchFailedMsg(ContainerLauncherImpl.java:405)
            at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:330)
            at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
            at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.InterruptedException
            at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1199)
            at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:312)
            at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:294)
            at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:168)
            ... 5 more
{code}",0
"The OldCombinerRunner class inside Task.java uses a NULL Reporter.  If the combiner code runs for an extended period of time, even with reporting progress as it should, the map task can timeout and be killed.  It appears that the NewCombinerRunner class uses a valid reporter and as such is not impacted by this bug.",0
"I have an OutputFormat which implements Configurable.  I set new config entries to a job configuration during checkOutputSpec() so that the tasks will get the config entries through the job configuration.  This works fine in 0.20.2, but stopped working starting from 0.20.203.  With 0.20.203, my OutputFormat still has the configuration set, but the copy a task gets does not have the new entries that are set as part of checkOutputSpec().  

I believe that the problem is with JobClient.  The job configuration needs to wait till checkOutputSpec() is returned before being cloned and submitted.",0
"The JobClient.getDelegationToken() method is returning NULL, this makes Oozie fail when trying to get the delegation token to use it for starting a job.
What is seems to be happing is that Jobclient.getDelegationToken() calls Cluster.getDelegationToken() that calls YarnRunner.getDelegationToken() that calls ResourceMgrDelegate.getDelegationToken(). And the last one is not implemented. (Thanks Ahmed for tracing this in MR2 code)",0
MAPREDUCE-3028 added support for job-end notification from MR AMs after the job finishes. Network ACLs can have an implication on this one - outgoing connections from the compute nodes may be restricted in some settings and so job-end notification( that can originate from the AMs which may run on random nodes in the cluster) may have issues.,0
"Log aggregation in secure mode does not work with MAPREDUCE-2977. The nodemanager relies on the users credentials to write out logs to HDFS. These credentials are currently cancelled once a job completes, before the NM can write out the logs.",0
"When forcing a mapper to take significantly longer than other map tasks, speculative map tasks are
launched even if the mapreduce.job.maps.speculative.execution parameter is set to 'false'.

Testcase: ran default WordCount job with spec execution set to false for both map and reduce but still saw a fifth mapper
task launch, ran job as follows:

hadoop --config <config>  jar   /tmp/testphw/wordcount.jar   WordCount  
-Dmapreduce.job.maps.speculative.execution=false  -Dmapreduce.job.reduces.speculative.execution=false 
/tmp/test_file_of_words* /tmp/file_of_words.out

Input data was 4 text files >hdfs blocksize, with same word pattern plus one diff text line in each file, fourth
file was 4 times as large as others:

hadoop --config <config>  fs -ls  /tmp
Found 5 items
drwxr-xr-x   - user hdfs          0 2011-10-20 16:17 /tmp/file_of_words.out
-rw-r--r--   3 user hdfs   62800021 2011-10-20 14:45 /tmp/test_file_of_words1
-rw-r--r--   3 user hdfs   62800024 2011-10-20 14:46 /tmp/test_file_of_words2
-rw-r--r--   3 user hdfs   62800024 2011-10-20 14:46 /tmp/test_file_of_words3
-rw-r--r--   3 user hdfs  271708312 2011-10-20 15:50 /tmp/test_file_of_words4

Job launched 5 mappers despite spec exec set to false, output snippet:

        org.apache.hadoop.mapreduce.JobCounter
                NUM_FAILED_MAPS=1
                TOTAL_LAUNCHED_MAPS=5
                TOTAL_LAUNCHED_REDUCES=1
                RACK_LOCAL_MAPS=5
                SLOTS_MILLIS_MAPS=273540
                SLOTS_MILLIS_REDUCES=212876


Reran same case as above only set both spec exec params to 'true', same results only this time the fifth task being
launched is expected since spec exec = true.

job run:

hadoop --config <config>  jar   /tmp/testphw/wordcount.jar   WordCount  
-Dmapreduce.job.maps.speculative.execution=true  -Dmapreduce.job.reduces.speculative.execution=true 
/tmp/test_file_of_words* /tmp/file_of_words.out

output snippet:

        org.apache.hadoop.mapreduce.JobCounter
                NUM_FAILED_MAPS=1
                TOTAL_LAUNCHED_MAPS=5
                TOTAL_LAUNCHED_REDUCES=1
                RACK_LOCAL_MAPS=5
                SLOTS_MILLIS_MAPS=279653
                SLOTS_MILLIS_REDUCES=211474",0
"Sharad Agarwal bumped into this while simulating fetch failures. 

Removed the map output directory. Shuffle runs in tight loop throwing
:

2011-06-01 09:02:20,511 WARN org.apache.hadoop.mapreduce.task.reduce.Fetcher: Invalid map id 
java.lang.IllegalArgumentException: TaskAttemptId string : TTP/1.1 500 Internal Server Error
Content-Type: text/plain; charset=UTF is not properly formed
    at org.apache.hadoop.mapreduce.TaskAttemptID.forName(TaskAttemptID.java:174)
    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:284)
    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:251)
    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:149)


Fetch failure is not triggered.",0
"Exception should be logged properly when there is any while deserializing Shuffle Header information .
    {code}
      if (mapId == null || mapOutput == null) {
        LOG.info(""fetcher#"" + id + "" failed to read map header"" + 
                 mapId + "" decomp: "" + 
                 decompressedLength + "", "" + compressedLength, ioe);
        return false;
      }
    {code}",0
Incorrect setup of the uber tasks causes tasks to try to write intermidiate outputs into dirs that the user does not have permissions to write to on a secure cluster. ,0
bringing up a resource manager failed; shutdown triggered an NPE,0
"Oozie is having issues with job submission, since it does the following:

{code}
doAs(userwhosubmittedjob) {
 jobclient = new JobClient(jobconf);
}

jobclient.submitjob()

{code}

In 0.20.2** this works because the JT proxy is created as soon as we call new JobClient(). But in 0.23 this is no longer true since the client has to talk to multiple servers (AM/RM/JHS). To keep this behavior we will have to store the ugi in new JobClient() and make sure all the calls are run with a doAs() inside the jobclient.",0
"When an AM is assigned a FAILED_MAP (priority = 5) container on a nodemanager which it has blacklisted - it tries to
find a corresponding container request.
This uses the hostname to find the matching container request - and can end up returning any of the ContainerRequests which may have requested a container on this node. This container request is cleaned to remove the bad node - and then added back to the RM 'ask' list.
The AM cleans the 'ask' list after each heartbeat - The RM Allocator is still aware of the priority=5 container (in 'remoteRequestsTable') - but this never gets added back to the 'ask' set - which is what is sent to the RM.",0
"Set yarn.resourcemanager.am.max-retries=5 in yarn-site.xml. Started yarn 4 Node cluster.
First Ran Randowriter/Sort/Sort-validate successfully
Then again sort, when job was 50% complete
Login node running AppMaster, and killed AppMaster with kill -9
On Client side failed with following:
{code}
11/11/23 10:57:27 INFO mapreduce.Job:  map 58% reduce 8%
11/11/23 10:57:27 INFO mapred.ClientServiceDelegate: Failed to contact AM/History for job job_1322040898409_0005 retrying..
11/11/23 10:57:28 INFO mapreduce.Job:  map 0% reduce 0%
11/11/23 10:57:37 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=UNDEFINED. Redirecting to job history server
11/11/23 10:57:37 INFO client.ClientTokenSelector: Looking for a token with service <RM Host>:Port
11/11/23 10:57:37 INFO client.ClientTokenSelector: Token kind is YARN_CLIENT_TOKEN and the token's service name is <New AM Host>:Port
11/11/23 10:57:38 WARN mapred.ClientServiceDelegate: Error from remote end: Unknown job job_1322040898409_0005
RemoteTrace: 
 at Local Trace: 
	org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1322040898409_0005
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:151)
	at $Proxy10.getTaskAttemptCompletionEvents(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:172)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:273)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:320)
	at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:438)
	at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:621)
	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1231)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1179)
	at org.apache.hadoop.examples.Sort.run(Sort.java:181)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
	at org.apache.hadoop.examples.Sort.main(Sort.java:192)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
{code}

On lookig RM logs found second AM was also lauched, it was saying -:
{code}
011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1322040898409_0005_000002 State change from RUNNING to FINISHED
2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Processing event for application_1322040898409_0005 of type ATTEMPT_FINISHED
2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1322040898409_0005 State change from RUNNING to FINISHED
2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application appattempt_1322040898409_0005_000002 is done. finalState=FINISHED
{code}

Now looking at AM logs and found Second AM was shutdown gracefully due to :-
{code}
2011-11-23 10:57:37,640 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService: Sending assigned event to attempt_1322040898409_0005_m_000000_0
2011-11-23 10:57:37,641 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread. Exiting..
java.lang.IllegalArgumentException: Invalid NodeId [<NMHostName>]. Expected host:port
        at org.apache.hadoop.yarn.util.ConverterUtils.toNodeId(ConverterUtils.java:144)
        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$InterceptingEventHandler.sendAssignedEvent(RecoveryService.java:410)
        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$InterceptingEventHandler.handle(RecoveryService.java:314)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$RequestContainerTransition.transition(TaskAttemptImpl.java:1010)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$RequestContainerTransition.transition(TaskAttemptImpl.java:985)
        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:851)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:128)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:853)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:845)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:116)
        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(RecoveryService.java:270)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:619)
2011-11-23 10:57:37,642 INFO [CompositeServiceShutdownHook for org.apache.hadoop.mapreduce.v2.app.MRAppMaster] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler
{code}",0
nan,0
"When external systems submit jobs whose tasks need to submit additional jobs (such as oozie/pig), they include their own MR token used to submit the job.  The token's renewer may not allow the JT to renew the token.  The JT log will include very long SASL/GSSAPI exceptions when the job is submitted.  It is also dubious for the JT to renew its token because it renders the expiry as meaningless since the JT will renew its own token until the max lifetime is exceeded.

After speaking with Owen & Jitendra, the immediate solution is for the JT to not attempt to renew its own tokens.",0
"Saw a case where a job was stuck trying to get reducers.  The issue is the capacity scheduler reserved a container on the same node as the application master but there wasn't ever enough memory to run the reducer on that node.  Node total memory was 8G, Reducer needed 8G, AM was using 2G.  This particular job had 10 reducers and it was stuck waiting on the one because the AM + reserved reducer memory was already over the queue limit.  ",0
"We noticed JobEndNotifier was getting an InterruptedException before completing all its retries.

To fix this, Job end notification method should be called before stop() in handle(JobFinishEvent).",0
"The RMContainerAllocator does not differentiate between failed and successful maps while calculating whether reduce tasks are ready to launch. Failed tasks are also counted towards total completed tasks. 
Example. 4 failed maps, 10 total maps. Map%complete = 4/14 * 100 instead of being 0.",0
"When sum of all capacities >=101 or <100, we got the following error when starting jobtracker. However, when the 100 <= sum < 101, jobtracker does not report exception and started with all queues initialized.
for instance (capacity sum = 29.5+60+11.4 = 100.9) does not cause exception.

",0
Somehow the priority field under JobHistoryParser.JobInfo is not set. Calling getPriority on Jobinfo after parsing a Job hisotry log throws NPE,0
nan,0
"*org.apache.hadoop.mapred.MapTask.MapOutputBuffer.collect* accepts a pair of Key and Value. There is chance that if somehow if a Null value or Key is passed to the method, we can end up having NPE.",0
"mapred queue -info default -showJobs

Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.tools.CLI.displayJobList(CLI.java:572)
        at org.apache.hadoop.mapred.JobQueueClient.displayQueueInfo(JobQueueClient.java:190)
        at org.apache.hadoop.mapred.JobQueueClient.run(JobQueueClient.java:103)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.mapred.JobQueueClient.main(JobQueueClient.java:234)
",0
nan,0
"Hierarchical Queues do not inherit parent ACLs correctly by default. Instead, if no value is specified for submit or administer acls, then all access is granted.",0
"viewfs returns a list of delegation tokens for the actual namenodes. TokenCache caches these based on the actual service name - subsequent calls to TokenCache end up trying to get a new set of tokens.

Tasks which happen to access TokenCache fail when using viewfs - since they end up trying to get a new set of tokens even though the tokens are already available.

{noformat}
Error: java.io.IOException: Delegation Token can be issued only with kerberos or web authentication
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:4027)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:281)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:365)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1490)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1486)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1484)

        at org.apache.hadoop.ipc.Client.call(Client.java:1085)
        at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:193)
        at $Proxy8.getDelegationToken(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:100)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:65)
        at $Proxy8.getDelegationToken(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.getDelegationToken(DFSClient.java:456)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken(DistributedFileSystem.java:812)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationTokens(DistributedFileSystem.java:839)
        at org.apache.hadoop.fs.viewfs.ChRootedFileSystem.getDelegationTokens(ChRootedFileSystem.java:311)
        at org.apache.hadoop.fs.viewfs.ViewFileSystem.getDelegationTokens(ViewFileSystem.java:490)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:144)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:91)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:84)
{noformat}


This will likely require some changes in viewfs/hdfs - will open a Jira with details.",0
"Sometimes NODE_UPDATE to the scheduler throws NPE causes scheduling to stop but ResourceManager keeps on running.
I have been observing intermitently for last 3 weeks.
But with latest svn code. I tried to run sort twice and both times Job got stuck due to NPE.
{code}
java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.containerLaunchedOnNode(SchedulerApp.java:181)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.containerLaunchedOnNode(CapacityScheduler.java:596)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:539)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:617)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:77)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:294)
        at java.lang.Thread.run(Thread.java:619)
{code}",0
"Filling this Jira a bit late
Started 350 cluster
sbummited large sleep job.
Foud that job was not running as RM has not allocated resouces to it.
{code}
2011-12-01 11:56:25,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: <NMHost>:48490 clusterResources: memory: 3225600
2011-12-01 11:56:25,202 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event
type NODE_UPDATE to the scheduler
java.lang.IllegalArgumentException: Invalid key to HMAC computation
        at org.apache.hadoop.security.token.SecretManager.createPassword(SecretManager.java:141)
        at org.apache.hadoop.yarn.server.security.ContainerTokenSecretManager.createPassword(ContainerTokenSecretManager.java:61)
        atorg.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.createContainer(LeafQueue.java:1108)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getContainer(LeafQueue.java:1091)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1137)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:1001)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:973)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:760)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:583)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:513)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:569)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:611)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:77)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:294)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.security.InvalidKeyException: Secret key expected
        at com.sun.crypto.provider.HmacCore.a(DashoA13*..)
        at com.sun.crypto.provider.HmacSHA1.engineInit(DashoA13*..)
        at javax.crypto.Mac.init(DashoA13*..)
        at org.apache.hadoop.security.token.SecretManager.createPassword(SecretManager.java:139)
        ... 14 more
{code}
As this stack is from 30 Nov checkou line number may be different",0
"I tried following -:
yarn.nodemanager.address=0.0.0.0:0
yarn.nodemanager.webapp.address=0.0.0.0:0
yarn.nodemanager.localizer.address=0.0.0.0:0
mapreduce.shuffle.port=0

When 0 is provided as number in yarn.nodemanager.webapp.address. 
NM instantiate WebServer as 0 piort e.g.
{code}
2011-12-08 11:33:02,467 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:0
{code}

After that WebServer pick up some random port e.g.
{code}
2011-12-08 11:33:02,562 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 36272
2011-12-08 11:33:02,562 INFO org.mortbay.log: jetty-6.1.26
2011-12-08 11:33:02,831 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:36272
2011-12-08 11:33:02,831 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 36272
{code}

And NM WebServer responds correctly but
 RM's cluster/Nodes page shows the following -:
{code}
/Rack RUNNING NM:57963 NM:0 Healthy 8-Dec-2011 11:33:01 Healthy 8 12 GB 0 KB
{code}
Whereas NM:0 is not clickable.
Seems even NM's webserver pick random port but it never gets updated and so NM report 0 as HTTP port to RM causing NM Hyperlinks un-clickable
But verified that MR job runs successfully with random.
",0
"DCE relies cwd before calling ContainerLocalizer.runLocalization. However, with multiple containers setting cwd on same localFS reference leads to race. ",0
"In such corner cases, clients can see that the job has become successful but they cannot get any information from JobHistoryServer. And there is no means of figuring out what happened in the system except from the AM logs.

Ideally we should set the JobState to become SUCCESS as the last step, once everything else is done. The code changes may be a bit complicated to achieve this, but we can investigate and see.",0
"bq.MultipleOutputs 
  The close of recordwriters should be synchronized. 
  public void close() throws IOException, InterruptedException { 
    for (RecordWriter writer : recordWriters.values()) { 
      writer.close(context); 

bq.JobControl.java 
  the getters of the jobs to be synchronized. 

bq.Counters.java 
   makeEscapedCompactString to be made synchronized. 
",0
"LocalJobRunner doesn't handle Jobs using o.a.h.mapreduce.OutputCommitter, ran into this debugging PIG-2347.",0
"[~daijy] found this. Here's what he says:
bq. I see hundreds of MRAppMaster process on my machine, and lots of tests fail for ""Too many open files"".",0
"Courtesy [~vinaythota]
{quote}
Ran sort benchmark couple of times and every time the job got hang after completion 99% map phase. There are some map tasks failed. Also it's not scheduled some of the pending map tasks.
Cluster size is 350 nodes.

Build Details:
==============

Compiled:       Fri Dec 9 16:25:27 PST 2011 by someone from branches/branch-0.23/hadoop-common-project/hadoop-common 
ResourceManager version:        revision 1212681 by someone source checksum on Fri Dec 9 16:52:07 PST 2011
Hadoop version:         revision 1212592 by someone Fri Dec 9 16:25:27 PST 2011
{quote}


",0
Streaming isn't checking for mapreduce.framework.name as part of check for 'local' mode.,0
"Courtesy [~dcapwell]

{quote}
If the AM is running and you kill the process (sudo kill #pid), the State in Yarn would be FINISHED and FinalStatus is UNDEFINED.  The Tracking UI would say ""History"" and point to the proxy url (which will redirect to the history server).

The state should be more descriptive that the job failed and the tracker url shouldn't point to the history server.
{quote}",0
"The following mapred ant tests fail and have been failing for a very long time:

[junit] Running org.apache.hadoop.mapreduce.lib.db.TestDBJob
[junit] Running org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat",0
We should make sure that the daemons crash in case the dispatchers get exceptions and stop processing. That way we will be debugging RM/NM/AM crashes instead of hard-to-track hanging jobs. ,0
Ref HADOOP-7963.,0
"When calling job end notification for oozie the AM fails with the following trace:

{noformat}
2012-01-09 23:45:41,732 WARN [AsyncDispatcher event handler] org.mortbay.log: Job end notification to http://HOST:11000/oozie/v0/callback?id=0000000-120109234442311-oozie-oozi-W@mr-node&status=SUCCEEDED& failed
java.net.UnknownServiceException: no content-type
	at java.net.URLConnection.getContentHandler(URLConnection.java:1192)
	at java.net.URLConnection.getContent(URLConnection.java:689)
	at org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notifyURLOnce(JobEndNotifier.java:95)
	at org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notify(JobEndNotifier.java:139)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:388)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:375)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)
{noformat}",0
"The following tests fail:
org.apache.hadoop.mapred.TestQueueManagerRefresh.testRefreshWithRemovedQueues 
org.apache.hadoop.mapred.TestQueueManagerRefresh.testRefreshOfSchedulerProperties 

It looks like its simply trying to remove one of the queues but the remove is failing.It looks like MAPREDUCE-3328. mapred queue -list output inconsistent and missing child queues - change the getChilren routine to do a new JobQueueInfo on each one when returning it which is making the remove routine fail since they aren't the same object now.",0
"With the code checked out on last two days. 
Sort Job on 350 node scale with 16800 maps and 680 reduces consistently failing for around last 6 runs
When around 50% of maps are completed, suddenly job jumps to failed state.
On looking at NM log, found RM sent Stop Container Request to NM for AM container.
But at INFO level from RM log not able find why RM is killing AM when job is not killed manually.
One thing found common on failed AM logs is -:
org.apache.hadoop.yarn.state.InvalidStateTransitonException
With with different.
For e.g. One log says -:
{code}
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_UPDATE at ASSIGNED 
{code}
Whereas other logs says -:
{code}
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_COUNTER_UPDATE at ERROR
{code}

",0
Roll up bug for gridmix3 benchmark,0
"On a secure cluster, when running a job we are seeing a lot of PriviledgedActionException / SaslExceptions.  The job runs fine, its just the jobclient can't connect to the AM to get the progress information.

Its in a very tight loop retrying while getting the exceptions.

snip of the client log is:
12/01/13 15:33:45 INFO security.SecurityUtil: Acquired token Ident: 00 1c 68 61 64 6f 6f 70 71 61 40 44 45 56 2e 59 47
52 49 44 2e 59 41 48 4f 4f 2e 43 4f 4d 08 6d 61 70 72 65 64 71 61 00 8a 01 34 d7 b3 ff f5 8a 01 34 fb c0 83 f5 08 02,
Kind: HDFS_DELEGATION_TOKEN, Service: 10.10.10.10:8020
12/01/13 15:33:45 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 8 for user1 on 10.10.10.10:8020
12/01/13 15:33:45 INFO security.TokenCache: Got dt for
hdfs://host1.domain.com:8020;uri=10.10.10.10:8020;t.service=10.10.10.10:8020
12/01/13 15:33:45 WARN conf.Configuration: mapred.used.genericoptionsparser is deprecated. Instead, use
mapreduce.client.genericoptionsparser.used
12/01/13 15:33:45 INFO mapreduce.JobSubmitter: number of splits:2
12/01/13 15:33:45 INFO mapred.ResourceMgrDelegate: Submitted application application_1326410042859_0008 to
ResourceManager at rmhost.domain/10.10.10.11:8040
12/01/13 15:33:45 INFO mapreduce.Job: Running job: job_1326410042859_0008
12/01/13 15:33:52 INFO mapred.ClientServiceDelegate: The url to track the job:
rmhost.domain:8088/proxy/application_1326410042859_0008/
12/01/13 15:33:52 ERROR security.UserGroupInformation: PriviledgedActionException as:user1@DEV.YGRID.YAHOO.COM
(auth:SIMPLE) cause:javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Fail
ed to find any
Kerberos tgt)]
12/01/13 15:33:52 WARN ipc.Client: Exception encountered while connecting to the server :
javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided
(Mechanism level: Failed to find any Kerberos tgt)]
12/01/13 15:33:52 ERROR security.UserGroupInformation: PriviledgedActionException as:user1@DEV.YGRID.YAHOO.COM
(auth:SIMPLE) cause:java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (
Mechanism level:
Failed to find any Kerberos tgt)]
12/01/13 15:33:52 INFO mapred.ClientServiceDelegate: The url to track the job:
rmhost.domain:8088/proxy/application_1326410042859_0008/",0
"We count maps that are killed, say by speculator, towards JobCounter.NUM_FAILED_MAPS. We should instead have a separate JobCounter for killed maps.

Same with reduces too.",0
"In the Capacity scheduler if you configure the queues to be hierarchical where you have root -> parent queue -> leaf queue, the leaf queue doesn't calculate the used capacity properly. It seems to be using the entire cluster memory rather then its parents memory capacity. 

In updateResource in LeafQueue:
    setUsedCapacity(
        usedResources.getMemory() / (clusterResource.getMemory() * capacity));

I think the clusterResource.getMemory() should be something like getParentsMemory().",0
"In the Capacity scheduler if you configure the queues to be hierarchical where you have root -> parent queue -> leaf queue, the leaf queue doesn't take into account its parents maximum capacity when calculate its own maximum capacity, instead it seems to use the parents capacity.  Looking at the code its using the parents absoluteCapacity and I think it should be using the parents absoluteMaximumCapacity.

It also seems to only use the parents capacity in the leaf queues max capacity calculation when the leaf queue has a max capacity configured. If the leaf queues maximum-capacity is not configured, then it can use 100% of the cluster.  ",0
"We need better error messages in the UI if the AM gets killed or throws an Exception.

If the following error gets thrown: 
java.lang.NumberFormatException: For input string: ""9223372036854775807l"" // last char is an L

then the UI should say this exception.  Instead I get the following:

Application application_1326504761991_0018 failed 1 times due to AM Container for appattempt_1326504761991_0018_000001
exited with exitCode: 1 due to: Exception from container-launch: org.apache.hadoop.util.Shell$ExitCodeException",0
"12/01/19 02:56:22 ERROR security.UserGroupInformation: PriviledgedActionException as:XXX@XXX(auth:KERBEROS) cause:java.io.IOException: Failed to specify server's Kerberos principal name
12/01/19 02:56:22 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.",0
"I had a hadoop.http.filter.initializers in place to do user authentication, but was purposely trying to let it bypass authentication on certain pages.  One of those was the proxy and the application master main page. When I then tried to go to the application master through the proxy it throws an internal server error:

Problem accessing /mapreduce. Reason:

    INTERNAL_SERVER_ERROR
Caused by:

java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:100)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:940)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)


It looks like the problem is that AmIpFilter doesn't check for null returned from httpReq.getCookies()",0
"Submitted an application with the following configuration
{code:xml}
<property>
 <name>yarn.resourcemanager.am.max-retries</name>
 <value>2</value>
</property>
{code}
In the above case, application had failed first time. So AM attempted the same application again. 
While attempting the same application, *Apps Submitted* counter also has been incremented.",0
"The last split generated by FileInputFormat.getSplits considers {{blkLocations.length-1}} to be the hosts for the split.
The last split may be larger than the rest (SPLIT_SLOP=1.1 by default) - in which case locality is picked up from a smaller block.
e.g. 1027MB file with a 128MB split size. The last split ends up being 131MB. The hosts for locality end up being the nodes containing the 3MB block instead of the 128MB block.
",0
"With multiple jobs submitted per user, and multiple users submitting jobs - the headroom reported to the AppMasters is incorrect (very high).
Leads to a deadlock - reduces started, map tasks not complete... and reduces are not preempted by the AM due to the incorrect headroom.",0
"[~karams] found this long time back and we(Sid/I) ran into this again.

Logs to follow..",0
container-launch.sh specifies java option java.io.tmpdir when executing the java process for the child container but fails to create the tmpdir. All uses of createTempFile and other commands relying on java.io.tmpdir will fail when called from child container jvms.,0
"If all current {{Fetcher}}s complete while an in-memory merge is in progress - shuffle could hang. 
Specifically - if the memory freed by an in-memory merge does not bring {{MergeManager.usedMemory}} below {{MergeManager.memoryLimit}} and all current Fetchers complete before the in-memory merge completes, another in-memory merge will not be triggered - and shuffle will hang. (All new fetchers are asked to WAIT).
",0
"Oozie launcher job (for MR/Pig/Hive/Sqoop action) reads the location of the jobtoken file from the *HADOOP_TOKEN_FILE_LOCATION* ENV var and seeds it as the *mapreduce.job.credentials.binary* property in the jobconf that will be used to launch the real (MR/Pig/Hive/Sqoop) job.

The MR/Pig/Hive/Sqoop submission code (via Hadoop job submission) uses correctly the injected *mapreduce.job.credentials.binary* property to load the credentials and submit their MR jobs.

The problem is that the *mapreduce.job.credentials.binary* property also makes it to the tasks of the MR/Pig/Hive/Sqoop MR jobs.

If for some reason the MR/Pig/Hive/Sqoop MR code does some logic that triggers the credential loading, because the property is set, the credential loading fails trying to load a jobtoken file of the launcher job which does not exists in the context of the MR/Pig/Hive/Sqoop jobs.

More specifically, we are seeing this happening with certain hive queries that trigger a conditional code within their RowContainer which then uses the FileInputFormat.getSplits() and then the TokenCache tries to load credentials for a file that is for the wrong job.
",0
"While running the simplest of jobs (Pi) on MR2 in a fully secure configuration I have noticed that the job was failing on the reduce side with the following messages littering the nodemanager logs:

{noformat}
2012-01-19 08:35:32,544 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error
org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find usercache/rvs/appcache/application_1326928483038_0001/output/attempt_1326928483038_0001_m_000003_0/file.out.index in any of the configured local directories
{noformat}

While digging further I found out that the permissions on the files/dirs were prohibiting nodemanager (running under the user yarn) to access these files:

{noformat}
$ ls -l /data/3/yarn/usercache/testuser/appcache/application_1327102703969_0001/output/attempt_1327102703969_0001_m_000001_0
-rw-r----- 1 testuser testuser 28 Jan 20 15:41 file.out
-rw-r----- 1 testuser testuser 32 Jan 20 15:41 file.out.index
{noformat}

Digging even further revealed that the group-sticky bit that was faithfully put on all the subdirectories between testuser and application_1327102703969_0001 was gone from output and attempt_1327102703969_0001_m_000001_0. 

Looking into how these subdirectories are created (org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.initDirs())
{noformat}
      // $x/usercache/$user/appcache/$appId/filecache
      Path appFileCacheDir = new Path(appBase, FILECACHE);
      appsFileCacheDirs[i] = appFileCacheDir.toString();
      lfs.mkdir(appFileCacheDir, null, false);
      // $x/usercache/$user/appcache/$appId/output
      lfs.mkdir(new Path(appBase, OUTPUTDIR), null, false);
{noformat}

Reveals that lfs.mkdir ends up manipulating permissions and thus clears sticky bit from output and filecache.

At this point I'm at a loss about how this is supposed to work. My understanding was
that the whole sequence of events here was predicated on a sticky bit set so
that daemons running under the user yarn (default group yarn) can have access
to the resulting files and subdirectories down at output and below. Please let
me know if I'm missing something or whether this is just a bug that needs to be fixed.

On a related note, when the shuffle side of the Pi job failed the job itself didn't.
It went into the endless loop and only exited when it exhausted all the local storage
for the log files (at which point the nodemanager died and thus the job ended). Perhaps
this is even more serious side effect of this issue that needs to be investigated 
separately.",0
"I'm seeing the same failure as MAPREDUCE-3462 in downstream projects running against a recent build of branch-23. MR-3462 modified the tests rather than fixing the framework. In that jira Ravi mentioned ""I'm still ignorant of the change which made the tests start to fail. I should probably understand better the reasons for that change before proposing a more generalized fix."" Let's figure out the general fix (rather than require all projects to set mapreduce.job.hdfs-servers in their conf we should fix this in the framework). Perhaps we should not default this config to ""$fs.default.name""?",0
"If an AppLogAggregator thread dies unexpectedly (e.g.: uncaught exception like OutOfMemoryError in the case I saw) then this will lead to a hang during nodemanager shutdown.  The NM calls AppLogAggregatorImpl.join() during shutdown to make sure log aggregation has completed, and that method internally waits for an atomic boolean to be set by the log aggregation thread to indicate it has finished.  Since the thread was killed off earlier due to an uncaught exception, the boolean will never be set and the NM hangs during shutdown repeating something like this every second in the log file:

2012-01-25 22:20:56,366 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl: Waiting for aggregation to complete for application_1326848182580_2806",0
nan,0
"Iterating over a counter's groups while adding more groups will cause a ConcurrentModificationException.

This was found while running Hive unit tests against a recent 0.23 version.",0
nan,0
Rumen Folder is not adjusting the shuffleFinished and sortFinished times of reduce task attempts when it is adjusting the attempt-start-time and attempt-finish-time. This is leading to wrong values which are greater than the attempt-finish-time in trace file.,0
"The AM info field on ""bin/mapred job -list"" currently has a value <resourcemanager hostname>:8088/proxy/appID. This info is irrelevant unless it shows the real information of where the AM was launched. This needs to be fixed to show the AM host details.",0
"Thanks to [~harip] for pointing out the issue. This is the stack trace for bringing up RM with default CS configs:

{code}
java.lang.IllegalArgumentException: Illegal value  of maximumCapacity -0.01 used in call to setMaxCapacity for queue default
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueueUtils.checkMaxCapacity(CSQueueUtils.java:28)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.setupQueueConfigs(LeafQueue.java:210)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.<init>(LeafQueue.java:184)
{code}",0
"If a streaming job doesn't consume all of its input then the job can be marked successful even though the job's output is truncated.

Here's a simple setup that can exhibit the problem.  Note that the job output will most likely be truncated compared to the same job run with a zero-length input file.

{code}
$ hdfs dfs -cat in
foo
$ yarn jar ./share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -Dmapred.map.tasks=1 -Dmapred.reduce.tasks=1 -mapper /bin/env -reducer NONE -input in -output out
{code}

Examining the map task log shows this:

{code:title=Excerpt from map task stdout log}
2012-02-02 11:27:25,054 WARN [main] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: Broken pipe
2012-02-02 11:27:25,054 INFO [main] org.apache.hadoop.streaming.PipeMapRed: mapRedFinished
2012-02-02 11:27:25,056 WARN [Thread-12] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: Bad file descriptor
2012-02-02 11:27:25,124 INFO [main] org.apache.hadoop.mapred.Task: Task:attempt_1328203555769_0001_m_000000_0 is done. And is in the process of commiting
2012-02-02 11:27:25,127 WARN [Thread-11] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: DFSOutputStream is closed
2012-02-02 11:27:25,199 INFO [main] org.apache.hadoop.mapred.Task: Task attempt_1328203555769_0001_m_000000_0 is allowed to commit now
2012-02-02 11:27:25,225 INFO [main] org.apache.hadoop.mapred.FileOutputCommitter: Saved output of task 'attempt_1328203555769_0001_m_000000_0' to hdfs://localhost:9000/user/somebody/out/_temporary/1
2012-02-02 11:27:27,834 INFO [main] org.apache.hadoop.mapred.Task: Task 'attempt_1328203555769_0001_m_000000_0' done.
{code}

In PipeMapRed.mapRedFinished() we can see it will eat IOExceptions and return without waiting for the output threads or throwing a runtime exception to fail the job.  Net result is that the DFS streams could be shutdown too early if the output threads are still busy and we could lose job output.

Fixing this brings up the bigger question of what *should* happen when a streaming job doesn't consume all of its input.  Should we have grabbed all of the output from the job and still marked it successful or should we have failed the job?  If the former then we need to fix some other places in the code as well, since feeding a much larger input file (e.g.: 600K) to the same sample streaming job results in the job failing with the exception below.  It wouldn't be consistent to fail the job that doesn't consume a lot of input but pass the job that leaves just a few leftovers.

{code}
2012-02-02 10:29:37,220 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1270)) - Running job: job_1328200108174_0001
2012-02-02 10:29:44,354 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1291)) - Job job_1328200108174_0001 running in uber mode : false
2012-02-02 10:29:44,355 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1298)) -  map 0% reduce 0%
2012-02-02 10:29:46,394 INFO  mapreduce.Job (Job.java:printTaskEvents(1386)) - Task Id : attempt_1328200108174_0001_m_000000_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:282)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:109)
	at java.io.DataOutputStream.write(DataOutputStream.java:90)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:394)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:329)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)
{code}

Assuming the job returns a successful exit code, I think we should allow the job to complete successfully even though it doesn't consume all of its inputs.  Part of the reasoning is that there's already this comment in PipeMapper.java that implies we desire that behavior:

{code:title=PipeMapper.java}
        // terminate with success:
        // swallow input records although the stream processor failed/closed
{code}",0
"""mapred job -list"" lists only the jobs submitted by the user who ran the command. This behavior is different from 1.x. 
",0
nan,0
"Yarn webapp interface may be vulnerable to certain cross scripting attacks, injected through URL request.

",0
"This was while running LoadGen.

{noformat}
Error: java.lang.NullPointerException at org.apache.hadoop.fs.Path.<init>(Path.java:67) 
at org.apache.hadoop.fs.Path.<init>(Path.java:56) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingJobAttemptsPath(FileOutputCommitter.java:118) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(FileOutputCommitter.java:167) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(FileOutputCommitter.java:149) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingTaskAttemptsPath(FileOutputCommitter.java:185) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:209) 
at org.apache.hadoop.mapred.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:100) 
at org.apache.hadoop.mapred.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:94) 
at org.apache.hadoop.mapred.FileOutputCommitter.needsTaskCommit(FileOutputCommitter.java:176) 
at org.apache.hadoop.mapred.OutputCommitter.needsTaskCommit(OutputCommitter.java:248) 
at org.apache.hadoop.mapred.Task.isCommitRequired(Task.java:955) 
at org.apache.hadoop.mapred.Task.done(Task.java:912) 
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331) 
at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Subject.java:396) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157) 
at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)
{noformat}",0
TestJobCounters fails sometimes on trunk. I have tracked it down to stats issue in FileSystem. Still working on it. ,0
Distributed caches are not being properly removed by the TaskTracker when they are expected to be expired. ,0
"This is the counterpart to HADOOP-7967.  
MR gets tokens for all input, output and the default filesystem when a MR job is submitted. 

The APIs in FileSystem make it challenging to avoid duplicate tokens when there are file systems that have embedded
filesystems.


Here is the original description that Daryn wrote: 
The token cache currently tries to assume a filesystem's token service key.  The assumption generally worked while there was a one to one mapping of filesystem to token.  With the advent of multi-token filesystems like viewfs, the token cache will try to use a service key (ie. for viewfs) that will never exist (because it really gets the mounted fs tokens).

The descriop",0
nan,0
"This bug was found by Phil Su as part of our testing.

After MAPREDUCE-3354 went in, the Job summary log file seems to have gone missing on the
RM host.

The job summary log appears to be interspersed in yarn-mapredqa-historyserver-<host>.out. 
e.g. 
12/02/09 15:57:21 INFO jobhistory.JobSummary:
jobId=job_1328658619341_0011,submitTime=1328802904381,launchTime=1328802909977,firstMapTaskLaunchTime=1328802912116,firstReduceTaskLaunchTime=1328802915074,finishTime=1328802933797,resourc
esPerMap=1024,resourcesPerReduce=2048,numMaps=10,numReduces=10,user=hadoopqa,queue=default,status=KILLED,mapSlotSeconds=0,reduceSlotSeconds=0

1) On the RM with older hadoop version where the job summary log does not exist
mapredqa 10903  0.0  1.2 1424404 210240 ?      Sl   Feb07   0:19 /home/gs/java/jdk64/current/bin/java -Xmx1000m
-Djava.net.preferIPv4Stack=true
-Djava.library.path=/home/gs/gridre/theoden/share/hadoop/lib/native/Linux-amd64-64:/
home/gs/gridre/theoden/share/hadoop/lib/native/Linux-amd64-64 -Dhadoop.log.dir=/home/gs/var/log/mapredqa
-Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/gs/gridre/theoden/share/hadoop -Dhadoop.id.str=mapredqa
-Dhadoop
.root.logger=INFO,console
-Djava.library.path=/home/gs/gridre/theoden/share/hadoop/lib/native/Linux-amd64-64:/home/gs/gridre/theoden/share/hadoop/lib/native/Linux-amd64-64:/home/gs/gridre/theoden/share/hadoop/lib/nat
ive -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Dmapred.jobsummary.logger=INFO,console
-Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer

2) On the RM with older hadoop version where the job summary log exists
mapredqa 24851  0.0  0.5 1463280 90516 ?       Sl   Jan25   0:37 /home/gs/java/jdk64/current/bin/java
-Dproc_historyserver -Xmx1000m -Dmapred.jobsummary.logger=INFO,JSA -Dyarn.log.dir=/home/gs/var/log/mapredqa
-Dyarn.log.file=yarn.log -Dyarn.home.dir= -Dyarn.id.str= -Dyarn.root.logger=INFO,console
-Djava.library.path=/home/gs/gridre/shelob/share/hadoop/lib/native/Linux-amd64-64
-Dyarn.policy.file=hadoop-policy.xml -Dyarn.log.dir=/home/gs/var/log/mapredqa
-Dyarn.log.file=yarn-mapredqa-historyserver-<host>.log -Dyarn.home.dir= -Dyarn.id.str=mapredqa
-Dyarn.root.logger=INFO,DRFA -Djava.library.path=/home/gs/gridre/shelob/share/hadoop/lib/native/Linux-amd64-64
-Dyarn.policy.file=hadoop-policy.xml -Dmapred.jobsummary.logger=INFO,JSA -Dhadoop.log.dir=/home/gs/var/log/mapredqa
-Dyarn.log.dir=/home/gs/var/log/mapredqa
-Dhadoop.log.file=yarn-mapredqa-historyserver-<host>.log
-Dyarn.log.file=yarn-mapredqa-historyserver-<host>.log
-Dyarn.home.dir=/home/gs/gridre/shelob/share/hadoop -Dhadoop.root.logger=INFO,DRFA -Dyarn.root.logger=INFO,DRFA
-Djava.library.path=/home/gs/gridre/shelob/share/hadoop/lib/native/Linux-amd64-64 -classpath
/home/gs/gridre/shelob/conf/hadoop:/home/gs/gridre/shelob/conf/hadoop:/home/gs/gridre/shelob/conf/hadoop:/home/gs/gridre/shelob/conf/hadoop:/home/gs/gridre/shelob/share/hadoop/share/hadoop/common/lib/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/common/*:/home/gs/gridre/shelob/share/hadoop/hadoop-*-capacity-scheduler.jar:/home/gs/gridre/shelob/share/hadoop/hadoop-*-capacity-scheduler.jar:/home/gs/gridre/shelob/share/hadoop/hadoop-*-capacity-scheduler.jar:/home/gs/gridre/shelob/share/hadoop/share/hadoop/hdfs:/home/gs/gridre/shelob/share/hadoop/share/hadoop/hdfs/lib/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/hdfs/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/mapreduce/lib/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/mapreduce/*:/home/gs/java/jdk64/current/lib/tools.jar:/home/gs/gridre/shelob/share/hadoop/share/hadoop/mapreduce/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/mapreduce/lib/*
org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer

1) On the RM with older hadoop version where the job summary log does not exist
jobhistory ps shows using the option:
-Dmapred.jobsummary.logger=INFO,console 

2) On the RM with older hadoop version where the job summary log exists
jobhistory ps shows using the option:
-Dmapred.jobsummary.logger=INFO,JSA 
-Dmapred.jobsummary.logger=INFO,JSA

",0
nan,0
"When obtaining the tokens for a FileSystem, the TokenCache will read the binary token file if a token is not already in the Credentials. However, it will overwrite any existing tokens in the Credentials with the contents of the binary token file if a single token is missing. This may cause new tokens to be replaced with invalid/cancelled tokens from the binary file. The new tokens will not be canceled, and thus ""leak"" in the namenode until they expire.
The binary tokens should be merged with, but not replace, existing tokens in the Credentials.
The code that reads the binary token file is prefaced with:
//TODO: Need to come up with a better place to put
//this block of code to do with reading the file
Also, the loading of the binary token file is the only reason that the TokenCache has to use getCanonicalService. If this linkage can be broken, then the 1-to-1 filesystem to token service coupling may be removed. And use of getCanonicalService can be removed in a subsequent jira.",0
The TokenCache will repeatedly call the same filesystem for tokens. This is inefficient and can easily be changed to only call each filesystem once.,0
"On a terasort job a task attempt failed during the commit phase. Another attempt was rescheduled, but when it tried to commit it failed.

{noformat}
attempt_1329019187148_0083_r_000586_0 already given a go for committing the task output, so killing attempt_1329019187148_0083_r_000586_1
{noformat}

The job hung as new attempts kept getting scheduled only to fail during commit.

",0
"Imagine, we have a queue A with capacity 10 slots and 20 as extra-capacity, jobs which use 3 map slots will never consume more than 9 slots, regardless how many free slots on a cluster.",0
nan,0
"TestContainerLauncher is failing intermittently for me.

{noformat}
junit.framework.AssertionFailedError: Expected: <null> but was: Expected 22 but found 21
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at junit.framework.Assert.assertNull(Assert.java:233)
	at junit.framework.Assert.assertNull(Assert.java:226)
	at org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher.testPoolSize(TestContainerLauncher.java:117)
{noformat}

Patch momentarily.",0
running pig job on oozie hangs due to race condition,0
nan,0
"in 1.0 there was a config mapreduce.cluster.administrators that allowed administrators to view anyones job.  That no longer works on yarn.
yarn has the new config yarn.admin.acl but it appears the mr app master and job history server don't use that.  ",0
User is not allowed to submit applications to a queue even though the queue is configured correctly and mapred queue -showacls shows that the user is allowed to submit,0
"When set mapred.max.map.failures.percent and there does have some failed maps, then shuffle will hang",0
"[~karams] reported this offline. Seems that tasks are randomly failing during gridmix runs:
{code}
2012-02-24 21:03:34,912 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1330116323296_0140_m_003868_0: RemoteTrace:
java.io.IOException: Resource hdfs://hostname.com:8020/user/hadoop15/.staging/job_1330116323296_0140/job.jar changed on src filesystem (expected 2971811411, was 1330116705875
       at org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:90)
       at org.apache.hadoop.yarn.util.FSDownload.access$000(FSDownload.java:49)
       at org.apache.hadoop.yarn.util.FSDownload$1.run(FSDownload.java:157)
       at org.apache.hadoop.yarn.util.FSDownload$1.run(FSDownload.java:155)
       at java.security.AccessController.doPrivileged(Native Method)
       at javax.security.auth.Subject.doAs(Subject.java:396)
       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
       at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:153)
       at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:49)
       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
       at java.util.concurrent.FutureTask.run(FutureTask.java:138)
       at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
       at java.util.concurrent.FutureTask.run(FutureTask.java:138)
       at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
       at java.lang.Thread.run(Thread.java:619)
 at LocalTrace:
       org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Resource hdfs://hostname.com:8020/user/hadoop15/.staging/job_1330116323296_0140/job.jar changed on src filesystem (expected 2971811411, was 1330116705875
       at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.convertFromProtoFormat(LocalResourceStatusPBImpl.java:217)
       at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.getException(LocalResourceStatusPBImpl.java:147)
       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.update(ResourceLocalizationService.java:827)
       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker.processHeartbeat(ResourceLocalizationService.java:497)
       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.heartbeat(ResourceLocalizationService.java:222)
       at org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.service.LocalizationProtocolPBServiceImpl.heartbeat(LocalizationProtocolPBServiceImpl.java:46)
       at org.apache.hadoop.yarn.proto.LocalizationProtocol$LocalizationProtocolService$2.callBlockingMethod(LocalizationProtocol.java:57)
       at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:342)
       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1493)
       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)
       at java.security.AccessController.doPrivileged(Native Method)
       at javax.security.auth.Subject.doAs(Subject.java:396)
       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1487)
{code}",0
"[~karams] reported this offline. One reduce task gets preempted because of zero headRoom and crashes the AM.
{code}
2012-02-23 11:30:15,956 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 44544
2012-02-23 11:30:16,959 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 44544
2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0
2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Assign: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0
2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 3
2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000006 to attempt_1329995034628_0983_r_000000_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000007 to attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000008 to attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Assign: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:20 AssignedMaps:0 AssignedReduces:3 completedMaps:4 completedReduces:0 containersAllocated:7 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down all scheduled reduces:20
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Going to preempt 2
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule...
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.4 totalMemLimit:4608 finalMapMemLimit:2765 finalReduceMemLimit:1843 netScheduledMapMem:9216 netScheduledReduceMem:4608
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down 0
2012-02-23 11:30:16,968 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host6 to /$rack6
2012-02-23 11:30:16,976 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2012-02-23 11:30:16,976 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host1 to /$rack1
2012-02-23 11:30:16,977 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2012-02-23 11:30:16,981 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host9 to /$rack9
2012-02-23 11:30:16,982 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2012-02-23 11:30:16,982 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000002_0 TaskAttempt Transitioned from ASSIGNED to KILL_CONTAINER_CLEANUP
2012-02-23 11:30:16,983 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from ASSIGNED to KILL_CONTAINER_CLEANUP
2012-02-23 11:30:16,983 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000000_0
2012-02-23 11:30:16,983 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,983 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000000_0
2012-02-23 11:30:16,984 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,984 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for taskAttempt attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,984 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for taskAttempt attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,987 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,988 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,988 ERROR [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Container was killed before it was launched
2012-02-23 11:30:17,061 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1329995034628_0983_r_000000_0 : 53990
2012-02-23 11:30:17,077 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2012-02-23 11:30:17,077 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1329995034628_0983_r_000001_0: Container was killed before it was launched
2012-02-23 11:30:17,078 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1329995034628_0983_r_000001_0
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_CONTAINER_LAUNCH_FAILED at KILL_TASK_CLEANUP
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:926)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:135)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:870)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:862)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)
	at java.lang.Thread.run(Thread.java:619)
2012-02-23 11:30:17,080 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1329995034628_0983_r_000000_0] using containerId: [container_1329995034628_0983_01_000006 on NM: [$host6:51529]
2012-02-23 11:30:17,081 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2012-02-23 11:30:17,207 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1329995034628_0983_r_000002_0 : 47960
2012-02-23 11:30:17,207 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:17,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1329995034628_0983Job Transitioned from RUNNING to ERROR
2012-02-23 11:30:17,216 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_COUNTER_UPDATE at ERROR
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:657)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:111)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:848)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:844)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)
	at java.lang.Thread.run(Thread.java:619)

{code}",0
"RM should generate the expiry time for a container
A ContainerToken should have its expire time encoded
NMs should reject containers with expired tokens.
Expiry interval for a ContainerToken is same as the expiry interval for a container.",0
"Master key for authentication of AMs need to be automatically generated.
The key needs to be rolled every so often but AMs with old keys should continue to be able to talk to the RM.",0
JobHistoryServer gives off delegation tokens so that clients can talk to it. It needs to store them off somewhere to authenticate clients across the server restart,0
"Hive get unexpected result when using MR2(When using MR1, always get expected result).

In MR2, when Total input paths to process == 1, CombinefileInputFormat.getSplits() returns 0 split.

The calling code in Hive, in Hadoop23Shims.java:

InputSplit[] splits = super.getSplits(job, numSplits);

this get splits.length == 0.

In MR1, everything goes fine, the calling code in Hive, in Hadoop20Shims.java:

CombineFileSplit[] splits = (CombineFileSplit[]) super.getSplits(job, numSplits);

this get splits.length == 1.",0
When TaskImpl transitions to SUCCEEDED then it kills the other running task attempts. In the SUCCEEDED state the TaskImpl state machine ignores T_ATTEMPT_KILLED events from those killed attempts. Hence those completions events are not reported to the job. Every other attempt completion event is reported to the job.,0
"After MAPREDUCE-3975, mapreduce.job.local.dir is set correctly for the tasks but it doesn't point to the same directory for all tasks running on the node.

It is a public API. Either we should point to a single directory or point it to all directories and change the documentation to say that it points to all dirs.",0
"Currently, the reduce fetch code doesn't check the HTTP status code of the response. This can lead to the following situation:
- the map output servlet gets an IOException after setting the headers but before the first call to flush()
- this causes it to send a response with a non-OK result code, including the exception text as the response body (response.sendError() does this if the response isn't committed)
- it will still include the response headers indicating it's a valid response

In the case of a merge-to-memory, the compression codec might then try to interpret the HTML response as compressed data, resulting in either a huge allocation (OOME) or some other nasty error. This bug seems to be present in MR1, but haven't checked trunk/MR2 yet.",0
"When using a compression codec for intermediate compression, some cases of corrupt data can cause the codec to throw exceptions other than IOException (eg java.lang.InternalError). This will currently cause the whole reduce task to fail, instead of simply treating it like another case of a failed fetch.",0
"hello锛孖 have dwelled on this hadoop(cdhu3) problem for 2 days,I have tried every google method.This is the issue: when ran hadoop example ""wordcount"" ,the tasktracker's log in one slave node presented such errors

 1.WARN org.apache.hadoop.mapred.DefaultTaskController: Task wrapper stderr: bash: /var/tmp/mapred/local/ttprivate/taskTracker/hdfs/jobcache/job_201203131751_0003/attempt_201203131751_0003_m_000006_0/taskjvm.sh: Permission denied

2.WARN org.apache.hadoop.mapred.TaskRunner: attempt_201203131751_0003_m_000006_0 : Child Error java.io.IOException: Task process exit with nonzero status of 126.

3.WARN org.apache.hadoop.mapred.TaskLog: Failed to retrieve stdout log for task: attempt_201203131751_0003_m_000003_0 java.io.FileNotFoundException: /usr/lib/hadoop-0.20/logs/userlogs/job_201203131751_0003/attempt_201203131751_0003_m_000003_0/log.index (No such file or directory)

I could not find similar issues in google,just got some posts seem a little relevant ,which suggest: A. the ulimit of hadoop user----but my ulimit is set large enough for this bundled example;B. the memory used by jvm,but my jvm only use Xmx200m,too small to exceed the limit of my machine ;C.the privilege of the mapred.local.dir and logs dir----I set them by ""chmod 777"";D .the disk space is full----there are enough space for hadoop in my log directory and mapred.local.dir.

Thanks for you all,I am really at my wit's end,I have spend days on it. I really appreciate any light!
",0
"If a task attempt reports a bogus progress value (e.g.: something above 1.0) then the AM can crash like this:

{noformat}
java.lang.ArrayIndexOutOfBoundsException: 12
	at org.apache.hadoop.mapred.PeriodicStatsAccumulator.extend(PeriodicStatsAccumulator.java:185)
	at org.apache.hadoop.mapred.WrappedPeriodicStatsAccumulator.extend(WrappedPeriodicStatsAccumulator.java:31)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.updateProgressSplits(TaskAttemptImpl.java:1043)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.access$4100(TaskAttemptImpl.java:136)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$StatusUpdater.transition(TaskAttemptImpl.java:1509)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$StatusUpdater.transition(TaskAttemptImpl.java:1490)
	at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:931)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:135)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:886)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:878)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:74)
	at java.lang.Thread.run(Thread.java:619)
{noformat}",0
"I have the MAPREDUCE-3862 changes which fixed this issue earlier and ""yarn.nodemanager.delete.debug-delay-sec"" set to default value but still getting this issue.",0
"With log aggregation enabled, users other than the app owner or admins are sometimes unable to view the task logs on the history server even though they are in the ACL for the app.  The same users are able to see the configuration and counters.  Sometimes the users can see some task logs but not other task logs for the same application.",0
"The following scenario works in 0.20.205 but no longer works in 0.23:

1) During job submission, a secret key is set by calling jobConf.getCredentials().addSecretKey(Text, byte[])
2) A map task retrieves the secret key by calling jobConf.getCredentials().getSecretKey(Text)

In 205 the secret key is retrieved successfully but in 0.23 the secret key is missing.",0
"The application master launcher has a thread pool that is configured with core size 1, maximum 10.  The thread pool will not create over
the core size thread unless the queue it is using is full. We are using an unbounded queue, so the thread pool will only ever create 1 thread.  We need to have more then 1 AM launch thread.

If that thread becomes hung for some reason, the RM can no longer launch any application masters.  We have seen an instance of this when a NM become unresponsive - something bad happened to host, not sure what yet.  ",0
"We saw an instance where the RM stopped launch Application masters.  We found that the launcher thread was hung because something weird/bad happened to the NM node. Currently there is only 1 launcher thread (jira 4061 to fix that). We need this to not happen.  Even once we increase the number of threads  to > 1 if that many nodes go bad the RM would be stuck.  Note that this was stuck like this for approximately 9 hours.

Stack trace on hung AM launcher:

""pool-1-thread-1"" prio=10 tid=0x000000004343e800 nid=0x3a4c in Object.wait()
[0x000000004fad2000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    at java.lang.Object.wait(Object.java:485)
    at org.apache.hadoop.ipc.Client.call(Client.java:1076)
    - locked <0x00002aab05a4f3f0> (a org.apache.hadoop.ipc.Client$Call)
    at
org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:135)
    at $Proxy76.startContainer(Unknown Source)
    at
org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:87)
    at
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:118)
    at
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:265)
    at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:619)",0
"Prior to hadoop 0.23, users could add third party jars to the lib subdirectory of the submitted job jar and they become available in the task's classpath. I see this functionality was in TaskRunner.java, but I can't see similar functionality in hadoop 0.23 (neither in MapReduceChildJVM.java nor other places).",0
"While running the shutdown hook of MRAppMaster, hit NPE
{noformat}
Exception in thread ""Thread-1"" java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.setSignalled(MRAppMaster.java:668)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1004)
{noformat}",0
"CS is supposed to be allocating a single off-switch container per node heartbeat (MAPREDUCE-3641). This works for queues directly under root, but not in the case of multi-level queues.
",0
"Client continuously tries to RM and logs the below messages when the RM goes down before launching App Master. 

I feel exception should be thrown or break the loop after finite no of retries.

{code:xml}
28/03/12 07:15:03 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 0 time(s).
28/03/12 07:15:04 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 1 time(s).
28/03/12 07:15:05 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 2 time(s).
28/03/12 07:15:06 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 3 time(s).
28/03/12 07:15:07 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 4 time(s).
28/03/12 07:15:08 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 5 time(s).
28/03/12 07:15:09 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 6 time(s).
28/03/12 07:15:10 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 7 time(s).
28/03/12 07:15:11 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 8 time(s).
28/03/12 07:15:12 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 9 time(s).
28/03/12 07:15:13 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 0 time(s).
28/03/12 07:15:14 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 1 time(s).
28/03/12 07:15:15 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 2 time(s).
28/03/12 07:15:16 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 3 time(s).
28/03/12 07:15:17 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 4 time(s).
{code}",0
"The AM will timeout a task through mapreduce.task.timeout only when it does not hear from the task within the given timeframe.  On 1.0 a task must be making progress, either by reading input from HDFS, writing output to HDFS, writing to a log, or calling a special method to inform it that it is still making progress.

This is because on 0.23 a status update which happens every 3 seconds is counted as progress.",0
"If commitJob throws an exception JobImpl will swallow the exception with a warning and succeed the Job. This is a break from 0.20 and 1.0 where commitJob exception will fail the job

Exception logged in the AM as WARN
  org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Could not do commit for Job
Job still finishes as succeeded",0
nan,0
"{code:xml}
dev@ubuntudev-linux:~/hadoop/hadoop-trunk/bin$ ./mapred job -status job_1333408894669_0001

Exception in thread ""main"" java.lang.NullPointerException
    at org.apache.hadoop.mapreduce.Job.getTaskFailureEventString(Job.java:512)
    at org.apache.hadoop.mapreduce.Job.toString(Job.java:463)
    at java.lang.String.valueOf(String.java:2838)
    at java.io.PrintStream.println(PrintStream.java:788)
    at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:255)
    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
    at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1244)
{code}",0
"When the main thread calls ResourceManager$SchedulerEventDispatcher.stop() it grabs a lock on the object, kicks the event processor thread, and then waits for the thread to exit.  However the interrupted event processor thread can end up trying to call the synchronized getConfig() method which results in deadlock.",0
"The RM on one of our clusters has exited twice in the past few days because of an NPE while trying to handle a NODE_UPDATE:

{noformat}
2012-04-12 02:09:01,672 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler
 [ResourceManager Event Processor]java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateNodeLocal(AppSchedulingInfo.java:261)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:223)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.allocate(SchedulerApp.java:246)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1229)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:1078)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:1048)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignReservedContainer(LeafQueue.java:859)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:756)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:573)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:622)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:78)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:302)
        at java.lang.Thread.run(Thread.java:619)
{noformat}

This is very similar to the failure reported in MAPREDUCE-3005.",0
nan,0
nan,0
"1.Configure ""mapreduce.job.ubertask.enable"" to true
2.Configure ""mapreduce.job.ubertask.maxreduces"" to 0(zero)
3.Run job such that it has one reducer(more than ""mapreduce.job.ubertask.maxreduces"" value) 

Observe that job is running in Uber mode instead of normal mode(non uber mode)",0
Use SecurityUtils.setTokenService to set token services.,0
column is mistakenly sorted lexically,0
MAPREDUCE-3607 accidentally left the println statement. ,0
"{noformat}
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo.getLiveNodeManagers(RMNMInfo.java:96)
        at sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)
        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)
        at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:65)
        at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:216)
        at javax.management.StandardMBean.getAttribute(StandardMBean.java:358)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:666)
{noformat}

Looks like rmcontext.getRMNodes() is not kept in sync with scheduler.getNodeReport(), so that the report can be null even though the context still knowns about the node.

The simple fix is to add in a null check.",0
"MAPREDUCE-2767 removed LinuxTaskController. 
This task is revert that so LinuxtaskController is introduced back.",0
There was a recent fix related supplemental groups.,0
"This happens when security is enabled on 22
When TaskTracker starts p, it invokes MRAsyncDiskService moves the contents of scratch/tasktracker to toBeDeleted under a directory created with the current timestamp.
The owner of this directory is hadoop (owner of tasktracker)
The contents of this directory are various usernames and they are owned by individual users. But MRAsyncDiskService tries to delete the newly created directory as hadoop and it fails.
2012-05-01 16:04:58,805 DEBUG org.apache.hadoop.mapred.LinuxTaskController: deleteAsUser: [/apache/hadoop-assemble-argon-0.228/hadoop-0.22-argon-0.105/bin/../bin/task-controller, hadoop, 3, /hadoop00/scratch/toBeDeleted/2012-04-17_16-22-03.965_0]
2012-05-01 16:04:58,809 WARN org.apache.hadoop.mapreduce.util.MRAsyncDiskService: Failure in deletion of toBeDeleted/2012-04-17_16-22-03.965_0 on /hadoop00/scratch with original name /hadoop00/scratch/toBeDeleted/2012-04-17_16-22-03.965_0 with exception org.apache.hadoop.util.Shell$ExitCodeException:
at org.apache.hadoop.util.Shell.runCommand(Shell.java:256)
at org.apache.hadoop.util.Shell.run(Shell.java:183)
at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:376)
at org.apache.hadoop.mapred.LinuxTaskController.deleteAsUser(LinuxTaskController.java:273)
at org.apache.hadoop.mapreduce.util.MRAsyncDiskService$DeleteTask.run(MRAsyncDiskService.java:237)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)",0
"This is the MR side of HADOOP-8393

If you start a pseudo distributed yarn using ""start-yarn.sh"" you need to specify exports for HADOOP_COMMON_HOME, HADOOP_HDFS_HOME, YARN_HOME, YARN_CONF_DIR, and HADOOP_MAPRED_HOME in hadoop-env.sh (or elsewhere), otherwise the spawned node manager will be missing 
these in it's environment. This is due to start-yarn using yarn-daemons. With this fix it's possible to start yarn (etc...) with only HADOOP_CONF_DIR specified in the environment. Took some time to track down this failure, so seems worthwhile to fix.",0
"{code:xml}
2012-05-14 17:59:41,906 FATAL org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: Error starting JobHistoryServer
org.apache.hadoop.yarn.YarnException: History Server Failed to login
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.init(JobHistoryServer.java:69)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:132)
Caused by: java.io.IOException: Running in secure mode, but config doesn't have a keytab
	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:258)
	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:229)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.doSecureLogin(JobHistoryServer.java:98)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.init(JobHistoryServer.java:67)
	... 1 more
2012-05-14 17:59:41,918 INFO org.apache.hadoop.yarn.service.CompositeService: Error stopping org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.stop(JobHistoryServer.java:115)
	at org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:122)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2012-05-14 17:59:41,918 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: SHUTDOWN_MSG: 
{code}",0
"{code:xml}
2012-05-16 18:55:54,222 INFO [Thread-1] org.apache.hadoop.yarn.service.CompositeService: Error stopping org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter.stop(MRAppMaster.java:716)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1036)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2012-05-16 18:55:54,222 INFO [Thread-1] org.apache.hadoop.yarn.service.CompositeService: Error stopping org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getStat(RMContainerAllocator.java:521)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.stop(RMContainerAllocator.java:227)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.stop(MRAppMaster.java:668)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1036)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
{code}",0
nan,0
"Allow setting yarn.nodemanager.delete.debug-delay-sec property to ""-1"" to have it never clear (like older TT time).",0
"I cannot run two local mode jobs from Pig in parallel from the same gateway, this is a typical use case. If I re-run the tests sequentially, then the test pass. This seems to be a problem from Hadoop.

Additionally, the pig harness, expects to be able to run Pig-version-undertest against Pig-version-stable from the same gateway.


To replicate the error:

I have two clusters running from the same gateway.
If I run the Pig regression suites nightly.conf in local mode in paralell - once on each cluster. Conflicts in M/R local mode result in failures in the tests. 


ERROR1:

org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find
output/file.out in any of the configured local directories
        at
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:429)
        at
org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:160)
        at
org.apache.hadoop.mapred.MapOutputFile.getOutputFile(MapOutputFile.java:56)
        at org.apache.hadoop.mapred.Task.calculateOutputSize(Task.java:944)
        at org.apache.hadoop.mapred.Task.sendLastUpdate(Task.java:924)
        at org.apache.hadoop.mapred.Task.done(Task.java:875)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:374)
---

ERROR2:

2012-05-17 20:25:36,762 [main] INFO
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher
-
HadoopJobId: job_local_0001
2012-05-17 20:25:36,778 [Thread-3] INFO  org.apache.hadoop.mapred.Task -
Using ResourceCalculatorPlugin : org.apache.
hadoop.util.LinuxResourceCalculatorPlugin@ffa490e
2012-05-17 20:25:36,837 [Thread-3] WARN
org.apache.hadoop.mapred.LocalJobRunner - job_local_0001
java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
        at java.util.ArrayList.RangeCheck(ArrayList.java:547)
        at java.util.ArrayList.get(ArrayList.java:322)
        at
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getLoadFunc(PigInputFormat.java
:153)
        at
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.createRecordReader(PigInputForm
at.java:106)
        at
org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:489)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:731)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:370)
        at
org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:212)
2012-05-17 20:25:41,291 [main] INFO
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher
",0
"{noformat}
java.io.IOException: Server returned HTTP response code: 400 for URL: http://HOST-10-18-52-224:8080/tasklog?plaintext=true&attemptid=attempt_1338370885386_0006_m_000000_0&filter=profile
        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1290)
        at org.apache.hadoop.mapreduce.Job.downloadProfile(Job.java:1421)
        at org.apache.hadoop.mapreduce.Job.printTaskEvents(Job.java:1376)
        at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1310)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1247)
        at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:200)
{noformat}",0
"we had a DNS outage and the RM crashed with the following backtrace:

2012-05-29 19:17:34,492 FATAL
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in
handling event type NODE_UPDATE to the scheduler
java.lang.IllegalArgumentException: java.net.UnknownHostException:
host.com        at
org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:430)
        at
org.apache.hadoop.yarn.util.BuilderUtils.newContainerToken(BuilderUtils.java:261)
       at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.createContainer(LeafQueue.java:1184)
        at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getContainer(LeafQueue.java:1167)
        at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1213)",0
"What happens is that the number of reducers ramp up until they occupy all of the job's containers, at which point the maps no longer make any progress and the job hangs.

When the same job is run with the CapacityScheduler it succeeds, so this looks like a FifoScheduler bug.",0
"It looks like 4 threads in the AM died with OOM but not the one pinging the RM.

stderr for this AM
{noformat}
WARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.
May 30, 2012 4:49:55 AM com.google.inject.servlet.InternalServletModule$BackwardsCompatibleServletContextProvider get
WARNING: You are attempting to use a deprecated API (specifically, attempting to @Inject ServletContext inside an eagerly created singleton. While we allow this for backwards compatibility, be warned that this MAY have unexpected behavior if you have more than one injector (with ServletModule) running in the same JVM. Please consult the Guice documentation at http://code.google.com/p/google-guice/wiki/Servlets for more information.
May 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class
May 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
May 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class
May 30, 2012 4:49:55 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.8 06/24/2011 12:17 PM'
May 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope ""Singleton""
May 30, 2012 4:49:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope ""Singleton""
May 30, 2012 4:49:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope ""PerRequest""
Exception in thread ""ResponseProcessor for block BP-1114822160-<IP>-1322528669066:blk_-6528896407411719649_34227308"" java.lang.OutOfMemoryError: Java heap space
	at com.google.protobuf.CodedInputStream.(CodedInputStream.java:538)
	at com.google.protobuf.CodedInputStream.newInstance(CodedInputStream.java:55)
	at com.google.protobuf.AbstractMessageLite$Builder.mergeFrom(AbstractMessageLite.java:201)
	at com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:738)
	at org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto.parseFrom(DataTransferProtos.java:7287)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:95)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:656)
Exception in thread ""DefaultSpeculator background processing"" java.lang.OutOfMemoryError: Java heap space
	at java.util.HashMap.resize(HashMap.java:462)
	at java.util.HashMap.addEntry(HashMap.java:755)
	at java.util.HashMap.put(HashMap.java:385)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getTasks(JobImpl.java:632)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.maybeScheduleASpeculation(DefaultSpeculator.java:465)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.maybeScheduleAMapSpeculation(DefaultSpeculator.java:433)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.computeSpeculations(DefaultSpeculator.java:509)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.access$100(DefaultSpeculator.java:56)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator$1.run(DefaultSpeculator.java:176)
	at java.lang.Thread.run(Thread.java:619)
Exception in thread ""Timer for 'MRAppMaster' metrics system"" java.lang.OutOfMemoryError: Java heap space
Exception in thread ""Socket Reader #4 for port 50500"" java.lang.OutOfMemoryError: Java heap space
{noformat}",0
nan,0
"When a container launch request is sent to the NM, if _any_ exception occurs during the init of log aggregation then the NM goes down.  The problem can be induced by situations including, but certainly not limited to: transient rpc connection issues, missing tokens, expired tokens, permissions, full/quota exceeded dfs, etc.  The problem may occur with and without security enabled.

The ramification is an entire cluster can be rather easily brought down either maliciously, accidentally, or via a submission bug.",0
"Using the tarball, if you start the yarn daemons using one user and then switch to a different user. You can successfully run MR jobs, but DS jobs fail to run. Only able to run DS jobs using the user who started the daemons.",0
"The class that does view-based checks, JSPUtil.JobWithViewAccessCheck, has the following internal member:

{code}private boolean isViewAllowed = true;{code}

Note that its true.

Now, in the method that sets proper view-allowed rights, has:

{code}
if (user != null && job != null && jt.areACLsEnabled()) {
      final UserGroupInformation ugi =
        UserGroupInformation.createRemoteUser(user);
      try {
        ugi.doAs(new PrivilegedExceptionAction<Void>() {
          public Void run() throws IOException, ServletException {

            // checks job view permission
            jt.getACLsManager().checkAccess(job, ugi,
                Operation.VIEW_JOB_DETAILS);
            return null;
          }
        });
      } catch (AccessControlException e) {
        String errMsg = ""User "" + ugi.getShortUserName() +
            "" failed to view "" + jobid + ""!<br><br>"" + e.getMessage() +
            ""<hr><a href=\""jobtracker.jsp\"">Go back to JobTracker</a><br>"";
        JSPUtil.setErrorAndForward(errMsg, request, response);
        myJob.setViewAccess(false);
      } catch (InterruptedException e) {
        String errMsg = "" Interrupted while trying to access "" + jobid +
        ""<hr><a href=\""jobtracker.jsp\"">Go back to JobTracker</a><br>"";
        JSPUtil.setErrorAndForward(errMsg, request, response);
        myJob.setViewAccess(false);
      }
    }
    return myJob;
{code}

In the above snippet, you can notice that if user==null, which can happen if user is not http-authenticated (as its got via request.getRemoteUser()), can lead to the view being visible since the default is true and we didn't toggle the view to false for user == null case.

Ideally the default of the view job ACL must be false, or we need an else clause that sets the view rights to false in case of a failure to find the user ID.",0
nan,0
"On running MapReduce job, username is changed to jobid and the job fails.
Exception is as follows:

{code}
2012-06-08 19:39:26,555 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user job_201206081934_0002
org.apache.hadoop.util.Shell$ExitCodeException: id: job_201206081934_0002: no such user

        at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
        at org.apache.hadoop.util.Shell.run(Shell.java:182)
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
        at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
        at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
        at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
        at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
        at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
        at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1026)
        at org.apache.hadoop.security.authorize.AccessControlList.isUserAllowed(AccessControlList.java:141)
        at org.apache.hadoop.security.authorize.ServiceAuthorizationManager.authorize(ServiceAuthorizationManager.java:99)
        at org.apache.hadoop.ipc.Server.authorize(Server.java:1659)
        at org.apache.hadoop.ipc.Server$Connection.authorizeConnection(Server.java:1320)
        at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:1286)
        at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1182)
        at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:537)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:344)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:680)
{code}

This issue can be reproduced by following steps:

1. set hadoop.security.authorization = true in core-site.xml

{code}
  <property>
    <name>hadoop.security.authorization</name>
    <value>true</value>
  </property>
{code}

2. set any value except for '*' to security.task.umbilical.protocol.acl in hadoop-policy.xml

{code}

  <property>
    <name>security.task.umbilical.protocol.acl</name>
    <value>sho sho</value>
    <description>ACL for TaskUmbilicalProtocol, used by the map and reduce 
    tasks to communicate with the parent tasktracker. 
    The ACL is a comma-separated list of user and group names. The user and 
    group list is separated by a blank. For e.g. ""alice,bob users,wheel"". 
    A special value of ""*"" means all users are allowed.</description>
  </property>
{code}

3. run any mapreduce job.


h4. Code Analysis

./src/mapred/org/apache/hadoop/mapred/Child.java:102-118

{code}
    UserGroupInformation taskOwner 
     = UserGroupInformation.createRemoteUser(firstTaskid.getJobID().toString());
    taskOwner.addToken(jt);
    
    // Set the credentials
    defaultConf.setCredentials(credentials);
    
    final TaskUmbilicalProtocol umbilical = 
      taskOwner.doAs(new PrivilegedExceptionAction<TaskUmbilicalProtocol>() {
        @Override
        public TaskUmbilicalProtocol run() throws Exception {
          return (TaskUmbilicalProtocol)RPC.getProxy(TaskUmbilicalProtocol.class,
              TaskUmbilicalProtocol.versionID,
              address,
              defaultConf);
        }
    });
{code}


This code indicates that TaskUmbilicalProtocol uses jobid as username.
This code came from MAPREDUCE-1457. 
https://issues.apache.org/jira/browse/MAPREDUCE-1457

Devaraj said as follows in the JIRA:

{quote}
2) In Child.java, the task authenticates to the TaskTracker using the jobtoken. The username in the jobtoken is jobId. The doAs block done using taskOwner is required so that the username mentioned in the token and the one doing the operation matches.
{quote}

We can't change security.task.umbilical.protocol.acl and should always be '*' .
TaskUmbilicalProtocol should be removed from MapReducePolicyProvider to disable security.task.umbilical.protocol.acl.

",0
nan,0
"jcarder identified this deadlock in branch-1 (though it may also be present in trunk):
- Counters.size() is synchronized and locks Counters before Group
- Counters.Group.getCounterForName() is synchronized and calls through to Counters.size()

This creates a potential cycle which could cause a deadlock (though probably quite rare in practice)",0
"Negative waiting_maps and waiting_reduces count is observed in the mapred metrics.  MAPREDUCE-1238 partially fixed this but it appears there is still issues as we are seeing it, but not as bad.
",0
nan,0
Please find the attached resource manager thread dump for the issue.,0
"{code:xml}
Exception in thread ""Container Monitor"" java.lang.OutOfMemoryError: Java heap space
	at java.io.BufferedReader.<init>(BufferedReader.java:80)
	at java.io.BufferedReader.<init>(BufferedReader.java:91)
	at org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.constructProcessInfo(ProcfsBasedProcessTree.java:410)
	at org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessTree(ProcfsBasedProcessTree.java:171)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.run(ContainersMonitorImpl.java:389)
	Exception in thread ""LocalizerRunner for container_1340690914008_10890_01_000003"" java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOfRange(Arrays.java:3209)
	at java.lang.String.<init>(String.java:215)
	at com.sun.org.apache.xerces.internal.xni.XMLString.toString(XMLString.java:185)
	at com.sun.org.apache.xerces.internal.parsers.AbstractDOMParser.characters(AbstractDOMParser.java:1188)
	at com.sun.org.apache.xerces.internal.xinclude.XIncludeHandler.characters(XIncludeHandler.java:1084)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:464)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:808)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:737)
	at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:119)
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:235)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:284)
	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:180)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1738)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1689)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1635)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:722)
	at org.apache.hadoop.conf.Configuration.setStrings(Configuration.java:1300)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.initDirs(ContainerLocalizer.java:375)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.runLocalization(ContainerLocalizer.java:127)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.startLocalizer(DefaultContainerExecutor.java:103)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:862)
{code}",0
"TestIndexCache is intermittently failing due to a race condition. Up on inspection of IndexCache implementation, more potential issues have been discovered.",0
"{code:title=ClientDistributedCacheManager#determineTimestamps|borderStyle=solid}
URI[] tfiles = DistributedCache.getCacheFiles(job);
{code}

It may be possible that tfiles array contains *null* as it's entry, and subsequently leads to NPE.",0
"There is use-cases where users may need to specify the ports used for the resource manager and history server for the minicluster.

In the current implementation, the MiniCluster sets these addresses regardless of them being already set by the user in the conf.

Users should be able to add these properties to the conf and in such case the MiniCluster will use the specified addresses. If not specified then the current behavior of the MiniCluster for explicitly setting the addresses will be used.

I'll be uploading a patch momentarily.",0
"Currently Shuffle fetches go on the clear. While Kerberos provides comprehensive authentication for the cluster, it does not provide confidentiality. 
When processing sensitive data confidentiality may be desired (at the expense of job performance and resources utilization for doing encryption).",0
"We have observed this issue consistently running hadoop CDH4 version (based upon 2.0 alpha release):

In case our hadoop client code gets a notification for a completed job ( using RunningJob object job, with (job.isComplete() && job.isSuccessful()==false)
the hadoop client code does an unconditional job.killJob() to terminate the job.

With earlier hadoop versions (verified on hadoop 0.20.2 version), we still  have full access to job logs afterwards through hadoop console. However, when using MapReduceV2, the failed hadoop job no longer shows up under jobhistory server. Also, the tracking URL of the job still points to the non-existent Application master http port.

Once we removed the call to job.killJob() for failed jobs from our hadoop client code, we were able to access the job in job history with mapreduce V2 as well. Therefore this appears to be a race condition in the job management wrt. job history for failed jobs.

We do have the application master and node manager logs collected for this scenario if that'll help isolate the problem and the fix better.",0
If the MR AM is notified of container completion by the RM before the AM receives notification of the container cleanup from the NM then it can fail to schedule reducers indefinitely.  Logs showing the issue to follow.,0
"We saw this problem migrating applications to MapReduceV2:

Our applications use hadoop counters extensively (1000+ counters for certain jobs). While this may not be one of recommended best practices in hadoop, the real issue here is reliability of the framework when applications exceed counter limits.

The hadoop servers (yarn, history server) were originally brought up with mapreduce.job.counters.max=1000 under core-site.xml

We then ran map-reduce job under an application using its own job specific overrides, with  mapreduce.job.counters.max=10000

All the tasks for the job finished successfully; however the overall job still failed due to AM encountering exceptions as:

{code}
2012-07-12 17:31:43,485 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks
: 712012-07-12 17:31:43,502 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher threa
dorg.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 1001 max=1000
        at org.apache.hadoop.mapreduce.counters.Limits.checkCounters(Limits.java:58)        at org.apache.hadoop.mapreduce.counters.Limits.incrCounters(Limits.java:65)
        at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.addCounter(AbstractCounterGroup.java:77)        at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.addCounterImpl(AbstractCounterGroup.java:94)
        at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.findCounter(AbstractCounterGroup.java:105)
        at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.incrAllCounters(AbstractCounterGroup.java:202)
        at org.apache.hadoop.mapreduce.counters.AbstractCounters.incrAllCounters(AbstractCounters.java:337)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.constructFinalFullcounters(JobImpl.java:1212)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.mayBeConstructFinalFullCounters(JobImpl.java:1198)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.createJobFinishedEvent(JobImpl.java:1179)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.logJobHistoryFinishedEvent(JobImpl.java:711)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.checkJobCompleteSuccess(JobImpl.java:737)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$TaskCompletedTransition.checkJobForCompletion(JobImpl.java:1360)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$TaskCompletedTransition.transition(JobImpl.java:1340)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$TaskCompletedTransition.transition(JobImpl.java:1323)
        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:380)        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:666)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:113)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:890)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:886)        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:74)        at java.lang.Thread.run(Thread.java:662)
2012-07-12 17:31:43,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..2012-07-12 17:31:43,503 INFO [Thread-1] org.apache.had
{code}

The overall job failed, and the job history wasn't accessible either at the end of the job (didn't show up in job history server).

We were able to workaround the issue by changing to higher limits in core-site.xml and restarting yarn servers. However that forced us to increase the counters global limit to be as high as possible use by any individual application, which is hard to predict.

The original job then succeeded with new global limits. 

However, since we didn't restart the job history server, it was unable to display job history page for the successful job altogether as it still hit counter exceeded exception. Restart of job history server finally got the application available under job history.

I'll also attach AM logs to help debug the issue 

",0
nan,0
"When log aggregation is enabled, the nodemanager can crash if log aggregation for an application failed to start.",0
"Using FairScheduler in Hadoop 1.0.3 with kerberos authentication configured. Job initialization fails:

{code}
2012-07-17 15:15:09,220 ERROR org.apache.hadoop.mapred.JobTracker: Job initialization failed:
java.io.IOException: Call to /192.168.7.80:8020 failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
        at org.apache.hadoop.ipc.Client.wrapException(Client.java:1129)
        at org.apache.hadoop.ipc.Client.call(Client.java:1097)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
        at $Proxy7.getProtocolVersion(Unknown Source)
        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:411)
        at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:125)
        at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:329)
        at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:294)
        at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1411)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1429)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
        at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
        at org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:169)
        at org.apache.hadoop.mapred.JobInProgress.generateAndStoreTokens(JobInProgress.java:3558)
        at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:696)
        at org.apache.hadoop.mapred.JobTracker.initJob(JobTracker.java:3911)
        at org.apache.hadoop.mapred.FairScheduler$JobInitializer$InitJob.run(FairScheduler.java:301)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
        at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:543)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)
        at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:488)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:590)
        at org.apache.hadoop.ipc.Client$Connection.access$2100(Client.java:187)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1228)
        at org.apache.hadoop.ipc.Client.call(Client.java:1072)
        ... 20 more
Caused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:194)
        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:134)
        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:385)
        at org.apache.hadoop.ipc.Client$Connection.access$1200(Client.java:187)
        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:583)
        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:580)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:579)
        ... 23 more
Caused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
        at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:130)
        at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:106)
        at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:172)
        at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:209)
        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:195)
        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:162)
        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:175)
        ... 32 more

{code}

When a job is submitted, fairscheduler calls JobTracker.initJob, which calls JobInProgress.generateAndStoreTokens to write security keys to hdfs. However, the operation is involved in the server side rpc call path, using UGI created by UserGroupInformation.createRemoteUser in rpc server, which have no tgt. This should be done with UGI used by JobTracker.",0
"{noformat}
java.lang.ArrayIndexOutOfBoundsException: 1
        at
org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:194)
        at
org.apache.hadoop.mapred.LocalJobRunner$Job.<init>(LocalJobRunner.java:154)
        at
org.apache.hadoop.mapred.LocalJobRunner.submitJob(LocalJobRunner.java:620)
        at
org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:385)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1215)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1212)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1212)
        at
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:336)
        at
org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run(JobControl.java:233)
        at java.lang.Thread.run(Thread.java:619)
        at
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:260)
{noformat}",0
Recovery fails when the job user is different to the JT owner (i.e. on anything bigger than a pseudo-distributed cluster).,0
nan,0
nan,0
"When using LinuxTaskController, JVM reuse (mapred.job.reuse.jvm.num.tasks > 1) with more map tasks in a job than there are map slots in the cluster will result in immediate task failures for the second task in each JVM (and then the JVM exits). We have investigated this bug and the root cause is as follows. When using LinuxTaskController, the userlog directory for a task attempt (../userlogs/job/task-attempt) is created only on the first invocation (when the JVM is launched) because userlogs directories are created by the task-controller binary which only runs *once* per JVM. Therefore, attempting to create log.index is guaranteed to fail with ENOENT leading to immediate task failure and child JVM exit.

{quote}
2012-07-24 14:29:11,914 INFO org.apache.hadoop.mapred.TaskLog: Starting logging for a new task attempt_201207241401_0013_m_000027_0 in the same JVM as that of the first task /var/log/hadoop/mapred/userlogs/job_201207241401_0013/attempt_201207241401_0013_m_000006_0
2012-07-24 14:29:11,915 WARN org.apache.hadoop.mapred.Child: Error running child
ENOENT: No such file or directory
        at org.apache.hadoop.io.nativeio.NativeIO.open(Native Method)
        at org.apache.hadoop.io.SecureIOUtils.createForWrite(SecureIOUtils.java:161)
        at org.apache.hadoop.mapred.TaskLog.writeToIndexFile(TaskLog.java:296)
        at org.apache.hadoop.mapred.TaskLog.syncLogs(TaskLog.java:369)
        at org.apache.hadoop.mapred.Child.main(Child.java:229)
{quote}

The above error occurs in a JVM which runs tasks 6 and 27.  Task6 goes smoothly. Then Task27 starts. The directory /var/log/hadoop/mapred/userlogs/job_201207241401_0013/attempt_201207241401_0013_m_0000027_0 is never created so when mapred.Child tries to write the log.index file for Task27, it fails with ENOENT because the attempt_201207241401_0013_m_0000027_0 directory does not exist. Therefore, the second task in each JVM is guaranteed to fail (and then the JVM exits) every time when using LinuxTaskController. Note that this problem does not occur when using the DefaultTaskController because the userlogs directories are created for each task (not just for each JVM as with LinuxTaskController).

For each task, the TaskRunner calls the TaskController's createLogDir method before attempting to write out an index file.

* DefaultTaskController#createLogDir: creates log directory for each task
* LinuxTaskController#createLogDir: does nothing
** task-controller binary creates log directory [create_attempt_directories] (but only for the first task)

Possible Solution: add a new command to task-controller *initialize task* to create attempt directories.  Call that command, with ShellCommandExecutor, in the LinuxTaskController#createLogDir method




",0
"When dealing with sensitive data, it is required to keep the data encrypted wherever it is stored. Common use case is to pull encrypted data out of a datasource and store in HDFS for analysis. The keys are stored in an external keystore. 
The feature adds a customizable framework to integrate different types of keystores, support for Java KeyStore, read keys from keystores, and transport keys from JobClient to Tasks.
The feature adds PGP encryption as a codec and additional utilities to perform encryption related steps.
The design document is attached. It explains the requirement, design and use cases.
Kindly review and comment. Collaboration is very much welcome.
I have a tested patch for this for 1.1 and will upload it soon as an initial work for further refinement.
Update: The patches are uploaded to subtasks. ",0
"The distributed cache does not work like it does in 1.0.

mapreduce.job.cache.symlink.create is completely ignored and symlinks are always created no matter what.  Files and archives without a fragment will also have symlinks created.

If two cache archives or cache files happen to have the same name, or same symlink fragment only the last one in the list is localized.

The localCacheArchives and LocalCacheFiles are not set correctly when these duplicates happen causing off by one or more errors for anyone trying to use them.

The reality is that use of symlinking is so common currently that these incompatibilities are not that likely to show up, but we still need to fix them.",0
"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off .",0
"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes.

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.
In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be changed for two reasons:
1) It is not backward compatible.鈥?2) Credentials should be passed even if security is turned off .
",0
The task log servlet can no longer access user logs because MAPREDUCE-2415 introduce symlinks to the logs and jetty is not configured by default to serve symlinks. ,0
"This causes the AM to fail the job at the same time as it blacklists a node, thus never actually trying another node.

Marking as critical because we need this in 0.23.3 before it releases.",0
"The MR AM always thinks that it is being killed by the RM when it gets a kill signal and it has not finished processing yet.  In reality the RM kill signal is only sent when the client cannot communicate directly with the AM, which probably means that the AM is in a bad state already.  The much more common case is that the node is marked as unhealthy or decomissioned.

I propose that in the short term the AM will only clean up if 

 # The process has been asked by the client to exit (kill)
 # The process job has finished cleanly and is exiting already
 # This is that last retry of the AM retries.

The downside here is that the .staging directory will be leaked and the job will not show up in the history server on an kill from the RM in some cases.

At least until the full set of AM cleanup issues can be addressed, probably as part of MAPREDUCE-4428",0
nan,0
nan,0
nan,0
Attempting to kill a task attempt that has been scheduled but is not running causes an invalid state transition and the AM to stop with an error. ,0
nan,0
"If the job committer throws an {{IOException}} from {{commitJob}} then the job will be marked as FINISHED/FAILED on the RM apps page, but the history server will show the job as SUCCEEDED.",0
"After investigating the methodology used to add HTTPS support in branch-2, I feel that this same approach should be back-ported to branch-1. I have taken many of the patches used for branch-2 and merged them in.
I was working on top of HDP 1 at the time - I will provide a patch for trunk soon once I can confirm I am adding only the necessities for supporting HTTPS on the webUIs.
As an added benefit – this patch actually provides HTTPS webUI to HBase by extension. If you take a hadoop-core jar compiled with this patch and put it into the hbase/lib directory and apply the necessary configs to hbase/conf.
========= OLD IDEA(s) BEHIND ADDING HTTPS (look @ Sept 17th patch) ==========
In order to provide full security around the cluster, the webUI should also be secure if desired to prevent cookie theft and user masquerading. 
Here is my proposed work. Currently I can only add HTTPS support. I do not know how to switch reliance of the HttpServer from HTTP to HTTPS fully.
In order to facilitate this change I propose the following configuration additions:
CONFIG PROPERTY -> DEFAULT VALUE
mapred.https.enable -> false
mapred.https.need.client.auth -> false
mapred.https.server.keystore.resource -> ""ssl-server.xml""
mapred.job.tracker.https.port -> 50035
mapred.job.tracker.https.address -> ""<IP_ADDR>:50035""
mapred.task.tracker.https.port -> 50065
mapred.task.tracker.https.address -> ""<IP_ADDR>:50065""
I tested this on my local box after using keytool to generate a SSL certficate. You will need to change ssl-server.xml to point to the .keystore file after. Truststore may not be necessary; you can just point it to the keystore.",0
"Say the AM wanted a container at hosts h1, h2, h3. After getting a container at h1 it should tell RM that it no longer needs containers at h2, h3. Otherwise on the RM h2, h3 remain valid allocation locations.
The AM RMContainerAllocator does remove these resource requests internally. When the resource request container count drops to 0 then it drops the resource request from its tables but forgets to send the 0 sized request to the RM.",0
"When calling JobClient.getMapTaskReports for a job that has failed results in an NPE.  For example:

{noformat}
Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.counters.AbstractCounters.<init>(AbstractCounters.java:107)
	at org.apache.hadoop.mapred.Counters.<init>(Counters.java:71)
	at org.apache.hadoop.mapred.Counters.downgrade(Counters.java:80)
	at org.apache.hadoop.mapred.TaskReport.downgrade(TaskReport.java:81)
	at org.apache.hadoop.mapred.TaskReport.downgradeArray(TaskReport.java:88)
	at org.apache.hadoop.mapred.JobClient.getTaskReports(JobClient.java:691)
	at org.apache.hadoop.mapred.JobClient.getMapTaskReports(JobClient.java:681)
...
{noformat}
",0
"Example traceback from the client:

{noformat}
2012-09-27 20:28:38,068 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2012-09-27 20:28:38,530 [main] WARN  org.apache.hadoop.mapred.ClientServiceDelegate - Error from remote end: Unknown job job_1348097917603_3019
2012-09-27 20:28:38,530 [main] ERROR org.apache.hadoop.security.UserGroupInformation - PriviledgedActionException as:xxx (auth:KERBEROS) cause:org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1348097917603_3019
2012-09-27 20:28:38,531 [main] WARN  org.apache.pig.tools.pigstats.JobStats - Failed to get map task report
RemoteTrace: 
 at LocalTrace: 
        org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1348097917603_3019
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:156)
        at $Proxy11.getJobReport(Unknown Source)
        at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getJobReport(MRClientProtocolPBClientImpl.java:116)
        at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:298)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:383)
        at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:482)
        at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:184)
...
{noformat}
",0
"The historyserver can serve up links to jobs that become useless well before the job history files are purged.  For example on a large, heavily used cluster we can end up rotating through the maximum number of jobs the historyserver can track fairly quickly.  If a user was investigating an issue with a job using a saved historyserver URL, that URL can become useless because the historyserver has forgotten about the job even though the history files are still sitting in HDFS.

We can tell the historyserver to keep track of more jobs by increasing {{mapreduce.jobhistory.joblist.cache.size}}, but this has a direct impact on the responsiveness of the main historyserver page since it serves up all the entries to the client at once.  It looks like Hadoop 1.x avoided this issue by encoding the history file location into the URLs served up by the historyserver, so it didn't have to track a mapping between job ID and history file location.",0
"It says
{code}
$ $HADOOP_MAPRED_HOME/sbin/mr-jobhistory-daemon.sh --config /Users/vinodkv/tmp/conf/ start historyserver
Usage: mr-jobhistory-daemon.sh [--config <conf-dir>] (start|stop) <mapred-command>
{code}",0
nan,0
We're seeing a repeatable OOM crash in the AM for a task with around 30000 maps and 3000 reducers.  Details to follow.,0
"We saw this happen when running a large pig script.

{noformat}
2012-10-23 22:45:24,986 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Can't handle this event at current state for task_1350837501057_21978_m_040453
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: T_ATTEMPT_SUCCEEDED at SUCCEEDED
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handle(TaskImpl.java:604)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handle(TaskImpl.java:89)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher.handle(MRAppMaster.java:914)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher.handle(MRAppMaster.java:908)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:619)
{noformat}

Speculative execution was enabled, and that task did speculate so it looks like this is an error in the state machine either between the task attempts or just within that single task.",0
"Relative to Hadoop 0.20/1.x, KeyFieldBasedPartitioner is not distributing across partitions properly when configured.  This is related to the double-configure issue as described in HADOOP-7425.  KeyFieldBasedPartitioner is getting configured twice, and that ends up duplicating the keyspecs and causing the keys to be hashed twice.

KeyFieldBasedPartitioner should not duplicate keyspecs when configured twice.",0
"In one particular case we saw a NM go down at just the right time, that most of the reducers got the output of the map tasks, but not all of them.

The ones that failed to get the output reported to the AM rather quickly that they could not fetch from the NM, but because the other reducers were still running the AM would not relaunch the map task because there weren't more than 50% of the running reducers that had reported fetch failures.  Then because of the exponential back-off for fetches on the reducers it took until 1 hour 45 min for the reduce tasks to hit another 10 fetch failures and report in again. At that point the other reducers had finished and the job relaunched the map task.  If the reducers had still been running at 1:45 I have no idea how long it would have taken for each of the tasks to get to 30 fetch failures.

We need to trigger the map based off of percentage of reducers shuffling, not percentage of reducers running, we also need to have a maximum limit of the back off, so that we don't ever have the reducer waiting for days to try and fetch map output.  ",0
"The test org.apache.hadoop.mapred.TestClusterMRNotification.testMR frequently  fails in mapred build (e.g. see https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2988/testReport/junit/org.apache.hadoop.mapred/TestClusterMRNotification/testMR/ , or 
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2982//testReport/org.apache.hadoop.mapred/TestClusterMRNotification/testMR/).

The test aims to check Job status notifications received through HTTP Servlet. It runs 3 jobs: successfull, killed, and failed. 
The test expects the servlet to receive some expected notifications in some expected order. It also tries to test the retry-on-failure notification functionality, so on each 1st notification the servlet answers ""400 forcing error"", and on each 2nd notification attempt it answers ""ok"". 
In general, the test fails because the actual number and/or type of the notifications differs from the expected.

Investigation shows that actual root cause of the problem is an incorrect job state transition: the 3rd job mapred task fails (by intentionally thrown  RuntimeException, see UtilsForTests#runJobFail()), and the state of the task changes from RUNNING to FAILED.
At this point JobEventType.JOB_TASK_ATTEMPT_COMPLETED event is submitted (in  method org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handleTaskAttemptCompletion(TaskAttemptId, TaskAttemptCompletionEventStatus)), and this event gets processed in AsyncDispatcher, but this transition is impossible according to the event transition map (see org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl#stateMachineFactory). This causes the following exception to be thrown upon the event processing:
2012-11-06 12:22:02,335 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:309)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$3(StateMachineFactory.java:290)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:454)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:716)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:917)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:79)
        at java.lang.Thread.run(Thread.java:662) 

So, the job gets into state ""INTERNAL_ERROR"", the job end notification like this is sent:
http://localhost:48656/notification/mapred?jobId=job_1352199715842_0002&amp;jobStatus=ERROR 
(here we can see ""ERROR"" status instead of ""FAILED"")
After that the notification servlet receives either only ""ERROR"" notification, or one more notification ""ERROR"" after ""FAILED"", which finally causes the test to fail. (Some variation in the test behavior caused by racing conditions because there are many asynchronous processings there, and the test is flaky, in fact).

In any way, it looks like the root cause of the problem is the possibility of the forbidden transition ""Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED"". 
Need an expert advice on how that should be fixed.",0
"NLineInputFormat creates FileSplits that are then used by LineRecordReader to generate Text values. To deal with an idiosyncrasy of LineRecordReader, the begin and length fields of the FileSplit are constructed differently for the first FileSplit vs. the rest.

After looping through all lines of a file, the final FileSplit is created, but the creation does not respect the difference of how the first vs. the rest of the FileSplits are created.

This results in the first line of the final InputSplit being skipped. I've created a patch to NLineInputFormat, and this fixes the problem.",0
"If the AM reports final job status to the client but then crashes before unregistering with the RM then the RM can run another AM attempt.  Currently AM re-attempts assume that the previous attempts did not reach a final job state, and that causes the job to rerun (from scratch, if the output format doesn't support recovery).

Re-running the job when we've already told the client the final status of the job is bad for a number of reasons.  If the job failed, it's confusing at best since the client was already told the job failed but the subsequent attempt could succeed.  If the job succeeded there could be data loss, as a subsequent job launched by the client tries to consume the job's output as input just as the re-attempt starts removing output files in preparation for the output commit.",0
"It is possible for a networking issue to happen where the RM thinks an AM has gone down and launches a replacement, but the previous AM is still up and running.  If the previous AM does not need any more resources from the RM it could try to commit either tasks or jobs.  This could cause lots of problems where the second AM finishes and tries to commit too.  This could result in data corruption.  ",0
"The job staging directory is deleted in the job cleanup task, which happens before the job-info file is deleted from the system directory (by the JobInProgress garbageCollect() method). If the JT shuts down between these two operations, then when the JT restarts and tries to recover the job, it fails since the job.xml and splits are no longer available.",0
"Ran across a case where a reducer ran on a node where the disks were full, leading to an exception like this during the shuffle fetch:

{noformat}
2012-12-05 09:07:28,749 INFO [fetcher#25] org.apache.hadoop.mapreduce.task.reduce.MergeManager: attempt_1352354913026_138167_m_000654_0: Shuffling to disk since 235056188 is greater than maxSingleShuffleLimit (155104064)
2012-12-05 09:07:28,755 INFO [fetcher#25] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#25 failed to read map headerattempt_1352354913026_138167_m_000654_0 decomp: 235056188, 101587629
org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1352354913026_138167_r_000189_0/map_654.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:398)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.mapred.YarnOutputFiles.getInputFileForWrite(YarnOutputFiles.java:213)
	at org.apache.hadoop.mapreduce.task.reduce.MapOutput.<init>(MapOutput.java:81)
	at org.apache.hadoop.mapreduce.task.reduce.MergeManager.reserve(MergeManager.java:245)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:348)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:283)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:155)
2012-12-05 09:07:28,755 WARN [fetcher#25] org.apache.hadoop.mapreduce.task.reduce.Fetcher: copyMapOutput failed for tasks [attempt_1352354913026_138167_m_000654_0]
2012-12-05 09:07:28,756 INFO [fetcher#25] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Reporting fetch failure for attempt_1352354913026_138167_m_000654_0 to jobtracker.
{noformat}

Even though the error was local to the reducer, it reported the error as a fetch failure to the AM than failing the reducer itself.  It then proceeded to run into the same error for many other maps, causing them to relaunch from reported fetch failures.  In this case it would have been better to fail the reducer and try another node rather than blame the mapper for what is an error on the reducer's side.",0
"There is rare happenings during map or reduce phase, but mostly in map phase, the Exception messages: 
java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.io.IOException: Task process exit with nonzero status of 126.
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:258)

and error logs are cleaned, so It's very hard to debug.

but I compared DefaultTaskController.java with 0.22, they use ""bash command"" to start the job scritp, but 1.0.4 use ""bash, ""-c"", command"".

I removed ""-c"", everything is ok, 126 error code never happen again.

I read man document of bash, it indicates when fork a new thread with write command, another thread with ""bash -c"" also has a writable fd. so I think it could return 126 status occasionally.

So, there is only one line fix for this issue.
",0
"mapreduce.security.token.DelegationTokenRenewal synchronizes on removeDelegationToken, but fails to synchronize on addToken, and renewing tokens in run().

This inconsistency is exposed by frequent failures of TestDelegationTokenRenewal:
{noformat}
Error Message

renew wasn't called as many times as expected expected:<4> but was:<5>
Stacktrace

junit.framework.AssertionFailedError: renew wasn't called as many times as expected expected:<4> but was:<5>
	at org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal.testDTRenewal(TestDelegationTokenRenewal.java:317)
	at org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal.testDTRenewalAfterClose(TestDelegationTokenRenewal.java:338)

{noformat}
",0
"mapreduce.security.token.DelegationTokenRenewal doesn't seem to be used in branch-2 at all. grep on trunk yields no results, not even ReflectionUtils related suff.",0
"When the user needs to configure a larger split metainfo file size, mapred-default.xml points to the mapreduce.job.split.metainfo.maxsize property.  However the ApplicationMaster actually uses the mapreduce.*jobtracker*.split.metainfo.maxsize property when determining the largest allowed size.  This leads to much confusion on the part of end-users trying to increase the allowed limit.",0
"The sortAndSpill() method in MapTask.java has an error in estimating the length of the output file. 
The ""long size"" should be ""(bufvoid - bufstart) + bufend"" not ""(bufvoid - bufend) + bufstart"" when ""bufend < bufstart"".

Here is the original code in MapTask.java.
 private void sortAndSpill() throws IOException, ClassNotFoundException,
                                       InterruptedException {
      //approximate the length of the output file to be the length of the
      //buffer + header lengths for the partitions
      long size = (bufend >= bufstart
          ? bufend - bufstart
          : (bufvoid - bufend) + bufstart) +
                  partitions * APPROX_HEADER_LENGTH;
      FSDataOutputStream out = null;
------------------------------------------------------------------------------
I had a test on ""TeraSort"". A snippet from mapper's log is as follows:

MapTask: Spilling map output: record full = true
MapTask: bufstart = 157286200; bufend = 10485460; bufvoid = 199229440
MapTask: kvstart = 262142; kvend = 131069; length = 655360
MapTask: Finished spill 3

In this occasioin, Spill Bytes should be (199229440 - 157286200) + 10485460 = 52428700 (52 MB) because the number of spilled records is 524287 and each record costs 100B.",0
"There are a couple of issues when a task fails while speculating (i.e.: multiple attempts are active):

# The other active attempts are not killed.
# TaskImpl's FAILED state does not handle the T_ATTEMPT_* set of events which can be sent from the other active attempts.  These all need to be handled since they can be sent asynchronously from the other active task attempts.

Failure to handle this properly means jobs that are configured to normally tolerate failures via mapreduce.map.failures.maxpercent or mapreduce.reduce.failures.maxpercent and also speculate can easily end up failing due to invalid state transitions rather than complete successfully with a few explicitly allowed task failures.",0
nan,0
MR part of HADOOP-9173.,0
"With the way that the schedulers work, each request for a container on a node must consist of 3 ResourceRequests - one on the node, one on the rack, and one with *.

AppSchedulingInfo tracks the outstanding requests.  When a node is assigned a node-local container, allocateNodeLocal decrements the outstanding requests at each level - node, rack, and *.  If the rack requests reach 0, it removes the mapping.

A mapreduce task with multiple data local nodes submits multiple container requests, one for each node.  It also submits one for each unique rack, and one for *.  If there are fewer unique racks than data local nodes, this means that fewer rack-local ResourceRequests will be submitted than node-local ResourceRequests, so the rack-local mapping will be deleted before all the node-local requests are allocated and an NPE will come up the next time a node-local request from that rack is allocated.",0
MapReduce changes related to HADOOP-9192 to reuse the protobuf messages defined in common.,0
"In MR1, only mapred.task.timeout works.  Both should be made to work.",0
"createKVIterator in ReduceTask contains the following code:
{code}

          try {
            Merger.writeFile(rIter, writer, reporter, job);
            addToMapOutputFilesOnDisk(fs.getFileStatus(outputPath));
          } catch (Exception e) {
            if (null != outputPath) {
              fs.delete(outputPath, true);
            }
            throw new IOException(""Final merge failed"", e);
          } finally {
            if (null != writer) {
              writer.close();
            }
          }
{code}

Merger#writeFile() does not close the file after writing it, so when fs.getFileStatus() is called on it, it may not return the correct length.  This causes bad accounting further down the line, which can lead to map output data being lost.",0
"The cpu checks for uberizing have two issues:
# the defaults are hardcoded instead of using the conf defaults
# the comparison against the sys cpu size is using {{<}} instead of {{<=}}

{code}

    boolean smallCpu =
        (
            Math.max(
                conf.getInt(MRJobConfig.MAP_CPU_VCORES, 1), 
                conf.getInt(MRJobConfig.REDUCE_CPU_VCORES, 1)) < 
             sysCPUSizeForUberSlot
        );
{code}

Everything is defaulting to 1, so uber cpu checks are now disabled causing {{TestUberAM}} to fail.",0
"After HADOOP-8552, MR child tasks will attempt to create security audit log files with their user names.  On an insecure cluster, this has no effect, but on a secure cluster, log4j will try to create log files for tasks with names like SecurityAuth-joeuser.log.",0
"On Windows, {{TestMRJobs#testDistributedCache}} fails on an assertion while checking the length of a symlink.  It expects to see the length of the target of the symlink, but Java 6 on Windows always reports that a symlink has length 0.",0
A job hung in the Recovery Service on an AM restart. There were four map tasks events that were not processed and that prevented the complete task count from reaching zero which exits the recovery service. All four tasks were speculative,0
"hadoop jar myjar.jar MyDriver -fs file:/// -jt local input.txt output/
should run a job using the local file system and the local job runner. Instead it tries to connect to a jobtracker.

hadoop jar myjar.jar MyDriver -fs file:/// -jt host:port input.txt output/
does not use the given host/port

This appears to be because Cluster#initialize, which loads the ClientProtocol, contains no special handling for mapred.job.tracker.",0
"When a task is speculating and one attempt completes then sometimes the counters for the wrong attempt are aggregated into the total counters for the job.  The scenario looks like this:

# Two task attempts are racing, _0 and _1
# _1 finishes first, causing the task to issue a TA_KILL to attempt _0
# _0 receives TA_KILL, sets progress to 1.0f and waits for container cleanup
# if TaskImpl.getCounters() is called now, TaskImpl.selectBestAttempt() can return _0 since it is not quite yet in the KILLED state yet progress is maxed out and no other attempt has more progress.
",0
"Hive is hitting a race condition with LocalJobRunner and the Cluster class. The JobClient uses the Cluster class to obtain Job objects. The Cluster class uses the job.xml file to populate the JobConf object (https://github.com/apache/hadoop-common/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Cluster.java#L184). However, this file is deleted by the LocalJobRunner at the end of it's job (https://github.com/apache/hadoop-common/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalJobRunner.java#L484).

This results in the following exception:
{noformat}
2013-02-11 14:45:17,755 (main) [FATAL - org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2001)] error parsing conf file:/tmp/hadoop-brock/mapred/staging/brock1916441210/.staging/job_local_0432/job.xml
java.io.FileNotFoundException: /tmp/hadoop-brock/mapred/staging/brock1916441210/.staging/job_local_0432/job.xml (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:120)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1917)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1870)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1777)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:712)
	at org.apache.hadoop.mapred.JobConf.checkAndWarnDeprecation(JobConf.java:1951)
	at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:398)
	at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:388)
	at org.apache.hadoop.mapred.JobClient$NetworkedJob.<init>(JobClient.java:174)
	at org.apache.hadoop.mapred.JobClient.getJob(JobClient.java:655)
	at org.apache.hadoop.mapred.JobClient.getJob(JobClient.java:668)
	at org.apache.hadoop.mapreduce.TestMR2LocalMode.test(TestMR2LocalMode.java:40)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
{noformat}

Here is code which exposes this race fairly quickly:

{noformat}
    Configuration conf = new Configuration();
    conf.set(""mapreduce.framework.name"", ""local"");
    conf.set(""mapreduce.jobtracker.address"", ""local"");
    File inputDir = new File(""/tmp"", ""input-"" + System.currentTimeMillis());
    File outputDir = new File(""/tmp"", ""output-"" + System.currentTimeMillis());
    while(true) {
      Assert.assertTrue(inputDir.mkdirs());
      File inputFile = new File(inputDir, ""file"");
      FileUtils.copyFile(new File(""/etc/passwd""), inputFile);
      Path input = new Path(inputDir.getAbsolutePath());
      Path output = new Path(outputDir.getAbsolutePath());
      JobConf jobConf = new JobConf(conf, TestMR2LocalMode.class);
      FileInputFormat.addInputPath(jobConf, input);
      FileOutputFormat.setOutputPath(jobConf, output);      
      JobClient jobClient = new JobClient(conf);
      RunningJob runningJob = jobClient.submitJob(jobConf);
      while(!runningJob.isComplete()) {
        runningJob = jobClient.getJob(runningJob.getJobID());
      }      
      FileUtils.deleteQuietly(inputDir);
      FileUtils.deleteQuietly(outputDir);
    }
{noformat}",0
"After MAPREDUCE-2264, a segment's raw data length is calculated without the EOF_MARKER bytes.  However, when the merge is counting how many bytes it processed, it includes the marker.  This can cause the merge progress to go above 100%.

Whether these EOF_MARKER bytes should count should be consistent between the two.

This a JIRA instead of an amendment because MAPREDUCE-2264 already went into 2.0.3.",0
"A reduce task attempt was killed by the RM(pre-emptively), but had already been assigned to the commitAttempt member.  This causes all subsequent attempts to be killed by the AM.",0
"Verified the problem exists on branch-1 with the following configuration:

Pseudo-dist mode: 2 maps/ 1 reduce, mapred.child.java.opts=-Xmx2048m, io.sort.mb=1280, dfs.block.size=2147483648

Run teragen to generate 4 GB data
Maps fail when you run wordcount on this configuration with the following error: 
{noformat}
java.io.IOException: Spill failed
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1031)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:692)
	at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)
	at org.apache.hadoop.examples.WordCount$TokenizerMapper.map(WordCount.java:45)
	at org.apache.hadoop.examples.WordCount$TokenizerMapper.map(WordCount.java:34)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:370)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1149)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:375)
	at org.apache.hadoop.io.IntWritable.readFields(IntWritable.java:38)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKeyValue(ReduceContext.java:116)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKey(ReduceContext.java:92)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:175)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1505)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1438)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.access$1800(MapTask.java:855)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1346)
{noformat}",0
"If an application attempt fails and is relaunched the AM will try to recover previously completed tasks.  If a reducer needs to fetch the output of a map task attempt that was recovered then it will fail with a 401 error like this:

{noformat}
java.io.IOException: Server returned HTTP response code: 401 for URL: http://xx:xx/mapOutput?job=job_1361569180491_21845&reduce=0&map=attempt_1361569180491_21845_m_000016_0
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1615)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:231)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:156)
{noformat}

Looking at the corresponding NM's logs, we see the shuffle failed due to ""Verification of the hashReply failed"".",0
"To support IsolationRunner, split info is written to local directories.  This occurs inside MapTask#localizeConfiguration, which is called both tasktracker and by the child JVM.  On a secure cluster, the tasktacker's attempt to write it fails, because the tasktracker does not have permission to write to the user's directory. It is likely that the call to localizeConfiguration in the tasktracker can be removed. ",0
"In branch-1, CombineFileInputFormat doesn't take SplittableCompressionCodec into account and thinks that all compressible input files aren't splittable.  This is a regression from when handling for non-splitable compression codecs was originally added in MAPREDUCE-1597, and seems to have somehow gotten in when the code was pulled from 0.22 to branch-1.
",0
"lz4, snappy, zlib, and lzo Decompressor's only throw java.lang.InternalError. This exception will cause the reducer to fail and bypass all of the fetch failure logic.  The decompressing errors should be treated as fetch failures.",0
Change MR AM to use app-retry maximum limit that is made available by RM after YARN-378.,0
"When copying files between 2 clusters with different default block-sizes, one sees that the copy fails with a checksum-mismatch, even though the files have identical contents.

The reason is that on HDFS, a file's checksum is unfortunately a function of the block-size of the file. So you could have 2 different files with identical contents (but different block-sizes) have different checksums. (Thus, it's also possible for DistCp to fail to copy files on the same file-system, if the source-file's block-size differs from HDFS default, and -pb isn't used.)

I propose that we skip checksum comparisons under the following conditions:
1. -skipCrc is specified.
2. File-size is 0 (in which case the call to the checksum-servlet is moot).
3. source.getBlockSize() != target.getBlockSize(), since the checksums are guaranteed to differ in this case.

I have a patch for #3.

Edit: I've modified the fix to warn the user (instead of skipping the checksum-check). Skipping parity-checks is unsafe. The code now fails the copy, and suggests that the user either use -pb to preserve block-size, or consider -skipCrc (and forgo copy validation entirely).",0
"DistCp wraps the {{InputStream}} for each input file it reads in an instance of {{ThrottledInputStream}}.  This class does not close the wrapped {{InputStream}}.  {{RetriableFileCopyCommand}} guarantees that the {{ThrottledInputStream}} gets closed, but without closing the underlying wrapped stream, it still leaks a file handle.",0
nan,0
"After the fix for HADOOP-9299 I'm now getting the following bizzare exception in Oozie while trying to submit a job. This also seems to be KRB related:

{noformat}
2013-03-15 13:34:16,555  WARN ActionStartXCommand:542 - USER[hue] GROUP[-] TOKEN[] APP[MapReduce] JOB[0000001-130315123130987-oozie-oozi-W] ACTION[0000001-130315123130987-oozie-oozi-W@Sleep] Error starting action [Sleep]. ErrorType [ERROR], ErrorCode [UninitializedMessageException], Message [UninitializedMessageException: Message missing required fields: renewer]
org.apache.oozie.action.ActionExecutorException: UninitializedMessageException: Message missing required fields: renewer
	at org.apache.oozie.action.ActionExecutor.convertException(ActionExecutor.java:401)
	at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:738)
	at org.apache.oozie.action.hadoop.JavaActionExecutor.start(JavaActionExecutor.java:889)
	at org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:211)
	at org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:59)
	at org.apache.oozie.command.XCommand.call(XCommand.java:277)
	at org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:326)
	at org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:255)
	at org.apache.oozie.service.CallableQueueService$CallableWrapper.run(CallableQueueService.java:175)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
Caused by: com.google.protobuf.UninitializedMessageException: Message missing required fields: renewer
	at com.google.protobuf.AbstractMessage$Builder.newUninitializedMessageException(AbstractMessage.java:605)
	at org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto$Builder.build(SecurityProtos.java:973)
	at org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl.mergeLocalToProto(GetDelegationTokenRequestPBImpl.java:84)
	at org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl.getProto(GetDelegationTokenRequestPBImpl.java:67)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getDelegationToken(MRClientProtocolPBClientImpl.java:200)
	at org.apache.hadoop.mapred.YARNRunner.getDelegationTokenFromHS(YARNRunner.java:194)
	at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:273)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:392)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1218)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1215)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1439)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1215)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:581)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1439)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:576)
	at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:723)
	... 10 more
2013-03-15 13:34:16,555  WARN ActionStartXCommand:542 - USER[hue] GROUP[-] TOKEN[] APP[MapReduce] JOB[0000001-13031512313
{noformat}",0
"It seems that the HSClientProtocolPBClientImpl should implement Closeable as per the attached stack trace. The problem can be observed on a cluster running the latest branch-2.0.4-alpha with MAPREDUCE-5088 applied on top. The easiest way to reproduce it is to run an oozie pig job:

{noformat}
$ oozie job -oozie http://`hostname -f`:11000/oozie -run -DjobTracker=`hostname -f`:8032 -DnameNode=hdfs://`hostname -f`:17020 -DexamplesRoot=examples -config /tmp/examples/apps/pig/job.properties
{noformat}

Please also note that I can successfully submit simple jobs (Pi/Sleep) from a command line using hadoop jar command. Thus it *seems* related to MAPREDUCE-5088 change.
",0
"The AM does not have any flow control to limit the incoming rate of events from tasks.  If the AM is unable to keep pace with the rate of incoming events for a sufficient period of time then it will eventually exhaust the heap and crash.  MAPREDUCE-5043 addressed a major bottleneck for event processing, but the AM could still get behind if it's starved for CPU and/or handling a very large job with tens of thousands of active tasks.",0
"I've seen pig/hive applications bork during JT restart since they get NPEs - this is due to fact that jobs are not really inited, but are submitted.",0
MAPREDUCE-4970 introduced incompatible change and causes syslog to be missing from tasktracker on old clusters which just have log4j.properties configured,0
"In a secure setup, the jobtracker needs the job's delegation tokens to delete the staging directory.  MAPREDUCE-4850 made it so that job cleanup staging directory deletion occurs asynchronously, so that it could order it with system directory deletion.  This introduced the issue that a job's delegation tokens could be cancelled before the cleanup thread got around to deleting it, causing the deletion to fail.",0
"When mapred.jobtracker.restart.recover is set as true and mapreduce.job.restart.recover is set to false for a MR job, Job clean up never happens for that job if JT restarts while job is running.

.staging and job-info file for that job remains on HDFS forever. ",0
"If a reducer needs to shuffle a map output to disk, it opens an output stream and writes the data to disk.  However it does not release the reference to the output stream within the MapOutput, and the output stream can have a 128K buffer attached to it.  If enough of these on-disk outputs are queued up waiting to be merged, it can cause the reducer to OOM during the shuffle phase.  In one case I saw there were 1200 on-disk outputs queued up to be merged, leading to an extra 150MB of pressure on the heap due to the output stream buffers that were no longer necessary.",0
"This was noticed when within 5 seconds of submitting a word count job, the job tracker was restarted. Upon restart the job failed to recover",0
"CombineFileInputFormat can easily create splits that can come from many different locations (during the last pass of creating ""global"" splits). However, we observe that this often runs afoul of the mapreduce.job.max.split.locations check that's done by JobSplitWriter.

The default value for mapreduce.job.max.split.locations is 10, and with any decent size cluster, CombineFileInputFormat creates splits that are well above this limit.",0
nan,0
"This was noticed when job tracker would be restarted while jobs were running and would ask the task tracker to reinitialize. 

Tasktracker would fail with an error like

{code}
013-04-27 20:19:09,627 INFO org.apache.hadoop.mapred.TaskTracker: Good mapred local directories are: /grid/0/hdp/mapred/local,/grid/1/hdp/mapred/local,/grid/2/hdp/mapred/local,/grid/3/hdp/mapred/local,/grid/4/hdp/mapred/local,/grid/5/hdp/mapred/local
2013-04-27 20:19:09,628 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 42075 caught: java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:133)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:1717)
	at org.apache.hadoop.ipc.Server.access$2000(Server.java:98)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:744)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:808)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1433)

2013-04-27 20:19:09,628 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 42075: exiting
2013-04-27 20:19:10,414 ERROR org.apache.hadoop.mapred.TaskTracker: Got fatal exception while reinitializing TaskTracker: org.apache.hadoop.util.Shell$ExitCodeException: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.mapred.LinuxTaskController.deleteAsUser(LinuxTaskController.java:281)
	at org.apache.hadoop.mapred.TaskTracker.deleteUserDirectories(TaskTracker.java:779)
	at org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java:816)
	at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:2704)
	at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3934)
{code} ",0
"All the required tokens are propagated to AMs and containers via startContainer(), no need for explicitly creating the app-token file that we have today..",0
"MAPREDUCE-4397 added the capability to switch the location of the taskcontroller.cfg file, which weakens security.",0
ShuffleHandler (map output file) and SpillRecord (index file) are reading file using unsecured input stream. There exists a possibility for symlink attack. related to YARN-578 . Creating this issue to track map reduce changes.,0
"The following code in JobSubmissionFiles.java mandates strict permission on job submission :

{noformat}
    if (fs.exists(stagingArea)) {
      FileStatus fsStatus = fs.getFileStatus(stagingArea);
      String owner = fsStatus.getOwner();
      if (!(owner.equals(currentUser) || owner.equals(realUser))) {
         throw new IOException(""The ownership on the staging directory "" +
                      stagingArea + "" is not as expected. "" + 
                      ""It is owned by "" + owner + "". The directory must "" +
                      ""be owned by the submitter "" + currentUser + "" or "" +
                      ""by "" + realUser);
      }

{noformat}

For file systems such as S3, which do not have permission concept, user can never submit a job with staging area in S3. ",0
"The OnDiskMerger.merge method constructs an output path that is not unique to a reduce attempt, and as a result can result in a file collision with other reducers from the same app that are running on the same node.  In addition the name of the output file is based on MapOutput.toString which may not be unique in light of multi-pass merges on disk since the mapId will be null and the basename ends up as ""MapOutput(null, DISK)""",0
"While looking at the source, noticed that TokenCache#loadTokens methods are marked @Private but not used anywhere. 

We should either remove those methods or mark them Public or LimitedPrivate.",0
"If a combiner is specified using o.a.h.mapreduce.Job.setCombinerClass - this will silently ignored on the reduce side since the reduce side usage is only aware of the old api combiner.
This doesn't fail the job - since the new combiner key does not deprecate the old key.
",0
nan,0
"I am attaching a modified wordcount job that clearly demonstrates the problem we've encountered in running Sqoop2 on YARN (BIGTOP-949).

Here's what running it produces:

{noformat}
$ hadoop fs -mkdir in
$ hadoop fs -put /etc/passwd in
$ hadoop jar ./bug.jar org.myorg.LostCreds
13/05/12 03:13:46 WARN mapred.JobConf: The variable mapred.child.ulimit is no longer used.
numberOfSecretKeys: 1
numberOfTokens: 0
..............
..............
..............
13/05/12 03:05:35 INFO mapreduce.Job: Job job_1368318686284_0013 failed with state FAILED due to: Job commit failed: java.io.IOException:
numberOfSecretKeys: 0
numberOfTokens: 0
	at org.myorg.LostCreds$DestroyerFileOutputCommitter.commitJob(LostCreds.java:43)
	at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.handleJobCommit(CommitterEventHandler.java:249)
	at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.run(CommitterEventHandler.java:212)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
{noformat}

As you can see, even though we've clearly initialized the creds via:

{noformat}
job.getCredentials().addSecretKey(new Text(""mykey""), ""mysecret"".getBytes());
{noformat}

It doesn't seem to appear later in the job.

This is a pretty critical issue for Sqoop 2 since it appears to be DOA for YARN in Hadoop 2.0.4-alpha",0
"Two functions change their visibility in JobStatus from public to protected:
void setRunState(int)
void setSchedulingInfo(String)",0
"A job can fail if a reducer happens to run on a node with insufficient space to hold a map attempt's output.  The reducer keeps reporting the map attempt as bad, and if the map attempt ends up being re-launched too many times before the reducer decides maybe it is the real problem the job can fail.

In that scenario it would be better to re-launch the reduce attempt and hopefully it will run on another node that has sufficient space to complete the shuffle.  Reporting the map attempt is bad and relaunching the map task doesn't change the fact that the reducer can't hold the output.",0
"This was originally fixed as part of MAPREDUCE-5038, but that got reverted now. Which uncovers this issue, breaking HiveServer. Originally reported by [~thejas].",0
"In our cluster, jobs failed due to randomly task initialization failed because of JvmManager running into inconsistent state and TaskTracker failed to exit:

java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.getDetails(JvmManager.java:402)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.reapJvm(JvmManager.java:387)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.access$000(JvmManager.java:192)
	at org.apache.hadoop.mapred.JvmManager.launchJvm(JvmManager.java:125)
	at org.apache.hadoop.mapred.TaskRunner.launchJvmAndWait(TaskRunner.java:292)
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:251)

-------
java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.getDetails(JvmManager.java:402)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.reapJvm(JvmManager.java:387)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.access$000(JvmManager.java:192)
	at org.apache.hadoop.mapred.JvmManager.launchJvm(JvmManager.java:125)
	at org.apache.hadoop.mapred.TaskRunner.launchJvmAndWait(TaskRunner.java:292)
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:251)",0
nan,0
"Today, the JobTracker staging dir (""mapreduce.jobtracker.staging.root.dir) is set to point to HDFS, even though other file systems (e.g. Amazon S3 file system and Windows ASV file system) are the default file systems.

For ASV, this config was chosen and there are a few reasons why:

1. To prevent leak of the storage account credentials to the user's storage account; 
2. It uses HDFS for the transient job files what is good for two reasons 鈥?a) it does not flood the user's storage account with irrelevant data/files b) it leverages HDFS locality for small files

However, this approach conflicts with how distributed cache caching works, completely negating the feature's functionality.

When files are added to the distributed cache (thru files/achieves/libjars hadoop generic options), they are copied to the job tracker staging dir only if they reside on a file system different that the jobtracker's. Later on, this path is used as a ""key"" to cache the files locally on the tasktracker's machine, and avoid localization (download/unzip) of the distributed cache files if they are already localized.

In this configuration the caching is completely disabled and we always end up copying dist cache files to the job tracker's staging dir first and localizing them on the task tracker machine second.

This is especially not good for Oozie scenarios as Oozie uses dist cache to populate Hive/Pig jars throughout the cluster.

",0
"YARN-2 imported cpu dimension scheduling, but MR RMContainerAllocator doesn't take into account virtual cores while scheduling reduce tasks.
This may cause more reduce tasks to be scheduled because memory is enough. And on a small cluster, this will end with deadlock, all running containers are reduce tasks but map phase is not finished. ",0
"DistCp doesn't check the job-status when run in blocking-mode, before returning its exit-code. (The Yahoo-internal version did this correctly.)

In blocking-mode, DistCp must check that the launched job runs to completion, and return an appropriate exit-code.

Pretty serious bug, since it affects data integrity, in Oozie-launched-DistCp actions.

(I could've sworn I had another JIRA with this patch attached.)",0
"Courtesy [~amar_kamat]!
{quote}
We are seeing _temporary files left behind in the output folder if the job
fails.
The job were failed due to hitting quota issue.
I simply ran the randomwriter (from hadoop examples) with the default setting.
That failed and left behind some stray files.
{quote}",0
nan,0
"APPLICATION_INIT is never sent to AuxServices other than the built-in ShuffleHandler.  This means that 3rd party ShuffleProvider(s) will not be able to function, because APPLICATION_INIT enables the AuxiliaryService to map jobId->userId. This is needed for properly finding the MOFs of a job per reducers' requests.

NOTE: The built-in ShuffleHandler does get APPLICATION_INIT events due to hard-coded expression in hadoop code. The current TaskAttemptImpl.java code explicitly call: serviceData.put (ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID, ...) and ignores any additional AuxiliaryService. As a result, only the built-in ShuffleHandler will get APPLICATION_INIT events.  Any 3rd party AuxillaryService will never get APPLICATION_INIT events.


I think a solution can be in one of two ways:
1. Change TaskAttemptImpl.java to loop on all Auxiliary Services and register each of them, by calling serviceData.put (鈥? in loop.
2. Change AuxServices.java similar to the fix in: MAPREDUCE-2668  ""APPLICATION_STOP is never sent to AuxServices"".  This means that in case the 'handle' method gets APPLICATION_INIT event it will demultiplex it to all Aux Services regardless of the value in event.getServiceID().

I prefer the 2nd solution.  I am welcoming any ideas.  I can provide the needed patch for any option that people like.

See [Pluggable Shuffle in Hadoop documentation|http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html]
",0
"In MapReduce, we sometimes kill a task's JVM before it naturally shuts down if we want to launch other tasks (look in JvmManager$JvmManagerForType.reapJvm). This behavior means that if the map task process is in the middle of doing some cleanup/finalization after the task is done, it might be interrupted/killed without giving it a chance. 

In the Microsoft's Hadoop Service, after a Map/Reduce task is done and during closing file systems in a special shutdown hook, we're typically uploading storage (ASV in our context) usage metrics to Microsoft Azure Tables. So if this kill happens these metrics get lost. The impact is that for many MR jobs we don't see accurate metrics reported most of the time.",0
"When MiniMRYarnCluster configured to run on localFs instead of remoteFs, i.e. MiniDFSCluster, the job will fail on Windows. The error message looks like the following.

{noformat}
java.io.IOException: Job status not available
{noformat}

In my testing, the following unit tests hit this exception.

* TestMRJobsWithHistoryService
* TestClusterMRNotification
* TestJobCleanup
* TestJobCounters
* TestMiniMRClientCluster
* TestJobOutputCommitter
* TestMRAppWithCombiner
* TestMROldApiJobs
* TestSpeculativeExecution
",0
"In {{JobSubmissionFiles.getStagingDir()}}, we have following code that will throw exception if the directory owner is not the current user.

{code:java}
      String owner = fsStatus.getOwner();
      if (!(owner.equals(currentUser) || owner.equals(realUser))) {
         throw new IOException(""The ownership on the staging directory "" +
                      stagingArea + "" is not as expected. "" +
                      ""It is owned by "" + owner + "". The directory must "" +
                      ""be owned by the submitter "" + currentUser + "" or "" +
                      ""by "" + realUser);
      }
{code}

This check will fail on Windows when the underlying file system is LocalFileSystem. Because on Windows, the default file or directory owner could be ""Administrators"" group if the user belongs to ""Administrators"" group.

Quite a few MR unit tests that runs MR mini cluster with localFs as underlying file system fail because of this.",0
"MAPREDUCE-4860 introduced a local variable {{cancelled}} in {{RenewalTimerTask}} to fix the race where {{DelegationTokenRenewal}} attempts to renew a token even after the job is removed. However, the patch also makes {{run()}} and {{cancel()}} synchronized methods leading to a potential deadlock against {{run()}}'s catch-block (error-path).

The deadlock stacks below:

{noformat}
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask.cancel() @bci=0, line=240 (Interpreted frame)
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal.removeDelegationTokenRenewalForJob(org.apache.hadoop.mapreduce.JobID) @bci=109, line=319 (Interpreted frame)
{noformat}

{noformat}
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal.removeFailedDelegationToken(org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$DelegationTokenToRenew) @bci=62, line=297 (Interpreted frame)
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal.access$300(org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$DelegationTokenToRenew) @bci=1, line=47 (Interpreted frame)
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask.run() @bci=148, line=234 (Interpreted frame)
{noformat}",0
"The CombineFileRecordReader operates on splits consisting of multiple files. Each time a new record reader is initialised for a ""chunk"", certain parameters are supposed to be set on the configuration object (map.input.file, map.input.start and map.input.length)

However, the first reader is initialised in a different way to subsequent ones (i.e. initialize is called by the MapTask directly rather than from inside the record reader class). Because of this, these config parameters are not set properly and are returned as null when you access them from inside a mapper. ",0
"Filing on behalf of [~venkatnrangan] who found this originally and provided a patch.

Saw this in the JT logs while oozie tests were running with Hadoop.

When Oozie java action is executed, the following shows up in the job tracker log.

{code}
ERROR org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal: Exception renewing tokenIdent: 00 07 68 64 70 75 73 65 72 06 6d 61 70 72 65 64 26 6f 6f 7a 69 65 2f 63 6f 6e 64 6f 72 2d 73 65 63 2e 76 65 6e 6b 61 74 2e 6f 72 67 40 76 65 6e 6b 61 74 2e 6f 72 67 8a 01 3e a6 87 5e 5b 8a 01 3e ca 93 e2 5b 02 02, Kind: MAPREDUCE_DELEGATION_TOKEN, Service: ip:50300. Not rescheduled
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Client jt/host@domain.com tries to renew a token with renewer specified as mapred
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:267)
        at org.apache.hadoop.mapred.JobTracker.renewDelegationToken(JobTracker.java:3878)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1405)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1401)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1399)

        at org.apache.hadoop.ipc.Client.call(Client.java:1118)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
        at org.apache.hadoop.mapred.$Proxy8.renewDelegationToken(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
       at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
        at org.apache.hadoop.mapred.$Proxy8.renewDelegationToken(Unknown Source)
        at org.apache.hadoop.mapred.JobClient$Renewer.renew(JobClient.java:578)
        at org.apache.hadoop.security.token.Token.renew(Token.java:309)
        at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask$1.run(DelegationTokenRenewal.java:221)
        at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask$1.run(DelegationTokenRenewal.java:217)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
        at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask.run(DelegationTokenRenewal.java:216)
        at java.util.TimerThread.mainLoop(Timer.java:512)
        at java.util.TimerThread.run(Timer.java:462)
{code}

Setting the renewer to Kerberos Local name does not help because AbstractDelegationTokenIdentifier sets the renewer to Kerberos shortname but JobTracker.renewDelegationToken uses the fullName.  This essentially causes the renewal to fail.",0
"Currently ApplicationMaster's QOP(quality of protection) is derived from the client's config. If the client uses privacy, all the communication done by the application master will be set to privacy. 
As part of the feature to support multiple QOP (HADOOP -9709), the application master is modified so that application master can support a different QOPs for its communication with client vs its communication with other hadoop components.",0
"Running the mapred bin script with an invalid command returns exit code 0, but it should return a non-zero exit code.

{code}
[schu@hdfs-snapshots-1 ~]$ hadoop-3.0.0-SNAPSHOT/bin/mapred gibberish
gibberish - invalid command
Usage: mapred [--config confdir] COMMAND
       where COMMAND is one of:
  pipes                run a Pipes job
  job                  manipulate MapReduce jobs
  queue                get information regarding JobQueues
  classpath            prints the class path needed for running
                       mapreduce subcommands
  historyserver        run job history servers as a standalone daemon
  distcp <srcurl> <desturl> copy file or directories recursively
  archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive

Most commands print help when invoked w/o parameters.
[schu@hdfs-snapshots-1 ~]$ echo $?
0
[schu@hdfs-snapshots-1 ~]$ 
{code}",0
"There are a couple of races in DelegationTokenRenewal. 

One of them was addressed by MAPREDUCE-4860, which introduced a deadlock while fixing this race. Opening a new JIRA per discussion in MAPREDUCE-5364, since MAPREDUCE-4860 is already shipped in a release.

Races to fix:
# TimerTask#cancel() disallows future invocations of run(), but doesn't abort an already scheduled/started run().
# In the context of DelegationTokenRenewal, RenewalTimerTask#cancel() only cancels that TimerTask instance. However, it has no effect on any other TimerTasks created for that token. 



",0
"The counters Physical memory (bytes) snapshot - represented by PHYSICAL_MEMORY_BYTES ) and Virtual memory (bytes) snapshot - represented by VIRTUAL_MEMORY_BYTES have multiple issues

1. It calculates it as MemTotal from /proc/meminfo which is host level metric and not task level
2. Even if it is calculated as host level metric, the numbers shown in two different tasks on same host are different and way different than the MemTotal displayed in /proc/meminfo if you manually check it. E.g. on a host having 48G memory the tasks show the value of physical memory (byte) snapshot as 214,142,976 and the number varies every time the job is run.

What was the intention of these counters? Why would we need to get the metric for every job (as they should be more or less static for given host). ",0
nan,0
"HistoryFileManager is a service that starts threads, but it does not override the serviceStop method to stop the threads when the service is stopped.",0
"While running job , got OOM in app master and exitted the app master jvm.

{noformat}
2013-07-28 13:45:21,937 ERROR [IPC Server handler 14 on 59522] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:job_1374920247399_0422 (auth:TOKEN) cause:java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:21,937 INFO [IPC Server handler 22 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1374920247399_0422_r_000384_0
2013-07-28 13:45:46,100 INFO [IPC Server handler 22 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1374920247399_0422_r_000384_0 is : 0.22976667
2013-07-28 13:45:21,937 ERROR [IPC Server handler 15 on 59522] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:job_1374920247399_0422 (auth:TOKEN) cause:java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:21,937 ERROR [IPC Server handler 13 on 59522] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:job_1374920247399_0422 (auth:TOKEN) cause:java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:54,522 INFO [IPC Server handler 15 on 59522] org.apache.hadoop.ipc.Server: IPC Server handler 15 on 59522, call statusUpdate(attempt_1374920247399_0422_r_000225_0, org.apache.hadoop.mapred.ReduceTaskStatus@dd89c26), rpc version=2, client version=19, methodsFingerPrint=937413979 from 10.71.115.238:59691: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space
java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:21,937 INFO [IPC Server handler 19 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1374920247399_0422_r_000307_0
2013-07-28 13:45:21,937 INFO [IPC Server handler 16 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1374920247399_0422_r_000552_0
2013-07-28 13:46:09,900 INFO [IPC Server handler 16 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1374920247399_0422_r_000552_0 is : 0.17983334
2013-07-28 13:45:14,870 ERROR [IPC Server handler 6 on 59522] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:job_1374920247399_0422 (auth:TOKEN) cause:java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:14,870 FATAL [ResponseProcessor for block BP-myhacluster-25656:blk_-2026966945468195799_12352] org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[ResponseProcessor for block BP-myhacluster-25656:blk_-2026966945468195799_12352,5,main] threw an Error.  Shutting down now...
java.lang.OutOfMemoryError: Java heap space
{noformat}",0
nan,0
"Currently the mapred-default.xml has ""mapreduce.application.classpath"" entry set to
$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/
which is problematic on Windows since the path does not work on Windows OS.

Additionally, the yarn-default.xml has ""yarn.application.classpath"" entry that has similar problem, and is currently being tracked by YARN-1138",0
nan,0
nan,0
nan,0
"When MRClientService receives requests, it calls verifyAndGetJob which does not actually validate that the current user has the proper access.",0
nan,0
"TestUberAM has been timing out on trunk for some time now and surefire then fails the build.  I'm not able to reproduce it locally, but the Jenkins builds have been seeing it fairly consistently.  See https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1529/console

This is caused by changes made in MAPREDUCE-434 breaking Uber AMs.  The easiest fix is to make similar changes in Uber AMs to those in MAPREDUCE-434 to allow multiple reducers.",0
"MAPREDUCE-5357 does a fileystem chown() operation. chown() is not valid unless you are superuser. if you a chown() to yourself is a NOP, that is why has not been detected in Hadoop testcases where user is running as itself. However, in distcp testcases run by Oozie which use test users/groups from UGI for minicluster it is failing because of this chown() either because the test user does not exist of because the current use does not have privileges to do a chown().

We should revert MAPREDUCE-5357. Windows should handle this with some conditional logic used only when running in Windows.

Opening a new JIRA and not reverting directly because MAPREDUCE-5357 went in 2.1.0-beta.",0
"Here is the client stack trace

{code}
RUNNING: /usr/lib/hadoop/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.1.0.2.0.5.0-66.jar wordcount ""-Dmapreduce.reduce.input.limit=-1"" /user/user/test_yarn_ha/medium_wordcount_input /user/hrt_qa/test_yarn_ha/test_mapred_ha_single_job_applicationmaster-1-time
13/08/30 08:45:39 INFO client.RMProxy: Connecting to ResourceManager at hostname/68.142.247.148:8032
13/08/30 08:45:40 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 19 for user on ha-hdfs:ha-2-secure
13/08/30 08:45:40 INFO security.TokenCache: Got dt for hdfs://ha-2-secure; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ha-2-secure, Ident: (HDFS_DELEGATION_TOKEN token 19 for user)
13/08/30 08:45:40 INFO input.FileInputFormat: Total input paths to process : 20
13/08/30 08:45:40 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
13/08/30 08:45:40 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev cf4e7cbf8ed0f0622504d008101c2729dc0c9ff3]
13/08/30 08:45:40 INFO mapreduce.JobSubmitter: number of splits:180
13/08/30 08:45:40 WARN conf.Configuration: user.name is deprecated. Instead, use mapreduce.job.user.name
13/08/30 08:45:40 WARN conf.Configuration: mapred.jar is deprecated. Instead, use mapreduce.job.jar
13/08/30 08:45:40 WARN conf.Configuration: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
13/08/30 08:45:40 WARN conf.Configuration: mapreduce.combine.class is deprecated. Instead, use mapreduce.job.combine.class
13/08/30 08:45:40 WARN conf.Configuration: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
13/08/30 08:45:40 WARN conf.Configuration: mapred.job.name is deprecated. Instead, use mapreduce.job.name
13/08/30 08:45:40 WARN conf.Configuration: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
13/08/30 08:45:40 WARN conf.Configuration: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
13/08/30 08:45:40 WARN conf.Configuration: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
13/08/30 08:45:40 WARN conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
13/08/30 08:45:40 WARN conf.Configuration: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
13/08/30 08:45:40 WARN conf.Configuration: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
13/08/30 08:45:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1377851032086_0003
13/08/30 08:45:41 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ha-2-secure, Ident: (HDFS_DELEGATION_TOKEN token 19 for user)
13/08/30 08:45:42 INFO impl.YarnClientImpl: Submitted application application_1377851032086_0003 to ResourceManager at hostname/68.142.247.148:8032
13/08/30 08:45:42 INFO mapreduce.Job: The url to track the job: http://hostname:8088/proxy/application_1377851032086_0003/
13/08/30 08:45:42 INFO mapreduce.Job: Running job: job_1377851032086_0003
13/08/30 08:45:48 INFO mapreduce.Job: Job job_1377851032086_0003 running in uber mode : false
13/08/30 08:45:48 INFO mapreduce.Job:  map 0% reduce 0%
stop applicationmaster
beaver.component.hadoop|INFO|Kill container container_1377851032086_0003_01_000001 on host hostname
RUNNING: ssh -o StrictHostKeyChecking=no hostname ""sudo su - -c \""ps aux | grep container_1377851032086_0003_01_000001 | awk '{print \\\$2}' | xargs kill -9\"" root""
Warning: Permanently added 'hostname,68.142.247.155' (RSA) to the list of known hosts.
kill 8978: No such process
waiting for down time 10 seconds for service applicationmaster
13/08/30 08:45:55 INFO ipc.Client: Retrying connect to server: hostname/68.142.247.155:52713. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1 SECONDS)
13/08/30 08:45:56 INFO ipc.Client: Retrying connect to server: hostname/68.142.247.155:52713. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1 SECONDS)
13/08/30 08:45:56 ERROR security.UserGroupInformation: PriviledgedActionException as:user@REALM (auth:KERBEROS) cause:java.io.IOException: java.net.ConnectException: Call From hostname.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
java.io.IOException: java.net.ConnectException: Call From hostname.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:319)
at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:354)
at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:529)
at org.apache.hadoop.mapreduce.Job$5.run(Job.java:668)
at org.apache.hadoop.mapreduce.Job$5.run(Job.java:665)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:665)
at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1349)
at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1289)
at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: java.net.ConnectException: Call From hostname.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
at org.apache.hadoop.ipc.Client.call(Client.java:1351)
at org.apache.hadoop.ipc.Client.call(Client.java:1300)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
at $Proxy14.getTaskAttemptCompletionEvents(Unknown Source)
at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:177)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:310)
... 23 more
Caused by: java.net.ConnectException: Connection refused
at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:547)
at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:642)
at org.apache.hadoop.ipc.Client$Connection.access$2600(Client.java:314)
at org.apache.hadoop.ipc.Client.getConnection(Client.java:1399)
at org.apache.hadoop.ipc.Client.call(Client.java:1318)
... 32 more
{code}",0
"When RM restarted, if during restart one NM went bad (bad disk), NM got blacklisted by AM and RM keeps giving the containers on the same node even though AM doesn't want it there.

Need to change AM to specifically blacklist node in the RM requests.
",0
"Currently, MapReduce uses the command line argument to pass the classpath to the child. This breaks if the process forks a child that needs the same classpath. Such a case happens in Hive when it uses map-side joins. I propose that we make MapReduce in branch-1 use the CLASSPATH environment variable like YARN does.",0
"When there are multiple NICs and JobTracker need listen on all NICs, for example when set mapred.job.tracker to 0.0.0.0:8021, then getJobTrackerMachine() will return 0.0.0.0, it cause some problems, for example url in JobProfile won't work. Set this to a hostname can make it work.
",0
"For running jobs on Hadoop 2.0, trying to access Task counters page throws Server 500 error. Digging a bit I see this exception in MRAppMaster logs

{noformat}

2013-08-09 21:54:35,083 ERROR [556661283@qtp-875702288-23] org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /mapreduce/task/task_1376081364308_0002_m_000001
java.lang.reflect.InvocationTargetException
     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
     at java.lang.reflect.Method.invoke(Method.java:606)
     at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:150)
     at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
     at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)
     at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:178)
     at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)
     at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:62)
     at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)
     at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)
     at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)
     at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)
     at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)
     at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)
     at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)
     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
     at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:123)
     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
     at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1069)
     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
     at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
     at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
     at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
     at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
     at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
     at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
     at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
     at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
     at org.mortbay.jetty.Server.handle(Server.java:326)
     at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
     at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
     at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
     at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
     at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
     at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
     at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Caused by: org.apache.hadoop.yarn.webapp.WebAppException: Error rendering block: nestLevel=6 expected 5
     at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:66)
     at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
     at org.apache.hadoop.yarn.webapp.View.render(View.java:233)
     at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:47)
     at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)
     at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:843)
     at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:54)
     at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:80)
     at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:210)
     at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.task(AppController.java:256)
     ... 39 more
2013-08-09 21:54:36,660 INFO [IPC Server handler 4 on 51776] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1376081364308_0002_m_000000_0
2013-08-09 21:54:36,661 INFO [IPC Server handler 4 on 51776] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1376081364308_0002_m_000000_0 is : 0.21281

{noformat}

This looks to be critical bug because unable to access counters will be major setback for users to be able to debug running jobs.

Note that same job counters work fine if we access it from JobHistoryServer",0
"
History link in resource manager is broken for KILLED jobs.

Seems to happen with jobs with State 'KILLED' and FinalStatus 'KILLED'. If the State is 'FINISHED' and FinalStatus is 'KILLED', then the ""History"" link is fine.

It isn't easy to reproduce the problem since the time at which the app is killed determines the state it ends up in, which is hard to guess. these particular jobs seem to get a Diagnostics message of ""Application killed by user."" where as the other killed jobs get "" Kill Job received from client job_1378766187901_0002
Job received Kill while in RUNNING state. ""
",0
"After I set:
- 'jobConf.setMapRunnerClass(MultithreadedMapRunner.class);' in MR app
- 'mapred.map.multithreadedrunner.threads = 2' in mapred-site.xml

A simple MR app failed as its Map task encountered ArrayIndexOutOfBoundsException as below(please ignore the line numbers in the exception as I added some log print codes):
java.lang.ArrayIndexOutOfBoundsException
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer$Buffer.write(MapTask.java:1331)
        at java.io.DataOutputStream.write(DataOutputStream.java:101)
        at org.apache.hadoop.io.Text.write(Text.java:282)
        at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:90)
        at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:77)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1060)
        at org.apache.hadoop.mapred.MapTask$OldOutputCollector.collect(MapTask.java:591)
        at study.hadoop.mapreduce.sample.WordCount$Map.map(WordCount.java:41)
        at study.hadoop.mapreduce.sample.WordCount$Map.map(WordCount.java:1)
        at org.apache.hadoop.mapred.lib.MultithreadedMapRunner$MapperInvokeRunable.run(MultithreadedMapRunner.java:231)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:897)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:919)
        at java.lang.Thread.run(Thread.java:738)


And the exception happens on line 'System.arraycopy(b, off, kvbuffer, bufindex, len)' in MapTask.java#MapOutputBuffer#Buffer#write(). When the exception occurs, 'b.length=4' but 'len=9'. 

Btw, if I set 'mapred.map.multithreadedrunner.threads = 1', no exception happened. So it should be an issue caused by multiple threads.
",0
"Today if we are setting ""yarn.app.mapreduce.am.job.reduce.rampup.limit"" and ""mapreduce.job.reduce.slowstart.completedmaps"" then reducers are launched more aggressively. However the calculation to either Ramp up or Ramp down reducer is not done in most optimal way. 
* If MR AM at any point sees situation something like 
** scheduledMaps : 30
** scheduledReducers : 10
** assignedMaps : 0
** assignedReducers : 11
** finishedMaps : 120
** headroom : 756 ( when your map /reduce task needs only 512mb)
* then today it simply hangs because it thinks that there is sufficient room to launch one more mapper and therefore there is no need to ramp down. However, if this continues forever then this is not the correct way / optimal way.
* Ideally for MR AM when it sees that assignedMaps drops have dropped to 0 and there are running reducers around then it should wait for certain time ( upper limited by average map task completion time ... for heuristic sake)..but after that if still it doesn't get new container for map task then it should preempt the reducer one by one with some interval and should ramp up slowly...
** Preemption of reducers can be done in little smarter way
*** preempt reducer on a node manager for which there is any pending map request.
*** otherwise preempt any other reducer. MR AM will contribute to getting new mapper by releasing such a reducer / container because it will reduce its cluster consumption and thereby may become candidate for an allocation.",0
"MAPREDUCE-5351 fixed a memory leak problem but introducing another filesystem object (see ""tempDirFs"") that is not properly released.
{code} JobInProgress#cleanupJob()

  void cleanupJob() {
...
          tempDirFs = jobTempDirPath.getFileSystem(conf);
          CleanupQueue.getInstance().addToQueue(
              new PathDeletionContext(jobTempDirPath, conf, userUGI, jobId));
...
 if (tempDirFs != fs) {
      try {
        fs.close();
      } catch (IOException ie) {
...
}
{code}
",0
"when it hadppen, I notice reduces were not preempt

2013-09-15 10:32:26,608 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1
2013-09-15 10:32:26,608 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce
2013-09-15 10:32:26,608 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1377833725640_158209_01_004100 to attempt_1377833725640_158209_r_000258_0
2013-09-15 10:32:26,608 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=582656
2013-09-15 10:32:26,608 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.9940104 totalMemLimit:2548736 finalMapMemLimit:70656 finalReduceMemLimit:2478080 netScheduledMapMem:70656 netScheduledReduceMem:2460672
2013-09-15 10:32:26,608 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping up 1
2013-09-15 10:32:26,608 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:212 ScheduledMaps:22 ScheduledReds:55 AssignedMaps:1 AssignedReds:213 CompletedMaps:3817 CompletedReds:0 ContAlloc:4031 ContRel:0 HostLocal:0 RackLocal:0
",0
"TaskTracker hung after failed reconnect to the JobTracker. 

This is the problematic piece of code:
{code}
    this.distributedCacheManager = new TrackerDistributedCacheManager(
        this.fConf, taskController);
    this.distributedCacheManager.startCleanupThread();
    
    this.jobClient = (InterTrackerProtocol) 
    UserGroupInformation.getLoginUser().doAs(
        new PrivilegedExceptionAction<Object>() {
      public Object run() throws IOException {
        return RPC.waitForProxy(InterTrackerProtocol.class,
            InterTrackerProtocol.versionID,
            jobTrackAddr, fConf);
      }
    });
{code}

In case RPC.waitForProxy() throws, TrackerDistributedCacheManager cleanup thread will never be stopped, and given that it is a non daemon thread it will keep TT up forever.",0
"JobControl.toList is locking individual lists to iterate them, but those lists can be modified elsewhere without holding the list lock.  The locking approaches are mismatched, with toList holding the lock on the actual list object while other methods hold the JobControl lock when modifying the lists.",0
related issue YARN-1203. We need to disable https for MR-AM by default as they will need access to keystore which can not be granted in the cluster.,0
"Since there is no reducer, the memory allocated to reducer is irrelevant to enable uber mode of a job",0
We have sort job where reduce attempt does not send heartbeat in timely manner to application master. The AM should kick off another attempt to let job succeeds. What we find is the job fails and there is no speculation happening.,0
"The jobhistory server starts on port defined by mapreduce.jobhistory.webapp.address property instead mapreduce.jobhistory.webapp.https.address when hadoop.ssl.enabled=true.

",0
"the  environment:
hive-0.8.1
hadoop-0.20.2-cdh3u6
the Presentation:
i use the hive-0.8.1 to exec the query:
select count(*) from table t1;

the table t1 is lzo formatted ,and the follows is :
# Storage Information                                                                                                
SerDe Library:                  org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                   
InputFormat:                    com.hadoop.mapred.DeprecatedLzoTextInputFormat                                       
OutputFormat:                   org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat 

and the hive.hadoop.supports.splittable.combineinputformat =true
when i index the table t1,the result is  265329 .
when i remove the index of the t1,the result is  265325.",0
nan,0
If a client tries to kill a job just as the job is finishing then the client can crash with an NPE.,0
nan,0
nan,0
nan,0
nan,0
nan,0
"On secure clusters we see the following exceptions in the jt log

{code}
2013-10-04 04:52:31,753 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:tt/host@REALM cause:javax.security.sasl.SaslException: GSS
initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
{code}


And after the job finishes the staging dir is not cleaned up. While debugging with [~acmurthy] we determined that file system object needs to be created in the the context of the user who ran the job.

Job however successfully completes",0
"The closing split is not calculated correctly:
{code}
     // Catch any overage and create the closed interval for the last split.
     if (curLower <= maxVal || splits.size() == 1) {
       splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(
-          lowClausePrefix + Double.toString(curUpper),
+          lowClausePrefix + Double.toString(curLower),
           colName + "" <= "" + Double.toString(maxVal)));
     }
{code}
For the case of min=5.0, max=7.0, 2 splits, the current code returns splits of (column1 >=5.0, column1 <6.0), (column1 >=7.0, column1 <=7.0). The second split is obviously not correct.",0
If a map task attempt is retroactively failed due to excessive fetch failures reported by reducers then the attempt's finish time is set to the time the task was retroactively failed rather than when the task attempt completed.  This causes the map task attempt to appear to have run for much longer than it actually did.,0
"The job submission and staging directories are explicitly given 0700 permissions restricting access of job submission files only to the submitter UID. this prevents hadoop daemon services running under different UIDs from reading the job submitters files.  it is common unix practice to run daemon services under their own UIDs for security purposes.

This bug can be demonstrated by creating a single node configuration, which runs LocalFileSystem and not HDFS.  Create two users and add them to a 'hadoop' group.  Start the hadoop services with one of the users, then submit a map/reduce job with the other user (or run one of the examples).  Job submission ultimately fails and the M/R job doesn't execute.

The fix is simple enough and secure-- change the staging directory permissions to 2750.  i have demonstrated the patch against 2.0.5 (along  with another fix for an incorrect decimal->octal conversion) and will attach the patch.

this bug is present since very early versions.  i would like to fix it at the lowest level as  it's a simple file mode change in all versions, and localized to one file.  is this possible?",0
If a user does not have view ACL permissions for a job and tries to view the job configuration URL (i.e.: .../jobhistory/conf/<jobid>) then the history server returns a 500 error rather than a descriptive error message informing the user that they lack permissions.,0
While running gridmix on 2.3 we noticed that jobs are running much slower than normal.  We tracked this down to reducers having difficulties shuffling data from maps.  Details to follow.,0
nan,0
"If you request {{/tasktracker.jsp}} frequently on a TaskTracker that's busy, every once in a while you'll get this:
{code}
2013-10-29 13:25:55,524 ERROR org.mortbay.log: /tasktracker.jsp
java.util.ConcurrentModificationException
        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1117)
        at java.util.TreeMap$EntryIterator.next(TreeMap.java:1153)
        at java.util.TreeMap$EntryIterator.next(TreeMap.java:1148)
        at org.apache.hadoop.mapred.TaskTracker.getTasksFromRunningJobs(TaskTracker.java:3991)
        at org.apache.hadoop.mapred.tasktracker_jsp._jspService(tasktracker_jsp.java:98)
        at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:98)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1056)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
{code}",0
nan,0
The test uses the full class name as a component of the {{yarn.nodemanager.local-dirs}} setting for a {{MiniMRYarnCluster}}.  This causes container launch to fail when trying to access files at a path longer than the maximum of 260 characters.,0
"when a  datanode was crash,the server can  ping ok,but can not  call rpc ,and also can not ssh login. and then jobTracker may be request a block on this datanode.
it will happened ,the  JobTracker can not work,the webUI is also unwork,hadoop job -list also unwork,the jobTracker logs no other info .

and then we need to restart the datanode.
then jobTraker can work too,but the taskTracker num come to zero,
we need run : hadoop mradmin -refreshNodes
then the JobTracker begin to add taskTraker ,but is very slowly.

this problem occur 5time  in 2weeks.
",0
nan,0
"In a Cluster with 16GB capacity, job has started with 100maps and 10 reducers. 

When the reducers has started its execution, one NM has went down and resulted a failure for 2 maps. But at this time, remaining 8Gb was used by 6 reducers and AM. So there was no place to launch the failed maps. [NM never came up again, and cluster size became 8GB]

If we kill one of reducers, then also the map cannot be launched as the priority of Failed map is lesser than that of reducer. So the remaining reducer only will get allocated from RM side.

This is causing a hang for in reducer side. ",0
"When one uses dedicated hprof mapreduce.task.profile.map.params or mapreduce.task.profile.reduce.params, the profiled tasks will fail to launch because hprof parameters are supplied to the child jvm twice.",0
"When a DistCp job is run through Oozie (through a Java action that launches DistCp), one sees that mapred.child.java.opts as set from the caller is honoured by DistCp. But, DistCp doesn't seem to honour any overrides for configs mapreduce.[map,reduce].memory.mb.

Problem has been identified. I'll post a patch shortly.",0
"Bzip2Codec.BZip2CompressionInputStream can cause records to be dropped when reading them in splits based on where record delimiters occur relative to compression block boundaries.

Thanks to [~knoguchi] for discovering this problem while working on PIG-3251.",0
"If a combine split consists of many ""empty"" files (i.e.: no record found by the underlying record reader) then theoretically a task can timeout due to lack of reported progress.",0
"MapReduce should filter ""illegal"" progress values that do not fall into (0,1) interval when the progress value is given.

If it is Float.NaN, Float.NEGATIVE_INFINITY, or smaller than 0: set progress to be 0;
If its is Float.POSITIVE_INFINITY or larger than 1: set progress to be 1;
",0
"org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing can fail because of race condition.
{noformat}
testHistoryParsingWithParseErrors(org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing)  Time elapsed: 4.102 sec  <<< ERROR!
java.io.IOException: Unable to initialize History Viewer
        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:520)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:137)
        at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:339)
        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:798)
        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.<init>(JobHistoryParser.java:86)
        at org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.<init>(HistoryViewer.java:85)
        at org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(TestJobHistoryParsing.java:339)
        at org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.testHistoryParsingWithParseErrors(TestJobHistoryParsing.java:125)
{noformat}

In the checkHistoryParsing() function, after 
{code}
HistoryFileInfo fileInfo = jobHistory.getJobFileInfo(jobId);
{code}
a thread named MoveIntermediateToDone will be launched to move history file from done_intermediate to done directory.
If the history file is moved, 
{code}
      HistoryViewer viewer = new HistoryViewer(fc.makeQualified(
          fileInfo.getHistoryFile()).toString(), conf, true);
{code}
will throw IOException锛宐ecause the history file is not found.",0
"We saw corner case where Jobs running on cluster were hung. Scenario was something like this. Job was running within a pool which was running at its capacity. All available containers were occupied by reducers and last 2 mappers. There were few more reducers waiting to be scheduled in pipeline. 
At this point two mappers which were running failed and went back to scheduled state. two available containers were assigned to reducers, now whole pool was full of reducers waiting on two maps to be complete. 2 maps never got scheduled because pool was full.

Ideally reducer preemption should have kicked in to make room for Mappers from this code in RMContaienrAllocator
{code}
int completedMaps = getJob().getCompletedMaps();
    int completedTasks = completedMaps + getJob().getCompletedReduces();
    if (lastCompletedTasks != completedTasks) {
      lastCompletedTasks = completedTasks;
      recalculateReduceSchedule = true;
    }

    if (recalculateReduceSchedule) {
      preemptReducesIfNeeded();
{code}

But in this scenario lastCompletedTasks is always completedTasks because maps were never completed. This would cause job to hang forever. As workaround if we kill few reducers, mappers would get scheduled and caused job to complete.

",0
"TestLocalMRNotificationis occasionally failing with the error:
{code}
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.mapred.TestLocalMRNotification
-------------------------------------------------------------------------------
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 24.992 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestLocalMRNotification
testMR(org.apache.hadoop.mapred.TestLocalMRNotification)  Time elapsed: 24.881 sec  <<< ERROR!
java.io.IOException: Job cleanup didn't start in 20 seconds
        at org.apache.hadoop.mapred.UtilsForTests.runJobKill(UtilsForTests.java:685)
        at org.apache.hadoop.mapred.NotificationTestCase.testMR(NotificationTestCase.java:178)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at junit.framework.TestCase.runTest(TestCase.java:168)
        at junit.framework.TestCase.runBare(TestCase.java:134)
        at junit.framework.TestResult$1.protect(TestResult.java:110)
        at junit.framework.TestResult.runProtected(TestResult.java:128)
        at junit.framework.TestResult.run(TestResult.java:113)
        at junit.framework.TestCase.run(TestCase.java:124)
        at junit.framework.TestSuite.runTest(TestSuite.java:243)
        at junit.framework.TestSuite.run(TestSuite.java:238)
        at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:254)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:149)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
{code}",0
