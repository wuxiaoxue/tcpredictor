HBASE-20345,"I am running HBase in a docker container. Version is 1.2.4 (Also tried 1.2.6)

Basically based on
{quote}[https://github.com/dajobe/hbase-docker]
{quote}
When i do the following:

1) Build the image: *docker build -t hbase-docker .*

2) Start the container: *./start-hbase.sh*

3) Go in the container: *docker exec -it hbase bash*

4) Open HBase shell: *hbase shell*

5) and then if i type something and press backspace, it crashes with following:
{code:java}
hbase(main):001:0> li ConsoleReader.java:1414:in `backspace': java.lang.ArithmeticException: / by zero
Any idea how to make backspace work and prevent this from happening?! Thank you"
HBASE-19221,"Copying the mail from the dev@
{code}
I tried running some IT test cases using the alpha-4 RC. I found this issue
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/hamcrest/SelfDescribing
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:760)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
        at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:361)

...
       at org.apache.hadoop.hbase.IntegrationTestsDriver.doWork(IntegrationTestsDriver.java:111)
        at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:154)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
        at org.apache.hadoop.hbase.IntegrationTestsDriver.main(IntegrationTestsDriver.java:47)

The same when run against latest master it runs without any issues
{code}"
HBASE-18896,"HADOOP-14267 change methods on DistCpOptions and introduced a new Builder class which doesn't exist on any previous releases.

We'll have to shim/reflect around this."
HBASE-20336,"running {{mvn verify}} for the spark integration tests against current master fails

{code}
$ mvn -DskipTests install
11:37:26,815 [INFO] Scanning for projects...
...
11:43:36,711 [INFO] ------------------------------------------------------------------------
11:43:36,711 [INFO] Reactor Summary:
11:43:36,711 [INFO] 
11:43:36,712 [INFO] Apache HBase ....................................... SUCCESS [  6.294 s]
11:43:36,712 [INFO] Apache HBase - Checkstyle .......................... SUCCESS [  1.742 s]
11:43:36,712 [INFO] Apache HBase - Build Support ....................... SUCCESS [  0.070 s]
11:43:36,712 [INFO] Apache HBase - Error Prone Rules ................... SUCCESS [  2.206 s]
11:43:36,712 [INFO] Apache HBase - Annotations ......................... SUCCESS [  1.413 s]
11:43:36,712 [INFO] Apache HBase - Build Configuration ................. SUCCESS [  0.254 s]
11:43:36,712 [INFO] Apache HBase - Shaded Protocol ..................... SUCCESS [ 37.870 s]
11:43:36,712 [INFO] Apache HBase - Common .............................. SUCCESS [ 12.526 s]
11:43:36,712 [INFO] Apache HBase - Metrics API ......................... SUCCESS [  2.412 s]
11:43:36,712 [INFO] Apache HBase - Hadoop Compatibility ................ SUCCESS [  3.260 s]
11:43:36,712 [INFO] Apache HBase - Metrics Implementation .............. SUCCESS [  2.756 s]
11:43:36,713 [INFO] Apache HBase - Hadoop Two Compatibility ............ SUCCESS [  3.959 s]
11:43:36,713 [INFO] Apache HBase - Protocol ............................ SUCCESS [ 11.295 s]
11:43:36,713 [INFO] Apache HBase - Client .............................. SUCCESS [ 15.360 s]
11:43:36,713 [INFO] Apache HBase - Zookeeper ........................... SUCCESS [  4.389 s]
11:43:36,713 [INFO] Apache HBase - Replication ......................... SUCCESS [  4.202 s]
11:43:36,713 [INFO] Apache HBase - Resource Bundle ..................... SUCCESS [  0.206 s]
11:43:36,713 [INFO] Apache HBase - HTTP ................................ SUCCESS [  8.530 s]
11:43:36,713 [INFO] Apache HBase - Procedure ........................... SUCCESS [  4.196 s]
11:43:36,713 [INFO] Apache HBase - Server .............................. SUCCESS [ 44.604 s]
11:43:36,713 [INFO] Apache HBase - MapReduce ........................... SUCCESS [ 11.122 s]
11:43:36,713 [INFO] Apache HBase - Testing Util ........................ SUCCESS [  6.633 s]
11:43:36,713 [INFO] Apache HBase - Thrift .............................. SUCCESS [  9.771 s]
11:43:36,713 [INFO] Apache HBase - RSGroup ............................. SUCCESS [  6.703 s]
11:43:36,713 [INFO] Apache HBase - Shell ............................... SUCCESS [  7.094 s]
11:43:36,713 [INFO] Apache HBase - Coprocessor Endpoint ................ SUCCESS [  7.542 s]
11:43:36,713 [INFO] Apache HBase - Backup .............................. SUCCESS [  6.246 s]
11:43:36,713 [INFO] Apache HBase - Integration Tests ................... SUCCESS [  7.461 s]
11:43:36,713 [INFO] Apache HBase - Examples ............................ SUCCESS [  9.054 s]
11:43:36,713 [INFO] Apache HBase - Rest ................................ SUCCESS [  8.972 s]
11:43:36,713 [INFO] Apache HBase - External Block Cache ................ SUCCESS [  5.180 s]
11:43:36,713 [INFO] Apache HBase - Spark ............................... SUCCESS [01:10 min]
11:43:36,713 [INFO] Apache HBase - Spark Integration Tests ............. SUCCESS [  7.774 s]
11:43:36,713 [INFO] Apache HBase - Assembly ............................ SUCCESS [ 15.075 s]
11:43:36,713 [INFO] Apache HBase - Shaded .............................. SUCCESS [  0.323 s]
11:43:36,713 [INFO] Apache HBase - Shaded - Client ..................... SUCCESS [  3.004 s]
11:43:36,713 [INFO] Apache HBase - Shaded - MapReduce .................. SUCCESS [  3.542 s]
11:43:36,714 [INFO] Apache HBase Shaded Packaging Invariants ........... SUCCESS [  3.105 s]
11:43:36,714 [INFO] Apache HBase - Archetypes .......................... SUCCESS [  0.063 s]
11:43:36,714 [INFO] Apache HBase - Exemplar for hbase-client archetype . SUCCESS [  4.843 s]
11:43:36,714 [INFO] Apache HBase - Exemplar for hbase-shaded-client archetype SUCCESS [  4.523 s]
11:43:36,714 [INFO] Apache HBase - Archetype builder ................... SUCCESS [  0.739 s]
11:43:36,714 [INFO] ------------------------------------------------------------------------
11:43:36,714 [INFO] BUILD SUCCESS
11:43:36,714 [INFO] ------------------------------------------------------------------------
11:43:36,714 [INFO] Total time: 06:09 min
11:43:36,714 [INFO] Finished at: 2018-04-03T11:43:36-05:00
11:43:38,408 [INFO] Final Memory: 305M/1087M
11:43:38,408 [INFO] ------------------------------------------------------------------------
$ mvn -pl hbase-spark -pl hbase-spark-it verify
11:45:14,664 [INFO] Scanning for projects...
...

11:49:27,439 [INFO] --- maven-failsafe-plugin:2.21.0:integration-test (integration-test) @ hbase-spark-it ---
11:49:27,576 [WARNING] The parameter forkMode is deprecated since version 2.14. Use forkCount and reuseForks instead.
11:49:27,641 [INFO] 
11:49:27,641 [INFO] -------------------------------------------------------
11:49:27,641 [INFO]  T E S T S
11:49:27,641 [INFO] -------------------------------------------------------
11:49:27,866 [WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /Users/busbey/tmp_projects/hbase/hbase-spark-it/target/failsafe-reports/2018-04-03T11-49-27_574-jvmRun1.dumpstream
11:49:28,752 [INFO] Running org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad
11:49:36,776 [ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 7.995 s <<< FAILURE! - in org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad
11:49:36,776 [ERROR] testBulkLoad(org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad)  Time elapsed: 7.699 s  <<< ERROR!
java.io.IOException: Shutting down
	at org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad.setUpCluster(IntegrationTestSparkBulkLoad.java:613)
Caused by: java.lang.RuntimeException: Failed construction of RegionServer: class org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer
	at org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad.setUpCluster(IntegrationTestSparkBulkLoad.java:613)
Caused by: java.lang.IllegalArgumentException: port out of range:-1
	at org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad.setUpCluster(IntegrationTestSparkBulkLoad.java:613)

11:49:37,190 [INFO] 
11:49:37,190 [INFO] Results:
11:49:37,191 [INFO] 
11:49:37,191 [ERROR] Errors: 
11:49:37,191 [ERROR]   IntegrationTestSparkBulkLoad>IntegrationTestBase.setUp:170->setUpCluster:613 禄 IO
11:49:37,191 [INFO] 
11:49:37,191 [ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0
11:49:37,191 [INFO] 
11:49:37,199 [INFO] 
11:49:37,199 [INFO] --- maven-failsafe-plugin:2.21.0:verify (verify) @ hbase-spark-it ---
11:49:37,848 [INFO] ------------------------------------------------------------------------
11:49:37,848 [INFO] Reactor Summary:
11:49:37,848 [INFO] 
11:49:37,848 [INFO] Apache HBase - Spark ............................... SUCCESS [03:57 min]
11:49:37,848 [INFO] Apache HBase - Spark Integration Tests ............. FAILURE [ 22.686 s]
11:49:37,849 [INFO] ------------------------------------------------------------------------
11:49:37,849 [INFO] BUILD FAILURE
11:49:37,849 [INFO] ------------------------------------------------------------------------
11:49:37,849 [INFO] Total time: 04:23 min
11:49:37,849 [INFO] Finished at: 2018-04-03T11:49:37-05:00
11:49:38,093 [INFO] Final Memory: 75M/762M
11:49:38,094 [INFO] ------------------------------------------------------------------------
11:49:38,096 [ERROR] Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.21.0:verify (verify) on project hbase-spark-it: There are test failures.
11:49:38,096 [ERROR] 
11:49:38,096 [ERROR] Please refer to /Users/busbey/tmp_projects/hbase/hbase-spark-it/target/failsafe-reports for the individual test results.
11:49:38,096 [ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
11:49:38,096 [ERROR] -> [Help 1]
11:49:38,096 [ERROR] 
11:49:38,096 [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
11:49:38,096 [ERROR] Re-run Maven using the -X switch to enable full debug logging.
11:49:38,096 [ERROR] 
11:49:38,096 [ERROR] For more information about the errors and possible solutions, please read the following articles:
11:49:38,096 [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
11:49:38,096 [ERROR] 
11:49:38,096 [ERROR] After correcting the problems, you can resume the build with the command
11:49:38,096 [ERROR]   mvn <goals> -rf :hbase-spark-it
{code}"
HBASE-20381,see HBASE-20219 and related builds.
HBASE-2042,"Below is from Stefan Will:

{code}
I just ran into another case where a Regionserver wouldn't properly shut down (this is on my development cluster, so not too critical). In this case, it is also holding over 27000 datanode sockets (port 50010) in CLOSE_WAIT state. I was actually using so many that the SSH daemon wouldn't let me log in to the machine due to too many open file handles (I can probably figure out how to increase that limit). So I shut down the Master and the other regionservers, which might have been the cause for it to be in ""handleConnectionFailure()"". The last few lines of the log were:

009-12-06 10:30:12,609 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: aborting server at: 10.1.20.144:60020 <http://10.1.20.144:60020>
- Hide quoted text -
2009-12-06 10:30:12,646 INFO org.apache.hadoop.hbase.regionserver.LogFlusher: regionserver/10.1.20.144:60020.logFlusher exiting
2009-12-06 10:30:12,646 INFO org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker: regionserver/10.1.20.144:60020.majorCompactionChecker exiting
2009-12-06 10:30:14,871 INFO org.apache.hadoop.hbase.Leases: regionserver/10.1.20.144:60020.leaseChecker closing leases
2009-12-06 10:30:14,871 INFO org.apache.hadoop.hbase.Leases: regionserver/10.1.20.144:60020.leaseChecker closed leases
2009-12-06 10:30:17,366 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting
2009-12-06 10:30:17,366 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x2255b24f9f1003a
2009-12-06 10:30:17,366 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn for session: 0x2255b24f9f1003a
2009-12-06 10:30:17,387 INFO org.apache.zookeeper.ClientCnxn: Exception while closing send thread for session 0x2255b24f9f1003a : Read error rc = -1 java.nio.DirectByteBuffer[
pos=0 lim=4 cap=4]
2009-12-06 10:30:17,489 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn for session: 0x2255b24f9f1003a
2009-12-06 10:30:17,489 INFO org.apache.zookeeper.ZooKeeper: Session: 0x2255b24f9f1003a closed
2009-12-06 10:30:17,548 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-12-06 20:35:25,725 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Starting shutdown thread.

And here is the stacktrace taken after I was able to log back into the machine and send a kill to the process (at the last timestamp). It is now 15 minutes later, and the process is still running with no further log output.

Between midnight and 10:30, there are also over 6700 checksum errors in the log, always with the same log file name:

org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_4234778497757442733:of:/hbase/post/1926133619/oldlogfile.log at 62521344
        at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
        at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)

Here is the stack dump:

Exception in thread ""LeaseChecker"" java.lang.NullPointerException
    at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:351)
    at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:313)
    at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:176)
    at org.apache.hadoop.ipc.Client.getConnection(Client.java:859)
    at org.apache.hadoop.ipc.Client.call(Client.java:719)
    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
    at $Proxy1.renewLease(Unknown Source)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
    at $Proxy1.renewLease(Unknown Source)
    at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1046)
    at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1058)
    at java.lang.Thread.run(Thread.java:619)
2009-12-06 20:43:32
Full thread dump Java HotSpot(TM) 64-Bit Server VM (14.0-b16 mixed mode):

""Thread-28"" prio=10 tid=0x00000000539e5800 nid=0x742e in Object.wait() [0x0000000040a45000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab7803738> (a java.lang.Thread)
    at java.lang.Thread.join(Thread.java:1143)
    - locked <0x00002aaab7803738> (a java.lang.Thread)
    at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:77)
    at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:66)
    at org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread.run(HRegionServer.java:992)

""SIGTERM handler"" daemon prio=10 tid=0x0000000053ca6000 nid=0x742d in Object.wait() [0x0000000043b02000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab7941978> (a org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread)
    at java.lang.Thread.join(Thread.java:1143)
    - locked <0x00002aaab7941978> (a org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread)
    at java.lang.Thread.join(Thread.java:1196)
    at java.lang.ApplicationShutdownHooks.runHooks(ApplicationShutdownHooks.java:79)
    at java.lang.ApplicationShutdownHooks$1.run(ApplicationShutdownHooks.java:24)
    at java.lang.Shutdown.runHooks(Shutdown.java:79)
    at java.lang.Shutdown.sequence(Shutdown.java:123)
    at java.lang.Shutdown.exit(Shutdown.java:168)
    - locked <0x00002aaaed6f2ef0> (a java.lang.Class for java.lang.Shutdown)
    at java.lang.Terminator$1.handle(Terminator.java:35)
    at sun.misc.Signal$1.run(Signal.java:195)
    at java.lang.Thread.run(Thread.java:619)

""Thread-23"" prio=10 tid=0x00002aab08019800 nid=0x2036 sleeping[0x00000000413de000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
    at java.lang.Thread.sleep(Native Method)
    at org.apache.hadoop.ipc.Client.stop(Client.java:679)
    at org.apache.hadoop.ipc.RPC$ClientCache.stopClient(RPC.java:192)
    at org.apache.hadoop.ipc.RPC$ClientCache.access$400(RPC.java:141)
    at org.apache.hadoop.ipc.RPC$Invoker.close(RPC.java:234)
    - locked <0x00002aaab7955f10> (a org.apache.hadoop.ipc.RPC$Invoker)
    at org.apache.hadoop.ipc.RPC$Invoker.access$500(RPC.java:199)
    at org.apache.hadoop.ipc.RPC.stopProxy(RPC.java:393)
    at org.apache.hadoop.hdfs.DFSClient.close(DFSClient.java:241)
    - locked <0x00002aaab78e5078> (a org.apache.hadoop.hdfs.DFSClient)
    at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:269)
    at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:1419)
    - locked <0x00002aaab79563f0> (a org.apache.hadoop.fs.FileSystem$Cache)
    at org.apache.hadoop.fs.FileSystem.closeAll(FileSystem.java:212)
    at org.apache.hadoop.fs.FileSystem$ClientFinalizer.run(FileSystem.java:197)
    - locked <0x00002aaab78037e0> (a org.apache.hadoop.fs.FileSystem$ClientFinalizer)

""LruBlockCache.EvictionThread"" daemon prio=10 tid=0x0000000053920800 nid=0x31a4 in Object.wait() [0x0000000043900000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab7a56160> (a org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread)
    at java.lang.Object.wait(Object.java:485)
    at org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread.run(LruBlockCache.java:512)
    - locked <0x00002aaab7a56160> (a org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread)

""DestroyJavaVM"" prio=10 tid=0x00002aaaf800f000 nid=0x2f53 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""regionserver/10.1.20.144:60020 <http://10.1.20.144:60020> "" prio=10 tid=0x00002aaaf800e000 nid=0x2f6c waiting for monitor entry [0x00000000415e2000]
- Hide quoted text -

   java.lang.Thread.State: BLOCKED (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab78037e0> (a org.apache.hadoop.fs.FileSystem$ClientFinalizer)
    at java.lang.Thread.join(Thread.java:1151)
    - locked <0x00002aaab78037e0> (a org.apache.hadoop.fs.FileSystem$ClientFinalizer)
    at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:77)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.runThread(HRegionServer.java:722)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:677)
    at java.lang.Thread.run(Thread.java:619)

""Low Memory Detector"" daemon prio=10 tid=0x00000000536b5000 nid=0x2f66 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""CompilerThread1"" daemon prio=10 tid=0x00000000536b2800 nid=0x2f65 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""CompilerThread0"" daemon prio=10 tid=0x00000000536ae000 nid=0x2f64 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Signal Dispatcher"" daemon prio=10 tid=0x00000000536ac000 nid=0x2f63 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Surrogate Locker Thread (CMS)"" daemon prio=10 tid=0x00000000536aa000 nid=0x2f62 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Finalizer"" daemon prio=10 tid=0x0000000053687800 nid=0x2f61 in Object.wait() [0x00000000421e9000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab77f0108> (a java.lang.ref.ReferenceQueue$Lock)
    at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)
    - locked <0x00002aaab77f0108> (a java.lang.ref.ReferenceQueue$Lock)
    at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)
    at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)

""Reference Handler"" daemon prio=10 tid=0x0000000053685800 nid=0x2f60 in Object.wait() [0x00000000420e8000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab77f32b8> (a java.lang.ref.Reference$Lock)
    at java.lang.Object.wait(Object.java:485)
    at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)
    - locked <0x00002aaab77f32b8> (a java.lang.ref.Reference$Lock)

""VM Thread"" prio=10 tid=0x000000005367e800 nid=0x2f5f runnable

""Gang worker#0 (Parallel GC Threads)"" prio=10 tid=0x00000000534c1800 nid=0x2f54 runnable

""Gang worker#1 (Parallel GC Threads)"" prio=10 tid=0x00000000534c3800 nid=0x2f55 runnable

""Gang worker#2 (Parallel GC Threads)"" prio=10 tid=0x00000000534c5800 nid=0x2f56 runnable

""Gang worker#3 (Parallel GC Threads)"" prio=10 tid=0x00000000534c7000 nid=0x2f57 runnable

""Gang worker#4 (Parallel GC Threads)"" prio=10 tid=0x00000000534c9000 nid=0x2f58 runnable

""Gang worker#5 (Parallel GC Threads)"" prio=10 tid=0x00000000534cb000 nid=0x2f59 runnable

""Gang worker#6 (Parallel GC Threads)"" prio=10 tid=0x00000000534cc800 nid=0x2f5a runnable

""Gang worker#7 (Parallel GC Threads)"" prio=10 tid=0x00000000534ce800 nid=0x2f5b runnable

""Concurrent Mark-Sweep GC Thread"" prio=10 tid=0x000000005359e800 nid=0x2f5e runnable
""Gang worker#0 (Parallel CMS Threads)"" prio=10 tid=0x000000005359b000 nid=0x2f5c runnable

""Gang worker#1 (Parallel CMS Threads)"" prio=10 tid=0x000000005359c800 nid=0x2f5d runnable

""VM Periodic Task Thread"" prio=10 tid=0x00000000536b7800 nid=0x2f67 waiting on condition

JNI global references: 960

Heap
 par new generation   total 115200K, used 67320K [0x00002aaaae6f0000, 0x00002aaab63f0000, 0x00002aaab63f0000)
  eden space 102400K,  65% used [0x00002aaaae6f0000, 0x00002aaab28a6130, 0x00002aaab4af0000)
  from space 12800K,   0% used [0x00002aaab5770000, 0x00002aaab5777f10, 0x00002aaab63f0000)
  to   space 12800K,   0% used [0x00002aaab4af0000, 0x00002aaab4af0000, 0x00002aaab5770000)
 concurrent mark-sweep generation total 896000K, used 705982K [0x00002aaab63f0000, 0x00002aaaecef0000, 0x00002aaaecef0000)
 concurrent-mark-sweep perm gen total 27204K, used 16361K [0x00002aaaecef0000, 0x00002aaaee981000, 0x00002aaaf22f0000)
{code}"
HBASE-13088,"[~busbey] noticed that the module hbase-native-client was not part of the release candidate 1.0.0RC5 in the src tarball (and neither in binary arifacts). 

I think we have added that as a part of C-API, but without implementation it just sits there. 

We should decide: 
1. Remove it
2. Add it to the release artifacts (src tarball from maven)

Does anybody have a plan around it? A reference implementation? I do not want to release it as official C API, without anything to back it up. 
"
HBASE-5608,"Many of the MR testcases are failing in PreCommit builds (triggered by Hadoop QA).
Failing testcases are
a) TestImportTsv
b) TestHFileOutputFormat
c) TestTableMapReduce"
HBASE-24,"We've been here before (HADOOP-2341).

Today the rapleaf gave me an lsof listing from a regionserver.  Had thousands of open sockets to datanodes all in ESTABLISHED and CLOSE_WAIT state.  On average they seem to have about ten file descriptors/sockets open per region (They have 3 column families IIRC.  Per family, can have between 1-5 or so mapfiles open per family -- 3 is max... but compacting we open a new one, etc.).

They have thousands of regions.   400 regions -- ~100G, which is not that much -- takes about 4k open file handles.

If they want a regionserver to server a decent disk worths -- 300-400G -- then thats maybe 1600 regions... 16k file handles.  If more than just 3 column families..... then we are in danger of blowing out limits if they are 32k.

We've been here before with HADOOP-2341.

A dfsclient that used non-blocking i/o would help applications like hbase (The datanode doesn't have this problem as bad -- CLOSE_WAIT on regionserver side, the bulk of the open fds in the rapleaf log, don't have a corresponding open resource on datanode end).

Could also just open mapfiles as needed, but that'd kill our random read performance and its bad enough already."
HBASE-11419,"After increasing and decreasing the TTL value of a Hbase Table , table gets inaccessible. Scan table not working.

Scan in hbase shell throws

java.lang.IllegalStateException: Block index not loaded
at com.google.common.base.Preconditions.checkState(Preconditions.java:145)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV1.blockContainingKey(HFileReaderV1.java:181)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV1$AbstractScannerV1.seekTo(HFileReaderV1.java:426)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:226)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:145)
at org.apache.hadoop.hbase.regionserver.StoreScanner.<init>(StoreScanner.java:131)
at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:2015)
at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.<init>(HRegion.java:3706)
at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1761)
at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1753)
at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1730)
at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:2409)
at sun.reflect.GeneratedMethodAccessor56.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:320)
at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1426)

"
HBASE-1972,"As part of a split, we go to close the region.  The close fails because flush failed -- a DN was down and HDFS refuses to move past it -- so we jump up out of the close with an IOE.  But the region has been closed yet its still in the .META. as online.

Here is where the hole is:

1. CompactSplitThread calls split.
2. This calls HRegion splitRegion.
3. splitRegion calls close(false).
4. Down the end of the close, we get as far as the LOG.info(""Closed "" + this)..... but a DFSClient running thread throws an exception because it can't allocate block for the flush made as part of the close (Ain't sure how... we should add more try/catch in here):


{code}
2009-11-12 00:47:17,865 [regionserver/208.76.44.142:60020.compactor] DEBUG org.apache.hadoop.hbase.regionserver.Store: Added hdfs://aa0-000-12.u.powerset.com:9002/hbase/TestTable/868626151/info/5071349140567656566, entries=46975, sequenceid=2350017, memsize=52.0m, filesize=46.5m to TestTable,,1257986664542
2009-11-12 00:47:17,866 [regionserver/208.76.44.142:60020.compactor] DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~52.0m for region TestTable,,1257986664542 in 7985ms, sequence id=2350017, compaction requested=false
2009-11-12 00:47:17,866 [regionserver/208.76.44.142:60020.compactor] DEBUG org.apache.hadoop.hbase.regionserver.Store: closed info
2009-11-12 00:47:17,866 [regionserver/208.76.44.142:60020.compactor] INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed TestTable,,1257986664542
2009-11-12 00:47:17,906 [Thread-315] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:17,906 [Thread-315] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_1351692500502810095_1391
2009-11-12 00:47:23,918 [Thread-315] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:23,918 [Thread-315] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-3310646336307339512_1391
2009-11-12 00:47:29,982 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:29,982 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_3070440586900692765_1393
2009-11-12 00:47:35,997 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:35,997 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-5656011219762164043_1393
2009-11-12 00:47:42,007 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:42,007 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-2359634393837722978_1393
2009-11-12 00:47:48,017 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:48,017 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-1626727145091780831_1393
2009-11-12 00:47:54,022 [Thread-318] WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSClient.java:3100)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2681)

2009-11-12 00:47:54,022 [Thread-318] WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file ""/hbase/TestTable/868626151/splits/1211221550/info/5071349140567656566.868626151"" - Aborting...
2009-11-12 00:47:54,029 [regionserver/208.76.44.142:60020.compactor] ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction/Split failed for region TestTable,,1257986664542
java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.createBlockOutputStream(DFSClient.java:3160)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSClient.java:3080)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2681)
{code}

Marking this as blocker."
HBASE-1750,"This is so broke, its hard to know where to start.

In the below, node 14 expires, we continue to take on messages from it queueing open region todos for us to work on later.  Then we start to process shutdown of server 14.  Meantime we are assigning it regions.

Later, not reported here.  The open of a particular region is queued on the todo list > 1 time.  Processing the 2nd and 3rd times we call the assignment a duplicate and tell remote server close its region (it'll be same region as was in the first todo message).  It dutifully closes without report.  Now we NSRE till the end of time trying to find this closed region.

{code}
2009-08-05 04:39:12,007 [main-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got notification sessionid:0x22e734176a0001
2009-08-05 04:39:12,007 [main-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got WatchedEvent: Znode change. Path: /hbase/rs/1249419499242 Type: NodeDeleted for sessionid 0x22e734176a0001
2009-08-05 04:39:12,007 [main-EventThread] INFO org.apache.hadoop.hbase.master.ServerManager: 14.powerset.com,60020,1249419499242 znode expired
2009-08-05 04:39:12,137 [IPC Server handler 22 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.142:60020, startcode: 1249419499272, load: (requests=5, regions=243,  
usedHeap=732, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:13,028 [main-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got ping response for sessionid:0x22e734176a0001 after 0ms
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0707104931,1249439925123 from 14.powerset.com,60
020,1249447142944; 1 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0807477918,1249435417405 from 14.powerset.com,60
020,1249447142944; 2 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0239771780,1249436471662 from 14.powerset.com,60
020,1249447142944; 3 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0295087929,1249438529628 from 14.powerset.com,60
020,1249447142944; 4 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0344538034,1249438625837 from 14.powerset.com,60
020,1249447142944; 5 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0067977092,1249431465797 from 14.powerset.com,60
020,1249447142944; 6 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0521945645,1249426826597 from 14.powerset.com,60
020,1249447142944; 7 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0221136504,1249447128488 from 14.powerset.com,60
020,1249447142944; 8 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0272411446,1249433459428 from 14.powerset.com,60
020,1249447142944; 9 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0284541889,1249434580130 from 14.powerset.com,60020,1249
447142944; 10 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0707104931,1249439925123 from 14.powerset.com,60020,1249
447142944; 11 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0807477918,1249435417405 from 14.powerset.com,60020,1249
447142944; 12 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0239771780,1249436471662 from 14.powerset.com,60020,1249
447142944; 13 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0295087929,1249438529628 from 14.powerset.com,60020,1249
447142944; 14 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0344538034,1249438625837 from 14.powerset.com,60020,1249
447142944; 15 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0067977092,1249431465797 from 14.powerset.com,60020,1249
447142944; 16 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0521945645,1249426826597 from 14.powerset.com,60020,1249
447142944; 17 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0221136504,1249447128488 from 14.powerset.com,60020,1249
447142944; 18 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0272411446,1249433459428 from 14.powerset.com,60020,1249
447142944; 19 of 19
2009-08-05 04:39:14,260 [IPC Server handler 24 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.140:60020, startcode: 1249419499240, load: (requests=0, regions=236,  
usedHeap=644, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:14,994 [IPC Server handler 3 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.139:60020, startcode: 1249419499241, load: (requests=0, regions=242, u
sedHeap=715, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:15,196 [IPC Server handler 2 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.142:60020, startcode: 1249419499272, load: (requests=0, regions=243, u
sedHeap=733, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:15,289 [HMaster-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got ping response for sessionid:0x22e734176a0002 after 1ms
2009-08-05 04:39:15,319 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,321 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,321 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,322 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,323 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,325 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:14,260 [IPC Server handler 24 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.140:60020, startcode: 1249419499240, load: (requests=0, regions=236, 
usedHeap=644, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:14,994 [IPC Server handler 3 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.139:60020, startcode: 1249419499241, load: (requests=0, regions=242, u
sedHeap=715, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:15,196 [IPC Server handler 2 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.142:60020, startcode: 1249419499272, load: (requests=0, regions=243, u
sedHeap=733, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:15,289 [HMaster-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got ping response for sessionid:0x22e734176a0002 after 1ms
2009-08-05 04:39:15,319 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,321 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,321 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,322 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,323 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,325 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,327 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,328 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,330 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,331 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: ProcessServerShutdown of 14.powerset.com,60020,1249419499242
2009-08-05 04:39:15,331 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: process shutdown of server 14.powerset.com,60020,1249419499242: logSplit: false, rootRescanned: false, numbe
rOfMetaRegions: 1, onlineMetaRegions.size(): 1
2009-08-05 04:39:15,340 [HMaster] INFO org.apache.hadoop.hbase.regionserver.HLog: Splitting 34 hlog(s) in hdfs://12.powerset.com:9002/hbase/.logs/14.powerset.com,60020,1249419499242
2009-08-05 04:39:15,341 [HMaster] DEBUG org.apache.hadoop.hbase.regionserver.HLog: Splitting hlog 1 of 34: hdfs://12.powerset.com:9002/hbase/.logs/14.powerset.com,60020,1249419499242/hlog.dat
.1249446428006, length=58628658
2009-08-05 04:39:15,412 [HMaster] DEBUG org.apache.hadoop.hbase.regionserver.HLog: Adding queue for TestTable,0855568194,1249436793311
2009-08-05 04:39:15,989 [HMaster] DEBUG org.apache.hadoop.hbase.regionserver.HLog: Adding queue for TestTable,0839835862,1249431318932
2009-08-05 04:39:16,030 [HMaster] DEBUG org.apache.hadoop.hbase.regionserver.HLog: Adding queue for TestTable,0470769394,1249439783171
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.141:60020, startcode: 1249447142944, load: (requests=0, regions=10, us
edHeap=51, maxHeap=1391): total nregions to assign=7, nregions to reach balance=0, isMetaAssign=false
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Doing for address: XX.XX.XX.141:60020, startcode: 1249447142944, load: (requests=0, regions=10, usedHe
ap=51, maxHeap=1391) nregions: 7 and nRegionsToAssign: 7
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0196260871,1249434878197 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0831634449,1249445668584 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0621687088,1249440865643 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0046898120,1249435993439 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0706868362,1249439909374 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0226534644,1249438950155 to 14.powerset.com,60020,1249447142944
{code}
"
HBASE-3322,"Testing HBASE-2467 and HDFS-895 on 100 node cluster w/ a heavy increment workload we experienced significant slowdown.

Stack traces show that most threads are on HLog.updateLock."
HBASE-3032,"Saw this message:

2010-09-22 13:10:03,547 FATAL org.apache.hadoop.hbase.master.MetaScanner: Caught error. Starting shutdown.
java.lang.OutOfMemoryError: unable to create new native thread
        at java.lang.Thread.start0(Native Method)
        at java.lang.Thread.start(Thread.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.setupIOstreams(HBaseClient.java:328)
        at org.apache.hadoop.hbase.ipc.HBaseClient.getConnection(HBaseClient.java:857)
        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:725)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:252)
        at $Proxy1.openScanner(Unknown Source)
        at org.apache.hadoop.hbase.master.BaseScanner.scanRegion(BaseScanner.java:182)
        at org.apache.hadoop.hbase.master.MetaScanner.scanOneMetaRegion(MetaScanner.java:73)
        at org.apache.hadoop.hbase.master.MetaScanner.maintenanceScan(MetaScanner.java:129)
        at org.apache.hadoop.hbase.master.BaseScanner.chore(BaseScanner.java:156)
        at org.apache.hadoop.hbase.Chore.run(Chore.java:68)

At this point the regionservers were instructed to exit, which caused more problems than if the master just terminated itself.  

This would prevent a backup master from picking up since the cluster is terminating!"
HBASE-3020,"From Ryan:

Log recovery didn't seem to run during META open, here is my hadoop lsr:

{code}

drwxr-xr-x   - hadoop supergroup          0 2010-09-20 19:20 /hbase-206/.META.
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 19:20
/hbase-206/.META./.META.,,1
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 19:20
/hbase-206/.META./.META.,,1/recovered.edits
-rw-r--r--   3 hadoop supergroup      35544 2010-09-20 19:20
/hbase-206/.META./.META.,,1/recovered.edits/0000000000000000008
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 13:36
/hbase-206/.META./1028785192
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 13:36
/hbase-206/.META./1028785192/.oldlogs
-rw-r--r--   3 hadoop supergroup        124 2010-09-20 13:36
/hbase-206/.META./1028785192/.oldlogs/hlog.1285015016913
-rw-r--r--   3 hadoop supergroup       1018 2010-09-20 13:36
/hbase-206/.META./1028785192/.regioninfo
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 13:36
/hbase-206/.META./1028785192/historian
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 13:36
/hbase-206/.META./1028785192/info
{code}

Notice how above recovered.edits is under a dir which is not the encoded name?

This is my fault I'd guess.  I tried to put in place actual region names of -ROOT- and .META. rather than the anonymous encodings.  Looks like I broke something split of .META. when I committed new master.  Will fix in morning."
HBASE-12612,"The namespace upgrade code from pre-0.96 requires a clean shutdown prior to run. Right now the NamespaceUpgrade code does the following

# instantiate wal factory
# ask for a meta-wal
# online meta and make changes
# clean up meta-wal

That last bit is done instead of closing the factory itself. Since the factory initializes a non-meta-wal as a part of its constructor, not closing it leaves behind an empty wal. The rest of hte upgrade process sees that empty wal as an indicator that there's been a failure and goes into recovery.

The recovery process skips the loading of the hbase:acl table, which then causes the upgrade after master initialization to fail."
HBASE-11538,"See thread on dev@ titled ""Comparing the performance of 0.98.4 RC0 and 0.98.0 using YCSB - 23% perf regression in workload E"""
HBASE-1076,"Running latest trunk plus jimk's patch for HBASE-543: 

2008-12-21 12:47:31,741 DEBUG org.apache.hadoop.hbase.regionserver.HStoreScanner
: Added a StoreFileScanner to outstanding HStoreScanner
2008-12-21 12:47:31,741 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: urls,http|playvideogame.net|,1229725620550
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:880)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:773)
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:228)
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushSomeRegions(MemcacheFlusher.java:292)
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.reclaimMemcacheMemory(MemcacheFlusher.java:262)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdates(HRegionServer.java:1594)
        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:894)
Caused by: java.util.ConcurrentModificationException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)
        at java.util.HashMap$KeyIterator.next(HashMap.java:828)
        at org.apache.hadoop.hbase.regionserver.HStore.notifyChangedReadersObservers(HStore.java:736)
        at org.apache.hadoop.hbase.regionserver.HStore.updateReaders(HStore.java:724)
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:693)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:629)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:865)
        ... 10 more
"
HBASE-7233,"Undo KeyValue being a Writable.

This issue wandered and became general discussion of KeyValue serialization, in particular, how to pass lots of KeyValues across rpc.  It was noticed that what we were passing over the wire for KeyValues was not protobuf'd KeyValues but the old serialization which assumes the KeyValue version 1 format.  After a bunch of good discussion working out rpc formats, was decided to close this issue in favor of more specific issues: see summary at https://issues.apache.org/jira/browse/HBASE-7233?focusedCommentId=13573259&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13573259"
HBASE-7981,"https://builds.apache.org/job/hbase-0.95/11/testReport/junit/org.apache.hadoop.hbase.regionserver/TestSplitTransactionOnCluster/testShutdownFixupWhenDaughterHasSplit/

Hard to tell which region is missing post crash.  Not logged."
HBASE-3346,"After the abort in HBASE-3345, I restarted the master, and it crashed again during startup

2010-12-13 12:57:00,367 DEBUG org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED event for c5005ca650c7e3bdbab4c8d3e9b7c618
2010-12-13 12:57:00,367 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region usertable
2010-12-13 12:57:00,367 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c780205200116 Deleting existing unassigned node for c5005ca650c7e3bdbab4c8d3e9b7c618 that is in expected state
2010-12-13 12:57:00,367 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: master:60000-0x12c780205200116 Retrieved 127 byte(s) of data from znode /hbase/unassigned/c5005ca650c7e3bdbab4c8d3e9b7c618; data=
2010-12-13 12:57:00,373 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher: master:60000-0x12c780205200116 Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/unassigned/
2010-12-13 12:57:00,374 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher: master:60000-0x12c780205200116 Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/una
2010-12-13 12:57:00,374 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c780205200116 Successfully deleted unassigned node for region c5005ca650c7e3bdbab4c8d3e9b7c618 in expected sta
2010-12-13 12:57:00,374 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: master:60000-0x12c780205200116 Retrieved 114 byte(s) of data from znode /hbase/unassigned/3dc9df76f111271c150c853716ce1f07 and se
2010-12-13 12:57:00,376 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
java.lang.NullPointerException
        at org.apache.hadoop.hbase.master.AssignmentManager.processRegionInTransition(AssignmentManager.java:263)
        at org.apache.hadoop.hbase.master.AssignmentManager.processFailover(AssignmentManager.java:222)
        at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:392)
        at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:274)
2010-12-13 12:57:00,377 INFO org.apache.hadoop.hbase.master.HMaster: Aborting
"
HBASE-5831,"No test failures but build complains it has failed.  trunk build seems to have the same affliction:

{code}
Results :

Tests run: 909, Failures: 0, Errors: 0, Skipped: 9

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 41:19.273s
[INFO] Finished at: Wed Apr 18 21:54:31 UTC 2012
[INFO] Final Memory: 59M/451M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.12-TRUNK-HBASE-2:test (secondPartTestsExecution) on project hbase: Failure or timeout -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException




-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12523250/5811+%281%29.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 findbugs.  The patch appears to introduce 6 new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

     -1 core tests.  The patch failed these unit tests:
{code}

Its not apparent that any particular test is not finishing."
HBASE-3345,"Running on a config that triggers lots of splits, I attempted to disable a table while it was getting a lot of load and injected failures. Got the following NPE in master, followed by an abort:

2010-12-13 12:52:27,323 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region usertable,user1182862181,1292273503885.d223f1dc4d9003508f2db7566518b05d. (offlining)
2010-12-13 12:52:27,323 FATAL org.apache.hadoop.hbase.master.HMaster: Remote unexpected exception
java.lang.NullPointerException: Passed server is null
        at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:581)
        at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1085)
        at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1032)
        at org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler$1.run(DisableTableHandler.java:132)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
"
HBASE-475,Add enable/disable to hql help.
HBASE-459,"Jim was just running a loading test.  It failed because of a WrongRegionException.  At first I thought it HBASE-428 -- because we were making regions w/ same start and end key -- but looking closer, it looks like the client is getting a WRE thought its making a legitimate request; it just happens to be asking for a row from the top-half of a region just as it split.  I would think that on WRE, the client would at least retry in same manner in which it does when it gets a NSRE?

Here is the split detail:

{code}
2008-02-21 19:15:11,747 INFO  [regionserver/0:0:0:0:0:0:0:0:8020.compactor] hbase.HRegionServer$CompactSplitThread(345): region split, META updated, and report to master all successful. Old region=regionname: TestTable,0018951818,1203620807290, startKey: <0018951818>, endKey: <0022085183>, encodedName: 1601381187, offline: true, split: true, tableDesc: {name: TestTable, families: {info:={name: info, max versions: 3, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}, new regions: TestTable,0018951818,1203621311590, TestTable,0020990296,1203621311590. Split took 0sec
{code}

Here is the WRE:

{code}
org.apache.hadoop.hbase.WrongRegionException: org.apache.hadoop.hbase.WrongRegionException: Requested row out of range for HRegion TestTable,0018951818,1203620807290, startKey='0018951818', getEndKey()='0022085183', row='0062914560'
	at org.apache.hadoop.hbase.HRegion.checkRow(HRegion.java:1496)
	at org.apache.hadoop.hbase.HRegion.obtainRowLock(HRegion.java:1541)
	at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1236)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1450)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
	at java.lang.reflect.Constructor.newInstance(Unknown Source)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
	at org.apache.hadoop.hbase.client.HTable.getRegionServerWithRetries(HTable.java:1008)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:751)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:740)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:721)
	at org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest.testRow(PerformanceEvaluation.java:463)
	at org.apache.hadoop.hbase.PerformanceEvaluation$Test.test(PerformanceEvaluation.java:331)
	at org.apache.hadoop.hbase.PerformanceEvaluation.runOneClient(PerformanceEvaluation.java:527)
	at org.apache.hadoop.hbase.PerformanceEvaluation$EvaluationMapTask.map(PerformanceEvaluation.java:176)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:208)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2071)
{code}"
HBASE-463,"I attempted to try out HBASE-458, and discovered that I couldn't create a table in shell at all on a fresh trunk. 

{code}
hql > show tables;
error msg : org.apache.hadoop.hbase.TableNotFoundException: Table '.META.' does not exist.
{code}

I tried wiping out my dfs to see if that made a difference, and it didn't.

This is a big problem."
HBASE-265,"The MiniDFSCluster used in many test cases is failing to start which causes test cases to fail.

    [junit] 07/07/18 09:56:30 INFO dfs.Storage: Storage directory /home/jim/Documents/workspace/hadoop-commit/build/contrib/hbase/test/data/dfs/name1 has been successfully formatted.
    [junit] 07/07/18 09:56:30 INFO dfs.Storage: Storage directory /home/jim/Documents/workspace/hadoop-commit/build/contrib/hbase/test/data/dfs/name2 has been successfully formatted.
    [junit] 07/07/18 09:56:30 INFO dfs.NameNode: Namenode up at: vermin.localdomain/127.0.0.1:46160
    [junit] 07/07/18 09:56:30 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
    [junit] 07/07/18 09:56:30 INFO ipc.Server: Stopping server on 46160
    [junit] 07/07/18 09:56:30 ERROR hbase.MiniHBaseCluster: Failed setup of mini dfs cluster
    [junit] java.io.IOException: 
    [junit]    Distributed upgrade for NameNode version -6 to current LV -6 is required.
    [junit]    Please restart NameNode with -upgrade option.
    [junit] 	at org.apache.hadoop.dfs.FSImage.verifyDistributedUpgradeProgress(FSImage.java:1059)
    [junit] 	at org.apache.hadoop.dfs.FSImage.recoverTransitionRead(FSImage.java:193)
    [junit] 	at org.apache.hadoop.dfs.FSDirectory.loadFSImage(FSDirectory.java:393)
    [junit] 	at org.apache.hadoop.dfs.FSNamesystem.<init>(FSNamesystem.java:248)
    [junit] 	at org.apache.hadoop.dfs.NameNode.init(NameNode.java:181)
    [junit] 	at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:219)
    [junit] 	at org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:839)
    [junit] 	at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:133)
    [junit] 	at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:77)
    [junit] 	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:116)
    [junit] 	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:73)
    [junit] 	at org.apache.hadoop.hbase.HBaseClusterTestCase.setUp(HBaseClusterTestCase.java:59)
"
HBASE-17229,Backport HBASE-17072 and HBASE-16146. The former needs to be backported to 1.3 ([~mantonov]) and 1.2 ([~busbey]). The latter is already in 1.3.  Needs to be backported to 1.2.
HBASE-17801,"In Apache 1.x, there is a Assignment Manager bug when SSH and drop table happens at the same time.  Here is the sequence:

(1). The Region Server hosting the target region is dead, SSH (server shutdown handler) offlined all regions hosted by the RS: 
{noformat}
2017-02-20 20:39:25,022 ERROR org.apache.hadoop.hbase.master.MasterRpcServices: Region server rs01.foo.com,60020,1486760911253 reported a fatal error:
ABORTING region server rs01.foo.com,60020,1486760911253: regionserver:60020-0x55a076071923f5f, quorum=zk01.foo.com:2181,zk02.foo.com:2181,zk3.foo.com:2181, baseZNode=/hbase regionserver:60020-0x1234567890abcdf received expired from ZooKeeper, aborting
Cause:
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:613)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:524)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:534)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:510)
2017-02-20 20:42:43,775 INFO org.apache.hadoop.hbase.master.handler.ServerShutdownHandler: Splitting logs for rs01.foo.com,60020,1486760911253 before assignment; region count=999
2017-02-20 20:43:31,784 INFO org.apache.hadoop.hbase.master.RegionStates: Transition {783a4814b862a6e23a3265a874c3048b state=OPEN, ts=1487568368296, server=rs01.foo.com,60020,1486760911253} to {783a4814b862a6e23a3265a874c3048b state=OFFLINE, ts=1487648611784, server=rs01.foo.com,60020,1486760911253}
{noformat}

(2). Now SSH goes through each region and check whether it should be re-assigned (at this time, SSH do check whether a table is disabled/deleted).  If a region needs to be re-assigned, it would put into a list.  Since at this time, the troubled region is still on the table that is enabled, it will be in the list.

{noformat}
2017-02-20 20:43:31,795 INFO org.apache.hadoop.hbase.master.handler.ServerShutdownHandler: Reassigning 999 region(s) that rs01.foo.com,60020,1486760911253 was carrying (and 0 regions(s) that were opening on this server)
{noformat}

(3). Now, disable and delete table come in and also try to offline the region; since the region is already offlined, the deleted table just removes the region from meta and in-memory.
{noformat}
2017-02-20 20:43:32,429 INFO org.apache.hadoop.hbase.master.HMaster: Client=b_kylin/null disable t1
2017-02-20 20:43:34,275 INFO org.apache.hadoop.hbase.zookeeper.ZKTableStateManager: Moving table t1 state from DISABLING to DISABLED
2017-02-20 20:43:34,276 INFO org.apache.hadoop.hbase.master.procedure.DisableTableProcedure: Disabled table, t1, is completed.
2017-02-20 20:43:35,624 INFO org.apache.hadoop.hbase.master.HMaster: Client=b_kylin/null delete t1
2017-02-20 20:43:36,011 INFO org.apache.hadoop.hbase.MetaTableAccessor: Deleted [{ENCODED => fbf9fda1381636aa5b3cd6e3fe0f6c1e, NAME => 't1,,1487568367030.fbf9fda1381636aa5b3cd6e3fe0f6c1e.', STARTKEY => '', ENDKEY => '\x00\x01'}, {ENCODED => 783a4814b862a6e23a3265a874c3048b, NAME => 't1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b.', STARTKEY => '\x00\x01', ENDKEY => ''}]
{noformat}

(4). However, SSH calls Assignment Manager to reassign the dead region (note that the dead region is in the re-assign list SSH collected and we don't re-check again)
{noformat}

2017-02-20 20:43:52,725 WARN org.apache.hadoop.hbase.master.AssignmentManager: Assigning but not in region states: {ENCODED => 783a4814b862a6e23a3265a874c3048b, NAME => 't1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b.', STARTKEY => '\x00\x01', ENDKEY => ''}

{noformat}

(5).  In the region server that the dead region tries to land, because the table is dropped, we could not open region and now the dead region is in FAILED_OPEN, which is in permanent RIT state. 

{noformat}
2017-02-20 20:43:52,861 INFO org.apache.hadoop.hbase.regionserver.RSRpcServices: Open t1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b.
2017-02-20 20:43:52,865 ERROR org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Failed open of region=t1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b., starting to roll back the global memstore size.
java.lang.IllegalStateException: Could not instantiate a region instance.
        at org.apache.hadoop.hbase.regionserver.HRegion.newHRegion(HRegion.java:5981)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6288)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6260)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6216)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6167)
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:362)
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:129)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.GeneratedConstructorAccessor340.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.hbase.regionserver.HRegion.newHRegion(HRegion.java:5978)
        ... 10 more
Caused by: java.lang.IllegalArgumentException: Need table descriptor
        at org.apache.hadoop.hbase.regionserver.HRegion.<init>(HRegion.java:654)
        at org.apache.hadoop.hbase.regionserver.HRegion.<init>(HRegion.java:631)
        ... 14 more
2017-02-20 20:43:52,866 INFO org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination: Opening of region {ENCODED => 783a4814b862a6e23a3265a874c3048b, NAME => 't1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b.', STARTKEY => '\x00\x01', ENDKEY => ''} failed, transitioning from OPENING to FAILED_OPEN in ZK, expecting version 1
{noformat}

Even no one would access this dead region, the dead region in RIT would prevent balancer to run; and warnings fired that regions stuck in RIT.

The issue could be resolved by restarting master, which is a good workaround, but undesirable."
HBASE-18152,"I've seen corruption from time-to-time testing.  Its rare enough. Often we can get over it but sometimes we can't. It took me a while to capture an instance of corruption. Turns out we are write to the WAL out-of-order which undoes a basic tenet; that WAL content is ordered in line w/ execution.

Below I'll post a corrupt WAL.

Looking at the write-side, there is a lot going on. I'm not clear on how we could write out of order. Will try and get more insight. Meantime parking this issue here to fill data into.

"
HBASE-14950,"Scenario:
1. Set hbase.quota.enabled to true
2. As per the [ACL matrix | http://hbase.apache.org/book.html#appendix_acl_matrix] for create table, grant '@group1', 'C', '@ns1'
3. From a user of group1, create 't1', 'd'  -- *Failed*
{noformat}
ERROR: java.io.IOException: Namespace Descriptor found null for ns1 This is unexpected.
	at org.apache.hadoop.hbase.namespace.NamespaceStateManager.checkAndUpdateNamespaceTableCount(NamespaceStateManager.java:170)
	at org.apache.hadoop.hbase.namespace.NamespaceAuditor.checkQuotaToCreateTable(NamespaceAuditor.java:76)
	at org.apache.hadoop.hbase.quotas.MasterQuotaManager.checkNamespaceTableAndRegionQuota(MasterQuotaManager.java:312)
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1445)
	at org.apache.hadoop.hbase.master.MasterRpcServices.createTable(MasterRpcServices.java:428)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:49404)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2136)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)
{noformat}
When quota is enabled, then as part of createTable we internally also call getNamespaceDescriptor which needs 'A' privilege.

So when quota is enabled we need both C and A permission to create a table. ACL Matrix needs to be updated."
HBASE-18144,Description to follow.
HBASE-19713,Make sure TestInterfaceAudienceAnnotations pass before 2.0 release.
HBASE-20203,"This is an odd one. Causes ITBLL to fail because region is offline.

Two seconds after reporting Finished, successful assign, another thread tries to finish the Procedure. The second run messes us up.

{code}
2018-03-14 11:04:07,987 INFO  [PEWorker-1] procedure2.ProcedureExecutor: Finished pid=3600, ppid=3591, state=SUCCESS; AssignProcedure table=IntegrationTestBigLinkedList, region=b58e6e7c3b2e449f80533ea999707319 in 4.4100sec
....
2018-03-14 11:04:10,600 INFO  [PEWorker-2] procedure.MasterProcedureScheduler: pid=3600, ppid=3591, state=SUCCESS; AssignProcedure table=IntegrationTestBigLinkedList, region=b58e6e7c3b2e449f80533ea999707319, IntegrationTestBigLinkedList,\x9Ey\xE7\x9Ey\xE7\x9Ep,1521050540660.b58e6e7c3b2e449f80533ea999707319.
2018-03-14 11:04:10,606 ERROR [PEWorker-2] procedure2.ProcedureExecutor: CODE-BUG: Uncaught runtime exception for pid=3600, ppid=3591, state=SUCCESS; AssignProcedure table=IntegrationTestBigLinkedList, region=b58e6e7c3b2e449f80533ea999707319                                                                                        java.lang.UnsupportedOperationException: Unhandled state REGION_TRANSITION_FINISH; there is no rollback for assignment unless we cancel the operation by dropping/disabling the table
  at org.apache.hadoop.hbase.master.assignment.RegionTransitionProcedure.rollback(RegionTransitionProcedure.java:345)                                                                                                                                                                                                                      at org.apache.hadoop.hbase.master.assignment.RegionTransitionProcedure.rollback(RegionTransitionProcedure.java:86)                                                                                                                                                                                                                       at org.apache.hadoop.hbase.procedure2.Procedure.doRollback(Procedure.java:859)
  at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeRollback(ProcedureExecutor.java:1353)
  at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeRollback(ProcedureExecutor.java:1309)                                                                                                                                                                                                                                     at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1178)
  at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$800(ProcedureExecutor.java:75)                                                                                                                                                                                                                                            at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1740)
{code}"
HBASE-19193,"This is a good one turned up by that really great unit test facility where we do double execution of procedures with kills in between.

The scenario in this case is interesting. It was brought on by the fix to ""HBASE-19165 TODO Handle stuck in transition: rit=OPENING, location=ve0538...."" HBASE-19165 removed the presumption that an empty region state in hbase:meta meant OPENING.

The test that started failing was #testRecoveryAndDoubleExecution in TestRestoreSnapshotProcedure. A table is being deleted with kills and double execution of procedures enabled. The Table delete has mostly completed the delete of all regions and then the Master is killed. The new Master comes up, sees a few regions left in the hbase:meta but at least for a few, the state field is empty.

AMv2 tries to do the wrong thing which is reassign the region. It needs to do some probing to figure what to do with a region it doesn't know state on... e..g see if table is enabled or not.

Filing this issue to fix. Its part of a broader problem of what to do when state is empty in meta."
HBASE-18919,"branch-1.1 nightly builds have been timing out in hbase-server on jdk7:

https://builds.apache.org/job/HBase%20Nightly/job/branch-1.1/

all recent runs look the same to me. yetus doesn't detect any hanging tests, so I'm not sure what's hanging exactly."
HBASE-12959,"I upgraded the hbase from 0.96.1.1 to 0.98.7 and hadoop from 2.2.0 to 2.5.1,some table encoding using prefix-tree was abnormal for compacting,  the gui shows the table's Compaction status is MAJOR_AND_MINOR(MAJOR) all the time.

in the regionserver dump , there are some logs as below:


Tasks:
===========================================================
Task: Compacting info in PREFIX_NOT_COMPACT,,1421954285670.41ef60e2c221772626e141d5080296c5.
Status: RUNNING:Compacting store info
Running for 1097s  (on the  site running more than 3 days)
............................

Thread 197 (regionserver60020-smallCompactions-1421954341530):
  State: RUNNABLE
  Blocked count: 7
  Waited count: 3
  Stack:
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.followFan(PrefixTreeArrayScanner.java:329)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:149)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)
    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)
    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)
    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)
    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)
    org.apache.hadoop.hbase.regionserver.compactions.Compactor.performCompaction(Compactor.java:222)
    org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:77)
    org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:110)
    org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1099)
    org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1482)

Thread 177 (regionserver60020-smallCompactions-1421954314809):
  State: RUNNABLE
  Blocked count: 40
  Waited count: 60
  Stack:
    org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnReader.populateBuffer(ColumnReader.java:81)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.populateQualifier(PrefixTreeArrayScanner.java:471)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.populateNonRowFields(PrefixTreeArrayScanner.java:452)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRow(PrefixTreeArrayScanner.java:226)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.advance(PrefixTreeArrayScanner.java:208)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtQualifierTimestamp(PrefixTreeArraySearcher.java:244)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:123)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)
    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)
    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)
    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)
    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)

Thread 170 (regionserver60020-smallCompactions-1421954306575):
  State: RUNNABLE
  Blocked count: 40
  Waited count: 46
  Stack:
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRowInternal(PrefixTreeArrayScanner.java:259)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRow(PrefixTreeArrayScanner.java:222)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.advance(PrefixTreeArrayScanner.java:208)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtQualifierTimestamp(PrefixTreeArraySearcher.java:244)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:123)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)
    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)
    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)
    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)
    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)
    org.apache.hadoop.hbase.regionserver.compactions.Compactor.performCompaction(Compactor.java:222)
    org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:77)



I also reproduce the appearance in the test env,actually the logs was fetch in my test env. 

schema :
create 'PREFIX_NOT_COMPACT', {NAME=>'info',VERSIONS=>1,BLOCKCACHE => true,DATA_BLOCK_ENCODING => 'PREFIX_TREE', BLOOMFILTER => 'ROW', IN_MEMORY => 'false', REPLICATION_SCOPE => '0', COMPRESSION => 'LZ4',MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', TTL => '600'},SPLITS =>['20150202']

data :
     see the attachments , load from the text data or storefiles."
HBASE-14319,"org.apache.hadoop.hbase.regionserver.TestAtomicOperation.testMultiRowMutationMultiThreads has been failing sporadically for a while on at least trunk. This might also be reproducible on other branches, but it's hard to tell the state since our b.a.o Jenkins matrix for different Java versions that we test against hasn't been set up to display test results in a pretty way (separate JIRA forthcoming)."
HBASE-13605,"As mentioned in https://issues.apache.org/jira/browse/HBASE-9514?focusedCommentId=13769761&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13769761 and HBASE-12844 we should have only 1 source of cluster membership. 

The list of dead server and RegionStates doing it's own liveliness check (ServerManager.isServerReachable()) has caused an assignment problem again in a test cluster where the region states ""thinks"" that the server is dead and SSH will handle the region assignment. However the RS is not dead at all, living happily, and never gets zk expiry or YouAreDeadException or anything. This leaves the list of regions unassigned in OFFLINE state. 

master assigning the region:
{code}
15-04-20 09:02:25,780 DEBUG [AM.ZK.Worker-pool3-t330] master.RegionStates: Onlined 77dddcd50c22e56bfff133c0e1f9165b on os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268 {ENCODED => 77dddcd50c
{code}

Master then disabled the table, and unassigned the region:
{code}
2015-04-20 09:02:27,158 WARN  [ProcedureExecutorThread-1] zookeeper.ZKTableStateManager: Moving table loadtest_d1 state from DISABLING to DISABLING
 Starting unassign of loadtest_d1,,1429520544378.77dddcd50c22e56bfff133c0e1f9165b. (offlining), current state: {77dddcd50c22e56bfff133c0e1f9165b state=OPEN, ts=1429520545780,   server=os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268}
bleProcedure$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268 for region loadtest_d1,,1429520544378.77dddcd50c22e56bfff133c0e1f9165b.
2015-04-20 09:02:27,414 INFO  [AM.ZK.Worker-pool3-t316] master.RegionStates: Offlined 77dddcd50c22e56bfff133c0e1f9165b from os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268
{code}

On table re-enable, AM does not assign the region: 
{code}
2015-04-20 09:02:30,415 INFO  [ProcedureExecutorThread-3] balancer.BaseLoadBalancer: Reassigned 25 regions. 25 retained the pre-restart assignment.路
2015-04-20 09:02:30,415 INFO  [ProcedureExecutorThread-3] procedure.EnableTableProcedure: Bulk assigning 25 region(s) across 5 server(s), retainAssignment=true

l,16000,1429515659726-GeneralBulkAssigner-4] master.RegionStates: Couldn't reach online server os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268

l,16000,1429515659726-GeneralBulkAssigner-4] master.AssignmentManager: Updating the state to OFFLINE to allow to be reassigned by SSH
nmentManager: Skip assigning loadtest_d1,,1429520544378.77dddcd50c22e56bfff133c0e1f9165b., it is on a dead but not processed yet server: os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268
{code}

"
HBASE-14506,See attached log. Flakey up on jenkins and down locally.
HBASE-12542,"Using alter command to delete a family of table online will make the regionsevers that serve the regions of the table crash.
{code}
alter 't', NAME => 'f', METHOD => 'delete'
{code}

The reason is that TableDeleteFamilyHandler in HMaster delete the family dir firstly and then reopen all the regions of table.
When the regionserver reopen the region, it will crash for the exception in flushing memstore to hfile of the deleted family during closing the region, because the parent dir of the hfile has been deleted in TableDeleteFamilyHandler.
See: TableDeleteFamilyHandler.java #57

A simple solution is change the order of operations in TableDeleteFamilyHandler.
- update table descriptor first, 
- reopen all the regions,
- delete the the family dir at last.

Suggestions are welcomed.
"
HBASE-6461,"Spun up a new dfs on hadoop-0.20.2-cdh3u3
Started hbase
started running loadtest tool.
killed rs and dn holding root with killall -9 java on server sv4r27s44 at about 2012-07-25 22:40:00

After things stabilize Root is in a bad state. Ran hbck and got:
Exception in thread ""main"" org.apache.hadoop.hbase.client.NoServerForRegionException: No server address listed in -ROOT- for region .META.,,1.1028785192 containing row 
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1016)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:841)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:810)
at org.apache.hadoop.hbase.client.HTable.finishSetup(HTable.java:232)
at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:172)
at org.apache.hadoop.hbase.util.HBaseFsck.connect(HBaseFsck.java:241)
at org.apache.hadoop.hbase.util.HBaseFsck.main(HBaseFsck.java:3236)



hbase(main):001:0> scan '-ROOT-'
ROW                                           COLUMN+CELL                                                                                                                       
12/07/25 22:43:18 INFO security.UserGroupInformation: JAAS Configuration already set up for Hadoop, not re-installing.
 .META.,,1                                    column=info:regioninfo, timestamp=1343255838525, value={NAME => '.META.,,1', STARTKEY => '', ENDKEY => '', ENCODED => 1028785192,}
 .META.,,1                                    column=info:v, timestamp=1343255838525, value=\x00\x00                                                                            
1 row(s) in 0.5930 seconds


Here's the master log: https://gist.github.com/3179194

I tried the same thing with 0.92.1 and I was able to get into a similar situation, so I don't think this is anything new. "
HBASE-5578,"The regeionserver log:
2012-03-11 11:55:37,808 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: ABORTING region server data3,60020,1331286604591: Unhandled exception: null
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.Store.getTotalStaticIndexSize(Store.java:1788)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.createRegionLoad(HRegionServer.java:994)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.buildServerLoad(HRegionServer.java:800)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:776)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:678)
	at java.lang.Thread.run(Thread.java:662)
2012-03-11 11:55:37,808 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: []
2012-03-11 11:55:37,808 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics: requestsPerSecond=1687, numberOfOnlineRegions=37, numberOfStores=37, numberOfStorefiles=144, storefileIndexSizeMB=2, rootIndexSizeKB=2362, totalStaticIndexSizeKB=229808, totalStaticBloomSizeKB=2166296, memstoreSizeMB=2854, readRequestsCount=1352673, writeRequestsCount=113137586, compactionQueueSize=8, flushQueueSize=3, usedHeapMB=7359, maxHeapMB=12999, blockCacheSizeMB=32.31, blockCacheFreeMB=3867.52, blockCacheCount=38, blockCacheHitCount=87713, blockCacheMissCount=22144560, blockCacheEvictedCount=122, blockCacheHitRatio=0%, blockCacheHitCachingRatio=99%, hdfsBlocksLocalityIndex=100
2012-03-11 11:55:37,992 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: STOPPED: Unhandled exception: null"
HBASE-4216,"Received one of these while doing a YCSB test on 26 nodes on trunk:
java.io.IOException: java.lang.IllegalArgumentException: hostname can't be null
"
HBASE-14177,"After adding a large row, scanning back that row winds up being empty. After a few attempts it will succeed (all attempts over the same data on an hbase getting no other writes).

Looking at logs, it seems this happens when there is memory pressure on the client and there are several Full GCs that happen. Then messages that indicate that region locations are being removed from the local client cache:

2015-07-31 12:50:24,647 [main] DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation  - Removed 192.168.1.131:50981 as a location of big_row_1438368609944,,1438368610048.880c849594807bdc7412f4f982337d6c. for tableName=big_row_1438368609944 from cache

Blaming the GC may sound fanciful, but if the test is run with -Xms4g -Xmx4g then it always passes on the first scan attempt. Maybe the pause is enough to remove something from the cache, or the client is using weak references somewhere?

More info http://mail-archives.apache.org/mod_mbox/hbase-user/201507.mbox/%3CCAE8tVdnFf%3Dob569%3DfJkpw1ndVWOVTkihYj9eo6qt0FrzihYHgw%40mail.gmail.com%3E

Test used to reproduce:
https://github.com/housejester/hbase-debugging#fullgctest


I tested and had failures in:

0.98.12 client/server
0.98.13 client 0.98.12 server
0.98.13 client/server
1.1.0 client 0.98.13 server
0.98.13 client and 1.1.0 server
0.98.12 client and 1.1.0 server

I tested without failure in:

1.1.0 client/server"
HBASE-14233,"{code}
15/08/17 14:10:50 INFO master.RegionStates: Transition null to {6486b9b9409b25f10eb806ec3bad442d state=MERGING_NEW, ts=1439845850422, server=hbase508.ash1.facebook.com,16020,1439844470302}
15/08/17 14:10:57 INFO master.AssignmentManager: Failed to record merged region 6486b9b9409b25f10eb806ec3bad442d
15/08/17 14:10:57 ERROR master.AssignmentManager: Failed to transtion region from {6486b9b9409b25f10eb806ec3bad442d state=MERGING_NEW, ts=1439845850422, server=hbase508.ash1.facebook.com,16020,1439844470302} to MERGE_PONR by hbase508.ash1.facebook.com,16020,1439844470302: Failed to record the merging in meta
15/08/17 14:11:08 WARN master.RegionStates: THIS SHOULD NOT HAPPEN: unexpected {6486b9b9409b25f10eb806ec3bad442d state=MERGING_NEW, ts=1439845857580, server=hbase508.ash1.facebook.com,16020,1439844470302}
{code}"
HBASE-3622,"On Dmitriy's cluster:

{code}

""IPC Reader 0 on port 60020"" prio=10 tid=0x00002aacb4a82800 nid=0x3a72 waiting on condition [0x00000000429ba000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00002aaabf5fa6d0> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:747)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:778)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1114)
        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:186)
        at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:262)
        at java.util.concurrent.LinkedBlockingQueue.signalNotEmpty(LinkedBlockingQueue.java:103)
        at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:267)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.processData(HBaseServer.java:985)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.readAndProcess(HBaseServer.java:946)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.doRead(HBaseServer.java:522)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener$Reader.run(HBaseServer.java:316)
        - locked <0x00002aaabf580fb0> (a org.apache.hadoop.hbase.ipc.HBaseServer$Listener$Reader)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
...
""IPC Server handler 29 on 60020"" daemon prio=10 tid=0x00002aacbc163800 nid=0x3acc waiting on condition [0x00000000462f3000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00002aaabf5e3800> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025)
""IPC Server handler 28 on 60020"" daemon prio=10 tid=0x00002aacbc161800 nid=0x3acb waiting on condition [0x00000000461f2000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00002aaabf5e3800> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025
...
{code}

This region server stayed in this state for hours. The reader is waiting to put and the handlers are waiting to take, and they wait on different lock ids. It reminds me of the UseMembar thing about the JVM sometime missing to notify waiters. In any case, that RS needed to be closed in order to get out of that state. "
HBASE-3331,"If you find the server hosting META and kill -STOP its region server, it will eventually lose its ZK session and the master will split its logs and try to reassign. However, at some point along here it tries to access the old META, and gets SocketTimeoutExceptions, which cause it to keep retrying forever. Once I kill -9ed the stopped server, things came back to life."
HBASE-2880,"I just ran into this testing 0.89 RC candidate.

So, Master is hung up because all threads are locked out because one thread is stuck inside a block that is synchronized on RegionManager (0x00007fe1f94777d0 in the below):

{code}
3277 ""IPC Server handler 9 on 60000"" daemon prio=10 tid=0x00007fe1dc00f000 nid=0x409d in Object.wait() [0x00007fe1e9200000]
3278    java.lang.Thread.State: WAITING (on object monitor)
3279         at java.lang.Object.wait(Native Method)
3280         at java.lang.Object.wait(Object.java:485)
3281         at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:732)
3282         - locked <0x00007fe1f8672818> (a org.apache.hadoop.hbase.ipc.HBaseClient$Call)
3283         at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:252)
3284         at $Proxy1.get(Unknown Source)
3285         at org.apache.hadoop.hbase.master.ServerManager.assignSplitDaughter(ServerManager.java:550)
3286         at org.apache.hadoop.hbase.master.ServerManager.processSplitRegion(ServerManager.java:525)
3287         - locked <0x00007fe1f94777d0> (a org.apache.hadoop.hbase.master.RegionManager)
3288         at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:476)
3289         at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:425)
3290         at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:335)
3291         at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:738)
3292         at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
3293         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
3294         at java.lang.reflect.Method.invoke(Method.java:597)
3295         at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:576)
3296         at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:919)
{code}

The above code is not returning because Call#callComplete is never going to be called on the outstanding Get.  The target RS OOME'd.  Something in the way an OOME is being processed made it so this connection is not ever going to be cleaned up/notified.

We're stuck here.

I'm trying to figure why the clean up is not happening."
HBASE-3637,"I don't 100% understand how this happened, but the following was observed:

- META is in OPENED state in ZK, for a server which no longer exists
- Handler sees that server is dead, and figures that the RIT timeout will handle it
- RIT timeout sees that it's already in OPENED state, and assumes that the OPENED handler will handle it
- loops in timeout state forever, never actually getting reassigned"
HBASE-4954,"On Tue, Nov 29, 2011 at 10:20 PM, Stack <stack@duboce.net> wrote:
> The first hbase 0.92.0 release candidate is available for download:
>
>  http://people.apache.org/~stack/hbase-0.92.0-candidate-0/

Here's another persistent issues that I'd appreciate somebody taking
a quick look at:
    http://bigtop01.cloudera.org:8080/view/Hadoop%200.22/job/Bigtop-hadoop22-smoketest/28/testReport/org.apache.bigtop.itest.hbase.smoke/TestHFileOutputFormat/testMRIncrementalLoadWithSplit/

Caused by: java.lang.IllegalArgumentException
       at java.nio.Buffer.position(Buffer.java:218)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.blockSeek(HFileReaderV2.java:632)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:545)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:503)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:511)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:475)
       at org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(HalfStoreFileReader.java:157)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.copyHFileHalf(LoadIncrementalHFiles.java:544)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.splitStoreFile(LoadIncrementalHFiles.java:516)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.splitStoreFile(LoadIncrementalHFiles.java:377)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.groupOrSplit(LoadIncrementalHFiles.java:441)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call(LoadIncrementalHFiles.java:325)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call(LoadIncrementalHFiles.java:323)
       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
       at java.util.concurrent.FutureTask.run(FutureTask.java:138)
       at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
       at java.lang.Thread.run(Thread.java:619)"
HBASE-6636,"The test class TestMasterZKSessionRecovery has been removed in trunk.  Its master tests were moved elsewhere or removed because useless (See nkeywal reasoning over in HBASE-5572 ""KeeperException.SessionExpiredException management could be improved in Master""; it was actually removed by HBASE-5549 ""Master can fail if ZooKeeper session expires"").

TestMasterZKSessionRecovery in 0.92 and 0.94 has an extra test that was not in trunk, the sporadically failing testRegionAssignmentAfterMasterRecoveryDueToZKExpiry.  This was added by ""HBASE-6046
Master retry on ZK session expiry causes inconsistent region assignments""."
HBASE-13782,"hbaes version: 1.0.0-cdh5.4.0
hadoop version: 2.6.0-cdh5.4.0 


Environment: 40-node hadoop cluster shared with a 10-node hbase cluster and a 30-node yarn.

We started to see that one RS stopped to serve any client request since 2015-05-26 01:05:33, while all other RS were okay. I checked RS log and found that there are some FATAL logs when org.apache.hadoop.hbase.regionserver.wal.FSHLog tried to append() and sync{}:

{code}

2015-05-26 01:05:33,700 FATAL org.apache.hadoop.hbase.regionserver.wal.FSHLog: Could not append. Requesting close of wal
java.io.IOException: Bad connect ack with firstBadLink as 10.28.1.17:50010
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1472)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1373)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:600)
2015-05-26 01:05:33,700 FATAL org.apache.hadoop.hbase.regionserver.wal.FSHLog: Could not append. Requesting close of wal
java.io.IOException: Bad connect ack with firstBadLink as 10.28.1.17:50010
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1472)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1373)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:600)
2015-05-26 01:05:33,700 FATAL org.apache.hadoop.hbase.regionserver.wal.FSHLog: Could not append. Requesting close of wal
java.io.IOException: Bad connect ack with firstBadLink as 10.28.1.17:50010
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1472)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1373)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:600)
2015-05-26 01:05:33,700 INFO org.apache.hadoop.hbase.regionserver.wal.FSHLog: Archiving hdfs://nameservice1/hbase/WALs/hbase08.company.com,60020,1431985722474/hbase08.company.com%2C60020%2C1431985722474.default.1432602140966 to hdfs://nameservice1/hbase/oldWALs/hbase08.company.com%2C60020%2C1431985722474.default.1432602140966
2015-05-26 01:05:33,701 ERROR org.apache.hadoop.hbase.regionserver.wal.FSHLog: Error syncing, request close of wal 

{code}

Since the HDFS cluster is shared with a YARN cluster, at the time, there were some io heavy jobs running, and exhausted xciever at some of the DNs at the exact same time. I think it's the reason why the RS got ``java.io.IOException: Bad connect ack with firstBadLink''

The problem is, the RS got stuck without any response since then. flushQueueLength grew to the ceiling and stayed there. The only log entries are from periodicFlusher:

{code}
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,3992+80bb1,1432526964367.c4906e519c1f8206a284c66a8eda2159. after a delay of 11000
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,0814+0416,1432541066864.cf42d5ab47e051d69e516971e82e84be. after a delay of 7874
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,2022+7a571,1432528246524.299c1d4bb28fda2a4d9f248c6c22153c. after a delay of 22740
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,2635+b9b677,1432540367215.749efc885317a2679e2ea39bb0845fbe. after a delay of 3162
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,0401+985e,1432527151473.eb97576381fce10a9616efd471103920. after a delay of 9142
{code}

Looks like there is a RS level deadlock triggered by the FATAL append exception handling. In the end, I had to restart the RS service to rescue the regions from the stuck RS.

{code}
      } catch (Exception e) {
        LOG.fatal(""Could not append. Requesting close of wal"", e);
        requestLogRoll();
        throw e;
      }
      numEntries.incrementAndGet();
    }
{code}

Maybe the RS can just suicide after the FATAL exception since it cannot append WAL to hdfs? "
HBASE-6289,"The ROOT RS has some network problem and its ZK node expires first, which kicks off the ServerShutdownHandler. it calls verifyAndAssignRoot() to try to re-assign ROOT. At that time, the RS is actually still working and passes the verifyRootRegionLocation() check, so the ROOT region is skipped from re-assignment.
{code}
  private void verifyAndAssignRoot()
  throws InterruptedException, IOException, KeeperException {
    long timeout = this.server.getConfiguration().
      getLong(""hbase.catalog.verification.timeout"", 1000);
    if (!this.server.getCatalogTracker().verifyRootRegionLocation(timeout)) {
      this.services.getAssignmentManager().assignRoot();
    }
  }
{code}
After a few moments, this RS encounters DFS write problem and decides to abort. The RS then soon gets restarted from commandline, and constantly report:
{code}
2012-06-27 23:13:08,627 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
2012-06-27 23:13:08,627 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
2012-06-27 23:13:08,628 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
2012-06-27 23:13:08,628 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
2012-06-27 23:13:08,630 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
{code}"
HBASE-2818,"I have a region that's open on a server, but META thinks it's not deployed anywhere. I get the following when trying to close it:

hbase(main):002:0> close_region 'usertable,user302806495,1278457018956.c4ad0681f7be3995490c745861af66ea.', '192.168.42.41:60020'

ERROR: java.io.IOException: java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.util.Bytes.toLong(Bytes.java:479)
        at org.apache.hadoop.hbase.util.Bytes.toLong(Bytes.java:453)
        at org.apache.hadoop.hbase.master.HMaster.modifyTable(HMaster.java:1021)
"
HBASE-11401,"After HBASE-8763, we have combined KV mvcc and HLog seqNo. This is implemented in a tricky way now.
In HRegion on write path, we first write to memstore and then write to HLog finally sync log. So at the time of write to memstore we dont know the WAL seqNo.  To overcome this, we hold the ref to the KV objects just added to memstore and pass those also to write to wal call. Once the seqNo is obtained, we will reset the mvcc is those KVs with this seqNo.  (While write to memstore we wrote kvs with a very high temp value for mvcc so that concurrent readers wont see them)
This model works well with the DefaultMemstore.  During the write there wont be any concurrent call to snapshot(). 
But now we have memstore as a pluggable interface. The above model of late binding assumes that the memstore internal datastructure continue to refer to same java objects. This might not be true always.  Like in HBASE-10713, in btw the kvs can be converted into a CellBlock. If we discontinue to refer to same KV java objects, we will fail in getting the seqNo assigned as kv mvcc.

If we were doing write and sync to wal and then write to memstore, this would have get solved. But this model we changed (in 94 I believe) for better perf. Under HRegion level lock, we write to memstore and then to wal. Finally out of lock we do the the log sync.  So we can not change it now

I tried changing the order of ops within the lock (ie. write to log and then to memstore) so that we can get the seqNo when write to memstore. But because of the new HLog write model, we are not guarenteed to get the write to done immediately. 

One possible way can be add a new API in Log level, to get a next seqNo alone. Call this first and then using which write to memstore and then to wal (using this seqNo).  Just a random thought. Not tried."
HBASE-4951,"It is easy to reproduce by following step:
step1:start master process.(do not start regionserver process in the cluster).
the master will wait the regionserver to check in:
org.apache.hadoop.hbase.master.ServerManager: Waiting on regionserver(s) to checkin

step2:stop the master by sh command bin/hbase master stop

result:the master process will never die because catalogTracker.waitForRoot() method will block unitl the root region assigned.
"
HBASE-3350,"With my ""crazy conf"" that causes tons of splits, I had a 2000 region table, which I disabled while inserting data (similar to HBASE-3345). This time I didn't get NPE, but I ended up with 68 regions stuck in transition (disable never finished)"
HBASE-2575,"We performed a fault test where we physically pulled the root drive out of a machine while it was on. The regionserver continued to run fine with existing clients. But any new clients that tried to connect to it for RPC would not work correctly. So when I started a new client, that client made no progress. Despite this, the RS continued to happily heartbeat to the master, so the master did not remove it from the cluster. Note that in this case, we were logging to NFS, and the logs continued to write, but no exceptions shown."
HBASE-2176,"We ran some tests on our cluster, and getting back reports about WrongRegionException, on some rows. After looking at the data, we see that we have ""gaps"" between regions, like this:

{noformat}
demo__users,user_8949795897,1264089193398  l2:60030  736660864  user_8949795897  user_8950697145 <- end key
demo__users,user_8953502603,1263992844343  l5:60030  593335873  user_8953502603 <- should be star key here   user_8956071605
{noformat}

Fact: we had 28 regions that were reported with empty HRegionInfo, and deleted from .META.. 

Fact: we recovered our data entirely, without any issues, by running the .META. restore script from table contents (bin/add_table.rb)

Fact: on our regionservers, we have three days with no logs. To the best of our knowledge, the machines were not rebooted, the processes were running. During these three days, on the master, the only entry in the logs (repeated), every second, is a .META. scan:

{noformat}
2010-01-23 00:01:27,816 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of 1 row(s) of meta region {server: 10.72.135.7:60020, regionname: -ROOT-,,0, startKey: <>} complete
2010-01-23 00:01:34,413 INFO org.apache.hadoop.hbase.master.ServerManager: 6 region servers, 0 dead, average load 1113.6666666666667
2010-01-23 00:02:23,645 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {server: 10.72.135.10:60020, regionname: .META.,,1, startKey: <>}
2010-01-23 00:02:26,002 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of 6679 row(s) of meta region {server: 10.72.135.10:60020, regionname: .META.,,1, startKey: <>} complete
2010-01-23 00:02:26,002 INFO org.apache.hadoop.hbase.master.BaseScanner: All 1 .META. region(s) scanned
2010-01-23 00:02:27,821 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {server: 10.72.135.7:60020, regionname: -ROOT-,,0, startKey: <>}
.......................................................
{noformat}

In the master logs, we see a pretty normal evolution: region r0 is split into r1 and r2. Now, r1 exists and is good, r2 does not exist in .META. anymore, because it was reported as having empty HRegionInfo. The only thing in the master logs that is weird is that the message about updating the region in meta comes up twice:

{noformat}
2010-01-27 22:46:45,007 INFO org.apache.hadoop.hbase.master.RegionServerOperation: demo__users,user_8950697145,1264089193398 open on 10.72.135.7:60020
2010-01-27 22:46:45,010 INFO org.apache.hadoop.hbase.master.RegionServerOperation: Updated row demo__users,user_8950697145,1264089193398 in region .META.,,1 with startcode=1264661019484, server=10.72.135.7:60020
2010-01-27 22:46:45,010 INFO org.apache.hadoop.hbase.master.RegionServerOperation: demo__users,user_8950697145,1264089193398 open on 10.72.135.7:60020
2010-01-27 22:46:45,012 INFO org.apache.hadoop.hbase.master.RegionServerOperation: Updated row demo__users,user_8950697145,1264089193398 in region .META.,,1 with startcode=1264661019484, server=10.72.135.7:60020
{noformat}

Attached you will find the entire forensics work, with explanations, in a text file. 

Suppositions:

Our entire cluster was in a really weird state. All the regionservers are missing logs for three days, and to the best of our knowledge they were running, and in this time the master has ONLY .META. scan messages, every second, reporting 6 regionservers live, out of 7 total. 

Also, during this time, we get filesystem closed messages on a regionservers with one of the missing regions. This is after the gap in the logs. 

How we suppose the data in .META. was lost

1. Race conditions in ServerManager / RegionManager. In our logs, we have about 3 or 4 CME, in these classes (see the attached file)
2. Data loss in HDFS. On a regionserver, we get filesystem closed messages
3. Data could not be read fro HDFS ( highly unlikely, there are no weird data read messages)
4. Race condition leading to loss of the HRegionInfo from memory, and then persisted as empty. 
"
HBASE-1214,"One of my region server falls in a long GC time that get it unresponsive during about 10 minutes.
As I can see in the log, it seems that its DFSClient component was sending a file to hdfs, the sending times out when it recovers from GC:

h5. 1. Region server log after recovering from GC
{noformat}
2009-02-21 01:22:26,454 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  
    for block blk_7545556036225037274_1820952java.io.IOException: Bad response 1 for block 
    blk_7545556036225037274_1820952 from datanode 192.168.1.10:50010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2342)
{noformat}

h5. 2. corresponding error in receiving datanode
{noformat}
2009-02-21 01:23:56,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block 
    blk_7545556036225037274_1820952 java.io.EOFException: while trying to read 65557 bytes
[...]
2009-02-21 01:23:59,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block 
    blk_7545556036225037274_1820952 Interrupted.
2009-02-21 01:24:01,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block 
    blk_7545556036225037274_1820952 terminating
2009-02-21 01:24:01,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock 
   blk_7545556036225037274_1820952 received exception java.io.EOFException: while trying to read 65557 bytes
{noformat}

Since region server misses its lease to report to the master, it has to close all its regions before recover, and reopens them when the master asks for.
From this time, it tries to _recover_ this block, as seen in the regionserver log:

h5. 3. Region server log in an endless loop to recover
{noformat}
009-02-21 01:22:29,327 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block 
    blk_7545556036225037274_1820952 bad datanode[1] 192.168.1.10:50010
2009-02-21 01:22:29,327 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block 
    blk_7545556036225037274_1820952 in pipeline 192.168.1.13:50010, 
   192.168.1.10:50010: bad datanode 192.168.1.10:50010
2009-02-21 01:22:29,689 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block 
    blk_7545556036225037274_1820952 failed  because recovery from primary datanode 192.168.1.13:50010 failed 2 times. Will retry...
{noformat}

To this _recover_ request, all datanodes fail with this Exception

h5. 4.
{noformat}
2009-02-21 01:24:18,650 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020, call 
   recoverBlock(blk_7545556036225037274_1820952, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@311c4f) from 
   192.168.1.13:56968: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: 
   blk_7545556036225037274_1820952 is already commited, storedBlock == null.
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:4536)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:402)
        at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_7545556036225037274_1820952 is already commited, 
   storedBlock == null.
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:4536)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:402)
        at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)

        at org.apache.hadoop.ipc.Client.call(Client.java:696)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
        at $Proxy4.nextGenerationStamp(Unknown Source)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1466)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1440)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1506)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
{noformat}

The problem is that, in this case, the RegionServer and therefore the master fails to stop when I launch the stop-hbase script.
A kill (-TERM) on the region server launches the SIGTERM handler thread, but the loop which try to reach the block does not stop.
here is a thread dump of the region server at this time:

h5. 5. Thread dump of the region server
{noformat}
Full thread dump Java HotSpot(TM) Server VM (10.0-b23 mixed mode):

""Thread-16"" prio=10 tid=0x081c3c00 nid=0x6e81 in Object.wait() [0x8f74f000..0x8f74fec0]
   java.lang.Thread.State: WAITING (on object monitor)                                
        at java.lang.Object.wait(Native Method)                                        
        at java.lang.Thread.join(Thread.java:1143)                                    
        - locked <0x93d0d060> (a java.lang.Thread)                                    
        at java.lang.Thread.join(Thread.java:1196)                                    
        at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:78)              
        at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:66)              
        at org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread.run(HRegionServer.java:814)

""SIGTERM handler"" daemon prio=10 tid=0x08dbcc00 nid=0x6e80 in Object.wait() [0x8edaf000..0x8edaff40]
   java.lang.Thread.State: WAITING (on object monitor)                                              
        at java.lang.Object.wait(Native Method)                                                    
        at java.lang.Thread.join(Thread.java:1143)                                                  
        - locked <0x93d0f3c0> (a org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread)
        at java.lang.Thread.join(Thread.java:1196)                                                  
        at java.lang.ApplicationShutdownHooks.run(ApplicationShutdownHooks.java:79)                
        at java.lang.Shutdown.runHooks(Shutdown.java:89)                                            
        at java.lang.Shutdown.sequence(Shutdown.java:133)                                          
        at java.lang.Shutdown.exit(Shutdown.java:178)                                              
        - locked <0xb0d3ed60> (a java.lang.Class for java.lang.Shutdown)                            
        at java.lang.Terminator$1.handle(Terminator.java:35)                                        
        at sun.misc.Signal$1.run(Signal.java:195)                                                  
        at java.lang.Thread.run(Thread.java:619)                                                    

""Attach Listener"" daemon prio=10 tid=0x081e8800 nid=0x6e50 waiting on condition [0x00000000..0x00000000]
   java.lang.Thread.State: RUNNABLE                                                                    

""IPC Client (47) connection to /192.168.1.13:50020 from an unknown user"" daemon prio=10 tid=0x8e97a400 nid=0x39d1 in Object.wait() [0x8ec81000..0x8ec81fc0]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                                                                              
        at java.lang.Object.wait(Native Method)                                                                                                            
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:395)                                                                            
        - locked <0xa44a36a0> (a org.apache.hadoop.ipc.Client$Connection)                                                                                  
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:437)                                                                                    

""IPC Client (47) connection to /192.168.1.10:50020 from an unknown user"" daemon prio=10 tid=0x8e5f1c00 nid=0x523f in Object.wait() [0x8ecd3000..0x8ecd3140]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                                                                              
        at java.lang.Object.wait(Native Method)                                                                                                            
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:395)                                                                            
        - locked <0xa448ca50> (a org.apache.hadoop.ipc.Client$Connection)                                                                                  
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:437)                                                                                    

""BlockFSInputStreamReferenceQueueChecker"" daemon prio=10 tid=0x085a9400 nid=0x8c8 waiting on condition [0x8ee6c000..0x8ee6cdc0]
   java.lang.Thread.State: WAITING (parking)                                                                                  
        at sun.misc.Unsafe.park(Native Method)                                                                                
        - parking to wait for  <0x93e76068> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)          
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                                  
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)  
        at java.util.concurrent.DelayQueue.take(DelayQueue.java:160)                                                          
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:582)        
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:575)        
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:946)                                        
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:906)                                    
        at java.lang.Thread.run(Thread.java:619)                                                                              

""IPC Server handler 9 on 60020"" daemon prio=10 tid=0x0882e000 nid=0x889 waiting on condition [0x8eebd000..0x8eebdfc0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 8 on 60020"" daemon prio=10 tid=0x0882cc00 nid=0x888 waiting on condition [0x8ef0e000..0x8ef0f040]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 7 on 60020"" daemon prio=10 tid=0x0882b800 nid=0x887 waiting on condition [0x8ef5f000..0x8ef5fec0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 6 on 60020"" daemon prio=10 tid=0x0882a400 nid=0x886 waiting on condition [0x8efb0000..0x8efb0f40]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 5 on 60020"" daemon prio=10 tid=0x08829000 nid=0x885 waiting on condition [0x8f001000..0x8f001dc0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 4 on 60020"" daemon prio=10 tid=0x083bcc00 nid=0x884 waiting on condition [0x8f052000..0x8f052e40]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 3 on 60020"" daemon prio=10 tid=0x083bb800 nid=0x883 waiting on condition [0x8f0a3000..0x8f0a40c0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 2 on 60020"" daemon prio=10 tid=0x083ba400 nid=0x882 waiting on condition [0x8f0f4000..0x8f0f5140]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 1 on 60020"" daemon prio=10 tid=0x083b9400 nid=0x881 waiting on condition [0x8f145000..0x8f145fc0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 0 on 60020"" daemon prio=10 tid=0x083b8400 nid=0x880 waiting on condition [0x8f196000..0x8f197040]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server listener on 60020"" daemon prio=10 tid=0x083bfc00 nid=0x87f runnable [0x8f1e7000..0x8f1e7ec0]
   java.lang.Thread.State: RUNNABLE                                                                    
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)                                        
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)                                
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)                            
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)                                
        - locked <0x93d0c090> (a sun.nio.ch.Util$1)                                                    
        - locked <0x93d0c120> (a java.util.Collections$UnmodifiableSet)                                
        - locked <0x93d0c0b0> (a sun.nio.ch.EPollSelectorImpl)                                          
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)                                        
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:84)                                        
        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.run(HBaseServer.java:299)                  

""IPC Server Responder"" daemon prio=10 tid=0x083bec00 nid=0x87e runnable [0x8f238000..0x8f238f40]
   java.lang.Thread.State: RUNNABLE                                                            
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)                                
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)                        
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)                    
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)                        
        - locked <0x93d0c0f0> (a sun.nio.ch.Util$1)                                            
        - locked <0x93d0c100> (a java.util.Collections$UnmodifiableSet)                        
        - locked <0x93d0be30> (a sun.nio.ch.EPollSelectorImpl)                                  
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)                                
        at org.apache.hadoop.hbase.ipc.HBaseServer$Responder.run(HBaseServer.java:458)          

""SocketListener0-1"" prio=10 tid=0x088d5000 nid=0x87c in Object.wait() [0x8f2da000..0x8f2dae40]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                  
        at java.lang.Object.wait(Native Method)                                              
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:522)                    
        - locked <0x93e39bc8> (a org.mortbay.util.ThreadPool$PoolThread)                      

""SocketListener0-0"" prio=10 tid=0x08ab5000 nid=0x87b in Object.wait() [0x8f32b000..0x8f32c0c0]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                  
        at java.lang.Object.wait(Native Method)                                              
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:522)                    
        - locked <0x93e39920> (a org.mortbay.util.ThreadPool$PoolThread)                      

""Acceptor ServerSocket[addr=0.0.0.0/0.0.0.0,port=0,localport=60030]"" prio=10 tid=0x084f6800 nid=0x87a 
   runnable [0x8f37c000..0x8f37d140]
   java.lang.Thread.State: RUNNABLE                                                                                                    
        at java.net.PlainSocketImpl.socketAccept(Native Method)                                                                        
        at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:384)                                                                  
        - locked <0x93e382a8> (a java.net.SocksSocketImpl)                                                                            
        at java.net.ServerSocket.implAccept(ServerSocket.java:453)                                                                    
        at java.net.ServerSocket.accept(ServerSocket.java:421)                                                                        
        at org.mortbay.util.ThreadedServer.acceptSocket(ThreadedServer.java:432)                                                      
        at org.mortbay.util.ThreadedServer$Acceptor.run(ThreadedServer.java:631)                                                      

""SessionScavenger"" daemon prio=10 tid=0x088f1400 nid=0x879 waiting on condition [0x8f3cd000..0x8f3cdfc0]
   java.lang.Thread.State: TIMED_WAITING (sleeping)                                                    
        at java.lang.Thread.sleep(Native Method)                                                        
        at org.mortbay.jetty.servlet.AbstractSessionManager$SessionScavenger.run(AbstractSessionManager.java:587)

""SessionScavenger"" daemon prio=10 tid=0x08ab5c00 nid=0x878 waiting on condition [0x8f41e000..0x8f41f040]
   java.lang.Thread.State: TIMED_WAITING (sleeping)                                                    
        at java.lang.Thread.sleep(Native Method)                                                        
        at org.mortbay.jetty.servlet.AbstractSessionManager$SessionScavenger.run(AbstractSessionManager.java:587)

""regionserver/0.0.0.0:60020.leaseChecker"" prio=10 tid=0x086d5800 nid=0x877 waiting on condition [0x8f476000..0x8f476ec0]
   java.lang.Thread.State: TIMED_WAITING (parking)                                                                      
        at sun.misc.Unsafe.park(Native Method)                                                                          
        - parking to wait for  <0x93d0e980> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)  
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)                                      
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1963)
        at java.util.concurrent.DelayQueue.poll(DelayQueue.java:201)                                                            
        at org.apache.hadoop.hbase.Leases.run(Leases.java:78)                                                                    

""regionserver/0.0.0.0:60020.majorCompactionChecker"" daemon prio=10 tid=0x086d4000 nid=0x876 waiting on 
   condition [0x8f4c7000..0x8f4c7f40]
   java.lang.Thread.State: TIMED_WAITING (sleeping)                                                                                      
        at java.lang.Thread.sleep(Native Method)                                                                                        
        at org.apache.hadoop.hbase.util.Sleeper.sleep(Sleeper.java:74)                                                                  
        at org.apache.hadoop.hbase.Chore.run(Chore.java:72)                                                                              

""LeaseChecker"" daemon prio=10 tid=0x0837cc00 nid=0x870 waiting on condition [0x8f6ad000..0x8f6ae040]
   java.lang.Thread.State: TIMED_WAITING (sleeping)                                                
        at java.lang.Thread.sleep(Native Method)                                                    
        at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:979)                    
        at java.lang.Thread.run(Thread.java:619)                                                    

""DataStreamer for file /hbase/log_192.168.1.13_1235129194745_60020/hlog.dat.1235129195649 block blk_7545556036225037274_1820952"" 
   daemon prio=10 tid=0x08375400 nid=0x86f in Object.wait() [0x8f6fe000..0x8f6feec0]                                                                                                      
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                                                                                
        at java.lang.Object.wait(Native Method)                                                                                                            
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2166)                                                          
        - locked <0x93d0ea10> (a java.util.LinkedList)                                                                                                      

""DestroyJavaVM"" prio=10 tid=0x0805a000 nid=0x855 waiting on condition [0x00000000..0xb7dd2090]
   java.lang.Thread.State: RUNNABLE                                                          

""regionserver/0.0.0.0:60020"" prio=10 tid=0x085b2400 nid=0x863 in Object.wait() [0x8f7f7000..0x8f7f7f40]
   java.lang.Thread.State: WAITING (on object monitor)                                                
        at java.lang.Object.wait(Native Method)                                                        
        at java.lang.Object.wait(Object.java:485)                                                      
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.flushInternal(DFSClient.java:3015)        
        - locked <0x93d0ea10> (a java.util.LinkedList)                                                
        - locked <0x93d0ec58> (a org.apache.hadoop.hdfs.DFSClient$DFSOutputStream)                    
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3104)        
        - locked <0x93d0ec58> (a org.apache.hadoop.hdfs.DFSClient$DFSOutputStream)                    
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3053)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:59)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:79)
        at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:959)
        - locked <0x93d50d20> (a org.apache.hadoop.io.SequenceFile$Writer)
        at org.apache.hadoop.hbase.regionserver.HLog.close(HLog.java:421)
        - locked <0x93d4ce00> (a java.lang.Integer)
        at org.apache.hadoop.hbase.regionserver.HLog.closeAndDelete(HLog.java:404)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:373)
        at java.lang.Thread.run(Thread.java:619)

""Low Memory Detector"" daemon prio=10 tid=0x080dd800 nid=0x85e runnable [0x00000000..0x00000000]
   java.lang.Thread.State: RUNNABLE

""CompilerThread1"" daemon prio=10 tid=0x080dc400 nid=0x85d waiting on condition [0x00000000..0x8fbc1588]
   java.lang.Thread.State: RUNNABLE

""CompilerThread0"" daemon prio=10 tid=0x080d9c00 nid=0x85c waiting on condition [0x00000000..0x8fc42608]
   java.lang.Thread.State: RUNNABLE

""Signal Dispatcher"" daemon prio=10 tid=0x080d8800 nid=0x85b runnable [0x00000000..0x8fc93e80]
   java.lang.Thread.State: RUNNABLE

""Surrogate Locker Thread (CMS)"" daemon prio=10 tid=0x080d7800 nid=0x85a waiting on condition [0x00000000..0x8fce522c]
   java.lang.Thread.State: RUNNABLE

""Finalizer"" daemon prio=10 tid=0x080bbc00 nid=0x859 in Object.wait() [0x8fd7b000..0x8fd7bec0]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116)
        - locked <0x93d0bdc0> (a java.lang.ref.ReferenceQueue$Lock)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)

""Reference Handler"" daemon prio=10 tid=0x080ba800 nid=0x858 in Object.wait() [0x8fdcc000..0x8fdccf40]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object"
HBASE-6737,"Real cluster, scenario in HBASE-5843.
There are two exceptions, I create a single JIRA with both of them.

2012-09-04 18:14:49,264 FATAL org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: WriterThread-1 Got while writing log entry to log
java.io.IOException: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.append(SequenceFileLogWriter.java:229)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:949)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:919)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:891)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.SequenceFile$Writer.checkAndWriteSync(SequenceFile.java:1026)
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1068)
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1035)
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.append(SequenceFileLogWriter.java:226)
	... 3 more


2012-09-04 18:15:52,546 ERROR org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Error in log splitting write thread
java.lang.reflect.UndeclaredThrowableException
	at $Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:875)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:513)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:768)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getRegionSplitEditsPath(HLogSplitter.java:559)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.createWAP(HLogSplitter.java:974)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.access$800(HLogSplitter.java:82)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$OutputSink.getWriterAndPath(HLogSplitter.java:1309)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:942)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:919)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:891)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:261)
	... 11 more
Caused by: java.io.IOException: Call to BOX1/192.168.15.5:9000 failed on local exception: java.nio.channels.ClosedByInterruptException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1107)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy7.getFileInfo(Unknown Source)
	... 15 more
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:783)
	at org.apache.hadoop.ipc.Client.call(Client.java:1051)
	... 23 more

"
HBASE-8416,"This morning one our region servers (we have 44) stopped responding to
the '/jmx' request. (It's working for regular activity.)  Additionally,
the region server is now using all the CPU on the host, running all 8
cores at 100%.

A full jstack is at:
http://pastebin.com/dGTmTEN7


Right now, there are 37 threads stuck here:
""38565532@qtp-228776471-196"" prio=10 tid=0x00002aaacc4f2800 nid=0x7f57 runnable [0x0000000054a48000]
   java.lang.Thread.State: RUNNABLE
        at java.util.HashMap.get(HashMap.java:303)
        at org.apache.hadoop.metrics.util.MetricsDynamicMBeanBase.getAttribute(MetricsDynamicMBeanBase.java:137)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:666)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:638)
        at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:315)
        at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:293)
        at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:193)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:734)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:847)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1056)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

"
HBASE-1774,"HTable$ClientScanner modifies the Scan that is passed to it on construction.

I would consider this to be bad programming practice because if I wanted to use the same Scan object to scan multiple tables, I would not expect one table scan to effect the other, but it does.

If input parameters are going to be modified either now or later it should be called out *loudly* in the javadoc. The only way I found this behavior was by creating an application that did scan multiple tables using the same Scan object and having 'wierd stuff' happen.

In my opinion, if you want to modify a field in an input parameter, you should:
- make a copy of the original object
- optionally return a reference to the copy.

There is no javadoc about this behavior. The only thing I found was a comment in HTable$ClientScanner:
{code}
    // HEADSUP: The scan internal start row can change as we move through table.
{code}

Is there a use case that requires this behavior? If so, I would recommend that ResultScanner  (and the classes that implement it) provide an accessor to the mutable copy of the input Scan and leave the input argument alone."
HBASE-6401,"This comes from a hdfs bug, fixed in some hdfs versions. I haven't found the hdfs jira for this.

Context: HBase Write Ahead Log features. This is using hdfs append. If the node crashes, the file that was written is read by other processes to replay the action.
- So we have in hdfs one (dead) process writing with another process reading.
- But, despite the call to syncFs, we don't always see the data when we have a dead node. It seems to be because the call in DFSClient#updateBlockInfo ignores the ipc errors and set the length to 0.
- So we may miss all the writes to the last block if we try to connect to the dead DN.

hdfs 1.0.3, branch-1 or branch-1-win: we have the issue
http://svn.apache.org/viewvc/hadoop/common/branches/branch-1/src/hdfs/org/apache/hadoop/hdfs/DFSClient.java?revision=1359853&view=markup

hdfs branch-2 or trunk: we should not have the issue (but not tested)
http://svn.apache.org/viewvc/hadoop/common/branches/branch-2/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java?view=markup


The attached test will fail ~50 of the time.
"
HBASE-4481,"TestMergeTool failed due to the following exception:
{code}
java.lang.StringIndexOutOfBoundsException: String index out of range: -1
	at java.lang.String.substring(String.java:1937)
	at org.apache.hadoop.hbase.ServerName.parseHostname(ServerName.java:81)
	at org.apache.hadoop.hbase.ServerName.<init>(ServerName.java:63)
	at org.apache.hadoop.hbase.MasterAddressTracker.getMasterAddress(MasterAddressTracker.java:62)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getMaster(HConnectionManager.java:583)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:108)
	at org.apache.hadoop.hbase.client.HBaseAdmin.checkHBaseAvailable(HBaseAdmin.java:1588)
	at org.apache.hadoop.hbase.util.Merge.run(Merge.java:94)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.TestMergeTool.mergeAndVerify(TestMergeTool.java:186)
	at org.apache.hadoop.hbase.util.TestMergeTool.testMergeTool(TestMergeTool.java:264)
{code}
Log can be found at:
https://builds.apache.org/view/G-L/view/HBase/job/HBase-0.92/20/testReport/junit/org.apache.hadoop.hbase.util/TestMergeTool/testMergeTool/"
HBASE-907,"I have a table with 8 byte binary row keys.  There are a a few hundred thousands rows, each with two families and between 1k and 50k of total data across about 15 columns.

When attempting to get a scanner using a specified startRow, my client freezes on the HT.getScanner(cols,row) with no exception ever thrown and no debug output in any server logs.

If I get a scanner with HT.getScanner(cols) and then iterate through, I will eventually reach the row I was seeking before successfully.

Some rows can be found, some cannot.  At this point I'm not able to distinguish anything special about the ones that cause the client the hang.

At first I thought this was only a problem with 0.19 trunk as a downgrade to 0.18 resolved the issue for a particular key.  However other keys still have this issue on 0.18 branch."
HBASE-3466,"Happened while running ycsb against a single RS.  BlockSize was set to 64M to tickle more splits. No compression, and replication factor set to 1.
 
I noticed that  https://issues.apache.org/jira/browse/HBASE-2455 applied to 0.20.4, so opened this new one (didn't check to see if the code was the same in 0.20.4 and 0.90.0)

YCSB was run as follows:

java -mx3000m -cp conf/:build/ycsb.jar:db/hbase/lib/* com.yahoo.ycsb.Client -t -db com.yahoo.ycsb.db.HBaseClient -P workloads/workloada -p columnfamily=family -p operationcount=10000000 -s -threads 30 -target 30000

workloada was modified to do 1 billion records:
----------
recordcount=1000000000
operationcount=1000
workload=com.yahoo.ycsb.workloads.CoreWorkload
readallfields=true
readproportion=0.5
updateproportion=0.4
scanproportion=0
insertproportion=0.1
requestdistribution=zipfian
---------------

Relevant portions from the RS's log:

2011-01-23 10:48:20,719 INFO  org.apache.hadoop.hbase.regionserver.SplitTransaction [regionserver60020.compactor]: Starting split of region usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c.
2011-01-23 10:48:20,788 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Renaming flushed file at maprfs:/hbase/usertable/44386ab6079bd5b497a6de3ab95e850c/.tmp/3202441284831392385 to maprfs:/hbase/usertable/44386ab6079bd5b497a6de3ab95e850c/family/1800354539520698957
2011-01-23 10:48:20,791 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Added maprfs:/hbase/usertable/44386ab6079bd5b497a6de3ab95e850c/family/1800354539520698957, entries=10943, sequenceid=128924, memsize=3.4m, filesize=1.5m
2011-01-23 10:48:20,792 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: Closed usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c.
2011-01-23 10:48:20,828 INFO  org.apache.hadoop.hbase.catalog.MetaEditor [regionserver60020.compactor]: Offlined parent region usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c. in META
2011-01-23 10:48:20,856 INFO  org.apache.hadoop.hbase.regionserver.HRegion [perfnode15.perf.lab,60020,1295807975391-daughterOpener=89e0f70da1e5ce2d5c4024ca6cc1addb]: Onlined usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb.; next sequenceid=128925
2011-01-23 10:48:20,791 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Added maprfs:/hbase/usertable/44386ab6079bd5b497a6de3ab95e850c/family/1800354539520698957, entries=10943, sequenceid=128924, memsize=3.4m, filesize=1.5m
2011-01-23 10:48:20,792 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: Closed usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c.
2011-01-23 10:48:20,828 INFO  org.apache.hadoop.hbase.catalog.MetaEditor [regionserver60020.compactor]: Offlined parent region usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c. in META
2011-01-23 10:48:20,856 INFO  org.apache.hadoop.hbase.regionserver.HRegion [perfnode15.perf.lab,60020,1295807975391-daughterOpener=89e0f70da1e5ce2d5c4024ca6cc1addb]: Onlined usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb.; next sequenceid=128925
2011-01-23 10:48:20,863 INFO  org.apache.hadoop.hbase.catalog.MetaEditor [perfnode15.perf.lab,60020,1295807975391-daughterOpener=89e0f70da1e5ce2d5c4024ca6cc1addb]: Added daughter usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb. in region .META.,,1, serverInfo=perfnode15.perf.lab,60020,1295807975391
2011-01-23 10:48:20,868 INFO  org.apache.hadoop.hbase.regionserver.HRegion [perfnode15.perf.lab,60020,1295807975391-daughterOpener=fd1d4e71c9a7e262a6e26adc0742414e]: Onlined usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e.; next sequenceid=128926
2011-01-23 10:48:20,869 INFO  org.apache.hadoop.hbase.catalog.MetaEditor [perfnode15.perf.lab,60020,1295807975391-daughterOpener=fd1d4e71c9a7e262a6e26adc0742414e]: Added daughter usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e. in region .META.,,1, serverInfo=perfnode15.perf.lab,60020,1295807975391
2011-01-23 10:48:20,870 INFO  org.apache.hadoop.hbase.regionserver.CompactSplitThread [regionserver60020.compactor]: Region split, META updated, and report to master. Parent=usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c., new regions: usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb., usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e.. Split took 0sec
2011-01-23 10:48:20,871 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: Starting compaction on region usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb.
2011-01-23 10:48:20,873 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Started compaction of 4 file(s) in cf=family, hasReferences=true, into maprfs:/hbase/usertable/89e0f70da1e5ce2d5c4024ca6cc1addb/.tmp, seqid=128924, totalSize=271.3m
2011-01-23 10:48:21,822 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer [IPC Server handler 1 on 60020]: 
java.lang.RuntimeException: Cached an already cached block
        at org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(LruBlockCache.java:252)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:1056)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1433)
        at org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(HalfStoreFileReader.java:160)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:139)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:96)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.<init>(StoreScanner.java:77)
        at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1338)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.<init>(HRegion.java:2229)
        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateInternalScanner(HRegion.java:1119)
        at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1111)
        at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1095)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2951)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2853)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1623)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:570)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1036)
2011-01-23 10:48:28,877 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Completed compaction of 4 file(s), new file=maprfs:/hbase/usertable/89e0f70da1e5ce2d5c4024ca6cc1addb/family/1639385306246002272, size=125.9m; total size for store is 125.9m
2011-01-23 10:48:28,877 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: completed compaction on region usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb. after 8sec
2011-01-23 10:48:28,879 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: Starting compaction on region usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e.
2011-01-23 10:48:28,881 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Started compaction of 4 file(s) in cf=family, hasReferences=true, into maprfs:/hbase/usertable/fd1d4e71c9a7e262a6e26adc0742414e/.tmp, seqid=128925, totalSize=271.3m
2011-01-23 10:48:33,880 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Completed compaction of 4 file(s), new file=maprfs:/hbase/usertable/fd1d4e71c9a7e262a6e26adc0742414e/family/7964093352375224080, size=141.2m; total size for store is 141.2m
2011-01-23 10:48:33,880 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: completed compaction on region usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e. after 5sec
2011-01-23 10:48:44,117 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.cacheFlusher]: Renaming flushed file at maprfs:/hbase/usertable/fd1d4e71c9a7e262a6e26adc0742414e/.tmp/8006640041641015018 to maprfs:/hbase/usertable/fd1d4e
71c9a7e262a6e26adc0742414e/family/2931765299907917041
"
HBASE-4722,I'm digging in.  It fails occasionally for me locally to.
HBASE-485,"Two runs of the PerformanceEvaluation job on our test cluster running HBase trunk failed with region offline error.

The following is an excerpt from the failed task's log:
{code}
2008-03-01 19:30:42,184 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:30:42,186 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.
2008-03-01 19:30:42,186 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999
2008-03-01 19:30:42,188 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:30:52,196 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:30:52,200 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.
2008-03-01 19:30:52,200 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999
2008-03-01 19:30:52,203 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:31:02,219 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:31:02,236 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.
2008-03-01 19:31:02,237 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999
2008-03-01 19:31:02,240 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:31:12,261 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:31:12,270 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.lang.RuntimeException: java.lang.IllegalStateException: region offline: TestTable,0012639235,1204398750147
	at org.apache.hadoop.hbase.client.HTable.getRegionServerWithRetries(HTable.java:1019)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:753)
	at org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest.testRow(PerformanceEvaluation.java:465)
	at org.apache.hadoop.hbase.PerformanceEvaluation$Test.test(PerformanceEvaluation.java:333)
	at org.apache.hadoop.hbase.PerformanceEvaluation.runOneClient(PerformanceEvaluation.java:529)
	at org.apache.hadoop.hbase.PerformanceEvaluation$EvaluationMapTask.map(PerformanceEvaluation.java:178)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:208)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2071)
Caused by: java.lang.IllegalStateException: region offline: TestTable,0012639235,1204398750147
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:447)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:352)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:314)
	at org.apache.hadoop.hbase.client.HTable.getRegionLocation(HTable.java:109)
	at org.apache.hadoop.hbase.client.HTable$ServerCallable.instantiateServer(HTable.java:992)
	at org.apache.hadoop.hbase.client.HTable.getRegionServerWithRetries(HTable.java:1006)
	... 8 more
{code}
"
HBASE-17384,"From https://builds.apache.org/job/PreCommit-HBASE-Build/5072/testReport/org.apache.hadoop.hbase.regionserver/TestHRegionWithInMemoryFlush/org_apache_hadoop_hbase_regionserver_TestHRegionWithInMemoryFlush/ :
{code}
org.junit.runners.model.TestTimedOutException: test timed out after 10 minutes
	at java.lang.Object.wait(Native Method)
	at org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.waitForRead(MultiVersionConcurrencyControl.java:218)
	at org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.completeAndWait(MultiVersionConcurrencyControl.java:149)
	at org.apache.hadoop.hbase.regionserver.HRegion.getNextSequenceId(HRegion.java:2732)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2447)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2343)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2314)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2304)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1601)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1506)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1456)
	at org.apache.hadoop.hbase.HBaseTestingUtility.closeRegionAndWAL(HBaseTestingUtility.java:374)
	at org.apache.hadoop.hbase.regionserver.TestHRegion.testFlushCacheWhileScanning(TestHRegion.java:3839)
{code}
As can be seen from test output:
{code}
2016-12-28 13:43:28,379 INFO  [Time-limited test] regionserver.HStore(1431): Completed major compaction of 1 (all) file(s) in family1 of testWritesWhileScanning,,1482932605883.2e46061b97a54d7f8434c4a705b3c4a2. into 255e7eb61cfc4945ac5887957d39b1fe(size=98.0 K), total size for store is 98.0 K
...[truncated 4062267 bytes]...
TUCK: MultiVersionConcurrencyControl{readPoint=1090, writePoint=1093}
2016-12-28 13:48:29,396 WARN  [Time-limited test] regionserver.MultiVersionConcurrencyControl(214): STUCK: MultiVersionConcurrencyControl{readPoint=1090, writePoint=1093}
2016-12-28 13:48:30,406 WARN  [Time-limited test] regionserver.MultiVersionConcurrencyControl(214): STUCK: MultiVersionConcurrencyControl{readPoint=1090, writePoint=1093}
2016-12-28 13:48:31,416 WARN  [Time-limited test] regionserver.MultiVersionConcurrencyControl(214): STUCK: MultiVersionConcurrencyControl{readPoint=1090, writePoint=1093}
{code}
At least 5 minutes passed with the above log showing waitForRead() stuck.

Since the flush is blocked, we should consider aborting region server when waitForRead() gets stuck for extended period of time."
HBASE-21379,"聽log as follow:
{code:java}
//浠ｇ爜鍗犱綅绗?
2018-10-24 09:22:42,381 INFO聽 [regionserver/11-3-19-10:16020] wal.AbstractFSWAL: New WAL /hbase/WALs/11-3-19-10.jd.local,16020,1540344155469/11-3-19-10.jd.local%2C16020%2C1540344155469.1540344162124聽 聽 聽 聽 聽鈹?

2018-10-24 09:23:05,151 ERROR [regionserver/11-3-19-10:16020.replicationSource.11-3-19-10.jd.local%2C16020%2C1540344155469,2.replicationSource.wal-reader.11-3-19-10.jd.local%2C16020%2C1540344155469,2] region鈹?
server.ReplicationSource: Unexpected exception in regionserver/11-3-19-10:16020.replicationSource.11-3-19-10.jd.local%2C16020%2C1540344155469,2.replicationSource.wal-reader.11-3-19-10.jd.local%2C16020%2C1540鈹?
344155469,2 currentPath=hdfs://11-3-18-67.JD.LOCAL:9000/hbase/WALs/11-3-19-10.jd.local,16020,1540344155469/11-3-19-10.jd.local%2C16020%2C1540344155469.1540344162124 鈹?
java.lang.ArrayIndexOutOfBoundsException: 8830 鈹?
at org.apache.hadoop.hbase.KeyValue.getFamilyLength(KeyValue.java:1365) 鈹?
at org.apache.hadoop.hbase.KeyValue.getFamilyLength(KeyValue.java:1358) 鈹?
at org.apache.hadoop.hbase.CellUtil.cloneFamily(CellUtil.java:114) 鈹?
at org.apache.hadoop.hbase.replication.ScopeWALEntryFilter.filterCell(ScopeWALEntryFilter.java:54) 鈹?
at org.apache.hadoop.hbase.replication.ChainWALEntryFilter.filterCells(ChainWALEntryFilter.java:90) 鈹?
at org.apache.hadoop.hbase.replication.ChainWALEntryFilter.filter(ChainWALEntryFilter.java:77) 鈹?
at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.filterEntry(ReplicationSourceWALReader.java:234) 鈹?
at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.readWALEntries(ReplicationSourceWALReader.java:170) 鈹?at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.run(ReplicationSourceWALReader.java:133) 鈹?
2018-10-24 09:23:05,153 INFO [regionserver/11-3-19-10:16020.replicationSource.11-3-19-10.jd.local%2C16020%2C1540344155469,2.replicationSource.wal-reader.11-3-19-10.jd.local%2C16020%2C1540344155469,2] region鈹?
server.HRegionServer: ***** STOPPING region server '11-3-19-10.jd.local,16020,1540344155469' *****
{code}
hbase wal -p output
{code:java}
//浠ｇ爜鍗犱綅绗?
writer Classes: ProtobufLogWriter AsyncProtobufLogWriter
Cell Codec Class: org.apache.hadoop.hbase.regionserver.wal.WALCellCodec
Sequence=15 , region=fee7a9465ced6ce9e319d37e9d71c63c at write timestamp=Wed Oct 24 09:22:49 CST 2018
row=80000000, column=METAFAMILY:HBASE::REGION_EVENT
value: \x08\x00\x12\x1Cmlaas:ump_host_second_181029\x1A fee7a9465ced6ce9e319d37e9d71c63c \x0E*\x06\x0A\x01f\x12\x01f2\x1F\x0A\x1311-3-19-10.JD.LOCAL\x10\x94}\x18\xCD\x9A\xAA\x9D\xEA,:Umlaas:ump_host_second_181029,80000000,1540271129253.fee7a9465ced6ce9e319d37e9d71c63c.
Sequence=9 , region=ba6684888d826328a6373435124dc1cd at write timestamp=Wed Oct 24 09:22:49 CST 2018
row=91000000, column=METAFAMILY:HBASE::REGION_EVENT
...
row=34975#00, column=f:\x09,
value: {""tp50"":1,""avg"":2,""min"":0,""tp90"":1,""max"":3,""count"":13,""tp99"":2,""tp999"":2,""error"":0}
row=349824#00, column=f:\x08\xFA
value: {""tp50"":2,""avg"":2,""min"":0,""tp90"":2,""max"":98,""count"":957,""tp99"":3,""tp999"":34,""error"":0}
row=349824#00, column=f:\x08\xD2
value: {""tp50"":2,""avg"":2,""min"":0,""tp90"":2,""max"":43,""count"":1842,""tp99"":2,""tp999"":31,""error"":0}
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 8830
at org.apache.hadoop.hbase.KeyValue.getFamilyLength(KeyValue.java:1365)
at org.apache.hadoop.hbase.KeyValue.getFamilyLength(KeyValue.java:1358)
at org.apache.hadoop.hbase.wal.WALPrettyPrinter.toStringMap(WALPrettyPrinter.java:336)
at org.apache.hadoop.hbase.wal.WALPrettyPrinter.processFile(WALPrettyPrinter.java:290)
at org.apache.hadoop.hbase.wal.WALPrettyPrinter.run(WALPrettyPrinter.java:421)
at org.apache.hadoop.hbase.wal.WALPrettyPrinter.main(WALPrettyPrinter.java:356)
{code}
聽"
HBASE-20671,"Another bug coming out of a master restart and replay of the pv2 logs.

The master merged two regions into one successfully, was restarted, but then ended up assigning the children region back out to the cluster. There is a log message which appears to indicate that RegionStates acknowledges that it doesn't know what this region is as it's replaying the pv2 WAL; however, it incorrectly assumes that the region is just OFFLINE and needs to be assigned.
{noformat}
2018-05-30 04:26:00,055 INFO聽 [RpcServer.default.FPBQ.Fifo.handler=29,queue=2,port=20000] master.HMaster: Client=hrt_qa//172.27.85.11 Merge regions a7dd6606dcacc9daf085fc9fa2aecc0c and 4017a3c778551d4d258c785d455f9c0b
2018-05-30 04:28:27,525 DEBUG [master/ctr-e138-1518143905142-336066-01-000003:20000] procedure2.ProcedureExecutor: Completed pid=4368, state=SUCCESS; MergeTableRegionsProcedure table=tabletwo_merge, regions=[a7dd6606dcacc9daf085fc9fa2aecc0c, 4017a3c778551d4d258c785d455f9c0b], forcibly=false
{noformat}
{noformat}
2018-05-30 04:29:20,263 INFO聽 [master/ctr-e138-1518143905142-336066-01-000003:20000] assignment.AssignmentManager: a7dd6606dcacc9daf085fc9fa2aecc0c regionState=null; presuming OFFLINE
2018-05-30 04:29:20,263 INFO聽 [master/ctr-e138-1518143905142-336066-01-000003:20000] assignment.RegionStates: Added to offline, CURRENTLY NEVER CLEARED!!! rit=OFFLINE, location=null, table=tabletwo_merge, region=a7dd6606dcacc9daf085fc9fa2aecc0c
2018-05-30 04:29:20,266 INFO聽 [master/ctr-e138-1518143905142-336066-01-000003:20000] assignment.AssignmentManager: 4017a3c778551d4d258c785d455f9c0b regionState=null; presuming OFFLINE
2018-05-30 04:29:20,266 INFO聽 [master/ctr-e138-1518143905142-336066-01-000003:20000] assignment.RegionStates: Added to offline, CURRENTLY NEVER CLEARED!!! rit=OFFLINE, location=null, table=tabletwo_merge, region=4017a3c778551d4d258c785d455f9c0b
{noformat}
Eventually, the RS reports in its online regions, and the master tells it to kill itself:
{noformat}
2018-05-30 04:29:24,272 WARN聽 [RpcServer.default.FPBQ.Fifo.handler=26,queue=2,port=20000] assignment.AssignmentManager: Killing ctr-e138-1518143905142-336066-01-000002.hwx.site,16020,1527654546619: Not online: tabletwo_merge,,1527652130538.a7dd6606dcacc9daf085fc9fa2aecc0c.
{noformat}"
HBASE-7044,"at the beginning there is 1 whole hbase cluster, then I decide to split is into 2 cluster, one is for offline mining, one is for online service, and the online one is striped, the offline one contains the original master.
unfortunately, the META of the original cluster is assigned to the machine stripped, and as there is a cache policy for META, the offline cluster is still access the META of the stripped one.
after inspected the code, I found that in verifyRegionLocation of CatalogTracker.java, although it checks if the region server still contains the region, but it didn't check if the regions erver is still in the cluster which is very easy, just inspect if it is registered int zk.
all in all, I have to shutdown the online cluster and restart the offline one, then the META is re-assgined. then everything is back to normal."
HBASE-7959,"While lots of region splits going on, HBCK incorrectly reports inconsistencies since it skips recently modified, but does not take those into account for computing the region chain. 

{code}
13/02/28 03:33:16 WARN util.HBaseFsck: Region { meta => cluster_test,,1362021481742.69639761fdf693ab1e2bf33f523cd1ae., hdfs => NN:8020/apps/hbase-trunk/data/cluster_test/69639761fdf693ab1e2bf33f523cd1ae, deployed =>  } was recently modified -- skipping
13/02/28 03:33:16 DEBUG util.HBaseFsck: There are 23 region info entries
ERROR: (region cluster_test,0ccccccc,1362021481742.ec3ba583b4ea01393591572bf1f31e07.) First region should start with an empty key.  You need to  create a new region and regioninfo in HDFS to plug the hole.
ERROR: Found inconsistency in table cluster_test
Summary:
  -ROOT- is okay.
    Number of regions: 1
    Deployed on:  RSs
  .META. is okay.
    Number of regions: 1
    Deployed on:  RSs
Table cluster_test is inconsistent.
    Number of regions: 19
    Deployed on:  RSs
1 inconsistencies detected.
Status: INCONSISTENT

{code}"
HBASE-6184,"insert data

hadoop-0.23.2 + hbase-0.94.0

2012-06-07 13:09:38,573 WARN  [org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation] Encountered problems when prefetch META table: 
java.io.IOException: HRegionInfo was null or empty in Meta for hbase_one_col, row=hbase_one_col,09115303780247449149,99999999999999
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:160)
        at org.apache.hadoop.hbase.client.MetaScanner.access$000(MetaScanner.java:48)
        at org.apache.hadoop.hbase.client.MetaScanner$1.connect(MetaScanner.java:126)
        at org.apache.hadoop.hbase.client.MetaScanner$1.connect(MetaScanner.java:123)
        at org.apache.hadoop.hbase.client.HConnectionManager.execute(HConnectionManager.java:359)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:123)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:99)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:894)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:948)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:836)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:1482)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1367)
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:945)
        at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:801)
        at org.apache.hadoop.hbase.client.HTable.put(HTable.java:776)
        at org.apache.hadoop.hbase.client.HTablePool$PooledHTable.put(HTablePool.java:397)
        at com.dinglicom.hbase.HbaseImport.insertData(HbaseImport.java:177)
        at com.dinglicom.hbase.HbaseImport.run(HbaseImport.java:210)
        at java.lang.Thread.run(Thread.java:662)"
HBASE-16674,"This test shows up on flaky dashboard here:
https://builds.apache.org/job/HBASE-Find-Flaky-Tests/lastSuccessfulBuild/artifact/dashboard.html

{code}
java.lang.AssertionError: expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.hadoop.hbase.regionserver.wal.TestAsyncLogRolling.testLogRollOnDatanodeDeath(TestAsyncLogRolling.java:63)
{code}
"
HBASE-10710,"This case ever failed in last month for HBASE-10648 / HBASE-10615 / HBASE-9990 / HBASE-10582 / HBASE-10527 / HBASE-10575 / HBASE-10570 / HBASE-10532 / HBASE-10537 / HBASE-10534 / HBASE-6642 / HBASE-3909 / HBASE-10169 and so on and on..., but seems it can't reproduce in local run.

This issue is created for any further tracking."
HBASE-9712,"Opening this issue to keep account of failures.  It failed for me locally just now.

Failed tests:   testTaskResigned(org.apache.hadoop.hbase.master.TestSplitLogManager): version1=2, version=2

{code}
durruti:hbase stack$ more hbase-server/target/surefire-reports/org.apache.hadoop.hbase.master.TestSplitLogManager.txt
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.hbase.master.TestSplitLogManager
-------------------------------------------------------------------------------
Tests run: 14, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 86.697 sec <<< FAILURE!
testTaskResigned(org.apache.hadoop.hbase.master.TestSplitLogManager)  Time elapsed: 0.004 sec  <<< FAILURE!
java.lang.AssertionError: version1=2, version=2
        at org.junit.Assert.fail(Assert.java:88)
        at org.junit.Assert.assertTrue(Assert.java:41)
        at org.apache.hadoop.hbase.master.TestSplitLogManager.testTaskResigned(TestSplitLogManager.java:387)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.junit.runners.Suite.runChild(Suite.java:127)
        at org.junit.runners.Suite.runChild(Suite.java:26)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
        at java.lang.Thread.run(Thread.java:680)
{code}

Let me attach the log"
HBASE-9014,"http://54.241.6.143/job/HBase-0.95/665/org.apache.hbase$hbase-server/testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLog/testAppendClose/

{code}
Error Message

Problem binding to localhost/127.0.0.1:37036 : Address already in use
Stacktrace

java.net.BindException: Problem binding to localhost/127.0.0.1:37036 : Address already in use
	at org.apache.hadoop.ipc.Server.bind(Server.java:228)
	at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:302)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1488)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:560)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:521)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:536)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1410)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSClusterForTestHLog(HBaseTestingUtility.java:525)
...
{code}


This testAppendClose stops hdfs and starts it again.  It looks problematic.  Has waits of 7 seconds for the hdfs cluster to go down but in this test it seems like it needs even more time."
HBASE-8999,"[~sershe] Is this your test boss?  Mind taking a looksee.  Here is the fail:

https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/624/consoleFull

Go to the end for the stack trace.

Otherwise I'll just disable for now.  Thanks."
HBASE-8922,"Started today as far as I can tell.  Doesn't always happen.  Looking at it, we are splitting region not where we are supposed to -- at the 1/4 mark rather than 1/2 mark which then throws off all calculations.  Let me commit some debug to help elicit where we are going wrong.  Here is a sample:

https://builds.apache.org/job/PreCommit-HBASE-Build/6294//testReport/org.apache.hadoop.hbase.client/TestAdmin/testForceSplitMultiFamily/"
HBASE-7896,"The rename_table function is very useful for our customers. However, rename_table.rb does not work for 92/94. It has several bugs. It will be useful to fix them so that users can solve their problems. "
HBASE-14707,"See this in branch-1 tip:

{code}
2015-10-27 08:01:08,954 INFO  [main-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/e1101.halxg.cloudera.com,16020,1445958006576 znode expired, triggering replicatorRemoved event
2015-10-27 08:01:20,645 ERROR [685943200@qtp-893835279-134] util.JSONBean: getting attribute Value of ""org.apache.hadoop.hbase.client"":type=""MetricsConnection"",scope=""hconnection-0x33abd9d3"",name=""executorPoolActiveThreads"" threw an exception
javax.management.RuntimeMBeanException: java.lang.NullPointerException
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:839)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:852)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:651)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)
        at org.apache.hadoop.hbase.util.JSONBean.writeAttribute(JSONBean.java:235)
        at org.apache.hadoop.hbase.util.JSONBean.write(JSONBean.java:209)
        at org.apache.hadoop.hbase.util.JSONBean.access$000(JSONBean.java:53)
        at org.apache.hadoop.hbase.util.JSONBean$1.write(JSONBean.java:96)
        at org.apache.hadoop.hbase.http.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:202)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:113)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.ClickjackingPreventionFilter.doFilter(ClickjackingPreventionFilter.java:48)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1354)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:49)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:49)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Caused by: java.lang.NullPointerException
{code}

TSDB is trying to get metrics on a period"
HBASE-21193,"This makes it hard to change retry count on a read of meta for instance.

I noticed this when trying to change the defaults for a meta read. I made a customer Connection inside in the master with a new Configuration that had rpc retries and timings upped radically. My reads nonetheless were finishing at the usual retry point (31 tries after 60 seconds or so) because it looked like the Retrying Callable that does the read was taking  max retries from defaults rather than reading the passed in Configuration."
HBASE-18910,HBASE-18900 will backport HBASE-17290 to branch-1.3.But  HBASE-17290 is dependent on HBASE-17292.so this issue will backport HBASE-17292 to branch-1.3.
HBASE-14163,It would appear that there is an infinite loop in the zk client connection code when performing a master stop when no external zk servers are configured.
HBASE-21109,"HBASE won't start and gives a Java error when I try in Java 9 but seems to start in Java 8

The error is:

~/Downloads/hbase-2.1.0$ export JAVA_HOME=/usr
~/Downloads/hbase-2.1.0$ bin/start-hbase.sh script
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
 at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
 at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/JarFile.java:1017)
 at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.java:399)
 at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
 at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:480)
 at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIndex.java:114)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:640)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:632)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.URLClassPath$JarLoader.ensureOpen(java.base@9-internal/URLClassPath.java:631)
 at jdk.internal.loader.URLClassPath$JarLoader.<init>(java.base@9-internal/URLClassPath.java:606)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassPath.java:386)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassPath.java:376)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLClassPath.java:375)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLClassPath.java:352)
 at jdk.internal.loader.URLClassPath.getResource(java.base@9-internal/URLClassPath.java:218)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/BuiltinClassLoader.java:463)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/BuiltinClassLoader.java:460)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(java.base@9-internal/BuiltinClassLoader.java:459)
 at jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(java.base@9-internal/BuiltinClassLoader.java:406)
 at jdk.internal.loader.BuiltinClassLoader.loadClass(java.base@9-internal/BuiltinClassLoader.java:364)
 at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(java.base@9-internal/ClassLoaders.java:184)
 at java.lang.ClassLoader.loadClass(java.base@9-internal/ClassLoader.java:419)
 at sun.launcher.LauncherHelper.loadMainClass(java.base@9-internal/LauncherHelper.java:585)
 at sun.launcher.LauncherHelper.checkAndLoadMain(java.base@9-internal/LauncherHelper.java:497)
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
 at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
 at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/JarFile.java:1017)
 at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.java:399)
 at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
 at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:480)
 at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIndex.java:114)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:640)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:632)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.URLClassPath$JarLoader.ensureOpen(java.base@9-internal/URLClassPath.java:631)
 at jdk.internal.loader.URLClassPath$JarLoader.<init>(java.base@9-internal/URLClassPath.java:606)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassPath.java:386)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassPath.java:376)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLClassPath.java:375)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLClassPath.java:352)
 at jdk.internal.loader.URLClassPath.getResource(java.base@9-internal/URLClassPath.java:218)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/BuiltinClassLoader.java:463)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/BuiltinClassLoader.java:460)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(java.base@9-internal/BuiltinClassLoader.java:459)
 at jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(java.base@9-internal/BuiltinClassLoader.java:406)
 at jdk.internal.loader.BuiltinClassLoader.loadClass(java.base@9-internal/BuiltinClassLoader.java:364)
 at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(java.base@9-internal/ClassLoaders.java:184)
 at java.lang.ClassLoader.loadClass(java.base@9-internal/ClassLoader.java:419)
 at sun.launcher.LauncherHelper.loadMainClass(java.base@9-internal/LauncherHelper.java:585)
 at sun.launcher.LauncherHelper.checkAndLoadMain(java.base@9-internal/LauncherHelper.java:497)
running master, logging to /opr/Downloads/hbase-2.1.0/bin/../logs/hbase-opr-master-nagios.out
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
 at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
 at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/JarFile.java:1017)
 at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.java:399)
 at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
 at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:480)
 at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIndex.java:114)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:640)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:632)
: running regionserver, logging to /opr/Downloads/hbase-2.1.0/bin/../logs/hbase-opr-regionserver-nagios.out
: Error: A JNI error has occurred, please check your installation and try again
: Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
: at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
: at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/JarFile.java:1017)
: at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.java:399)
: at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
: at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:480)
: at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIndex.java:114)
: at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:640)
: at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:632)
opr@nagios:~/Downloads/hbase-2.1.0$ more /opr/Downloads/hbase-2.1.0/bin/../logs/hbase-opr-regionserver-nagios.out
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
 at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
 at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/
JarFile.java:1017)
 at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.jav
a:399)
 at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
 at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:4
80)
 at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIn
dex.java:114)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal
/URLClassPath.java:640)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal
/URLClassPath.java:632)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Nati
ve Method)
 at jdk.internal.loader.URLClassPath$JarLoader.ensureOpen(java.base@9-int
ernal/URLClassPath.java:631)
 at jdk.internal.loader.URLClassPath$JarLoader.<init>(java.base@9-interna
l/URLClassPath.java:606)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassP
ath.java:386)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassP
ath.java:376)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Nati
ve Method)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLCl
assPath.java:375)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLCl
assPath.java:352)
 at jdk.internal.loader.URLClassPath.getResource(java.base@9-internal/URL
ClassPath.java:218)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/Bui
ltinClassLoader.java:463)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/Bui
ltinClassLoader.java:460)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Nati
ve Method)
 at jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(jav
a.base@9-internal/BuiltinClassLoader.java:459)
 at jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(java.base@9-in
ternal/BuiltinClassLoader.java:406)
 at jdk.internal.loader.BuiltinClassLoader.loadClass(java.base@9-internal
/BuiltinClassLoader.java:364)
 at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(java.base@9
-internal/ClassLoaders.java:184)
 at java.lang.ClassLoader.loadClass(java.base@9-internal/ClassLoader.java
:419)
 at sun.launcher.LauncherHelper.loadMainClass(java.base@9-internal/Launch
erHelper.java:585)
 at sun.launcher.LauncherHelper.checkAndLoadMain(java.base@9-internal/Lau
ncherHelper.java:497)"
HBASE-16374,"While testing the 0.98.21 RC found these failures
{code}
IntegrationTestIngestWithACL
IntegrationTestMTTR.testKillRsHoldingMeta
IntegrationTestMTTR.testRestartRsHoldingTable
{code}
The first one was a failure and the last 2 are errors.
{code}
java.util.concurrent.ExecutionException: java.io.IOException: did timeout 60000ms waiting for region server to start: stobdtserver5
        at java.util.concurrent.FutureTask.report(FutureTask.java:122)
        at java.util.concurrent.FutureTask.get(FutureTask.java:192)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.run(IntegrationTestMTTR.java:317)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.testKillRsHoldingMeta(IntegrationTestMTTR.java:276)
Caused by: java.io.IOException: did timeout 60000ms waiting for region server to start: stobdtserver5
        at org.apache.hadoop.hbase.HBaseCluster.waitForRegionServerToStart(HBaseCluster.java:173)
        at org.apache.hadoop.hbase.chaos.actions.Action.startRs(Action.java:142)
        at org.apache.hadoop.hbase.chaos.actions.RestartActionBaseAction.restartRs(RestartActionBaseAction.java:52)
        at org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingMetaAction.perform(RestartRsHoldingMetaAction.java:38)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR$ActionCallable.call(IntegrationTestMTTR.java:585)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR$ActionCallable.call(IntegrationTestMTTR.java:576)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

testRestartRsHoldingTable(org.apache.hadoop.hbase.mttr.IntegrationTestMTTR)  Time elapsed: 120.533 sec  <<< ERROR!
java.util.concurrent.ExecutionException: java.io.IOException: did timeout 60000ms waiting for region server to start: stobdtserver5
        at java.util.concurrent.FutureTask.report(FutureTask.java:122)
        at java.util.concurrent.FutureTask.get(FutureTask.java:192)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.run(IntegrationTestMTTR.java:317)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.testRestartRsHoldingTable(IntegrationTestMTTR.java:271)
Caused by: java.io.IOException: did timeout 60000ms waiting for region server to start: stobdtserver5
        at org.apache.hadoop.hbase.HBaseCluster.waitForRegionServerToStart(HBaseCluster.java:173)
        at org.apache.hadoop.hbase.chaos.actions.Action.startRs(Action.java:142)
        at org.apache.hadoop.hbase.chaos.actions.RestartActionBaseAction.restartRs(RestartActionBaseAction.java:52)
        at org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingTableAction.perform(RestartRsHoldingTableAction.java:56)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR$ActionCallable.call(IntegrationTestMTTR.java:585)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR$ActionCallable.call(IntegrationTestMTTR.java:576)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{code}"
HBASE-18353,"HBASE-14614 disabled TestCorruptedRegionStoreFile, as it depends on a half-implemented reopen of a region when a store file goes missing.

This JIRA tracks the work to fix/enable the test."
HBASE-20872,"running
{code:java}
mvn clean test{code}
on hbase-spark fails with
{code:java}
Cause: java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMasterUncompilable source code - package org.apache.hbase.thirdparty.io.netty.channel does not exist
at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:136)
at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:212)
at org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:159)
at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:250)
at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:121)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1042)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:988)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:859)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:853)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:782)
...
Cause: java.lang.ExceptionInInitializerError:
at org.apache.hadoop.hbase.regionserver.HRegionServer.setupNetty(HRegionServer.java:688)
at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:547)
at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:486)
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:131)
at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:212)
at org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:159)
...
Cause: java.lang.RuntimeException: Uncompilable source code - package org.apache.hbase.thirdparty.io.netty.channel does not exist
at org.apache.hadoop.hbase.util.NettyEventLoopGroupConfig.<clinit>(NettyEventLoopGroupConfig.java:20)
at org.apache.hadoop.hbase.regionserver.HRegionServer.setupNetty(HRegionServer.java:688)
at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:547)
at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:486)
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:131)
at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:212){code}"
HBASE-19169,"I got the following error running rowcounter against hadoop3 beta1 based on commit a9f0c5d4e2c85c1faae1b4b277e3c290c8b81d2a :
{code}
2017-11-03 17:10:59,583 INFO  [main] mapreduce.Job: Task Id : attempt_1509641483571_0006_m_000029_1, Status : FAILED
Error: java.lang.ArrayIndexOutOfBoundsException: 2
	at org.apache.hadoop.hbase.mapreduce.TableSplit$Version.fromCode(TableSplit.java:77)
	at org.apache.hadoop.hbase.mapreduce.TableSplit.readFields(TableSplit.java:285)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:71)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:372)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:760)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
{code}"
HBASE-18296,"Saw this in logs while debugging other failing tests:

{noformat}
2017-06-29 13:54:15,995 ERROR [M:0;172.18.16.40:55484] server.NIOServerCnxnFactory$1(44): Thread Thread[M:0;172.18.16.40:55484,5,FailOnTimeoutGroup] died
java.lang.NullPointerException
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.removeChore(ProcedureExecutor.java:656)
	at org.apache.hadoop.hbase.master.assignment.AssignmentManager.stop(AssignmentManager.java:233)
	at org.apache.hadoop.hbase.master.HMaster.stopServiceThreads(HMaster.java:1154)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1189)
	at java.lang.Thread.run(Thread.java:748)
{noformat}

I think it was related to an initialization failure, but we should code more defensively anyway"
HBASE-17996,"Impala includes HBase in its local test environment, and we have found that intermittently, the HBase master node fails to start when we are testing on RHEL7.

In these failures, what we typically see in the logs is this:
{noformat}
17/04/29 21:33:47 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x15bbd21b797000a, negotiated timeout = 90000
17/04/29 21:33:47 INFO client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
17/04/29 21:33:48 INFO master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/localhost,16000,1493526758211 from backup master directory
{noformat}

On a successful startup, the log looks like this:
{noformat}
17/04/16 21:32:29 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x15b7a2ed6860005, negotiated timeout = 90000
17/04/16 21:32:29 INFO client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
17/04/16 21:32:30 INFO util.FSUtils: Created version file at hdfs://localhost:20500/hbase with version=8
17/04/16 21:32:31 INFO master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
{noformat}

So the event that we don't see in the failed start up attempts is {{master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region}}.

The full logs will be attached."
HBASE-19076,"After HBASE-16321 ensure findbugs jsr305 jar isn't present, we have failures with the hbase-error-prone module.

{code}
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (min-maven-min-java-banned-xerces) @ hbase-error-prone ---
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (banned-jsr305) @ hbase-error-prone ---
[WARNING] Rule 0: org.apache.maven.plugins.enforcer.BannedDependencies failed with message:
We don't allow the JSR305 jar from the Findbugs project, see HBASE-16321.
Found Banned Dependency: com.google.code.findbugs:jsr305:jar:1.3.9
Use 'mvn dependency:tree' to locate the source of the banned dependencies.
{code}"
HBASE-18345,"Incorrect mocking, easy fix

Tests run: 7, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 67.898 sec <<< FAILURE! - in org.apache.hadoop.hbase.tool.TestCanaryTool
testReadTableTimeouts(org.apache.hadoop.hbase.tool.TestCanaryTool)  Time elapsed: 11.727 sec  <<< FAILURE!
org.mockito.exceptions.verification.junit.ArgumentsAreDifferent: 
Argument(s) are different! Wanted:
mockAppender.doAppend(
    <custom argument matcher>
);
-> at org.apache.hadoop.hbase.tool.TestCanaryTool.testReadTableTimeouts(TestCanaryTool.java:150)
Actual invocation has different arguments:
mockAppender.doAppend(
    org.apache.log4j.spi.LoggingEvent@7ed49a7f
);
-> at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.hbase.tool.TestCanaryTool.testReadTableTimeouts(TestCanaryTool.java:150)
"
HBASE-19971,"From https://builds.apache.org/job/HBASE-Flaky-Tests/25784/testReport/junit/org.apache.hadoop.hbase.regionserver/TestMajorCompaction/testDataBlockEncodingInCacheOnly_2_/ :
{code}
java.io.IOException: java.lang.IllegalArgumentException: In CellChunkMap, cell must be associated with chunk.. We were looking for a cell at index 0
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.majorCompaction(TestMajorCompaction.java:206)
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.majorCompactionWithDataBlockEncoding(TestMajorCompaction.java:186)
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.testDataBlockEncodingInCacheOnly(TestMajorCompaction.java:166)
Caused by: java.lang.IllegalArgumentException: In CellChunkMap, cell must be associated with chunk.. We were looking for a cell at index 0
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.majorCompaction(TestMajorCompaction.java:206)
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.majorCompactionWithDataBlockEncoding(TestMajorCompaction.java:186)
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.testDataBlockEncodingInCacheOnly(TestMajorCompaction.java:166)
{code}
From the index of the test, EAGER policy was used."
HBASE-18900,"HBASE-17290 fixes data loss bug.

Bulk loaded hfile replication support is in branch-1.3

This issue is to backport HBASE-17290 to branch-1.3"
HBASE-19347,"In the download hbase-1.1.12-src.tar.gz the directory hbase-native-client is missing. 


"
HBASE-19824,"There are two cells in table t1:
{code}
ROW                                                         COLUMN+CELL
 r1                                                         column=f1:a1, timestamp=1516313683984, value=a2
 r1                                                         column=f1:b1, timestamp=1516313700744, value=b2
{code}
When SingleColumnValueFilter is used in shell command, no filtering was done:
{code}
hbase(main):022:0> scan 't1', {FILTER => ""SingleColumnValueFilter('f1', 'a1', =, 'binary:a2')""}
ROW                                                         COLUMN+CELL
 r1                                                         column=f1:a1, timestamp=1516313683984, value=a2
 r1                                                         column=f1:b1, timestamp=1516313700744, value=b2
{code}"
HBASE-18712,"Add -X in dev-support/hbase-personality.sh for precommit unit tests so that we have more information when ""The forked VM terminated without saying properly goodbye"" happens again.

The following (initial proposal) doesn't apply to jdk 1.8 and has limited benefit:

Currently hbase-surefire.argLine doesn't specify MaxPermSize for the test run(s).

This sometimes resulted in mvn build prematurely exiting, leaving some large tests behind.
The tests would be deemed timed out.

As indicated by the following post:

https://stackoverflow.com/questions/23260057/the-forked-vm-terminated-without-saying-properly-goodbye-vm-crash-or-system-exi

We should specify large enough MaxPermSize so that mvn build doesn't end prematurely."
HBASE-20005,"By adding message for the assertions, the test failed at:
{code}
     ok = table.checkAndMutate(ROW, FAMILY).qualifier(QUALIFIER)
         .ifMatches(CompareOperator.GREATER, value4).thenDelete(delete);
-    assertTrue(ok);
+    assertTrue(""gr"", ok);
{code}
I ran the test with MemoryCompactionPolicy.NONE but it still failed at the same place.

Both branch-2 and master have this intermittent test failure."
HBASE-20137,"It was the single test that failed the hbase-2 nightlies in #440 at the hadoop2 stage.

The failure manifests as a timeout. It actually has an interesting cause calling into question some of the clauses in UnassignProcedure#remoteCallFailed.

We are running a disabletable concurrent with a shutdown. pid=309 is the disable. pid=311 is the interesting one. The below is a little hard to read -- the exception 'message' is the the current procedure as a String... hard to parse, fixing -- but we are trying to unassign as part of a the disabletable. Our RPC fails because the server we are trying to rpc too is currently being processed as crashed (pid=308 is a servercrashprocedure for this server). As part of the processing of the failed RPC we will expire the server -- if we can't RPC to it, it must be gone. The current procedure is then suspended until it gets woken up by the servercrashprocedure triggered by the expire.... only in this case we are shutting down so the expire is ignored... The current procedure is left in its suspend state. This prevents the Master going down. So we time out.

2018-03-05 11:29:22,507 INFO  [PEWorker-13] assignment.RegionTransitionProcedure(213): Dispatch pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524; rit=CLOSING, location=1cfd208ff882,40584,1520249102524
2018-03-05 11:29:22,508 WARN  [PEWorker-13] assignment.RegionTransitionProcedure(187): Remote call failed pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524; rit=CLOSING, location=1cfd208ff882,40584,1520249102524; exception=pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524 to 1cfd208ff882,40584,1520249102524
2018-03-05 11:29:22,508 WARN  [PEWorker-13] assignment.UnassignProcedure(276): Expiring server pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524; rit=CLOSING, location=1cfd208ff882,40584,1520249102524, exception=org.apache.hadoop.hbase.master.assignment.FailedRemoteDispatchException: pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524 to 1cfd208ff882,40584,1520249102524
2018-03-05 11:29:22,508 WARN  [PEWorker-13] master.ServerManager(580): Expiration of 1cfd208ff882,40584,1520249102524 but server shutdown already in progress

I need to cater for case where the expire server is rejected.

"
HBASE-19733,"Currently build is failing (https://builds.apache.org/job/HBase-TRUNK_matrix/4363/jdk=JDK%201.8%20(latest),label=(Hadoop%20&&%20!H5)/console) due to:
{code}
[ERROR] src/main/java/org/apache/hadoop/hbase/thrift/TBoundedThreadPoolServer.java:[291,78] (blocks) EmptyBlock: Must have at least one statement.
...
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:2.17:check (checkstyle) on project hbase-thrift: You have 1 Checkstyle violation. -> [Help 1]
{code}"
HBASE-13405,"Once in a while I'm seeing the following, running #testContainedRegionOverlap test in IDE after clean install (mac osx, hbase master):

{code}
regionserver.HRegionServer(1863): Post open deploy tasks for tableContainedRegionOverlap,A,1428099123733.03a139b02119e99ef08149addd9a7996.
2015-04-03 15:12:11,695 INFO  [PostOpenDeployTasks:03a139b02119e99ef08149addd9a7996] regionserver.HRegionServer(1956): Failed to report region transition, will retry
java.io.InterruptedIOException: Origin: InterruptedException
	at org.apache.hadoop.hbase.util.ExceptionUtil.asInterrupt(ExceptionUtil.java:65)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:313)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(HRegionServer.java:1955)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1882)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:241)
Caused by: java.lang.InterruptedException: callId: 158 methodName: ReportRegionStateTransition param {TODO: class org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$ReportRegionStateTransitionRequest}
	at io.netty.util.concurrent.DefaultPromise.await0(DefaultPromise.java:333)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:266)
	at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:42)
	at org.apache.hadoop.hbase.ipc.AsyncRpcClient.call(AsyncRpcClient.java:226)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.reportRegionStateTransition(RegionServerStatusProtos.java:9030)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(HRegionServer.java:1946)
	... 2 more
2015-04-03 15:12:11,696 INFO  [B.defaultRpcServer.handler=1,queue=0,port=51217] master.MasterRpcServices(237): Client=mantonov//10.1.4.219 set balanceSwitch=false
2015-04-03 15:12:11,696 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(388): maste
{code}

and then: 
{code}
015-04-03 15:12:11,796 INFO  [Thread-3019] client.HBaseAdmin$10(981): Started disable of tableContainedRegionOverlap
2015-04-03 15:12:21,641 INFO  [B.defaultRpcServer.handler=1,queue=0,port=51217] master.HMaster(1645): Client=mantonov//10.1.4.219 disable tableContainedRegionOverlap

java.lang.AssertionError: 
Expected :[]
Actual   :[NOT_DEPLOYED, HOLE_IN_REGION_CHAIN]
 <Click to see difference>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.assertNoErrors(HbckTestingUtil.java:92)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testContainedRegionOverlap(TestHBaseFsck.java:941)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}"
HBASE-13862,"I can reproduce it by running mvn test -Dtest=TestRegionRebalancing on fresh master about 1 out of 3-4 runs.

{code}
unning org.apache.hadoop.hbase.TestRegionRebalancing
2015-06-08 12:00:52.125 java[45610:5873722] Unable to load realm info from SCDynamicStore
Tests run: 2, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 26.743 sec <<< FAILURE! - in org.apache.hadoop.hbase.TestRegionRebalancing
testRebalanceOnRegionServerNumberChange[0](org.apache.hadoop.hbase.TestRegionRebalancing)  Time elapsed: 15.599 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.apache.hadoop.hbase.TestRegionRebalancing.testRebalanceOnRegionServerNumberChange(TestRegionRebalancing.java:144)

testRebalanceOnRegionServerNumberChange[1](org.apache.hadoop.hbase.TestRegionRebalancing)  Time elapsed: 10.671 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.apache.hadoop.hbase.TestRegionRebalancing.testRebalanceOnRegionServerNumberChange(TestRegionRebalancing.java:144)


Results :

Failed tests:
  TestRegionRebalancing.testRebalanceOnRegionServerNumberChange:144 null
  TestRegionRebalancing.testRebalanceOnRegionServerNumberChange:144 null

{code}"
HBASE-14335,"TestAssignmentManagerOnCluster#testSSHWhenDisablingTableRegionsInOpeningOrPendingOpenState is occasionally timing out when cleaning up after a test. Depends on environment. Given the right timing we get a timeout. One one test host, fails with 7u79. On another, passes with 7u79, fails with 8u45.

{noformat}
Running org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster
Tests run: 17, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 85.924 sec <<< 
FAILURE! - in org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster
testSSHWhenDisablingTableRegionsInOpeningOrPendingOpenState(org.apache.hadoop.hb
ase.master.TestAssignmentManagerOnCluster)  Time elapsed: 60.036 sec  <<< ERROR!
java.lang.Exception: test timed out after 60000 milliseconds
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hbase.client.HBaseAdmin.deleteTable(HBaseAdmin.java
:724)
        at org.apache.hadoop.hbase.HBaseTestingUtility.deleteTable(HBaseTestingU
tility.java:1581)
        at org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.testSSH
WhenDisablingTableRegionsInOpeningOrPendingOpenState(TestAssignmentManagerOnClus
ter.java:676)
{noformat}"
HBASE-13887,"The build instructions in the online manual do not describe the extra steps we need to take to build 0.98. Add a section on this.

A quick enumeration of the differences:

1. Source assemblies will be missing the hbase-hadoop1-compat module. This should be fixed in the POM somehow. What I do now is untar the src tarball, cp -a the module over, then tar up the result. (It's a hack in a release script.)

2. We must munge POMs for building hadoop1 and hadoop2 variants and then execute two builds pointing Maven at each munged POM. The generate-hadoop-X-poms script requires bash
{noformat}
$ bash dev-support/generate-hadoopX-poms.sh $version $version-hadoop1
$ bash dev-support/generate-hadoopX-poms.sh $version $version-hadoop2
{noformat}
Build Hadoop 1
{noformat}
  $ mvn -f pom.xml.hadoop1 clean install -DskipTests -Prelease && \
      mvn -f pom.xml.hadoop1 install -DskipTests site assembly:single \
        -Prelease && \
      mvn -f pom.xml.hadoop1 deploy -DskipTests -Papache-release
  $ cp hbase-assembly/target/hbase*-bin.tar.gz $release_dir
{noformat}
Build Hadoop 2
{noformat}
  $ mvn -f pom.xml.hadoop2 clean install -DskipTests -Prelease && \
      mvn -f pom.xml.hadoop2 install -DskipTests site assembly:single \
        -Prelease && \
      mvn -f pom.xml.hadoop2 deploy -DskipTests -Papache-release
  $ cp hbase-assembly/target/hbase*-bin.tar.gz $release_dir
{noformat}

3. Current HEAD of 0.98 branch enforces a requirement that the release be built with a JDK no more recent than the compile language level. For 0.98, that is 1.6, therefore the ancient 6u45 JDK. This JDK suffers from [JDK-6521495|http://bugs.java.com/bugdatabase/view_bug.do?bug_id=6521495] so the following workaround is required in order to deploy artifacts to Apache's Nexus:
3.a. Download https://www.bouncycastle.org/download/bcprov-jdk15on-152.jar and https://www.bouncycastle.org/download/bcprov-ext-jdk15on-152.jar into $JAVA_HOME/lib/ext.
3.b. Edit $JAVA_HOME/lib/security/java.security and add the BouncyCastle provider as the first provider: 
{noformat}
security.provider.1=org.bouncycastle.jce.provider.BouncyCastleProvider
{noformat}

"
HBASE-16795,"I did a naive update of docs on branch-1.1 from master like so:
{noformat}
$ git co master src
...
{noformat}
and the result failed a RAT check. Looking at rat.txt I noticed we are including binaries in our source tarball, checked in as part of HBASE-14785. 
{noformat}
HBASE-14785 Addendum: Add an in-project Maven repo

 src/main/site/resources/css/site.css                             |   1 -
 .../maven-fluido-skin/1.5-HBASE/maven-fluido-skin-1.5-HBASE.jar  | Bin 0 -> 344936 bytes
 .../maven-fluido-skin/1.5-HBASE/maven-fluido-skin-1.5-HBASE.pom  | 718 ++++++++++++++++++++++++++++
 .../maven/skins/maven-fluido-skin/maven-metadata-local.xml       |  12 +
 4 files changed, 730 insertions(+), 1 deletion(-)
{noformat}
I'm not sure why RAT flagged this in that 1.1 build when I see that previously we have copied back docs from master into the branch. Perhaps previous copies have been more selective. 

This change has been committed for over a year. Let's make sure we have discussed this and determined it is appropriate. "
HBASE-14341,"if you build a source assembly according to the book:

{quote}
mvn clean install -DskipTests assembly:single -Dassembly.file=hbase-assembly/src/main/assembly/src.xml -Prelease
{quote}

Then the resultant artifact has an extra set of the shaded modules at the top level (in addition to the ones in the hbase-shaded module)

{code}
$ ls -lah hbase-1.1.2/
total 608
drwxr-xr-x  32 busbey  staff   1.1K Aug 30 17:14 .
drwxr-xr-x   3 busbey  staff   102B Aug 30 17:14 ..
-rw-r--r--   1 busbey  staff   162K Aug 30 16:42 CHANGES.txt
-rw-r--r--   1 busbey  staff    36K Aug 30 16:15 LICENSE.txt
-rw-r--r--   1 busbey  staff   1.5K Aug 30 16:15 NOTICE.txt
-rw-r--r--   1 busbey  staff   1.4K Aug 30 16:15 README.txt
drwxr-xr-x  31 busbey  staff   1.0K Aug 30 16:42 bin
drwxr-xr-x   9 busbey  staff   306B Aug 30 16:42 conf
drwxr-xr-x  24 busbey  staff   816B Aug 30 16:42 dev-support
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-annotations
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:58 hbase-assembly
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-checkstyle
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-client
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-common
drwxr-xr-x   5 busbey  staff   170B Aug 30 16:58 hbase-examples
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-hadoop-compat
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-hadoop2-compat
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:58 hbase-it
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-prefix-tree
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-procedure
drwxr-xr-x   5 busbey  staff   170B Aug 30 16:56 hbase-protocol
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-resource-bundle
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-rest
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-server
drwxr-xr-x   5 busbey  staff   170B Aug 30 16:42 hbase-shaded
drwxr-xr-x   3 busbey  staff   102B Aug 30 16:42 hbase-shaded-client
drwxr-xr-x   3 busbey  staff   102B Aug 30 16:42 hbase-shaded-server
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:58 hbase-shell
drwxr-xr-x   3 busbey  staff   102B Aug 30 16:57 hbase-testing-util
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-thrift
-rw-r--r--   1 busbey  staff    94K Aug 30 16:42 pom.xml
drwxr-xr-x   3 busbey  staff   102B Aug 30 16:15 src
$ diff -r hbase-1.1.2/hbase-shaded-client hbase-1.1.2/hbase-shaded/hbase-shaded-client
Only in hbase-1.1.2/hbase-shaded/hbase-shaded-client: target
$ diff -r hbase-1.1.2/hbase-shaded-server hbase-1.1.2/hbase-shaded/hbase-shaded-server
Only in hbase-1.1.2/hbase-shaded/hbase-shaded-server: target
{code}

they're the same as the correct ones and they don't build by default since the top level pom doesn't mention them."
HBASE-16929,"HBASE-16626 added default method of shipped() to RegionScanner.

However, when building master branch of Phoenix against 2.0 SNAPSHOT, I got:
{code}
[ERROR] /a/phoenix/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/DelegateRegionScanner.java:[27,8] org.apache.phoenix.coprocessor.DelegateRegionScanner is not abstract and does not override  abstract method shipped() in org.apache.hadoop.hbase.regionserver.Shipper
[ERROR] /a/phoenix/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/BaseScannerRegionObserver.java:[344,36] <anonymous org.apache.phoenix.coprocessor.BaseScannerRegionObserver$1> is not         abstract and does not override abstract method shipped() in org.apache.hadoop.hbase.regionserver.Shipper
{code}
Here is the snippet for DelegateRegionScanner:
{code}
public class DelegateRegionScanner implements RegionScanner {
{code}
It seems adding default method in RegionScanner is not enough for downstream projects.

After moving the default method to Shipper interface, the above two compilation errors are gone in Phoenix."
HBASE-14750,"While writing an application that uses HBase I ran into the problem that although I have setup the hbase-site.xml in the {{HBASE_CONF_DIR}}; the settings in this file are not picked up in my application.

In several places I find instructions to include things like the {{hbase.zookeeper.quorum}} in a properties file and the explicitly set these value from within the application (I have actually done this in the past quite a few times).

Although this works I expect the system to automatically pickup the settings I have installed already which are picked up by tools like the hbase shell and pig.

So I ended up writing this helper method:
{code:java}
    public static Configuration createConfiguration() {
        String hbaseConfDir = System.getenv(""HBASE_CONF_DIR"");
        if (hbaseConfDir == null) {
            hbaseConfDir = ""/etc/hbase/conf"";
        }

        Configuration conf = HBaseConfiguration.create();
        conf.addResource(new Path(hbaseConfDir + ""/hbase-site.xml""));
        return conf;
    }
{code}

I expect HBaseConfiguration.create() to give me a working config in an environment where everything for all the other HBase clients has already been setup correctly.

My proposal is to change the HBaseConfiguration.create() to effectively include what my helper method does.
"
HBASE-9022,https://builds.apache.org/job/PreCommit-HBASE-Build/6428//testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/
HBASE-4030,"-- We've been seeing intermittent failures of calls to LoadIncrementalHFiles.  When this happens the node that made the call will see a FileNotFoundException such as this:

2011-06-23 15:47:34.379566500 java.net.SocketTimeoutException: Call to s8.XXX/67.2"
HBASE-17117,"We started seeing clients persistently throwing errors as they were trying to talk to a region that was non existent (split a few days ago). We verified that the region was deleted from meta when the split happened.

On performing a raw scan on meta, the deleted version for the split region appears, which also does on performing a normal reversed scan. Since MetaScanner uses a reversed scan, this explains why clients see non existent regions.

We also verified that there was no in-memory corrupt state by failing over the master. When we trigger major compaction on meta, the problem goes away further confirming the fact that we were seeing deleted versions."
HBASE-15406,"This was what I did on cluster with 1.4.0-SNAPSHOT built Thursday:

Run 'hbase hbck -disableSplitAndMerge' on gateway node of the cluster
Terminate hbck early
Enter hbase shell where I observed:
{code}
hbase(main):001:0> splitormerge_enabled 'SPLIT'
false
0 row(s) in 0.3280 seconds

hbase(main):002:0> splitormerge_enabled 'MERGE'
false
0 row(s) in 0.0070 seconds
{code}
Expectation is that the split / merge switches should be restored to default value after hbck exits."
HBASE-16079,"#testLockupAroundBadAssignSync

https://builds.apache.org/view/All/job/HBase-1.3/751/jdk=latest1.8,label=yahoo-not-h2/testReport/junit/org.apache.hadoop.hbase.regionserver/TestFailedAppendAndSync/testLockupAroundBadAssignSync/

Error Message

test timed out after 300000 milliseconds
Stacktrace

org.junit.runners.model.TestTimedOutException: test timed out after 300000 milliseconds
	at org.mockito.internal.debugging.LocationImpl.toString(LocationImpl.java:29)
	at java.lang.String.valueOf(String.java:2994)
	at java.lang.StringBuilder.append(StringBuilder.java:131)
	at org.mockito.exceptions.Reporter.wantedButNotInvoked(Reporter.java:320)
	at org.mockito.internal.verification.checkers.MissingInvocationChecker.check(MissingInvocationChecker.java:42)
	at org.mockito.internal.verification.AtLeast.verify(AtLeast.java:38)
	at org.mockito.internal.verification.MockAwareVerificationMode.verify(MockAwareVerificationMode.java:21)
	at org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:72)
	at org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29)
	at org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:38)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:61)
	at org.apache.hadoop.hbase.Server$$EnhancerByMockitoWithCGLIB$$323c5f5b.abort(<generated>)
	at org.apache.hadoop.hbase.regionserver.TestFailedAppendAndSync.testLockupAroundBadAssignSync(TestFailedAppendAndSync.java:239)"
HBASE-17810,"I saw that some fixes HBASE-17746 were in branch-1. So, I used this branch to see if I am getting any failures.
This is the result:
Results :

Failed tests:
  TestFuzzyRowFilter.testSatisfiesForward:80 expected:<YES> but was:<NO_NEXT>
  TestFuzzyRowFilter.testSatisfiesReverse:120 expected:<YES> but was:<NEXT_EXISTS>
Tests in error:
  TestSeekToBlockWithEncoders.testSeekToBlockWithDecreasingCommonPrefix:140->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffFamilyAndQualifer:249->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffQualifer:160->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffQualiferOnSameRow:183->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffQualiferOnSameRow1:206->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffQualiferOnSameRowButDescendingInSize:229->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithNonMatchingSeekKey:65->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekingToBlockToANotAvailableKey:117->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekingToBlockWithBiggerNonLength1:91->seekToTheKey:270 禄 NoClassDefFound
  TestHFileEncryption.testHFileEncryption:232 禄 NoClassDefFound Could not initia...
  TestSeekTo.testSeekBeforeWithReSeekTo:199->testSeekBeforeWithReSeekToInternals:216 禄 NoClassDefFound
  TestSeekTo.testSeekBefore:145->testSeekBeforeInternals:161 禄 NoClassDefFound C...
  TestSeekTo.testSeekTo:292->testSeekToInternals:308 禄 NoClassDefFound Could not...

Tests run: 1106, Failures: 2, Errors: 13, Skipped: 22
--------------------------------------------------------------------------------------------
Results :

Failed tests:
  IntegrationTestRegionReplicaReplication.testIngest:112->runIngestTest:214 Load failed with error code 1
  IntegrationTestBulkLoad.testBulkLoad:213->runLoad:223->runLinkedListMRJob:296 expected:<true> but was:<false>
  IntegrationTestImportTsv.testGenerateAndLoad:203 expected:<0> but was:<1>
  IntegrationTestLoadAndVerify.testLoadAndVerify:544->doLoad:353 null
  IntegrationTestWithCellVisibilityLoadAndVerify>IntegrationTestLoadAndVerify.testLoadAndVerify:544->doLoad:244->IntegrationTestLoadAndVerify.doLoad:353 null
Tests in error:
  IntegrationTestIngestWithACL>IntegrationTestBase.setUp:148->setUpCluster:64->IntegrationTestIngest.setUpCluster:84 禄 IO
  IntegrationTestMTTR.testKillRsHoldingMeta:278->run:319 禄 Execution java.io.IOE...
  IntegrationTestMTTR.testRestartRsHoldingTable:273->run:319 禄 Execution java.io...
  IntegrationTestBigLinkedList.testContinuousIngest:1798 禄 Runtime Generator fai...
  IntegrationTestBigLinkedListWithVisibility.testContinuousIngest:637 禄 Runtime ...
  IntegrationTestReplication>IntegrationTestBigLinkedList.testContinuousIngest:1798 禄 Runtime

Tests run: 32, Failures: 5, Errors: 6, Skipped: 2

Any idea what could be the reason for above failures?"
HBASE-17375,"Recently, we find our hbase compaction thread never end.  Assume we have following cells:
{quote}
<A,a> 1
<A,v> 1
<Aaeeee,a> 1
<Aaeeee,v> 1
<Abc,a> 1
<Abc,v> 1
<Abde,a> 1
<Abde,v> 1
{quote}

If we encode above datas into prefix tree block, then it looks like:
!row trie example.PNG!

Assume the current row is {color:red}Abc{color} (e.g. the current row node is 4), then the previous row should be *Aaeeee* (e.g. 2). However previousRowInternal return {color:red}A{color}(e.g. 1)

After investigation, I believe it's the bug of PrefixTreeArrayReversibleScanner#previousRowInternal.

{code}
  private boolean previousRowInternal() {
    //...
    while (!beforeFirst) {
      //....
      // what if currentRowNode is nub?
      if (currentRowNode.hasOccurrences()) {// escape clause
        currentRowNode.resetFanIndex();
        return true;// found some values
      }
    }
{code}

currentRowNode.hasOccurrences() only test whether it has cell or not. But in the case of  currentRowNode.isNub() is true, previousRowInternal should follow the previous fan instead of return."
HBASE-16487,"HBASE-15152 included the prefix tree module as dependency to TableMapReduceUtil. but the hardcoded string of the class name was wrong. HBASE-16360 fixed the hardcoded string. 

but, I was looking at the comment above and I can't figure out where is the circular dependency.
{code}
// PrefixTreeCodec is part of the hbase-prefix-tree module. If not included in MR jobs jar
// dependencies, MR jobs that write encoded hfiles will fail.
// We used reflection here so to prevent a circular module dependency.
// TODO - if we extract the MR into a module, make it depend on hbase-prefix-tree
{code}
from the pom.xml of the prefix-tree module I don't see hbase-server. but I can see prefix-tree module in the hbase-server/pom.xml. the TableMapReduceUtil is in hbase-server.. so in theory we don't have any circular dependency.
we can just probably drop all that try/catch block with the Class.forName() and just simply use org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeCodec as we do for the others. 

(or at least we should end up with a test to cover the that Class.fromName() in case we rename the PrefixTreeCodec or the namespace in the future and forget to update this reference)"
HBASE-16885,"I tried to compile master branch of Phoenix against 2.0-SNAPSHOT and observed some compilation errors.

/phoenix/phoenix-core/src/main/java/org/apache/hadoop/hbase/regionserver/LocalIndexStoreFileScanner.java:[31,54] cannot find symbol
  symbol:   class Reader
  location: class org.apache.hadoop.hbase.regionserver.StoreFile

/phoenix/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/MultiHfileOutputFormat.java:[300,16] cannot find symbol
  symbol:   class Writer
  location: class org.apache.hadoop.hbase.regionserver.StoreFile

The above inner classes of StoreFile are marked public as of branch-1.

We should deprecate them in 1.x release.
"
HBASE-3706,"HDFS is kinda dumb regards rereplication in that if it notices missing replicas, its crass in the way it goes about making redress; there is no facility for limiting the rate of rereplication (HDFS-1195).  We've seen the case where hdfs is rereplicating at such a rate after DN crash, it fills the network hampering data serving.  This issue is about noting this prob. and helping out/keeping an eye on HDFS-1195."
HBASE-12818,"Starting in late December, our internal runs on branch-1 have failed every few days with the following:
{code}
java.lang.AssertionError: Archived hfiles [] is missing snapshot file:c7ed21029d4e4cb28fdd138a28c8f3e7
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testSnapshotHFileArchiving(TestSnapshotFromMaster.java:347)
{code}
A full log of the stdout from one of these runs can be found [on Gist|https://gist.github.com/dimaspivak/1c27a5d95e26c4bedc4f]; the relevant portion seems to be
{code}
2015-01-07 05:04:06,015 DEBUG [B.defaultRpcServer.handler=3,queue=0,port=55325] util.FSTableDescriptors(177): Exception during readTableDecriptor. Current table name = test
org.apache.hadoop.hbase.TableInfoMissingException: No table descriptor file under hdfs://localhost:42974/user/jenkins/test-data/ce542e14-a8e7-4764-8a68-8fb6401ebeb8/data/default/test
	at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorFromFs(FSTableDescriptors.java:509)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorFromFs(FSTableDescriptors.java:487)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:172)
	at org.apache.hadoop.hbase.master.HMaster.listTableDescriptors(HMaster.java:2165)
	at org.apache.hadoop.hbase.master.MasterRpcServices.getTableDescriptors(MasterRpcServices.java:787)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:42402)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2028)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:744)
{code}

I've yet to see this on upstream runs, but I'll keep an eye out. Also, note that this is unrelated to HBASE-9072, which had the same test failing for other reasons back in 2013."
HBASE-4953,"When doing a kill -9 on all HBase processes and attempting to re-start HBase, the master does not properly assign the root region. The /hbase/root-region-server znode still contains the old regionserver, but the regionserver referenced in it does not get assigned the root region. This might get resolved after the znode expires, though, but some testing is required."
HBASE-6930,"When processing the multiPut, multiMutations or multiDelete operations, each IPC handler thread tries to acquire a lock for each row key in these batches. If there are duplicated row keys in these batches, previously the IPC handler thread will repeatedly acquire the same row key again and again.

So the optimization is to sort each batch operation based on the row key in the client side, and skip acquiring the same row lock repeatedly in the server side."
HBASE-10643,"When RS is brought up with XX:MaxDirectMemorySize of 22GB or higher, RS fails after a successful start. From the RS logs it looks like the bucketCache memory allocation is taking more time makes the RS considered dead by ZK. One option to fix the problem would be to allocate the bucketCache before registering with ZK. 

2014-02-28 18:54:42,967 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 33496ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-02-28 18:54:42,967 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 33496ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-02-28 18:54:42,967 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 23988ms
GC pool 'ParNew' had collection(s): count=1 time=24432ms
2014-02-28 18:54:43,006 FATAL [regionserver60020] regionserver.HRegionServer: ABORTING region server bbg-master2.bbg-test.hdp,60020,1393628951236: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing bbg-master2.bbg-test.hdp,60020,1393628951236 as dead server
        at org.apache.hadoop.hbase.master.ServerManager.checkIsDead(ServerManager.java:341)
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:254)"
HBASE-12255,"I have a phoenix table 'EVENT', and the table have a index 'IDX_DATE_HOUR_X'.
I restarted hdfs without stop hbase, after then, the hbase table cann't be scaned.
I try to restart hbase, the all hbase table still cann't be scaned.
the regionserver log have many exception like this:

2014-10-13 19:33:05,287 INFO  [A01101303447-V1,60020,1413199890407-recovery-writer--pool4-t3] client.AsyncProcess: #4, waiting for some tasks to finish. Expected max=0, tasksSent=9, tasksDone=8, currentTasksDone=8, retries=8 hasError=fal
se, tableName=IDX_DATE_HOUR_X
2014-10-13 19:33:05,298 INFO  [A01101303447-V1,60020,1413199890407-recovery-writer--pool4-t2] client.AsyncProcess: #5, waiting for some tasks to finish. Expected max=0, tasksSent=9, tasksDone=8, currentTasksDone=8, retries=8 hasError=fal
se, tableName=IDX_DATE_HOUR_X
2014-10-13 19:33:05,311 INFO  [A01101303447-V1,60020,1413199890407-recovery-writer--pool4-t1] client.AsyncProcess: #6, waiting for some tasks to finish. Expected max=0, tasksSent=9, tasksDone=8, currentTasksDone=8, retries=8 hasError=fal
se, tableName=IDX_DATE_HOUR_X
2014-10-13 19:33:06,452 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving A01101303447-V1,60020,1413199414409's hlogs to my queue
2014-10-13 19:33:15,325 INFO  [A01101303447-V1,60020,1413199890407-recovery-writer--pool4-t1] client.AsyncProcess: #6, waiting for some tasks to finish. Expected max=0, tasksSent=10, tasksDone=9, currentTasksDone=9, retries=9 hasError=fa
lse, tableName=IDX_DATE_HOUR_X
2014-10-13 19:33:15,333 INFO  [htable-pool6-t2] client.AsyncProcess: #6, table=IDX_DATE_HOUR_X, attempt=10/350 failed 12 ops, last exception: org.apache.hadoop.hbase.exceptions.RegionOpeningException: org.apache.hadoop.hbase.exceptions.R
egionOpeningException: Region IDX_DATE_HOUR_X,t\x00\x00\x00\x00\x00,1413186874829.9a92abb84768b129df3faedb877f7bea. is opening on A01101303447-V1,60020,1413199890407
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2759)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:4213)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3437)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29593)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2027)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
        at java.lang.Thread.run(Thread.java:744)



-------------------------------
After two days's try, i found that:
If idisable 'EVENT', other tables can be scanned, then i enable 'EVENT' manually, the region log show that NullPointExceptin has occur then replaying WAL, the following is log:

2014-10-13 19:25:21,043 INFO  [RS_OPEN_REGION-A01101303447-V1:60020-1] regionserver.HRegion: Replaying edits from hdfs://localhost/hbase-0.98/data/default/EVENT/def4a581d4ad963cbb8cad32cbfbab2e/recovered.edits/0000000000000000002
2014-10-13 19:25:21,048 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t2-SendThread(localhost:2182)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2182. Will not attempt to authe
nticate using SASL (unknown error)
2014-10-13 19:25:21,049 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t2-SendThread(localhost:2182)] zookeeper.ClientCnxn: Socket connection established to localhost/0:0:0:0:0:0:0:1:2182, initiating session
2014-10-13 19:25:21,051 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x199c8484 connecting to ZooKeeper ensemble=localhost:2182
2014-10-13 19:25:21,051 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2182 sessionTimeout=90000 watcher=hconnection-0x199c8484, quorum=lo
calhost:2182, baseZNode=/hbase
2014-10-13 19:25:21,052 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3-SendThread(localhost:2182)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2182. Will not attempt to authe
nticate using SASL (unknown error)
2014-10-13 19:25:21,052 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3-SendThread(localhost:2182)] zookeeper.ClientCnxn: Socket connection established to localhost/0:0:0:0:0:0:0:1:2182, initiating session
2014-10-13 19:25:21,053 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t2-SendThread(localhost:2182)] zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2182, sessionid = 0x149093
fc1c80203, negotiated timeout = 90000
2014-10-13 19:25:21,055 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3-SendThread(localhost:2182)] zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2182, sessionid = 0x149093
fc1c80204, negotiated timeout = 90000
2014-10-13 19:25:21,103 ERROR [RS_OPEN_REGION-A01101303447-V1:60020-1] handler.OpenRegionHandler: Failed open of region=EVENT,\x18,1413186838852.def4a581d4ad963cbb8cad32cbfbab2e., starting to roll back the global memstore size.
java.lang.NullPointerException
2014-10-13 19:25:21,104 INFO  [RS_OPEN_REGION-A01101303447-V1:60020-1] handler.OpenRegionHandler: Opening of region {ENCODED => def4a581d4ad963cbb8cad32cbfbab2e, NAME => 'EVENT,\x18,1413186838852.def4a581d4ad963cbb8cad32cbfbab2e.', START
KEY => '\x18', ENDKEY => '\x19'} failed, transitioning from OPENING to FAILED_OPEN in ZK, expecting version 28
2014-10-13 19:25:21,104 DEBUG [RS_OPEN_REGION-A01101303447-V1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x149093fc1c80001, quorum=localhost:2182, baseZNode=/hbase Transitioning def4a581d4ad963cbb8cad32cbfbab2e from RS_ZK_REGION_OPE
NING to RS_ZK_REGION_FAILED_OPEN
2014-10-13 19:25:21,107 DEBUG [RS_OPEN_REGION-A01101303447-V1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x149093fc1c80001, quorum=localhost:2182, baseZNode=/hbase Transitioned node def4a581d4ad963cbb8cad32cbfbab2e from RS_ZK_REGION
_OPENING to RS_ZK_REGION_FAILED_OPEN
2014-10-13 19:25:21,108 ERROR [RS_OPEN_REGION-A01101303447-V1:60020-2] handler.OpenRegionHandler: Failed open of region=EVENT,\x15,1413186838852.4592fbc9db5e6eb05c812dcd81f5fa4d., starting to roll back the global memstore size.
java.lang.NullPointerException
2014-10-13 19:25:21,108 INFO  [RS_OPEN_REGION-A01101303447-V1:60020-2] handler.OpenRegionHandler: Opening of region {ENCODED => 4592fbc9db5e6eb05c812dcd81f5fa4d, NAME => 'EVENT,\x15,1413186838852.4592fbc9db5e6eb05c812dcd81f5fa4d.', START
KEY => '\x15', ENDKEY => '\x16'} failed, transitioning from OPENING to FAILED_OPEN in ZK, expecting version 28
2014-10-13 19:25:21,108 DEBUG [RS_OPEN_REGION-A01101303447-V1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x149093fc1c80001, quorum=localhost:2182, baseZNode=/hbase Transitioning 4592fbc9db5e6eb05c812dcd81f5fa4d from RS_ZK_REGION_OPE
NING to RS_ZK_REGION_FAILED_OPEN
2014-10-13 19:25:21,111 DEBUG [RS_OPEN_REGION-A01101303447-V1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x149093fc1c80001, quorum=localhost:2182, baseZNode=/hbase Transitioned node 4592fbc9db5e6eb05c812dcd81f5fa4d from RS_ZK_REGION
_OPENING to RS_ZK_REGION_FAILED_OPEN
2014-10-13 19:25:21,113 ERROR [RS_OPEN_REGION-A01101303447-V1:60020-0] handler.OpenRegionHandler: Failed open of region=EVENT,\x1B,1413186838852.b45c35d23b23fda5643ec5d79083488e., starting to roll back the global memstore size.
java.lang.NullPointerException



 After deleteing the 'recovered.edits' in the 'EVENT' table's region, the hbase table can be scanned. so i think the reason maybe that:
after restart hbase, the regionserver begin opening the region and replaying WAL, when replaying the EVENT's WAL, because EVENT has a index table IDX_DATE_HOUR_X, so the replay process should operate IDX_DATE_HOUR_X, but at this moment, the IDX_DATE_HOUR_X table's region is in OPENING stats, it is't unavaiabled, so the EVENT replaying process Time and time again to retry and throw Exception aging and again.

if I disable EVENT first, others hbase table recory successfully, but when i enable EVENT, the region log occur java.lang.NullPointerException, this make the region transition to OPEN_FAILED."
HBASE-16858,"{code}
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 603.9 sec - in org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEnd
Exception in thread ""Thread-2545"" java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.Arrays.copyOfRange(Arrays.java:3664)
	at java.lang.StringBuffer.toString(StringBuffer.java:671)
	at java.io.BufferedReader.readLine(BufferedReader.java:359)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.maven.surefire.shade.org.apache.maven.shared.utils.cli.StreamPumper.run(StreamPumper.java:66)
Exception in thread ""Thread-2543"" java.lang.OutOfMemoryError: GC overhead limit exceeded
Exception in thread ""Thread-2549"" java.lang.OutOfMemoryError: GC overhead limit exceeded
Exception in thread ""Thread-2527"" java.lang.OutOfMemoryError: GC overhead limit exceeded
{code}"
HBASE-17078,"HBase build with hadoop.profile=3.0 is failing as hbase-assembly\src\main\assembly\hadoop-three-compat.xml is not present.
{code}	
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 06:18 min
[INFO] Finished at: 2016-11-12T13:17:48+05:30
[INFO] Final Memory: 230M/1118M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-assembly-plugin:2.4:single (default-cli) on project hbase-assembly: Error reading assemblies: Error locating assembly descriptor: src/main/assembly/hadoop-three-compat.xml
[ERROR]
[ERROR] [1] [INFO] Searching for file location: D:\gitHome\hbaseMaster\hbase-assembly\src\main\assembly\hadoop-three-compat.xml
[ERROR]
[ERROR] [2] [INFO] File: D:\gitHome\hbaseMaster\hbase-assembly\src\main\assembly\hadoop-three-compat.xml does not exist.
[ERROR]
[ERROR] [3] [INFO] File: D:\gitHome\hbaseMaster\src\main\assembly\hadoop-three-compat.xml does not exist.
[ERROR] -> [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hbase-assembly
{code}
"
HBASE-13556,"Long time ago, back in HBASE-8015, we noted that 'system tables' should be treated special when assigning; they should go out after hbase:meta and before userspace tables and that we should fix this in a follow-on issue (https://issues.apache.org/jira/browse/HBASE-8408?focusedCommentId=13728267&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13728267). This is the follow-up issue.

Do system tables like namespace need to keep their own WAL to make it easier recovering and assigning these tables ahead of userspace tables?"
HBASE-17529,"I built tar ball using master branch based on commit 616f4801b06a8427a03ceca9fb8345700ce1ad71.

Was running the following command:

hbase org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList -DinMemoryCompaction=BASIC Loop 4 6 1000000 /tmp/hbase-biglinkedlist-verify 6 --monkey slowDeterministic

Here was related snippet:
{code}
2017-01-24 21:29:00,107 DEBUG [RpcServer.deafult.FPBQ.Fifo.handler=0,queue=0,port=16000] procedure2.ProcedureExecutor: Stored MergeTableRegionsProcedure (table=IntegrationTestBigLinkedList regions=[IntegrationTestBigLinkedList,,1485292220242.4c5ea240e86ef22ec7264b1153dd557d., IntegrationTestBigLinkedList,\x0E8\xE3\x8E8\xE3\x8E8,1485292220242.6cdb98dfed41ea689b3cd66478c2c580. ] forcible=false), procId=12, owner=hbase, state=RUNNABLE:MERGE_TABLE_REGIONS_PREPARE
2017-01-24 21:29:00,108 DEBUG [ProcedureExecutorWorker-14] wal.WALProcedureStore: Set running procedure count=1, slots=24
2017-01-24 21:29:00,127 ERROR [ProcedureExecutorWorker-14] procedure2.ProcedureExecutor: CODE-BUG: Uncatched runtime exception for procedure: MergeTableRegionsProcedure (table=IntegrationTestBigLinkedList regions=[IntegrationTestBigLinkedList,,1485292220242.4c5ea240e86ef22ec7264b1153dd557d., IntegrationTestBigLinkedList,\x0E8\xE3\x8E8\xE3\x8E8,1485292220242.6cdb98dfed41ea689b3cd66478c2c580. ] forcible=false), procId=12, owner=hbase, state=RUNNABLE:MERGE_TABLE_REGIONS_MOVE_REGION_TO_SAME_RS
java.lang.ArrayIndexOutOfBoundsException
        at org.apache.hadoop.hbase.util.ByteBufferUtils.copyFromBufferToArray(ByteBufferUtils.java:1024)
        at org.apache.hadoop.hbase.nio.MultiByteBuff.get(MultiByteBuff.java:628)
        at org.apache.hadoop.hbase.ipc.RpcServer$ByteBuffByteInput.read(RpcServer.java:1483)
        at org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteInputByteString.copyToInternal(ByteInputByteString.java:105)
        at org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.toByteArray(ByteString.java:651)
        at org.apache.hadoop.hbase.RegionLoad.getName(RegionLoad.java:50)
        at org.apache.hadoop.hbase.ServerLoad.getRegionsLoad(ServerLoad.java:236)
        at org.apache.hadoop.hbase.master.procedure.MergeTableRegionsProcedure.getRegionLoad(MergeTableRegionsProcedure.java:774)
        at org.apache.hadoop.hbase.master.procedure.MergeTableRegionsProcedure.MoveRegionsToSameRS(MergeTableRegionsProcedure.java:461)
        at org.apache.hadoop.hbase.master.procedure.MergeTableRegionsProcedure.executeFromState(MergeTableRegionsProcedure.java:142)
        at org.apache.hadoop.hbase.master.procedure.MergeTableRegionsProcedure.executeFromState(MergeTableRegionsProcedure.java:72)
        at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:154)
        at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:708)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1332)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1133)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$800(ProcedureExecutor.java:76)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1588)
{code}
Master log to be attached."
HBASE-15993,Add support for regular expression in table names in backup/restore/set operations.
HBASE-14129,"We were doing a cluster restart the other day.  Some regionservers did not shut down cleanly.  Upon restart our locality went from 99% to 5%.  Upon looking at the AssignmentManager.joinCluster() code it calls AssignmentManager.processDeadServersAndRegionsInTransition().
If the failover flag gets set for any reason it seems we don't call assignAllUserRegions().  Then it looks like the balancer does the work in assigning those regions, we don't use a locality aware balancer and we lost our region locality.

I don't have a solid grasp on the reasoning for these checks but there could be some potential workarounds here.

1. After shutting down your cluster, move your WALs aside (replay later).  
2. Clean up your zNodes 

That seems to work, but requires a lot of manual labor.  Another solution which I prefer would be to have a flag for ./start-hbase.sh --clean 

If we start master with that flag then we do a check in AssignmentManager.processDeadServersAndRegionsInTransition()  thus if this flag is set we call: assignAllUserRegions() regardless of the failover state.

I have a patch for the later solution, that is if I am understanding the logic correctly."
HBASE-8028,"In case there is an exception while doing the log-sync, the memstore is not rollbacked, while the mvcc is _always_ forwarded to the writeentry created at the beginning of the operation. This may lead to scanners seeing results which are not synched to the fs.


"
HBASE-17400,"Looping TestHRegionWithInMemoryFlush with commit 0e48665641b16cd9b250503696b926a568063654 , I got the following error at iteration #33:
{code}
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 600.163 sec <<< FAILURE! - in org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush
org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush  Time elapsed: 600.019 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 10 minutes
  at java.lang.Object.wait(Native Method)
  at org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.waitForRead(MultiVersionConcurrencyControl.java:218)
  at org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.completeAndWait(MultiVersionConcurrencyControl.java:149)
  at org.apache.hadoop.hbase.regionserver.HRegion.getNextSequenceId(HRegion.java:2731)
  at org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2446)
  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2342)
  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2313)
  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2303)
  at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1600)
  at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1505)
  at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1455)
  at org.apache.hadoop.hbase.HBaseTestingUtility.closeRegionAndWAL(HBaseTestingUtility.java:374)
  at org.apache.hadoop.hbase.regionserver.TestHRegion.testWritesWhileScanning(TestHRegion.java:3985)
{code}
See attached test output for details."
HBASE-10396,"HBaseAdmin has the constructor:
{code}
  public HBaseAdmin(Configuration c)
  throws MasterNotRunningException, ZooKeeperConnectionException {
    this.conf = HBaseConfiguration.create(c);
    this.connection = HConnectionManager.getConnection(this.conf);
    ...
{code}
As shown in above code, HBaseAdmin will get a cached HConnection or create a new HConnection and use this HConnection to connect to Master. Then, HBaseAdmin will delete the HConnection when connecting to master fail as follows:
{code}
    while ( true ){
      try {
        this.connection.getMaster();
        return;
      } catch (MasterNotRunningException mnre) {
        HConnectionManager.deleteStaleConnection(this.connection);
        this.connection = HConnectionManager.getConnection(this.conf);
      }
{code} 
The above code will invoke HConnectionManager#deleteStaleConnection to delete the HConnection from global HConnection cache. The risk is that the deleted HConnection might be sharing by other threads, such as HTable or HTablePool. Then, these threads which sharing the deleted HConnection will get closed HConnection exception:
{code}
org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@61bc59aa closed
{code}
If users use HTablePool, the situation will become worse because closing HTable will only return HTable to HTablePool which won't reduce the reference count of the closed HConnection. Then, the closed HConnection will always be used before clearing HTablePool. In 0.94, some modules such as Rest server are using HTablePool, therefore may suffer from this problem. "
HBASE-6651,"There are some operations in HTablePool accessing PoolMap in multiple places without any explicit synchronization. 

For example HTablePool.closeTablePool() calls PoolMap.values(), and calls PoolMap.remove(). If other threads add new instances to the pool in the middle of the calls, the newly added instances might be dropped. (HTablePool.closeTablePool() also has another problem that calling it by multiple threads causes accessing HTable by multiple threads.)

Moreover, PoolMap is not thread safe for the same reason.

For example PoolMap.put() calles ConcurrentMap.get() and calles ConcurrentMap.put(). If other threads add a new instance to the concurent map in the middle of the calls, the new instance might be dropped.

And also implementations of Pool have the same problems.
"
HBASE-9739,"Just ran into a scenario where HBaseClient became permanently useless after we interrupted the using thread.
The problem is here:
{code}
      } catch(IOException e) {
        markClosed(e);
{code}
In sendParam(...).
If the IOException is caused by an interrupt we should not close the connection.
"
HBASE-10028,"The current documentation of the metrics is incomplete and at point incorrect (HDFS latencies are in ns rather than ms for example).
We should clean this up and add other related metrics as well."
HBASE-17841,"When writing unit test for HBASE-17287, I noticed that the wait for master to come down after hdfs enters safe mode times out (where meta server still has unflushed edits).
The same test in branch-1 passes fine.

Looking at org.apache.hadoop.hbase.master.procedure.TestSafemodeBringsDownMaster-output.txt , I don't see occurrence of ServerCrashProcedure.

While in branch-1, there is something similar to the following:
{code}
  at org.apache.hadoop.hdfs.DFSClient.rename(DFSClient.java:1661)
  at org.apache.hadoop.hdfs.DistributedFileSystem.rename(DistributedFileSystem.java:525)
  at org.apache.hadoop.hbase.master.MasterFileSystem.getLogDirs(MasterFileSystem.java:364)
  at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:429)
  at org.apache.hadoop.hbase.master.MasterFileSystem.splitMetaLog(MasterFileSystem.java:343)
  at org.apache.hadoop.hbase.master.MasterFileSystem.splitMetaLog(MasterFileSystem.java:334)
  at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.processMeta(ServerCrashProcedure.java:351)
  at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.executeFromState(ServerCrashProcedure.java:239)
  at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.executeFromState(ServerCrashProcedure.java:73)
  at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:139)
  at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:506)
  at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1152)
{code}"
HBASE-17820,"I used this command ""mvn clean install -Dhadoop-two.version=2.6.0 -DskipTests"" to build hbase-1.2.4 source code. 
Build failed at hbase-assembly module.

This is the fail message: 
""Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.5:process (default) on project hbase-assembly: Error rendering velocity resource. Error invoking method 'get(java.lang.Integer)' in java.util.ArrayList at META-INF/LICENSE.vm[line 1671, column 8]: InvocationTargetException: Index: 0, Size: 0 -> [Help 1]""."
HBASE-16431,Class `HTableWrapper` must either declared abstract or implement abstract method 'setRpcTimeout(int)' in 'Table'
HBASE-17311,"In preparation to big refactoring (separate project for backup) we need to move  'hbase:system' table out of HBase system namespace.  
"
HBASE-17548,"While investigating HBASE-17529, I wanted to trigger region merge where the
two (adjacent) regions are on different region servers.

I produced tar ball based on commit 85d701892ed969380a8bcca9c9f4e306c74af941

For table.jsp?name=IntegrationTestBigLinkedList, e.g., where there're
multiple regions for the table, I don't see regions listing.
Same with other multi-region tables.

First reported here:
http://search-hadoop.com/m/HBase/YGbbJglgx1N2qvO1"
HBASE-15130,"branch 98 version backport for HBASE-14355

"
HBASE-17300,"Attached is the test case. I have added some comments so hopefully the test makes sense. It actually is causing test failures on the Phoenix branches.

The test fails consistently using HBase-0.98.23. It exhibits flappy behavior with the 1.2 branch (failed twice in 5 tries). 

{code}
@Test
    public void testNullCheckAndPut() throws Exception {
            try (HBaseAdmin admin = TEST_UTIL.getHBaseAdmin()) {
                Callable<Boolean> c1 = new CheckAndPutCallable();
                Callable<Boolean> c2 = new CheckAndPutCallable();
                ExecutorService e = Executors.newFixedThreadPool(5);
                Future<Boolean> f1 = e.submit(c1);
                Future<Boolean> f2 = e.submit(c2);
                assertTrue(f1.get() || f2.get());
                assertFalse(f1.get() && f2.get());
            }    
        }
    }
    
    
    private static final class CheckAndPutCallable implements Callable<Boolean> {
        @Override
        public Boolean call() throws Exception {
            byte[] rowToLock = ""ROW"".getBytes();
            byte[] colFamily = ""COLUMN_FAMILY"".getBytes();
            byte[] column = ""COLUMN"".getBytes();
            byte[] newValue = ""NEW_VALUE"".getBytes();
            byte[] oldValue = ""OLD_VALUE"".getBytes();
            byte[] tableName = ""table"".getBytes();
            boolean acquired = false;
                try (HBaseAdmin admin = TEST_UTIL.getHBaseAdmin()) {
                    HTableDescriptor tableDesc = new HTableDescriptor(TableName.valueOf(tableName));
                    HColumnDescriptor columnDesc = new HColumnDescriptor(colFamily);
                    columnDesc.setTimeToLive(600);
                    tableDesc.addFamily(columnDesc);
                    try {
                        admin.createTable(tableDesc);
                    } catch (TableExistsException e) {
                        // ignore
                    }
                    try (HTableInterface table = admin.getConnection().getTable(tableName)) {
                        Put put = new Put(rowToLock);
                        put.add(colFamily, column, oldValue); // add a row with column set to oldValue
                        table.put(put);
                        put = new Put(rowToLock);
                        put.add(colFamily, column, newValue);
                        // only one of the threads should be able to get return value of true for the expected value of oldValue
                        acquired = table.checkAndPut(rowToLock, colFamily, column, oldValue, put); 
                        if (!acquired) {
                           // if a thread didn't get true before, then it shouldn't get true this time either
                           // because the column DOES exist
                           acquired = table.checkAndPut(rowToLock, colFamily, column, null, put);
                        }
                    }
                }
            }  
            return acquired;
        }
    }
{code}


cc [~apurtell], [~jamestaylor], [~lhofhansl]. 
"
HBASE-16115,"We ran into an interesting phenomenon which can easily render a cluster unusable.

We loaded some tests data into a test table and forced a manual compaction through the UI. We have some compaction hooks implemented in a region observer, which writes back to another HBase table when the compaction finishes. We noticed that this coprocessor is not setup correctly, it seems the security context is missing.

The interesting part is that this _only_ happens when the compaction is triggere through the UI. Automatic compactions (major or minor) or when triggered via the HBase shell (folling a kinit) work fine. Only the UI-triggered compactions cause this issues and lead to essentially neverending compactions, immovable regions, etc.

Not sure what exactly the issue is, but I wanted to make sure I capture this.

[~apurtell], [~ghelmling], FYI."
HBASE-6725,"When multiple threads race using CAP with and a lock on the same row, several instances may be allowed to update the cell with the new value (although the expected value is different).
If all threads race with a wrong expected value and a lock, none will be able to update."
HBASE-6660,"Recently I upgraded three data centers to our own checkout of 0.92.2, last commit :

{noformat}
commit 5accb6a1be4776630126ac21d07adb652b74df95
Author: Zhihong Yu <tedyu@apache.org>
Date:   Mon Aug 20 18:19:45 2012 +0000
HBASE-6608 Fix for HBASE-6160, META entries from daughters can be deleted before parent entries, shouldn't compare HRegionInfo's (Enis)
{noformat}

Two upgrades went fine, upgrade to one data center failed. Failed in the sense that ROOT and META assignment took forever. Panic struck I restarted master and all region servers. I may have deleted zookeeper node /hbase/root-region-server as well, dont ask me why :-( 

After this I managed to get ROOT assigned. But META assignment got stuck again. 

The log is here : https://raw.github.com/gist/3455435/adebd118b47aa3d715201010aa09e5eb8930033c/npe_rs_0.92.2.log

Notice how region server was stuck in a loop of NPE (grep processBatchCallback). There is one more NPE related to zookeeper constructor. 
"
HBASE-6465,"Through the master and regionserver log,I find load balancer repeatedly
close and open region in the same regionserver(period in
hbase.balancer.period ).
Does this is a bug in load balancer and how can I dig into or avoid this?


the hbase and hadoop version is
HBase Version0.94.0, r1332822Hadoop Version0.20.2-cdh3u1,
rbdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638
the following is a detail log about the same region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956,
and it repeats again and again.:
2012-07-16 00:12:49,843 INFO org.apache.hadoop.hbase.master.HMaster: balance
hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592
2012-07-16 00:12:49,843 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of
region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
(offlining)
2012-07-16 00:12:49,843 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Creating unassigned node for
93caf5147d40f5dd4625e160e1b7e956 in a CLOSING state
2012-07-16 00:12:49,845 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Sent CLOSE to
192.168.1.2,60020,1342017399608 for region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
2012-07-16 00:12:50,555 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_CLOSED, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,555 DEBUG
org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED
event for 93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,555 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE;
was=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
state=CLOSED, ts=1342368770556, server=192.168.1.2,60020,1342017399608
2012-07-16 00:12:50,555 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Creating (or updating) unassigned node for
93caf5147d40f5dd4625e160e1b7e956 with OFFLINE state
2012-07-16 00:12:50,558 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=M_ZK_REGION_OFFLINE, server=10.75.18.34,60000,1342017369575,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,558 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Found an existing plan
for
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
destination server is 192.168.1.2,60020,1342002082592
2012-07-16 00:12:50,558 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Using pre-existing plan
for region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.;
plan=hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592
2012-07-16 00:12:50,558 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Assigning region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
to 192.168.1.2,60020,1342002082592
2012-07-16 00:12:50,574 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENING, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,635 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENING, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,639 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENED, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,639 DEBUG
org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED
event for
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
from 192.168.1.2,60020,1342017399608; deleting unassigned node
2012-07-16 00:12:50,640 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Deleting existing unassigned node for
93caf5147d40f5dd4625e160e1b7e956 that is in expected state
RS_ZK_REGION_OPENED
2012-07-16 00:12:50,641 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: The znode of region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
has been deleted.
2012-07-16 00:12:50,641 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Successfully deleted unassigned node for
region 93caf5147d40f5dd4625e160e1b7e956 in expected state
RS_ZK_REGION_OPENED
2012-07-16 00:12:50,641 INFO
org.apache.hadoop.hbase.master.AssignmentManager: The master has opened the
region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
that was online on 192.168.1.2,60020,1342017399608
2012-07-16 00:17:49,870 INFO org.apache.hadoop.hbase.master.HMaster: balance
hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592
2012-07-16 00:17:49,870 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of
region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
(offlining)
2012-07-16 00:17:49,870 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Creating unassigned node for
93caf5147d40f5dd4625e160e1b7e956 in a CLOSING state
2012-07-16 00:17:49,872 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Sent CLOSE to
192.168.1.2,60020,1342017399608 for region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
2012-07-16 00:17:50,464 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_CLOSED, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,464 DEBUG
org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED
event for 93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,464 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE;
was=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
state=CLOSED, ts=1342369070465, server=192.168.1.2,60020,1342017399608
2012-07-16 00:17:50,464 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Creating (or updating) unassigned node for
93caf5147d40f5dd4625e160e1b7e956 with OFFLINE state
2012-07-16 00:17:50,467 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=M_ZK_REGION_OFFLINE, server=10.75.18.34,60000,1342017369575,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,467 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Found an existing plan
for
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
destination server is 192.168.1.2,60020,1342002082592
2012-07-16 00:17:50,467 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Using pre-existing plan
for region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.;
plan=hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592
2012-07-16 00:17:50,467 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Assigning region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
to 192.168.1.2,60020,1342002082592
2012-07-16 00:17:50,509 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENING, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,761 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENING, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,774 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENED, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,774 DEBUG
org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED
event for
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
from 192.168.1.2,60020,1342017399608; deleting unassigned node
2012-07-16 00:17:50,774 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Deleting existing unassigned node for
93caf5147d40f5dd4625e160e1b7e956 that is in expected state
RS_ZK_REGION_OPENED
2012-07-16 00:17:50,775 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: The znode of region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
has been deleted.
2012-07-16 00:17:50,775 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Successfully deleted unassigned node for
region 93caf5147d40f5dd4625e160e1b7e956 in expected state
RS_ZK_REGION_OPENED
2012-07-16 00:17:50,775 INFO
org.apache.hadoop.hbase.master.AssignmentManager: The master has opened the
region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
that was online on 192.168.1.2,60020,1342017399608
2012-07-16 00:22:49,916 INFO org.apache.hadoop.hbase.master.HMaster: balance
hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592"
HBASE-9968,"When we check whether the dead region is carrying root or meta, first we will check any transition znode for the region is there or not. In this case it got deleted. So from zookeeper we cannot find the region location. 
{code}
    try {
      data = ZKAssign.getData(master.getZooKeeper(), hri.getEncodedName());
    } catch (KeeperException e) {
      master.abort(""Unexpected ZK exception reading unassigned node for region=""
        + hri.getEncodedName(), e);
    }
{code}
Now we will check from the AssignmentManager whether its in online regions or not
{code}
    ServerName addressFromAM = getRegionServerOfRegion(hri);
    boolean matchAM = (addressFromAM != null &&
      addressFromAM.equals(serverName));
    LOG.debug(""based on AM, current region="" + hri.getRegionNameAsString() +
      "" is on server="" + (addressFromAM != null ? addressFromAM : ""null"") +
      "" server being checked: "" + serverName);
{code}
From AM we will get null because  while adding region to online regions we will check whether the RS is in onlineservers or not and if not we will not add the region to online regions.
{code}
      if (isServerOnline(sn)) {
        this.regions.put(regionInfo, sn);
        addToServers(sn, regionInfo);
        this.regions.notifyAll();
      } else {
        LOG.info(""The server is not in online servers, ServerName="" + 
          sn.getServerName() + "", region="" + regionInfo.getEncodedName());
      }
{code}


Even though the dead regionserver carrying ROOT region, its returning false. After that ROOT region never assigned.

Here are the logs
{code}
2013-11-11 18:04:14,730 INFO org.apache.hadoop.hbase.catalog.RootLocationEditor: Unsetting ROOT region location in ZooKeeper
2013-11-11 18:04:14,775 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for -ROOT-,,0.70236052 so generated a random one; hri=-ROOT-,,0.70236052, src=, dest=HOST-10-18-40-69,60020,1384173244404; 1 (online=1, available=1) available servers
2013-11-11 18:04:14,809 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region -ROOT-,,0.70236052 to HOST-10-18-40-69,60020,1384173244404
2013-11-11 18:04:18,375 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@12133926; serverName=HOST-10-18-40-69,60020,1384173244404
2013-11-11 18:04:26,213 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=HOST-10-18-40-69,60020,1384173244404, region=70236052/-ROOT-
2013-11-11 18:04:26,213 INFO org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for -ROOT-,,0.70236052 from HOST-10-18-40-69,60020,1384173244404; deleting unassigned node
2013-11-11 18:04:31,553 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: based on AM, current region=-ROOT-,,0.70236052 is on server=null server being checked: HOST-10-18-40-69,60020,1384173244404
2013-11-11 18:04:31,561 DEBUG org.apache.hadoop.hbase.master.ServerManager: Added=HOST-10-18-40-69,60020,1384173244404 to dead servers, submitted shutdown handler to be executed, root=false, meta=false
{code}
{code}
2013-11-11 18:04:32,323 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: The znode of region -ROOT-,,0.70236052 has been deleted.
2013-11-11 18:04:32,323 INFO org.apache.hadoop.hbase.master.AssignmentManager: The server is not in online servers, ServerName=HOST-10-18-40-69,60020,1384173244404, region=70236052
2013-11-11 18:04:32,323 INFO org.apache.hadoop.hbase.master.AssignmentManager: The master has opened the region -ROOT-,,0.70236052 that was online on HOST-10-18-40-69,60020,1384173244404
{code}"
HBASE-3792,"The TableInputFormat creates an HTable using a new Configuration object, and it never cleans it up. When running a Mapper, the TableInputFormat is instantiated and the ZK connection is created. While this connection is not explicitly cleaned up, the Mapper process eventually exits and thus the connection is closed. Ideally the TableRecordReader would close the connection in its close() method rather than relying on the process to die for connection cleanup. This is fairly easy to implement by overriding TableRecordReader, and also overriding TableInputFormat to specify the new record reader.

The leak occurs when the JobClient is initializing and needs to retrieves the splits. To get the splits, it instantiates a TableInputFormat. Doing so creates a ZK connection that is never cleaned up. Unlike the mapper, however, my job client process does not die. Thus the ZK connections accumulate.

I was able to fix the problem by writing my own TableInputFormat that does not initialize the HTable in the getConf() method and does not have an HTable member variable. Rather, it has a variable for the table name. The HTable is instantiated where needed and then cleaned up. For example, in the getSplits() method, I create the HTable, then close the connection once the splits are retrieved. I also create the HTable when creating the record reader, and I have a record reader that closes the connection when done."
HBASE-4988,"If metaserver crash now,
All the splitting regionserver will abort theirself.
Becasue the code
{code}
this.journal.add(JournalEntry.PONR);
MetaEditor.offlineParentInMeta(server.getCatalogTracker(),
            this.parent.getRegionInfo(), a.getRegionInfo(), b.getRegionInfo());
{code}
If the JournalEntry is PONR, split's roll back will abort itselef.

It is terrible in huge putting environment when metaserver crash
"
HBASE-4921,"The HTable initialization does something like this : 

{code}this.connection.locateRegion(tableName, HConstants.EMPTY_START_ROW);{code}

What is the rationale behind this ? What would happen if this region is in flight ? I ran into a problem where I disabled the first region of the table and now I can't create an HTable instance to this table.

Disabling the first region is like disabling the entire table from a client perspective. I feel this is not the correct behavior."
HBASE-4633,"Relevant Jiras: https://issues.apache.org/jira/browse/HBASE-2937,
https://issues.apache.org/jira/browse/HBASE-4003

We have been using the 'hbase.client.operation.timeout' knob
introduced in 2937 for quite some time now. It helps us enforce SLA.
We have two HBase clusters and two HBase client clusters. One of them
is much busier than the other.

We have seen a deterministic behavior of clients running in busy
cluster. Their (client's) memory footprint increases consistently
after they have been up for roughly 24 hours.
This memory footprint almost doubles from its usual value (usual case
== RPC timeout disabled). After much investigation nothing concrete
came out and we had to put a hack
which keep heap size in control even when RPC timeout is enabled. Also
note , the same behavior is not observed in 'not so busy
cluster.

The patch is here : https://gist.github.com/1288023"
HBASE-3782,"I've been testing HBASE-1861 in 0.90.2, which adds multi-family support for bulk upload tools.

I found that when running the importtsv program, some reduce tasks fail with a File Not Found exception if there are no keys in the input data which fall into the region assigned to that reduce task.  From what I can determine, it seems that an output directory is created in the write() method and expected to exist in the writeMetaData() method...if there are no keys to be written for that reduce task, the write method is never called and the output directory is never created, but writeMetaData is expecting the output directory to exist...thus the FnF exception:

2011-03-17 11:52:48,095 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.io.FileNotFoundException: File does not exist: hdfs://master:9000/awardsData/_temporary/_attempt_201103151859_0066_r_000000_0
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:468)
	at org.apache.hadoop.hbase.regionserver.StoreFile.getUniqueFile(StoreFile.java:580)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat$1.writeMetaData(HFileOutputFormat.java:186)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat$1.close(HFileOutputFormat.java:247)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:567)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:408)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)

Simply checking if the file exists should fix the issue. 

"
HBASE-4324,"Because we use a single znode for /unassigned, and we re-list it every time its contents change, assignment speed per region is O(number of unassigned regions) rather than O(1). Every time something changes about one unassigned region, the master has to re-list the entire contents of the directory inside of AssignmentManager.nodeChildrenChanged()."
HBASE-4246,"We ran into the following sequence of events:
- master startup failed after only ROOT had been assigned (for another reason)
- restarted the master without restarting other servers. Since there was at least one region assigned, it went through the failover code path
- master scanned META and inserted every region into /hbase/unassigned in ZK.
- then, it called ""listChildren"" on the /hbase/unassigned znode, and crashed with ""Packet len6080218 is out of range!"" since the IPC response was larger than the default maximum."
HBASE-2213,"right now we take the default HCD fields and 'snapshot' them into every HCD.  So things like 'BLOCKCACHE' and 'FILESIZE' are in every table, even if they don't differ from the defaults.  If the default changes in a meanful/important way, the user is left with the unenviable task of (a) determining this happened and (b) actually going through and disabling/altering the tables to fix it.

"
HBASE-16806,"In a new project checkout, Eclipse complains it cant find shaded protobufs though they src is checked in (FYI [~syuanjiang]) This issue came in with the recent commit:

{code}
commit 95c1dc93fb6780f66fd8ebb57914a050b75b9b11
Author: stack <stack@apache.org>
Date:   Mon Oct 3 21:37:32 2016 -0700

    HBASE-15638 Shade protobuf
    Which includes
...
{code}"
HBASE-14776,"We require patches to be created using 'git format-patch' or 'git diff', so patches should be tested using 'git am' or 'git apply', not 'patch -pX'. This causes false errors in the Jenkins patch tester."
HBASE-15598,"In CloneSnapshotProcedure#preCloneSnapshot():
{code}
      ProcedureSyncWait.getMasterQuotaManager(env)
        .checkNamespaceTableAndRegionQuota(getTableName(), manifest.getRegionManifestsMap().size());
{code}
Here is related code in SnapshotManifest#getRegionManifestsMap() :
{code}
    if (regionManifests == null || regionManifests.size() == 0) return null;
...
{code}
When there is no region manifest, null would be returned, resulting in NPE in CloneSnapshotProcedure#preCloneSnapshot()"
HBASE-13559,"We had some regions stay un-assigned. They were in pending open on a server that was dead. The cluster was restarted as a whole a few times and then the regions were stuck until a manual assign was performed on them.

I know timing things out has been a pain. Could we have a timeout on servers that are not alive?"
HBASE-16265,"See https://builds.apache.org/job/HBase-TRUNK_matrix/1265/jdk=latest1.8,label=yahoo-not-h2/testReport/org.apache.hadoop.hbase.spark/BulkLoadSuite/Wide_Row_Bulk_Load__Test_multi_family_and_multi_column_tests_with_one_column_family_with_custom_configs_plus_multi_region/ :
{code}
File does not exist: /tmp/junit811617169708528768/junit7419829633245108670/f1/b934f7ee0d414de5ab3457d057b9df64&#010; at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)&#010; at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)&#010; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1828)&#010; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1799)&#010; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1712)&#010; at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:587)&#010; at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:365)&#010; at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)&#010; at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)&#010; at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)&#010; at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)&#010; at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)&#010; at java.security.AccessController.doPrivileged(Native Method)&#010; at javax.security.auth.Subject.doAs(Subject.java:422)&#010; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)&#010; at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)&#010;
{code}"
HBASE-14549,"Looking at the code, I find that the logic is unnecessarily complex.
We indicate in updateReaders that the scanner stack needs to be reset. Then almost all store scanner (and derived classes) methods need to check and actually reset the scanner stack.
Compaction are rare, we should reset the scanner stack in update readers, and hence avoid needing to check in all methods.

Patch forthcoming."
HBASE-15059,Currently HBase 0.94 cannot be compiled against Hadoop 2.7.
HBASE-13667,"We can backport Split transaction, region merge transaction interfaces to branch 1.0 and 0.98 without changing coprocessor hooks. Then it should be compatible."
HBASE-15585,"While you can do all kinds of things with coprocessors, like arbitrarily discard memstore data or replace files randomly during compaction, I believe the ultimate power and flexibility is not there. The patch aims to address this shortcoming."
HBASE-15249,"AMS (Ambari Metrics System) developer found the following scenario:

Metrics table was pre-split with many regions on large cluster (1600 nodes).
After some time, AMS stopped working because region normalizer merged the regions into few big regions which were not able to serve high read / write load.
This is a big problem since the write requests flood the regions faster than the splits can happen resulting in poor performance.

We should consider setting reasonable lower bound on region count.
If the table is pre-split, we can use initial region count as the lower bound."
HBASE-5516,"Usage of GZip is leading to resident memory leak in 0.90.
We need to have something similar to HBASE-5387 in 0.90. "
HBASE-15207,"Balancer seems to have gotten stuck in 1.2.0RC1 soon after Master joins running cluster (previous Master had been killed by chaos monkey). Investigate. At least fix the crazy logging which made me notice the stuck balancer.

Last night my logs filled with this (10x256MB log files):

....
2016-02-01 11:25:26,958 DEBUG [B.defaultRpcServer.handler=9,queue=0,port=16000] balancer.BaseLoadBalancer: Lowest locality region server with non zero regions is ve0542.halxg.cloudera.com with locality 0.0
2016-02-01 11:25:26,958 DEBUG [B.defaultRpcServer.handler=9,queue=0,port=16000] balancer.BaseLoadBalancer:  Lowest locality region index is 0 and its region server contains 1 regions
...


Added by this:

commit 54028140f4f19a6af81c8c8f29dda0c52491a0c9
Author: tedyu <yuzhihong@gmail.com>
Date:   Thu Aug 13 09:11:59 2015 -0700

    HBASE-13376 Improvements to Stochastic load balancer (Vandana Ayyalasomayajula)

Looks like balancer got stuck. Logging at ten lines a millisecond.

Here is lead up. Nothing in particular jumps out. Rerun doesn't show this.

{code}
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0526.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0532.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0538.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Lowest locality region server with non zero regions is ve0540.halxg.cloudera.com with locality 0.0
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer:  Lowest locality region index is 0 and its region server contains 1 regions
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0526.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0532.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0538.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Lowest locality region server with non zero regions is ve0540.halxg.cloudera.com with locality 0.0
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer:  Lowest locality region index is 0 and its region server contains 1 regions
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0526.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0532.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0538.halxg.cloudera.com had 0 regions.
....
{code}

Nothing else is happening on this master

Happens just after a Master joins cluster after being killed by a monkey."
HBASE-13068,"I just came across in interesting exception:
{code}
Caused by: java.io.IOException: Call 10 not added as the connection newbunny/127.0.0.1:60020/ClientService/lars (auth:SIMPLE)/60000 is closing
        at org.apache.hadoop.hbase.ipc.RpcClient$Connection.addCall(RpcClient.java:495)
        at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1534)
        at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
        ... 13 more
{code}

Called from here:
{code}
        at org.apache.hadoop.hbase.client.ScannerCallable.close(ScannerCallable.java:291)
        at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:160)
        at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:115)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:91)
        at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:247)
{code}

This happened when I scanned with multiple client against a single region server when all data is filtered at the server by a filter.
I had 10 clients, the region server has 30 handles.

This means the scanners are not getting closed and their lease has to expire.

The workaround is to increase hbase.ipc.client.connection.maxidletime.
But it's strange that this *only* happens at close time. And since I am not using up all handlers there shouldn't be any starvation."
HBASE-1803,"this is a problem because we'd like to, for example, flush edits every second, yet we dont want to run all threads at a 10s interval (eg: lease checking, etc)"
HBASE-1826,"the replication level affects sync performance, so being able to tweak the r= level for HLog only can help."
HBASE-1155,"In order to guarantee that an HLog sync() flushes the data to the HDFS, we will need to invoke FSDataOutputStream.sync() per HADOOP-4379.

Currently, there is no access to the underlying FSDataOutputStream from SequenceFile.Writer, as it is a package private member.

"
HBASE-1700,"Look at the below from a cluster startup:

{code}
2009-07-24 16:42:04,013 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0006339440,1248391327448 from aa0-000-15.u.powerset.com,60020,1248453637413; 1 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0093409083,1248414246318 from aa0-000-15.u.powerset.com,60020,1248453637413; 2 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0132179111,1248393175577 from aa0-000-15.u.powerset.com,60020,1248453637413; 3 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0140578751,1248393308563 from aa0-000-15.u.powerset.com,60020,1248453637413; 4 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0037750701,1248391815865 from aa0-000-15.u.powerset.com,60020,1248453637413; 5 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0144734891,1248393369432 from aa0-000-15.u.powerset.com,60020,1248453637413; 6 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0006339440,1248391327448 from aa0-000-15.u.powerset.com,60020,1248453637413; 7 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0093409083,1248414246318 from aa0-000-15.u.powerset.com,60020,1248453637413; 8 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0132179111,1248393175577 from aa0-000-15.u.powerset.com,60020,1248453637413; 9 of 11
{code}

A regionserver, in the one report has messages reporting both region OPENING and region OPEN messages on the same region.  Regionserver should save the master work and do some edits on its side only returning the OPEN message."
HBASE-1666,"initial scan completed flag is set on scanner though it hasn't been deployed never mind scanned.  This means we pass out of safe mode soon after startup.

Even if metascanner is fixed so initialScan does not complete till after .META. has been scanned the first time, 'safe mode' seems to mess with region assignment in a way that makes it crawl.

Investigate and fix."
HBASE-934,"From Rong-en who has two regionservers:

{code}
When the second HRS starts up, but when all regions
are still not assigned to the first server. The 2nd HRS keeps
silence (though it's visible at master's ui). Once all regions are
assigned to first server, the balancer kicks in. Finally, the
regions are evenly split to two servers.
{code}

And then on IRC:

{code}
[21:38]    <rafan>    st^ack: got my mail?
[21:48]    <st^ack>    You have two HRSs?
[21:49]    <st^ack>    There is an odd decision made in the master that goes something like ""is there only one regionserver? or are there more"". If it decides the answer is 1, it just dumps all to it.
[21:49]    <st^ack>    My guess is that in your case, it decided that all regions were for server 1.
[21:50]    <st^ack>    Mind making a JIRA? Let the master parcel out the regions... the rate can vary with the number of OPEN messages it gets back.
[21:50]    <st^ack>    Allow that other regions could come in meantime? 
{code}

If many regions, master should allow that while its assigning, other regionservers could come online rather than make the binary decision ""There is only one regionserver in this cluster"""
HBASE-1742,"I killed server with -ROOT-.  It came back eventually but meantime we'd asked a server to open a region.  It failed in the below but then we never try to open the region elsewhere.
{code}
 803 2009-08-04 03:21:12,599 [regionserver/XX.XX.XX.140:60020.worker] ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: unable to process message: MSG_REGION_OPEN: TestTable,0916642860,1249356036404
 804 java.lang.reflect.UndeclaredThrowableException
 805     at $Proxy2.getRegionInfo(Unknown Source)
 806     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRootRegion(HConnectionManager.java:874)
 807     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:515)
 808     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:491)
 809     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:565)
 810     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:524)
 811     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:491)
 812     at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:125)
 813     at org.apache.hadoop.hbase.RegionHistorian.online(RegionHistorian.java:315)
 814     at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:1564)
 815     at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:1485)
 816     at java.lang.Thread.run(Unknown Source)
 817 Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: -ROOT-,,0
 818     at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2261)
 819     at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionInfo(HRegionServer.java:1741)
 820     at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
 821     at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
 822     at java.lang.reflect.Method.invoke(Unknown Source)
 823     at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
 824     at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
 825 
 826     at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:720)
 827     at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:328)
 828     ... 12 more
{code}"
HBASE-1461,"I have been playing with ZK recovery and other crash scenarios.  There is a very rare but potential bug where a region can be assigned to be open on an existing regionserver, but the regionserver itself doesn't have the region open.

The HMaster should also check the opposite of what it does - make sure that regions assigned to server X are actually _open_ on that server."
HBASE-3192,"A .META. without an HRI entry should never happen but if it does, it should not cause master shutdown (master is on a hair-trigger at mo. so that issues are noticed quickly).  HBASE-3151 fixed being able to deal w/ empty HRI.  This issue is about adding a test to verify hbase stays up (make sure chore runs and that test does meta scanning with MetaScanner and MetaReader)."
HBASE-3698,Can get them from Server Interface.
HBASE-3425,"On regionserver startup, the regionserver receives an HServerAddress from the master as a Writable.  It's a string hostname and an integer port.  Our master is also appending the port to the string, so when they are concatenated it becomes hadoopnode98:60020:60020 and the HServerAddress cannot be instantiated.  

This should probably be fixed in the master as well, but I don't know where it happens.  The attached patch handles it in the regionserver.

Regionserver startup log:

2011-01-06 15:55:48,813 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Connected to master at hadoopmaster.hotpads.srv:60000
2011-01-06 15:55:48,857 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Telling master at hadoopmaster.hotpads.srv:60000 that we are up
2011-01-06 15:55:48,910 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Config from master: hbase.regionserver.address=HadoopNode98.hotpads.srv:60020
2011-01-06 15:55:48,910 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Config from master: fs.default.name=hdfs://hadoopmaster.hotpads.srv:54310/hbase
2011-01-06 15:55:48,910 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://hadoopmaster.hotpads.srv:54310/hbase
2011-01-06 15:55:48,945 ERROR org.apache.hadoop.hbase.HServerAddress: Could not resolve the DNS name of HadoopNode98.hotpads.srv:60020:60020
2011-01-06 15:55:48,945 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: STOPPED: Failed initialization
2011-01-06 15:55:48,947 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Failed init
java.lang.IllegalArgumentException: Could not resolve the DNS name of HadoopNode98.hotpads.srv:60020:60020
        at org.apache.hadoop.hbase.HServerAddress.checkBindAddressCanBeResolved(HServerAddress.java:105)
        at org.apache.hadoop.hbase.HServerAddress.<init>(HServerAddress.java:76)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.handleReportForDutyResponse(HRegionServer.java:798)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.tryReportForDuty(HRegionServer.java:1394)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:522)
        at java.lang.Thread.run(Thread.java:619)"
HBASE-2354,we should use the old code which is more efficient and may have better error reporting for small number of commit rows. 
HBASE-2356,"we need a better test for this and a fix. i have seen, and have heard other people complain, about situations when regions move and the client does not seem to always relocate the region properly in a post HBASE-2066 hbase client.  I have seen cases where this DOES work so there is investigation to be done."
HBASE-2800,"TestMergeMeta and TestMergeTool both fail in hudson yet pass on local workstations.  Looking at the error for TestMergeMeta, the test complains '.META.' is online and thus cannot merge, but according to the code, these regions are being closed after they were created, and the mini HBase cluster is not started.  

"
HBASE-2671,"{code}java.lang.NullPointerException
    at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:351)
    at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:313)
    at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:176)
    at org.apache.hadoop.ipc.Client.getConnection(Client.java:860)
    at org.apache.hadoop.ipc.Client.call(Client.java:720)
    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
    at $Proxy7.getProtocolVersion(Unknown Source)
    at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
    at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
    at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
    at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
    at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:95)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:746)
    at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.init(MiniHBaseCluster.java:161)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:427)
    at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.run(MiniHBaseCluster.java:169)
    at java.lang.Thread.run(Thread.java:619)
{code}

See log attached to hbase-2614 for better context.

This issue is likely related to HBASE-2425, ""Crossport HADOOP-1849 rpc fix""

Brought it into 0.21."
HBASE-3898,It hangs for 15 minutes.  I see a NPE trying to split a region.  The splitKey passed is null.  Looks to be by-product of recent compaction refactorings.
HBASE-2493,"We use it in an unsafe manner in  HBasedBackedTransactionalLogger and in IndexedRegion. On upgrading from 20.1 to 0.20.4-RC I start to get CME's in HTable.

Fix by moving to an HTablePool."
HBASE-2232,"The following code, which attempts to insert certain number of rows into a table. 
This is running with hbase 0.20.3 after downloading without changing config.
Does not work if there is more than 500K or so rows .
I can see data being created in $HBASE_HOME/TestTable/xxxx/test_family where xxxx is a number. 
But the data disappear once it get 3  files of size around 16MB.
I guess it is being compacted or moved to somewhere ? But I see nothing in $HBASE_HOME/TestTable/compaction.dir.

To create 2Million rows , run it as  java  Test 2000
To create 10 Millions rows, run it as java Test 10000


import java.io.*;
import java.util.*;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.io.BatchUpdate;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.HBaseAdmin;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.ResultScanner;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.util.Bytes;

public class Test{

    public static HTable getTable(HBaseConfiguration config, String tableName, String[] columnFamilies)throws IOException{
	HBaseAdmin admin  = new HBaseAdmin(config);	
	createTable(admin, tableName, columnFamilies);
	HTable table =  new HTable(config, tableName);	
	table.setAutoFlush(false);
	table.setWriteBufferSize(1024*1024*12);
	return table;
    }

    public static boolean createTable(HBaseAdmin admin, String tableName, String[] columnFamilies)throws IOException{
	if(admin.tableExists(tableName))return false;
	HTableDescriptor desc  = new HTableDescriptor(tableName);
	for(String s : columnFamilies){
	    HColumnDescriptor col = new HColumnDescriptor(s.getBytes());
	    col.setMaxVersions(1);
	    desc.addFamily(col);
	}
	admin.createTable(desc);
	return true;
    }
    
    public static void test_serial_insert(HTable table, String family, int count)throws IOException{ 
	byte[] bf = Bytes.toBytes(family);
	for(int i = 0; i < count; i++){
	    int  id          = i;
	    byte[] qualifier = Bytes.toBytes(i); // ""i""
	    byte[] key       = Bytes.toBytes(i);
	    byte[] val       = Bytes.toBytes(i);
	    Put put = new Put(key);
	    put.setWriteToWAL(false); 
	    put.add(bf, qualifier, 0, val); 
	    table.put(put);
	    if( (i+1) % 1000000 == 0){System.out.println( (i+1)/1000000 +  ""  M""); }
	}
	table.flushCommits();
    }

    public static void count(HTable table)throws IOException{
	Scan scan = new Scan();
	ResultScanner scanner = table.getScanner(scan);       
	Result result = null;
	int i = 0;
	while( (result = scanner.next()) != null  ){
	    byte[] key  = result.getRow();
	    ++i;
	    if(i % 10000 == 0)System.out.println(i);
	}
	System.out.println(""TOTAL========== ""+i);
    }

    public static void removeTable(HBaseAdmin admin, String tableName)throws IOException{
	if(!admin.tableExists(tableName))return;
	admin.disableTable(tableName);
	admin.deleteTable(tableName);
    }
    
    public static void main(String[] args)throws Exception{
	int k = 1000;
	boolean insert = true;
	if(args.length > 0){
	    if(""read"".equals(args[0]))insert = false;
	    else k = Integer.parseInt(args[0]);
	}
	
	HBaseConfiguration config = new HBaseConfiguration();
	String tableName = ""TestTable"";
	String familyName = ""test_family"";
	HBaseAdmin admin  = new HBaseAdmin(config);
	removeTable(admin, tableName);
	HTable table = getTable(config, tableName, new String[]{familyName});
	if(insert)test_serial_insert(table, familyName, k*1000);
	count(table);
    }
"
HBASE-2278,"My tests have picked up a regression on branch:

test:
     [echo] contrib: indexed
...
    [junit] Running org.apache.hadoop.hbase.regionserver.TestHRegionWithIdxRegionNoIndexes
    [junit] Tests run: 41, Failures: 1, Errors: 0, Time elapsed: 18.382 sec
    [junit] Test org.apache.hadoop.hbase.regionserver.TestHRegionWithIdxRegionNoIndexes FAILED


Error Message

i=101 expected:<1000> but was:<0>

Stacktrace

junit.framework.AssertionFailedError: i=101 expected:<1000> but was:<0>
	at org.apache.hadoop.hbase.regionserver.TestHRegion.testWritesWhileGetting(TestHRegion.java:2085)

"
HBASE-3933,"NullPointerException while hmaster starting.
{code}
      java.lang.NullPointerException
        at java.util.TreeMap.getEntry(TreeMap.java:324)
        at java.util.TreeMap.get(TreeMap.java:255)
        at org.apache.hadoop.hbase.master.AssignmentManager.addToServers(AssignmentManager.java:1512)
        at org.apache.hadoop.hbase.master.AssignmentManager.regionOnline(AssignmentManager.java:606)
        at org.apache.hadoop.hbase.master.AssignmentManager.processFailover(AssignmentManager.java:214)
        at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:402)
        at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:283)
{code}"
HBASE-14659,"As i said in HBASE-14654
This testcase was hanged twice recently.   

the two QA information:
https://builds.apache.org/job/PreCommit-HBASE-Build/16118/console
https://builds.apache.org/job/PreCommit-HBASE-Build/16117/console

I notice that the two QA running simultaneously on same machine H0.
I doubt If there are some common resources the two QA conflicts.

"
HBASE-7755,"I was looking at and profiling the BlockEncoding code to figure out how to make it faster. One issue that jumped out was we call ByteBuffer.allocate(...) for each single KV.
As an experiment I tried using the MemStoreLAB code to allocate those buffers.

Here are some preliminary numbers, all scanning 10m rows (all in cache):
* no encoding: 5.2s
* FAST_DIFF without patch: 7.3s
* FAST_DIFF with patch and small LAB: 4.1s
* FAST_DIFF with patch and large LAB: 11s

So this is very sensitive to the right sizing of the LAB.

Need to do a bit more testing, but it seems that there is a chance to actually make scanning with block encoding faster than without!
"
HBASE-12325,"If there are several snapshots exported to a single directory, it's nice to be able to remove the oldest one. Since snapshots in the same directory can share files it's not as simple as just removing all files in a snapshot."
HBASE-9904,"The HTable client cannot retry a scan operation in the getRegionServerWithRetries code path.
This will result in the client missing data. This can be worked around using hbase.client.retries.number to 1.

The whole problem is that Callable knows nothing about retries and the protocol it dances to as well doesn't support retires.
This fix will keep Callable protocol (ugly thing worth merciless refactoring) intact but will change
ScannerCallable to anticipate retries. What we want is to make failed operations to be identities for outside world:
N1 , N2 , F3 , N3 , F4 , F4 , N4 ... = N1 , N2 , N3 , N4 ...
where Nk are successful operation and Fk are failed operations."
HBASE-5210,"We run an overnight map/reduce job that loads data from an external source and adds that data to an existing HBase table.  The input files have been loaded into hdfs.  The map/reduce job uses the HFileOutputFormat (and the TotalOrderPartitioner) to create HFiles which are subsequently added to the HBase table.  On at least two separate occasions (that we know of), a range of output would be missing for a given day.  The range of keys for the missing values corresponded to those of a particular region.  This implied that a complete HFile somehow went missing from the job.  Further investigation revealed the following:

 * Two different reducers (running in separate JVMs and thus separate class loaders)
 * in the same server can end up using the same file names for their
 * HFiles.  The scenario is as follows:
 * 	1.	Both reducers start near the same time.
 * 	2.	The first reducer reaches the point where it wants to write its first file.
 * 	3.	It uses the StoreFile class which contains a static Random object 
 * 		which is initialized by default using a timestamp.
 * 	4.	The file name is generated using the random number generator.
 * 	5.	The file name is checked against other existing files.
 * 	6.	The file is written into temporary files in a directory named
 * 		after the reducer attempt.
 * 	7.	The second reduce task reaches the same point, but its StoreClass
 * 		(which is now in the file system's cache) gets loaded within the
 * 		time resolution of the OS and thus initializes its Random()
 * 		object with the same seed as the first task.
 * 	8.	The second task also checks for an existing file with the name
 * 		generated by the random number generator and finds no conflict
 * 		because each task is writing files in its own temporary folder.
 * 	9.	The first task finishes and gets its temporary files committed
 * 		to the ""real"" folder specified for output of the HFiles.
 *     10.	The second task then reaches its own conclusion and commits its
 * 		files (moveTaskOutputs).  The released Hadoop code just overwrites
 * 		any files with the same name.  No warning messages or anything.
 * 		The first task's HFiles just go missing.
 * 
 *  Note:  The reducers here are NOT different attempts at the same 
 *  	reduce task.  They are different reduce tasks so data is
 *  	really lost.

I am currently testing a fix in which I have added code to the Hadoop 
FileOutputCommitter.moveTaskOutputs method to check for a conflict with
an existing file in the final output folder and to rename the HFile if
needed.  This may not be appropriate for all uses of FileOutputFormat.
So I have put this into a new class which is then used by a subclass of
HFileOutputFormat.  Subclassing of FileOutputCommitter itself was a bit 
more of a problem due to private declarations.

I don't know if my approach is the best fix for the problem.  If someone
more knowledgeable than myself deems that it is, I will be happy to share
what I have done and by that time I may have some information on the
results."
HBASE-14113,"mvn package -DskipTests

Compile failed!  

{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.2:compile (default-compile) on project hbase-client: Compilation failure: Compilation failure:
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/BinaryComparator.java:[54,3] method does not override or implement a method from a supertype
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/NullComparator.java:[64,3] method does not override or implement a method from a supertype
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/LongComparator.java:[51,5] method does not override or implement a method from a supertype
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/BitComparator.java:[137,3] method does not override or implement a method from a supertype
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/BinaryPrefixComparator.java:[56,3] method does not override or implement a method from a supertype
{code}

My java version:
{code}
java version ""1.8.0_40""
Java(TM) SE Runtime Environment (build 1.8.0_40-b25)
Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, mixed mode)
{code}


"
HBASE-9939,"Under load when I disabled network interface, all HBase threads were locked out.  I was expecting these threads to be released based on client.operation.timeout and rpc,timeout.

Here is a link for  thread dump.
https://www.dropbox.com/s/y1ng3yoywq09x2u/HBaseClient_Threaddump.txt

"
HBASE-6153,"I had a RS crash with the following:

2012-05-31 18:34:42,534 DEBUG org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://ip-10-140-14-134.ec2.internal:8020/apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/.tmp/294a7a31f04949b8bf07682a43157b35 to hdfs://ip-10-140-14-134.ec2.internal:8020/apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/f1/294a7a31f04949b8bf07682a43157b35
2012-05-31 18:34:42,536 WARN org.apache.hadoop.hbase.regionserver.Store: Unable to rename hdfs://ip-10-140-14-134.ec2.internal:8020/apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/.tmp/294a7a31f04949b8bf07682a43157b35 to hdfs://ip-10-140-14-134.ec2.internal:8020/apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/f1/294a7a31f04949b8bf07682a43157b35
2012-05-31 18:34:42,541 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: ABORTING region server ip-10-68-7-146.ec2.internal,60020,1338343120038: Replay of HLog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: TestLoadAndVerify_1338488017181,\x15\xD9\x01\x00\x00\x00\x00\x00/000087_0,1338491364569.8974506aa04c5a04e5cc23c11de0039d.
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1288)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1172)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1114)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:400)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:374)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:243)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.FileNotFoundException: File does not exist: /apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/f1/294a7a31f04949b8bf07682a43157b35
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1901)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.<init>(DFSClient.java:1892)
        at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:636)
        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:154)
        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:427)
        at org.apache.hadoop.hbase.io.hfile.HFile.createReader(HFile.java:387)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.<init>(StoreFile.java:1008)
        at org.apache.hadoop.hbase.regionserver.StoreFile.open(StoreFile.java:470)
        at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:548)
        at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:595)


On the NameNode logs:
2012-05-31 18:34:42,588 WARN org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.unprotectedRenameTo: failed to rename /apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/.tmp/294a7a31f04949b8bf07682a43157b35 to /apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/f1/294a7a31f04949b8bf07682a43157b35 because destination's parent does not exist


I haven't looked deeply yet but I guess it is a race of some sort.
"
HBASE-3138,"Testing rolling restart i turned up the following condition.

Master is joining an extant cluster and is trying to clean up RIT.  Then the server hosting .META. is shutdown in the middle of it all.  Deal.  Here is exception.

{code}
2010-10-21 06:45:58,592 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=sv2borg187,60020,1287643131919, region=efcd899283e96f20faa317772f52adca
2010-10-21 06:45:58,616 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
org.apache.hadoop.ipc.RemoteException: java.io.IOException: Server not running
    at org.apache.hadoop.hbase.regionserver.HRegionServer.checkOpen(HRegionServer.java:2198)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1499)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:561)
    at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025)

    at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:749)
    at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:255)
    at $Proxy1.get(Unknown Source)
    at org.apache.hadoop.hbase.catalog.MetaReader.getRegion(MetaReader.java:286)
    at org.apache.hadoop.hbase.master.AssignmentManager.processRegionInTransition(AssignmentManager.java:250)
    at org.apache.hadoop.hbase.master.AssignmentManager.processFailover(AssignmentManager.java:209)
    at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:392)
    at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:268)
2010-10-21 06:45:58,617 INFO org.apache.hadoop.hbase.master.HMaster: Aborting
{code}"
HBASE-8064,"when hconnection is used by one matchine,the connection return to the pool. if anather matchine reget the connection,it can be resued.
but in the code the caching map don't be managered correctly"
HBASE-6144,"RS abcdn0590 is live, but Master does not have it on its onlineserver list. So, Master put up the hlog for splitting as shown in the Master log below:
{code}
2012-05-17 21:43:57,692 INFO org.apache.hadoop.hbase.master.SplitLogManager: task /hbase/splitlog/hdfs%3A%2F%2Fnamenode.xyz.com%2Fhbase%2F.logs%2Fabcdn0590.xyz.com%2C60020%2C1337315957185-splitting%2Fabcdn0590.xyz.com%252C60020%252C1337315957185.1337315957711 acquired by abcdn0770.xyz.com,60020,1337315956278. 
{code}

After splitting succeeded, Master deleted the file:
{code}
2012-05-17 21:43:58,721 DEBUG org.apache.hadoop.hbase.master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitlog/hdfs%3A%2F%2Fnamenode.xyz.com%2Fhbase%2F.logs%2Fabcdn0590.xyz.com%2C60020%2C1337315957185-splitting%2Fabcdn0590.xyz.com%252C60020%252C1337315957185.1337315957711
{code}

RS abcdn0590 lost the lease to RS abcdn0770, and try to do a Log Roller which closes the current hlog, and create a new one, as shown in the namenode log:
{code}
2012-05-17 21:43:58,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(newblock=blk_2867982016684075739_12741027, file=/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185-splitting/abcdn0590.xyz.com%2C60020%2C1337315957185.1337315957711, newgenerationstamp=12911920, newlength=134, newtargets=[10.115.13.24:50010, 10.115.15.46:50010, 10.115.15.23:50010]) successful
2012-05-17 21:43:59,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.logs/abcdn0590.xyz.com,60020,1337315957185/abcdn0590.xyz.com%2C60020%2C1337315957185.1337316238882. blk_3811725326431482476_12913541{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.115.13.24:50010|RBW], ReplicaUnderConstruction[10.115.17.18:50010|RBW], ReplicaUnderConstruction[10.115.17.15:50010|RBW]]}
{code}
 
When RS 0590 try to close the old hlog 1337315957711, it received fatal error below due to the original hlog is already deleted. The fatal error will cause RS abcdn0590 to shutdown itself later.
{code}
2012-05-17 21:43:58,889 ERROR org.apache.hadoop.hbase.master.HMaster: Region server ^@^@abcdn0590.xyz.com,60020,1337315957185 reported a fatal error:
ABORTING region server abcdn0590.xyz.com,60020,1337315957185: IOE in log roller
Cause:
java.io.FileNotFoundException: File does not exist: hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185/abcdn0590.xyz.com%2C60020%2C1337315957185.1337315957711
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:742)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.rollWriter(HLog.java:583)
        at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:94)
{code}
 
RS abcdn0590 shutdown at around 21:44. But in the /hbase/.logs dir, it left two sub folder for the RS abcdn0590 with the same startcode 1337315957185 , they are
路         /hbase/.logs/abcdn0590.xyz.com,60020,1337315957185-splitting/
路         /hbase/.logs/abcdn0590.xyz.com,60020,1337315957185/
 
Later on, at around 21:46:30, Master retry log splitting, this time,  it still consider RS abcdn0590 as dead RS and try to put up its hlog for others to grab and split. It finds the folder /hbase/.logs/abcdn0590.xyz.com,60020,1337315957185/, and the first step it does is to rename it to adding suffix of 鈥搒plitting.  However, the same folder already exist. The rename function does not handle the case where the destination folder already exist, instead, the behavior is putting the src folder under the dst folder, so the path structure looks like dst/src/file. In our case, It is /hbase/.logs.20120518.1204/abcdn0590.xyz.com,60020,1337315957185-splitting/abcdn0590.xyz.com,60020,1337315957185/abcdn0590.xyz.com%2C60020%2C1337315957185.1337316238882.
 
This is from the master log, we can see that two folders for the same RS 0590 at same startcode exists:
{code}
2012-05-17 21:46:30,749 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1329941607395-splitting doesn't belong to a known region server, splitting
2012-05-17 21:46:30,749 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185 doesn't belong to a known region server, splitting
2012-05-17 21:46:30,749 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185-splitting doesn't belong to a known region server, splitting
 
2012-05-17 21:46:30,962 DEBUG org.apache.hadoop.hbase.master.MasterFileSystem: Renamed region directory: hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185-splitting
{code}

 "
HBASE-5805,"Trace:

java.lang.AssertionError: Results should contain region test,ccc,1334638013935.b9d77206f6eb226928b898e66fd1d508. for row 'ccc'
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.verifyRegionResults(TestServerCustomProtocol.java:363)
	at org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.testNullReturn(TestServerCustomProtocol.java:330)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)"
HBASE-5779,"Steps to reproduce: 
- change permission of /hbase to a user other than one running hbase
- delete hbase.id if already exists
- start master, it will try to create cluster ID file in /hbase and fail while doing so with org.apache.hadoop.security.AccessControlException

From this point it will go to infinite loop. 

Reason: org.apache.hadoop.hbase.util.FSUtils.setClusterId  has a wait > 0 and no control over retries when called during master initialization. 

Quoting : checkRootDir in MasterFileSystem
{noformat}
// Make sure cluster ID exists
    if (!FSUtils.checkClusterIdExists(fs, rd, c.getInt(
        HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000))) {
      FSUtils.setClusterId(fs, rd, UUID.randomUUID().toString(), c.getInt(
          HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000));
    }

{noformat}
"
HBASE-4822,"TestCoprocessorEndpoint is failing intermittently in Jenkins.  The errors are all similar to:
{noformat}
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint
-------------------------------------------------------------------------------
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 30.562 sec <<< FAILURE!
testAggregation(org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint)  Time elapsed: 0.069 sec  <<< FAILURE!
java.lang.AssertionError: Invalid result expected:<180> but was:<190>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.testAggregation(TestCoprocessorEndpoint.java:149)
{noformat}"
HBASE-5092,"  
Region is in PENDING_OPEN state and disable and enable are blocked.

We occasionally find if two assignments which have a short interval time will lead to a PENDING_OPEN state staying in the regionInTransition map and blocking the disable and enable table actions.

We found that the second assignment will set the zknode of this region to M_ZK_REGION_OFFLINE then set the state in assignmentMananger's regionInTransition map to PENDING_OPEN and abort its further operation because of finding the the region is already in the regionserver by a RegionAlreadyInTransitionException.
At the same time the first assignment is tickleOpening and find the version of the zknode is messed up by the  second assignment, so the OpenRegionHandler print out the following two lines:

{noformat} 
2011-12-23 22:12:15,197 WARN  [RS_OPEN_REGION-data16,59892,1324649528415-0] zookeeper.ZKAssign(788): regionserver:59892-0x1346b43b91e0002 Attempt to transition the unassigned node for 15237599c632752b8cfd3d5a86349768 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING failed, the node existed but was version 2 not the expected version 1
2011-12-23 22:12:15,197 WARN  [RS_OPEN_REGION-data16,59892,1324649528415-0] handler.OpenRegionHandler(403): Failed refreshing OPENING; region=15237599c632752b8cfd3d5a86349768, context=post_region_open
{noformat} 

After that it tries to turn the state to FAILED_OPEN, but also failed due to wrong version,

this is the output:

{noformat} 
2011-12-23 22:12:15,199 WARN  [RS_OPEN_REGION-data16,59892,1324649528415-0] zookeeper.ZKAssign(812): regionserver:59892-0x1346b43b91e0002 Attempt to transition the unassigned node for 15237599c632752b8cfd3d5a86349768 from RS_ZK_REGION_OPENING to RS_ZK_REGION_FAILED_OPEN failed, the node existed but was in the state M_ZK_REGION_OFFLINE set by the server data16,59892,1324649528415
2011-12-23 22:12:15,199 WARN  [RS_OPEN_REGION-data16,59892,1324649528415-0] handler.OpenRegionHandler(307): Unable to mark region {NAME => 'table1,,1324649533045.15237599c632752b8cfd3d5a86349768.', STARTKEY => '', ENDKEY => '', ENCODED => 15237599c632752b8cfd3d5a86349768,} as FAILED_OPEN. It's likely that the master already timed out this open attempt, and thus another RS already has the region.
{noformat} 

So after all that, the PENDING_OPEN state is left in the assignmentMananger's regionInTransition map and none will deal with it further,
This kind of situation will wait until the master find the state out of time.


The following is the test code:

{code:title=test.java|borderStyle=solid}
@Test
  public void testDisableTables() throws IOException {
    for (int i = 0; i < 20; i++) {
      HTableDescriptor des = admin.getTableDescriptor(Bytes.toBytes(table1));
      List<HRegionInfo> hris = TEST_UTIL.getHBaseCluster().getMaster()
          .getAssignmentManager().getRegionsOfTable(Bytes.toBytes(table1));
      TEST_UTIL.getHBaseCluster().getMaster()
          .assign(hris.get(0).getRegionName());
  
      TEST_UTIL.getHBaseCluster().getMaster()
          .assign(hris.get(0).getRegionName());
  
      admin.disableTable(Bytes.toBytes(table1));
      admin.modifyTable(Bytes.toBytes(table1), des);
      admin.enableTable(Bytes.toBytes(table1));
    }
  }

{code}

To fix this,we add a line to 

public static int ZKAssign.transitionNode() to make endState.RS_ZK_REGION_FAILED_OPEN transition pass.

{code:title=ZKAssign.java|borderStyle=solid}
   if((!existingData.getEventType().equals(beginState))
      //add the following line to make endState.RS_ZK_REGION_FAILED_OPEN transition pass.
      &&(!endState.equals(endState.RS_ZK_REGION_FAILED_OPEN))) {
      LOG.warn(zkw.prefix(""Attempt to transition the "" +
        ""unassigned node for "" + encoded +
        "" from "" + beginState + "" to "" + endState + "" failed, "" +
        ""the node existed but was in the state "" + existingData.getEventType() +
        "" set by the server "" + serverName));
      return -1;
    }
{code}

Run the test case again we found that before the first assignment trans the state from offline to opening, the second assignment could set the state to offline again and messed up the version of zknode.


In OpenRegionHandler.process() the following part failed and make the process() return.
{code:title=OpenRegionHandler.java|borderStyle=solid}
 if (!transitionZookeeperOfflineToOpening(encodedName,
          versionOfOfflineNode)) {
        LOG.warn(""Region was hijacked? It no longer exists, encodedName="" +
          encodedName);
        return;
{code}      }

//So we add the following code to the part to make this open region process to FAILED_OPEN.

{code:title=OpenRegionHandler.java|borderStyle=solid}
 if (!transitionZookeeperOfflineToOpening(encodedName,
          versionOfOfflineNode)) {
        LOG.warn(""Region was hijacked? It no longer exists, encodedName="" +
          encodedName);
        tryTransitionToFailedOpen(regionInfo);
        return;
      }
{code}

After the two amendments, two adjacent assignments will not lead to an unhandled PENDING_OPEN state.
"
HBASE-4866,"NPE encountered in users's HMaster logs:

{code}
11/11/22 23:45:37 FATAL master.HMaster: Unhandled exception. Starting shutdown.
java.lang.NullPointerException
   at org.apache.hadoop.hbase.master.AssignmentManager.regionOnline(AssignmentManager.java:731)
   at org.apache.hadoop.hbase.master.AssignmentManager.processFailover(AssignmentManager.java:215)
   at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:422)
   at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:295)
{code}

From user list: http://mail-archives.apache.org/mod_mbox/hbase-user/201111.mbox/%3C4ECC9AFC.6030307%40qualtrics.com%3E
"
HBASE-4590,"In the following case:

1.first,kill all the regionservers
2.then, start all the regionservers immediately
3.then, kill all the regionservers immediately
4.then, start all the regionservers immediately

Master may assign META region twice , and make two regionserver carrying META region.

Through logs, we find that:
Before 1, Regionserver A carrys the META region,

Between 2 and 3 , master receives Regionserver A startup message and is ready to assign meta region to Regionserver B

But, it fails because of 3, and then reassign meta region to Regionserver C,Then ,it is successful after 4,

when 4 , Regionserver C is started earlier than Regionserver A , and Regionserver A is started earlier than Regionserver C successfully online the META region. Therefore, when master receives Regionserver A startup message in 4, it consider Regionserver A carryed META region through  CatalogTracker and create a MetaServerShutdownHandler

In MetaServerShutdownHandler's process(), after completing split hlog, Regionserver C has already onlined META region,
however it will execute the following code all the same where isCarryingMeta() return true :
if (isCarryingMeta())this.services.getAssignmentManager().assignMeta();

After that, META region will online on two regionservers


In order to prevent it , we should verify meta region location before assign Meta region .
"
HBASE-7116,"org.apache.hadoop.hbase.TestZooKeeper unit tests were failed with testClientSessionExpired method as follwoing:

---------------------------------------------------------

Tests run: 5, Failures: 1, Errors: 0, Skipped: 0

testClientSessionExpired(org.apache.hadoop.hbase.TestZooKeeper)

java.lang.AssertionError:
at org.apache.hadoop.hbase.TestZooKeeper.testClientSessionExpired(TestZooKeeper.java:114)

impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-datanode.properties, hadoop-metrics2.properties
2012-01-22 01:44:45,764 WARN  [main] util.MBeans(59): Hadoop:service=DataNode,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
2012-01-22 01:46:07,153 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(336): org.apache.hadoop.hbase.TestZooKeeper-0x135015e9f9e000d Received Disconnected from ZooKeeper, ignoring
2012-01-22 01:46:07,157 WARN  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@55565556] datanode.DataXceiverServer(138): DatanodeRegistration(127.0.0.1:41145, storageID=DS-1858213200-9.123.196.159-41145-1327167899969, infoPort=36485, ipcPort=55138):DataXceiveServer:java.nio.channels.AsynchronousCloseException

Shutting down DataNode 0
2012-01-22 01:46:08,160 WARN  [main] util.MBeans(73): Hadoop:service=DataNode,name=FSDatasetState-UndefinedStorageId-1051654067
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-UndefinedStorageId-1051654067
"
HBASE-7868,"By HFilePerformanceEvaluation seems that 0.94 is slower then 0.92

Looking at the profiler for the Scan path, seems that most of the time, compared to 92, is spent in the metrics dictionary lookup. [~eclark] pointed out the new per family/block metrics.

By commenting the metrics call in HFileReaderV2, the performance seems to get better, but maybe metrics is not the only problem."
HBASE-13110,"TestCoprocessorEndpoint hangs with repeated RPC retries (RpcRetryingCallerImpl.callWithRetries) after the ProtobufCoprocessorService throws the test exception. Looks like a change on trunk has broken TestCoprocessorEndpoint.

jstack of interest:
{noformat}
""main"" prio=5 tid=0x00007f87eb003000 nid=0x1303 in Object.wait() [0x0000000105173000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        - waiting on <0x00000007c91aedf8> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:162)
        - locked <0x00000007c91aedf8> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.callExecService(RegionCoprocessorRpcChannel.java:
95)
        at org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.callBlockingMethod(CoprocessorRpcChannel.java:73)
        at org.apache.hadoop.hbase.ipc.protobuf.generated.TestRpcServiceProtos$TestProtobufRpcProto$BlockingStub.error(TestRpcServiceProtos.java:378)
        at org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.testCoprocessorError(TestCoprocessorEndpoint.java:308)
{noformat}

Tail of the log has entries like:
{noformat}
2015-02-25 18:50:03,659 DEBUG [B.defaultRpcServer.handler=3,queue=0,port=56093] ipc.CallRunner(110): B.defaultRpcServer.handler=3,queue=0,port=56093: callId: 75 service: ClientService methodName: ExecService size: 141 connection: 10.3.31.30:56149
java.io.IOException: Test exception
	at org.apache.hadoop.hbase.coprocessor.ProtobufCoprocessorService.error(ProtobufCoprocessorService.java:64)
	at org.apache.hadoop.hbase.ipc.protobuf.generated.TestRpcServiceProtos$TestProtobufRpcProto.callMethod(TestRpcServiceProtos.java:210)
	at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:6883)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.execServiceOnRegion(RSRpcServices.java:1696)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.execService(RSRpcServices.java:1678)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:31309)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2038)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)
{noformat}"
HBASE-13249,"In refreshCache, if step 3 fails for some reason, the successive call may return success directly but the cache is already corrupt (got cleared in the previous failed call):
{quote}
    // 1. update the modified time
    this.lastModifiedTime = lastTimestamp;

    // 2.clear the cache
    this.cache.clear();
    Map<String, SnapshotDirectoryInfo> known = new HashMap<String, SnapshotDirectoryInfo>();

    // 3. check each of the snapshot directories
{quote}

This will cause files got deleted unexpectedly."
HBASE-5289,"This might happen on heavy load in case of lagging HBase when sharing one HConnection by multiple threads:

{noformat}
2012-01-26 13:59:38,396 ERROR [http://*:8080-251-EventThread] zookeeper.ClientCnxn$EventThread(532): Error while calling watcher
java.lang.NullPointerException
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.resetZooKeeperTrackers(HConnectionManager.java:533)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.abort(HConnectionManager.java:1536)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:344)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:262)
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:530)
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:506)
{noformat}

The following code is not protected against NPE:

{code}
    private synchronized void resetZooKeeperTrackers()
        throws ZooKeeperConnectionException {
      LOG.info(""Trying to reconnect to zookeeper"");
      masterAddressTracker.stop();
      masterAddressTracker = null;
      rootRegionTracker.stop();
      rootRegionTracker = null;
      clusterId = null;
      this.zooKeeper = null;
      setupZookeeperTrackers();
    }
{code}

In some cases as proven by the log snippet above it might happen that either masterAddressTracker or rootRegionTracker might be null.
Because of the NPE the code can't reach setupZookeeperTrackers() call.

This should be fixed at least the way as shown in one of the patches in HBASE-5153

{code}
      LOG.info(""Trying to reconnect to zookeeper."");
      if (this.masterAddressTracker != null) {
        this.masterAddressTracker.stop();
        this.masterAddressTracker = null;
      }
      if (this.rootRegionTracker != null) {
        this.rootRegionTracker.stop();
        this.rootRegionTracker = null;
      }
{code}"
HBASE-9066,"This new test has failed a few times over last day or so.

Here is a sample w/ two fails in it.

http://54.241.6.143/job/HBase-0.95/707/

Hope you don't mind me assigning it to you Chris.

I'm going to disable these two tests for now so can get some good test runs in over the w/e.  Thanks boss."
HBASE-9292,"Running some simple loading tests i ran into the following running on hadoop-2.1.0-beta.

{code}
2013-08-20 16:51:56,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2013-08-20 16:51:56,314 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 655761 synced till here 655750
2013-08-20 16:51:56,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042714402 with entries=985, filesize=122.5 M; new WAL /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716311
2013-08-20 16:51:56,378 WARN  [Thread-4788] hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716311 could only be replicated to 0 nodes instead of minReplication (=1).  There are 5 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2458)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:525)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:387)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59582)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)

        at org.apache.hadoop.ipc.Client.call(Client.java:1347)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at $Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1220)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1073)
...
{code}

Thereafter the server is up but useless and can't go down because it just keeps doing this:


{code}
2013-08-20 16:51:56,380 FATAL [RpcServer.handler=3,port=60020] wal.FSHLog: Could not sync. Requesting roll of hlog
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716311 could only be replicated to 0 nodes instead of minReplication (=1).  There are 5 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2458)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:525)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:387)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59582)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)

        at org.apache.hadoop.ipc.Client.call(Client.java:1347)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at $Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1220)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1073)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:509)
...
{code}

It goes on like this for ever.

here is a bit more log:

{code}
2013-08-21 04:30:07,932 ERROR [regionserver60020.logSyncer] wal.FSHLog: Error while syncing, requesting close of hlog
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716482 could only be replicated to 0 nodes instead of minReplication (=1).  There are 5 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2458)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:525)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:387)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59582)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)

        at org.apache.hadoop.ipc.Client.call(Client.java:1347)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at $Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1220)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1073)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:509)
                                                                                                                                                                                          2993503,2-9   Bot
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)

        at org.apache.hadoop.ipc.Client.call(Client.java:1347)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at $Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1220)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1073)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:509)
2013-08-21 04:30:07,932 FATAL [regionserver60020.logSyncer] wal.FSHLog: Could not sync. Requesting roll of hlog
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716482 could only be replicated to 0 nodes instead of minReplication (=1).  There are 5 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2458)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:525)
{code}

We broke something in here (hadoop-2.0.1-beta going bad of a sudden is interesting tooo)"
HBASE-12846,"Several cases in TestZKLessAMOnCluster frequently fail with timeouts.

On Jenkins: https://builds.apache.org/job/HBase-0.98/791/testReport/

Locally, when failing:

Running org.apache.hadoop.hbase.master.TestZKLessAMOnCluster
Tests run: 17, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 842.524 sec <<< FAILURE! - in org.apache.hadoop.hbase.master.TestZKLessAMOnCluster

Locally, when passing:

Running org.apache.hadoop.hbase.master.TestZKLessAMOnCluster
Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.072 sec - in org.apache.hadoop.hbase.master.TestZKLessAMOnCluster
"
HBASE-12880,"During my work on patch HBASE-7332 I stumbled on strange behaviour in RegionStates. Split region doesn't removed from regionStates in regionOffline() method and RegionState for this region sits in regionStates map indefinitely long (until RS rebooted).
(that is clearly seen in HBASE-7332 by simple creating table and splitting it from command line).

Is that was intended to be so and some chore eventually will remove it from regionStates (didn't find with fast code scanning) or here can be resource leak?

"
HBASE-3243,"I ran some YCSB benchmarks which resulted in about 150 regions worth of data overnight. Then I disabled the table, and the master for some reason closed one region on the wrong server. The server ignored this, but the region remained open on a different server, which later flipped out when it tried to flush due to hlog accumulation."
HBASE-6015,"When after the 1st round of run and possible fixes, HBCK does a rerun to check the consistency of the regions. At this rerun
1.It should check all the regions which it checked in the 1st round. 
2.It should check only those regions which it checked in the 1st round. Might be some other regions can come out of the timelag check at rerun time."
HBASE-5312,"This is in reference to the mail sent in the dev mailing list
""Closed parent region present in Hlog.lastSeqWritten"".

The sceanrio described is

We had a region that was split into two daughters.  When the hlog roll tried to flush the region there was an entry in the HLog.lastSeqWritten that was not flushed or removed from the lastSeqWritten during the parent close.
Because this flush was not happening subsequent flushes were getting blocked
{code}
 05:06:44,422 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Too many
 hlogs: logs=122, maxlogs=32; forcing flush of 1 regions(s):
 2acaf8e3acfd2e8a5825a1f6f0aca4a8
 05:06:44,422 WARN org.apache.hadoop.hbase.regionserver.LogRoller: Failed
 to schedule flush of 2acaf8e3acfd2e8a5825a1f6f0aca4a8r=null,
requester=null
 05:10:48,666 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Too many
 hlogs: logs=123, maxlogs=32; forcing flush of 1 regions(s):
 2acaf8e3acfd2e8a5825a1f6f0aca4a8
 05:10:48,666 WARN org.apache.hadoop.hbase.regionserver.LogRoller: Failed
 to schedule flush of 2acaf8e3acfd2e8a5825a1f6f0aca4a8r=null,
requester=null
 05:14:46,075 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Too many
 hlogs: logs=124, maxlogs=32; forcing flush of 1 regions(s):
 2acaf8e3acfd2e8a5825a1f6f0aca4a8
 05:14:46,075 WARN org.apache.hadoop.hbase.regionserver.LogRoller: Failed
 to schedule flush of 2acaf8e3acfd2e8a5825a1f6f0aca4a8r=null,
requester=null
 05:15:41,584 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Too many
 hlogs: logs=125, maxlogs=32; forcing flush of 1 regions(s):
 2acaf8e3acfd2e8a5825a1f6f0aca4a8
 05:15:41,584 WARN org.apache.hadoop.hbase.regionserver.LogRoller: Failed
 to schedule flush of 2acaf8e3acfd2e8a5825a1f6f0aca4a8r=null,

{code}

Lets see what happened for the region 2acaf8e3acfd2e8a5825a1f6f0aca4a8
{code}
2012-01-06 00:30:55,214 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/2acaf8e3acfd2e8a5825a1f6f0aca4a8/.tmp/1755862026714756815 to hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/2acaf8e3acfd2e8a5825a1f6f0aca4a8/value/973789709483406123
2012-01-06 00:30:58,946 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Instantiated Htable_UFDR_016,049790700093168-04565200000,1325809837958.0ebe5bd7fcbc09ee074d5600b9d4e062.
2012-01-06 00:30:59,614 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/2acaf8e3acfd2e8a5825a1f6f0aca4a8/value/973789709483406123, entries=7537, sequenceid=20312223, memsize=4.2m, filesize=2.9m
2012-01-06 00:30:59,787 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished snapshotting, commencing flushing stores
2012-01-06 00:30:59,787 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~133.5m for region Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8. in 21816ms, sequenceid=20312223, compaction requested=true
2012-01-06 00:30:59,787 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8. because regionserver20020.cacheFlusher; priority=0, compaction queue size=5840

{code}

A user triggered split has been issued to this region which can be seen in the above logs.
The flushing of this region has resulted in a seq id 20312223.

The region has been splitted and the parent region has been closed
{code}
00:31:12,607 INFO org.apache.hadoop.hbase.regionserver.SplitTransaction: Starting split of region Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8.
00:31:13,694 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Closing Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8.: disabling compactions & flushes
00:31:13,694 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8.
00:31:13,718 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8.
00:31:39,552 INFO org.apache.hadoop.hbase.catalog.MetaEditor: Offlined parent region Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8. in META
00:31:41,374 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/259d0c620c9105928e52713f4a5a252e/value/239119195230239381.2acaf8e3acfd2e8a5825a1f6f0aca4a8, isReference=true, isBulkLoadResult=false, seqid=20201181, majorCompaction=false


2012-01-06 00:31:42,529 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/52ff3c7c6df6e0337876bbca29cee84a/value/973789709483406123.2acaf8e3acfd2e8a5825a1f6f0aca4a8, isReference=true, isBulkLoadResult=false, seqid=20312224, majorCompaction=false

2012-01-06 00:31:42,532 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/259d0c620c9105928e52713f4a5a252e/value/973789709483406123.2acaf8e3acfd2e8a5825a1f6f0aca4a8, isReference=true, isBulkLoadResult=false, seqid=20312223, majorCompaction=false

INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region split, META updated, and report to master. Parent=Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8., new regions: Htable_UFDR_031,00332,1325809872607.259d0c620c9105928e52713f4a5a252e., Htable_UFDR_031,003732800093168-03594291912,1325809872607.52ff3c7c6df6e0337876bbca29cee84a.. Split took 29sec

{code}
In the above logs we can also see that the new daugher regions have the next seq id as 20312223 and 20312224.

{code}
DEBUG org.apache.hadoop.hbase.regionserver.wal.HLog: Found 1 hlogs to remove out of total 4; oldest outstanding sequenceid is 20312224 from region 2acaf8e3acfd2e8a5825a1f6f0aca4a8
{code}
Now we see that the parent region which was clsoed has a seq id 20312224 which is not flushed.
So further flush are failing as the region is already removed from onlineRegionList.
The doubt here is before the region could be closed, a put has arrived for this region.  But due to some reason the flush has  not happened for that. We tried to dig this, but not able to get this problem again.
0.90.5 version + few 0.90.6 patches ( before 0.90.6RC0)
"
HBASE-5972,"Noticed 20-minute hangs when doing a namenode kill test on our production shadow cluster. All regionservers terminated except one, which got stuck with the following. There might be some race conditions/deadlocks on compaction thread shutdown worth investigating."
HBASE-3464,"I have a seed application that is executed via maven and runs a
single JVM ApplicationStarter that starts up hdfs, regionserver, hmaster
threads. It does some seeding then shuts those down in reverse order.
So this isn't a typical way of running hbase to be sure. However it has
always worked until I upgraded to HBase 0.90.0.

I didn't notice it when I was originally testing 0.90.0 because it only
seems to be happening on our EC2.small build server node when I run this
particular seeder.

Running the same thing locally on my mac works.

Attached is the error output starting from when the HRegionServer.stop() is
called to when HMaster.shutdown() is called and it starts looping forever in
letRegionServersShutdown().

It looks like RegionServerTracker is getting to ""RegionServer ephemeral node
deleted, processing expiration"" but then because it can't get the
HServerInfo it doesn't follow-through with actually expiring it.

The reason it can't get the HServerInfo is because it is looking for ""localhost."" instead of ""localhost"".

My /etc/hosts file was vanilla. But when I removed the following form hbase-site.xml:

<property>
       <name>hbase.master.dns.interface</name>
       <value>lo</value>
</property>
<property>
      <name>hbase.regionserver.dns.interface</name>
      <value>lo</value>
</property>

The issue went away.

So something about the ""lo"" interface isn't getting parsed right on that particular machine (An EC2 M.small running Ubuntu 9)."
HBASE-4924,"From Roman:

{code}
> 聽3. This is a little bit more sinister and it is not clear what
> 聽the resolution path here is. When compiled against .23
> 聽the MiniMRCluster dependency latches onto artifact
> 聽hadoop-mapreduce/test. There are 2 problems with that:
> 聽 聽1. this works only accidentally (but as long as it does
> 聽 聽may be it is fine) since we don't have an explicit
> 聽 聽dependency on hadoop-mapreduce test artifact (nor
> 聽 聽should we, I think!).
>
> 聽 聽2. MiniMRCluster from there is soon to be deprecated
> 聽 聽(MAPREDUCE-3169) ans HBaseTestingUtility should
> 聽 聽really transition onto using MiniMRClientClusterFactory
> 聽 聽to get a MiniMRCluster.
{code}

I think there already an issue for #2 above (courtesy of Andrew IIRC).  We should fix #1 too."
HBASE-5571,"If we restart master when it is disabling one table, the table will be disabling forever.

In current logic, Region CLOSE RPC will always returned NotServingRegionException because RS has already closed the region before we restart master. So table will be disabling forever because the region will in RIT all along.

In another case, when AssignmentManager#rebuildUserRegions(), it will put parent regions to AssignmentManager.regions, so we can't close these parent regions until it is purged by CatalogJanitor if we execute disabling the table."
HBASE-5528,"In current log-splitting retry logic, it will retry forever if throws IOException, I think we'd better change it to numbered times, and abort master when retries exhausted.
"
HBASE-5532,"We found error log (NullPointerException) below on our online cluster:

2012-03-05 00:17:09,592 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker: Caught exception
java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.Store.isMajorCompaction(Store.java:878)
        at org.apache.hadoop.hbase.regionserver.Store.isMajorCompaction(Store.java:857)
        at org.apache.hadoop.hbase.regionserver.HRegion.isMajorCompaction(HRegion.java:3017)
        at org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker.chore(HRegionServer.java:1172)
        at org.apache.hadoop.hbase.Chore.run(Chore.java:66)

After Check the code we found although it already check whether store files has null reader at the begin of the function(isMajorCompaction), but it still has some possibility the reader is closed before it return(eg mini compaction). So we need to check store file reader before we use it to avoid this NPE


"
HBASE-6664,"Gregory over in https://reviews.apache.org/r/6670/ explains the issue.  See the comment here at https://reviews.apache.org/r/6670/diff/1/?file=142078#file142078line88  Its about when tests call areSerializedFieldsEqual to figure if objects are equal.  When its comparators, and the comparator has been subclassed or is made of multiple sub comparators, then we'll not compare right."
HBASE-5157,Backporting to 0.90.6 considering the importance of the issue.
HBASE-6898,"Based on conversation here: http://mail-archives.apache.org/mod_mbox/hbase-dev/201209.mbox/%3CCAPcDmSvS-MpZLGXU0gpYUYz9JoqghcZEngML_JYEtWPCXhYvAw%40mail.gmail.com%3E

In short, we should have a single, committer accessible and audit-able place to store custom build artifacts for HBase.

Occasionally, we need to build custom artifacts for HBase that haven't made it into the upstream projects. In the past we have hosted them in various committer's people.apache.org/ publicly visible object hosting sites (which just need a certain file structure to work as maven repositories). While the best course of action is to get the upstream projects to release a version with the change we require, this is not always possible immediately and for the short term we need the modified artifact. 

This ticket would add a branch to the hbase source and update the pom to point to the apache visible svn tree to act as the pseudo-maven respositories. This gives us a low friction, auditable, committter accessible place to upload custom build artifacts. They can also be easily removed as the upstream projects release new versions."
HBASE-3093,"When calling Delete.deleteColumns to delete (all versions of) a column, the columns with a qualifier that is alphabetical higher than the deleted column are deleted as well when the cells have timestamp 0.
When the cells have a timestamp higher than 0 this is not the case.

The test case DeleteColumnsTest (tested against HBase 0.89.0-r1004203-3076) contains a scenario showing this behaviour :
- put values in 3 columns (A, B and C) of the same column family at timestamp 0.
- delete all versions of column B (using Delete.deleteColumns() )
- read columns A and C
- result : for column A a result is given, for column C not (the alphabetical order is in play here!)"
HBASE-7451,"Hi Matteo Bertozzi and Jesse Yates, My observation is base on code in github 锛?https://github.com/matteobertozzi/hbase/
If we create a snapshot and meet regionserver timeout. Rs will be lock and can not put any data. Please take a look at log below :

// regionserver snapshot timeout
org.apache.hadoop.hbase.server.commit.distributed.DistributedCommitException: org.apache.hadoop.hbase.server.errorhandling.exception.OperationAttemptTimeoutException: Timeout elapsed! Start:1356518666984, End:1356518667584, diff:600, max:600 ms
at org.apache.hadoop.hbase.server.commit.distributed.DistributedThreePhaseCommitErrorDispatcher.wrap(DistributedThreePhaseCommitErrorDispatcher.java:135)
at org.apache.hadoop.hbase.server.commit.distributed.DistributedThreePhaseCommitErrorDispatcher.operationTimeout(DistributedThreePhaseCommitErrorDispatcher.java:71)
at org.apache.hadoop.hbase.server.commit.ThreePhaseCommit$1.receiveError(ThreePhaseCommit.java:92)
at org.apache.hadoop.hbase.server.commit.ThreePhaseCommit$1.receiveError(ThreePhaseCommit.java:89)
at org.apache.hadoop.hbase.server.errorhandling.OperationAttemptTimer$1.run(OperationAttemptTimer.java:71)
at java.util.TimerThread.mainLoop(Timer.java:512)
at java.util.TimerThread.run(Timer.java:462)
Caused by: org.apache.hadoop.hbase.server.errorhandling.exception.OperationAttemptTimeoutException: Timeout elapsed! Start:1356518666984, End:1356518667584, diff:600, max:600 ms
... 3 more
2012-12-26 18:44:57,211 DEBUG org.apache.hadoop.hbase.server.commit.TwoPhaseCommit: Running cleanup phase.
2012-12-26 18:44:57,211 DEBUG org.apache.hadoop.hbase.regionserver.snapshot.operation.SnapshotOperation: Cleanup snapshot - handled in sub-tasks on error
2012-12-26 18:44:57,212 DEBUG org.apache.hadoop.hbase.serv

//Waiting for 'commit allowed' latch and do not exist

2012-12-26 18:44:57,211 DEBUG org.apache.hadoop.hbase.server.commit.TwoPhaseCommit: Running cleanup phase.
2012-12-26 18:44:57,211 DEBUG org.apache.hadoop.hbase.regionserver.snapshot.operation.SnapshotOperation: Cleanup snapshot - handled in sub-tasks on error
2012-12-26 18:44:57,212 DEBUG org.apache.hadoop.hbase.server.commit.TwoPhaseCommit: Running finish phase.
2012-12-26 18:44:57,212 DEBUG org.apache.hadoop.hbase.regionserver.snapshot.operation.SnapshotOperation: Finish snapshot - handling in subtasks on error
2012-12-26 18:44:57,212 WARN org.apache.hadoop.hbase.server.errorhandling.OperationAttemptTimer: Timer already marked completed, ignoring!
2012-12-26 18:45:01,990 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:06,990 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:11,991 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:16,991 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:17,002 INFO org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Received children changed event:/hbase-TERRY-73/online-snapshot/prepare
2012-12-26 18:45:17,002 INFO org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Recieved start event.
2012-12-26 18:45:17,002 DEBUG org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Looking for new operations under znode:/hbase-TERRY-73/online-snapshot/prepare
2012-12-26 18:45:17,003 INFO org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Received children changed event:/hbase-TERRY-73/online-snapshot/abort
2012-12-26 18:45:17,003 INFO org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Recieved abort event.
2012-12-26 18:45:17,003 DEBUG org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Checking for aborted operations on node:/hbase-TERRY-73/online-snapshot/abort
2012-12-26 18:45:21,991 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:26,992 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:31,992 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:36,992 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:41,992 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:43,481 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: LRU Stats: total=11.77 MB, free=1.39 GB, max=1.4 GB, blocks=5, accesses=96, hits=91, hitRatio=94.79%, cachingAccesses=96, cachingHits=91, cachingHitsRatio=94.79%, evictions=0, evicted=0, evictedPerRun=NaN
2012-12-26 18:45:46,993 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:51,993 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:56,993 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:01,994 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:06,994 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:11,994 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:16,994 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:21,995 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:26,995 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:31,995 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:36,996 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:41,996 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)"
HBASE-7308,"HBase-TRUNK-on-Hadoop-2.0.0 #287 had one example:
{code}
Tests in error:
  testRegionCaching(org.apache.hadoop.hbase.client.TestHCM): test timed out after 60000 milliseconds
{code}"
HBASE-6947,"From trunk build #3421 (https://builds.apache.org/job/HBase-TRUNK/3421/testReport/junit/org.apache.hadoop.hbase.coprocessor.example/TestZooKeeperScanPolicyObserver/testScanPolicyObserver/ and https://builds.apache.org/job/HBase-TRUNK/3414/testReport/junit/org.apache.hadoop.hbase.coprocessor.example/TestZooKeeperScanPolicyObserver/testScanPolicyObserver/):
{code}
java.lang.AssertionError: expected:<2> but was:<0>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.junit.Assert.assertEquals(Assert.java:456)
	at org.apache.hadoop.hbase.coprocessor.example.TestZooKeeperScanPolicyObserver.testScanPolicyObserver(TestZooKeeperScanPolicyObserver.java:105)
{code}"
HBASE-6810,"In build #3348, TestZKPermissionsWatcher#testPermissionsWatcher failed:
{code}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:92)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.junit.Assert.assertTrue(Assert.java:54)
	at org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.testPermissionsWatcher(TestZKPermissionsWatcher.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)

Standard Output

Starting DataNode 0 with dfs.data.dir: /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/dfs/data/data1,/x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/dfs/data/data2
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0

Standard Error

2012-09-18 20:29:59,306 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(639): Starting up minicluster with 1 master(s) and 1 regionserver(s) and 1 datanode(s)
2012-09-18 20:29:59,373 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(294): Created new mini-cluster data directory: /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e
2012-09-18 20:29:59,374 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting test.cache.data to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/cache_data in system properties and HBase conf
2012-09-18 20:29:59,374 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting hadoop.tmp.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/hadoop_tmp in system properties and HBase conf
2012-09-18 20:29:59,374 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting hadoop.log.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/hadoop_logs in system properties and HBase conf
2012-09-18 20:29:59,376 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting mapred.output.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/mapred_output in system properties and HBase conf
2012-09-18 20:29:59,376 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting mapred.local.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/mapred_local in system properties and HBase conf
2012-09-18 20:29:59,377 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting mapred.system.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/mapred_system in system properties and HBase conf
2012-09-18 20:29:59,377 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting mapred.temp.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/mapred_temp in system properties and HBase conf
2012-09-18 20:29:59,740 WARN  [pool-1-thread-1] impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-namenode.properties, hadoop-metrics2.properties
2012-09-18 20:29:59,933 INFO  [pool-1-thread-1] log.Slf4jLog(67): Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-09-18 20:30:00,005 INFO  [pool-1-thread-1] log.Slf4jLog(67): jetty-6.1.26
2012-09-18 20:30:00,038 INFO  [pool-1-thread-1] log.Slf4jLog(67): Extract jar:file:/home/jenkins/.m2/repository/org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar!/webapps/hdfs to /tmp/Jetty_localhost_36636_hdfs____.l2m074/webapp
2012-09-18 20:30:00,363 INFO  [pool-1-thread-1] log.Slf4jLog(67): Started SelectChannelConnector@localhost:36636
2012-09-18 20:30:00,445 WARN  [pool-1-thread-1] impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-datanode.properties, hadoop-metrics2.properties
2012-09-18 20:30:00,446 WARN  [pool-1-thread-1] util.MBeans(59): Hadoop:service=DataNode,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
	at com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:120)
	at com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:143)
	at com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:183)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:941)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:917)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:56)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.initSystemMBean(MetricsSystemImpl.java:500)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:140)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:40)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1520)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1496)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:417)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:432)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:653)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:603)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:572)
	at org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.beforeClass(TestZKPermissionsWatcher.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2012-09-18 20:30:00,509 INFO  [pool-1-thread-1] log.Slf4jLog(67): jetty-6.1.26
2012-09-18 20:30:00,521 INFO  [pool-1-thread-1] log.Slf4jLog(67): Extract jar:file:/home/jenkins/.m2/repository/org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar!/webapps/datanode to /tmp/Jetty_localhost_49745_datanode____.h2811i/webapp
2012-09-18 20:30:00,713 INFO  [pool-1-thread-1] log.Slf4jLog(67): Started SelectChannelConnector@localhost:49745
2012-09-18 20:30:00,785 INFO  [pool-1-thread-1] zookeeper.MiniZooKeeperCluster(196): Started MiniZK Cluster and connect 1 ZK server on client port: 54880
2012-09-18 20:30:01,281 DEBUG [pool-1-thread-1] util.FSUtils(442): Created version file at hdfs://localhost:42338/user/jenkins/hbase with version=7
2012-09-18 20:30:01,352 DEBUG [pool-1-thread-1] client.HConnectionManager(2453): Set serverside HConnection retries=100
2012-09-18 20:30:01,400 INFO  [pool-1-thread-1] ipc.HBaseRpcMetrics(65): Initializing RPC Metrics with hostName=HMaster, port=57673
2012-09-18 20:30:01,460 DEBUG [pool-1-thread-1] zookeeper.ZKUtil(102): master:57673 opening connection to ZooKeeper with ensemble (localhost:54880)
2012-09-18 20:30:01,476 INFO  [pool-1-thread-1] zookeeper.RecoverableZooKeeper(101): The identifier of this process is 25567@hemera
2012-09-18 20:30:01,496 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(265): master:57673 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2012-09-18 20:30:01,499 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(342): master:57673-0x139db12b83f0000 connected
2012-09-18 20:30:01,548 WARN  [pool-1-thread-1] impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-hbase.properties, hadoop-metrics2.properties
2012-09-18 20:30:01,549 WARN  [pool-1-thread-1] util.MBeans(59): Hadoop:service=hbase,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
	at com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:120)
	at com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:143)
	at com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:183)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:941)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:917)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:56)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.initSystemMBean(MetricsSystemImpl.java:500)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:140)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:40)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.<init>(BaseMetricsSourceImpl.java:70)
	at org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.<init>(MasterMetricsSourceImpl.java:51)
	at org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.<init>(MasterMetricsSourceImpl.java:43)
	at org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceFactoryImpl.create(MasterMetricsSourceFactoryImpl.java:33)
	at org.apache.hadoop.hbase.master.metrics.MasterMetrics.<init>(MasterMetrics.java:40)
	at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:383)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:132)
	at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:200)
	at org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:150)
	at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:209)
	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:89)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:693)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:666)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:661)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:603)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:572)
	at org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.beforeClass(TestZKPermissionsWatcher.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2012-09-18 20:30:01,614 DEBUG [pool-1-thread-1] client.HConnectionManager(2453): Set serverside HConnection retries=100
2012-09-18 20:30:01,643 INFO  [pool-1-thread-1] ipc.HBaseRpcMetrics(65): Initializing RPC Metrics with hostName=MiniHBaseCluster$MiniHBaseClusterRegionServer, port=56450
2012-09-18 20:30:01,702 INFO  [pool-1-thread-1] hfile.CacheConfig(350): Allocating LruBlockCache with maximum size 422.2m
2012-09-18 20:30:01,711 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(237): master:57673-0x139db12b83f0000 /hbase/shutdown does not exist. Watcher is set.
2012-09-18 20:30:01,714 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.ActiveMasterManager(149): Deleting ZNode for /hbase/backup-masters/hemera.apache.org,57673,1348000201449 from backup master directory
2012-09-18 20:30:01,716 WARN  [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.RecoverableZooKeeper(141): Node /hbase/backup-masters/hemera.apache.org,57673,1348000201449 already deleted, and this is not a retry
2012-09-18 20:30:01,717 WARN  [Master:0;hemera.apache.org,57673,1348000201449] hbase.ZNodeClearer(58): No filename given to save the znode used, it won't be saved (Environment variable HBASE_ZNODE_FILE is not set).
2012-09-18 20:30:01,717 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.ActiveMasterManager(158): Master=hemera.apache.org,57673,1348000201449
2012-09-18 20:30:01,722 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] master.SplitLogManager(175): timeout = 25000
2012-09-18 20:30:01,722 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] master.SplitLogManager(176): unassigned timeout = 180000
2012-09-18 20:30:01,724 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.SplitLogManager(806): found 0 orphan tasks and 0 rescan nodes
2012-09-18 20:30:01,761 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] util.FSUtils(571): Created cluster ID file at hdfs://localhost:42338/user/jenkins/hbase/hbase.id with ID: 5dbaab6f-b03b-4631-b4f3-dbaffefbe1e9
2012-09-18 20:30:01,785 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.MasterFileSystem(395): BOOTSTRAP: creating ROOT and first META regions
2012-09-18 20:30:01,785 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(3834): creating HRegion -ROOT- HTD == '-ROOT-', {METHOD => 'table_att', IS_META => 'true', IS_ROOT => 'true'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = hdfs://localhost:42338/user/jenkins/hbase Table name == -ROOT-
2012-09-18 20:30:01,791 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(458): FileSystem doesn't support getDefaultBlockSize
2012-09-18 20:30:01,794 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(429): HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true, optionallogflushinternal=1000ms
2012-09-18 20:30:01,805 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2012-09-18 20:30:01,805 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.SequenceFileLogWriter(193): Path=hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.logs/hlog.1348000201794, compression=false
2012-09-18 20:30:01,805 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(653):  for /user/jenkins/hbase/-ROOT-/70236052/.logs/hlog.1348000201794
2012-09-18 20:30:01,805 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(501): Using getNumCurrentReplicas--HDFS-826
2012-09-18 20:30:01,813 INFO  [pool-1-thread-1] regionserver.ShutdownHook(87): Installed shutdown hook thread: Shutdownhook:RegionServer:0;hemera.apache.org,56450,1348000201701
2012-09-18 20:30:01,815 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.ZKUtil(102): regionserver:56450 opening connection to ZooKeeper with ensemble (localhost:54880)
2012-09-18 20:30:01,816 INFO  [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.RecoverableZooKeeper(101): The identifier of this process is 25567@hemera
2012-09-18 20:30:01,817 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701-EventThread] zookeeper.ZooKeeperWatcher(265): regionserver:56450 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2012-09-18 20:30:01,818 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.ZKUtil(235): regionserver:56450 Set watcher on existing znode /hbase/master
2012-09-18 20:30:01,818 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701-EventThread] zookeeper.ZooKeeperWatcher(342): regionserver:56450-0x139db12b83f0001 connected
2012-09-18 20:30:01,824 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.ZKUtil(1141): regionserver:56450-0x139db12b83f0001 Retrieved 36 byte(s) of data from znode /hbase/master and set watcher; PBUF\x0A\x1E\x0A\x11hemera.ap...
2012-09-18 20:30:01,825 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.ZKUtil(237): regionserver:56450-0x139db12b83f0001 /hbase/shutdown does not exist. Watcher is set.
2012-09-18 20:30:01,834 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(474): Instantiated -ROOT-,,0.70236052
2012-09-18 20:30:01,840 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] util.FSUtils(167): Creating file=hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/.regioninfo with permission=rwxrwxrwx
2012-09-18 20:30:02,283 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] regionserver.HStore(215): hbase.hstore.compaction.min = 3
2012-09-18 20:30:02,329 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] util.ChecksumType$2(77): Checksum can use java.util.zip.CRC32
2012-09-18 20:30:02,350 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(622): Onlined -ROOT-,,0.70236052; next sequenceid=1
2012-09-18 20:30:02,351 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(3834): creating HRegion .META. HTD == '.META.', {METHOD => 'table_att', IS_META => 'true'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = hdfs://localhost:42338/user/jenkins/hbase Table name == .META.
2012-09-18 20:30:02,353 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(458): FileSystem doesn't support getDefaultBlockSize
2012-09-18 20:30:02,360 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(429): HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true, optionallogflushinternal=1000ms
2012-09-18 20:30:02,363 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2012-09-18 20:30:02,364 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.SequenceFileLogWriter(193): Path=hdfs://localhost:42338/user/jenkins/hbase/.META./1028785192/.logs/hlog.1348000202360, compression=false
2012-09-18 20:30:02,364 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(653):  for /user/jenkins/hbase/.META./1028785192/.logs/hlog.1348000202360
2012-09-18 20:30:02,364 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(501): Using getNumCurrentReplicas--HDFS-826
2012-09-18 20:30:02,365 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(474): Instantiated .META.,,1.1028785192
2012-09-18 20:30:02,368 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] util.FSUtils(167): Creating file=hdfs://localhost:42338/user/jenkins/hbase/.META./1028785192/.tmp/.regioninfo with permission=rwxrwxrwx
2012-09-18 20:30:02,785 INFO  [StoreOpenerThread-.META.,,1.1028785192-1] regionserver.HStore(215): hbase.hstore.compaction.min = 3
2012-09-18 20:30:02,790 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(622): Onlined .META.,,1.1028785192; next sequenceid=1
2012-09-18 20:30:02,803 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(954): Closing -ROOT-,,0.70236052: disabling compactions & flushes
2012-09-18 20:30:02,804 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(975): Updates disabled for region -ROOT-,,0.70236052
2012-09-18 20:30:02,804 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1481): Started memstore flush for -ROOT-,,0.70236052, current region memstore size 352.0
2012-09-18 20:30:02,805 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1528): Finished snapshotting -ROOT-,,0.70236052, commencing wait for mvcc, flushsize=352
2012-09-18 20:30:02,805 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1538): Finished snapshotting, commencing flushing stores
2012-09-18 20:30:02,826 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] util.FSUtils(167): Creating file=hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a with permission=rwxrwxrwx
2012-09-18 20:30:02,838 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] hfile.HFileWriterV2(142): Initialized with CacheConfig:enabled [cacheDataOnRead=false] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheCompressed=false]
2012-09-18 20:30:02,841 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.StoreFile$Writer(1021): Delete Family Bloom filter type for hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a: CompoundBloomFilterWriter
2012-09-18 20:30:02,857 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.StoreFile$Writer(1241): NO General Bloom and NO DeleteFamily was added to HFile (hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a) 
2012-09-18 20:30:02,857 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HStore(767): Flushed , sequenceid=2, memsize=352.0, into tmp file hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a
2012-09-18 20:30:02,881 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HStore(792): Renaming flushed file at hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a to hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/info/5971150f6ed745bda83363123504803a
2012-09-18 20:30:02,893 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HStore(815): Added hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/info/5971150f6ed745bda83363123504803a, entries=2, sequenceid=2, filesize=836.0
2012-09-18 20:30:02,894 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1617): Finished memstore flush of ~352.0/352, currentsize=0.0/0 for region -ROOT-,,0.70236052 in 90ms, sequenceid=2, compaction requested=false
2012-09-18 20:30:02,897 INFO  [StoreCloserThread--ROOT-,,0.70236052-1] regionserver.HStore(635): Closed info
2012-09-18 20:30:02,897 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1023): Closed -ROOT-,,0.70236052
2012-09-18 20:30:02,898 INFO  [Master:0;hemera.apache.org,57673,1348000201449.logSyncer] wal.HLog$LogSyncer(1245): Master:0;hemera.apache.org,57673,1348000201449.logSyncer exiting
2012-09-18 20:30:02,898 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(1007): closing hlog writer in hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.logs
2012-09-18 20:30:03,309 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(975): Moved 1 log files to /user/jenkins/hbase/-ROOT-/70236052/.oldlogs
2012-09-18 20:30:03,311 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(954): Closing .META.,,1.1028785192: disabling compactions & flushes
2012-09-18 20:30:03,311 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(975): Updates disabled for region .META.,,1.1028785192
2012-09-18 20:30:03,312 INFO  [StoreCloserThread-.META.,,1.1028785192-1] regionserver.HStore(635): Closed info
2012-09-18 20:30:03,312 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1023): Closed .META.,,1.1028785192
2012-09-18 20:30:03,312 INFO  [Master:0;hemera.apache.org,57673,1348000201449.logSyncer] wal.HLog$LogSyncer(1245): Master:0;hemera.apache.org,57673,1348000201449.logSyncer exiting
2012-09-18 20:30:03,313 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(1007): closing hlog writer in hdfs://localhost:42338/user/jenkins/hbase/.META./1028785192/.logs
2012-09-18 20:30:03,724 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(975): Moved 1 log files to /user/jenkins/hbase/.META./1028785192/.oldlogs
2012-09-18 20:30:03,762 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] fs.HFileSystem(196): Starting addLocationsOrderInterceptor with class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2012-09-18 20:30:03,763 INFO  [Master:0;hemera.apache.org,57673,1348000201449] fs.HFileSystem(243): Added intercepting call to namenode#getBlockLocations
2012-09-18 20:30:03,783 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(102): hconnection 0x2bfa91 opening connection to ZooKeeper with ensemble (localhost:54880)
2012-09-18 20:30:03,784 INFO  [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.RecoverableZooKeeper(101): The identifier of this process is 25567@hemera
2012-09-18 20:30:03,786 DEBUG [Master:0;hemera.apache.org,57673,1348000201449-EventThread] zookeeper.ZooKeeperWatcher(265): hconnection 0x2bfa91 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2012-09-18 20:30:03,787 DEBUG [Master:0;hemera.apache.org,57673,1348000201449-EventThread] zookeeper.ZooKeeperWatcher(342): hconnection 0x2bfa91-0x139db12b83f0002 connected
2012-09-18 20:30:03,788 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(1141): hconnection 0x2bfa91-0x139db12b83f0002 Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$5dbaab6f-b03b-4631-b...
2012-09-18 20:30:03,788 INFO  [Master:0;hemera.apache.org,57673,1348000201449] client.HConnectionManager$HConnectionImplementation(662): ClusterId is 5dbaab6f-b03b-4631-b4f3-dbaffefbe1e9
2012-09-18 20:30:03,791 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] catalog.CatalogTracker(240): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@959fa1
2012-09-18 20:30:03,792 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(237): master:57673-0x139db12b83f0000 /hbase/root-region-server does not exist. Watcher is set.
2012-09-18 20:30:03,793 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(237): master:57673-0x139db12b83f0000 /hbase/unassigned/1028785192 does not exist. Watcher is set.
2012-09-18 20:30:03,798 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(237): master:57673-0x139db12b83f0000 /hbase/balancer does not exist. Watcher is set.
2012-09-18 20:30:03,820 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(265): master:57673-0x139db12b83f0000 Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/shutdown
2012-09-18 20:30:03,820 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701-EventThread] zookeeper.ZooKeeperWatcher(265): regionserver:56450-0x139db12b83f0001 Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/shutdown
2012-09-18 20:30:03,821 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.HMaster(539): Server active/primary master; hemera.apache.org,57673,1348000201449, sessionid=0x139db12b83f0000, cluster-up flag was=false
2012-09-18 20:3"
HBASE-4371,"When writing unit tests for HBASE-4325, I noticed this:

create 'table0', 'f1','f2'
create 'table1', 'f1','f2'
create 'table2', 'f1','f2'
scan '.META.', { STARTROW=> 'table2' }

Which outputs table1 which is < table2.


hbase(main):007:0> scan '.META.', { STARTROW => 'table2' }
ROW                                                          COLUMN+CELL                                                                                                                                                                    
 table0,,1315776873140.ddc11620ad6d62eb6840853ecca46f39.     column=info:regioninfo, timestamp=1315776873202, value=REGION => {NAME => 'table0,,1315776873140.ddc11620ad6d62eb6840853ecca46f39.', TableName => 'table0', STARTKEY => '', END
                                                             KEY => '', ENCODED => ddc11620ad6d62eb6840853ecca46f39,}                                                                                                                       
 table0,,1315776873140.ddc11620ad6d62eb6840853ecca46f39.     column=info:server, timestamp=1315776873233, value=grimlock:44226                                                                                                              
 table0,,1315776873140.ddc11620ad6d62eb6840853ecca46f39.     column=info:serverstartcode, timestamp=1315776873233, value=1315776026457                                                                                                      
 table1,,1315776052776.dfbfdd038b1e42d38eff46e8282a15e5.     column=info:regioninfo, timestamp=1315776052829, value=REGION => {NAME => 'table1,,1315776052776.dfbfdd038b1e42d38eff46e8282a15e5.', TableName => 'table1', STARTKEY => '', END
                                                             KEY => '', ENCODED => dfbfdd038b1e42d38eff46e8282a15e5,}                                                                                                                       
 table1,,1315776052776.dfbfdd038b1e42d38eff46e8282a15e5.     column=info:server, timestamp=1315776052871, value=grimlock:44226                                                                                                              
 table1,,1315776052776.dfbfdd038b1e42d38eff46e8282a15e5.     column=info:serverstartcode, timestamp=1315776052871, value=1315776026457                                                                                                      
 table2,,1315776057157.5c6df57acb426b02660315e97bff80ff.     column=info:regioninfo, timestamp=1315776057207, value=REGION => {NAME => 'table2,,1315776057157.5c6df57acb426b02660315e97bff80ff.', TableName => 'table2', STARTKEY => '', END
                                                             KEY => '', ENCODED => 5c6df57acb426b02660315e97bff80ff,}                                                                                                                       
 table2,,1315776057157.5c6df57acb426b02660315e97bff80ff.     column=info:server, timestamp=1315776057232, value=grimlock:44226                                                                                                              
 table2,,1315776057157.5c6df57acb426b02660315e97bff80ff.     column=info:serverstartcode, timestamp=1315776057232, value=1315776026457                                                                                                      
3 row(s) in 0.0370 seconds
"
HBASE-5828,See recent 0.90 builds up on jenkins: https://builds.apache.org/view/G-L/view/HBase/job/hbase-0.90/471/console
HBASE-5309,hbasemaster:60010/jmx throws an NoSuchMethodError exception
HBASE-5214,"In master, both the shutdown threads and balancer thread could change the region state. It could create some race condition. HBase-4899 fixes the issue under normal situation. Still it seems like there is a really small time window HBase-4899 won't cover.

T1. ServerShutdownHandler. the check for ""if (rit != null && !rit.isClosing() && !rit.isPendingClose()"" return false as the region is still in closing state. It is actually closed by the RS; Master's state is ""closing"" due to the delay in ZK notification.
T2. Right after the above check, ZK notification happens and Master starts the opening of the region as requested by load balancer.
T3. ""else { this.services.getAssignmentManager().assign(e.getKey(), true); }"" is called for another assignment.

Also HBase-5094 has fixes and discussion about this.

Could we make it such that only one thread can transition a region at a time?"
HBASE-4836,"Messing around w/ 0.92 on cluster I got myself into a situation where the master would not go down because we were hung as follows in an infinite wait on meta to come up:

{code}
""MASTER_SERVER_OPERATIONS-sv4r11s38,7001,1321897362552-2"" prio=10 tid=0x000000004205d800 nid=0x19f6 waiting for monitor entry [0x00007fe4eb3f1000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:457)
        - waiting to lock <0x00000000ca199190> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:426)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:253)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:168)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)

""MASTER_SERVER_OPERATIONS-sv4r11s38,7001,1321897362552-1"" prio=10 tid=0x000000004237b000 nid=0x19f4 waiting for monitor entry [0x00007fe4ebefc000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:457)
        - waiting to lock <0x00000000ca199190> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:426)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:253)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:168)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)

""MASTER_SERVER_OPERATIONS-sv4r11s38,7001,1321897362552-0"" prio=10 tid=0x00007fe4ec610800 nid=0x18e1 waiting on condition [0x00007fe4eb4f2000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getRegionServerWithRetries(HConnectionManager.java:1295)
        at org.apache.hadoop.hbase.client.HTable.get(HTable.java:655)
        at org.apache.hadoop.hbase.catalog.MetaReader.get(MetaReader.java:245)
        at org.apache.hadoop.hbase.catalog.MetaReader.getRegion(MetaReader.java:347)
        at org.apache.hadoop.hbase.catalog.MetaReader.readRegionLocation(MetaReader.java:287)
        at org.apache.hadoop.hbase.catalog.MetaReader.getMetaRegionLocation(MetaReader.java:274)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.getMetaServerConnection(CatalogTracker.java:399)
        - locked <0x00000000ca199190> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:458)
        - locked <0x00000000ca199190> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:426)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:253)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:168)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
{code}

This bit of code needs a bit of refactor such that we can get in state of hosting server -- whether its stopped/stopping or not."
HBASE-5323,"We know that while parsing the HLog we expect the proper length from HDFS.
In WALReaderFSDataInputStream
{code}
              assert(realLength >= this.length);
{code}
We are trying to come out if the above condition is not satisfied.  But if SSH.splitLog() gets this problem then it lands in the run method of EventHandler.  This kills the SSH thread and so further assignment does not happen.  If ROOT and META are to be assigned they cannot be.
I think in this condition we abort the master by catching such exceptions.
Please do suggest."
HBASE-5116,"As part of HBASE-5094 we found the possibility of doubly assignments of regions.  This JIRA is to avoid such double assignments.

The idea is to get the regions corresponding to an RS in the the META and compare the regions online in the RS.  Remove those regions from the online list if they dont match.
"
HBASE-12236,"As discussed in thread 'NoSuchMethodError using zipkin with hbase 0.98.5', HBaseSpanReceiver.config() method from htrace-hbase module expects parameter of type org.htrace.HTraceConfiguration.

However, org.apache.hadoop.hbase.trace.HBaseHTraceConfiguration in 0.98 extends org.cloudera.htrace.HTraceConfiguration , leading to the following compilation error when building htrace-hbase against 0.98:
{code}
[ERROR]
/home/hadoop/git/htrace/htrace-hbase/src/main/java/org/htrace/impl/HBaseSpanReceiver.java:[341,12]
error: method configure in class HBaseSpanReceiver cannot be applied to
given types;
{code}
Thanks to Abhishek Kumar who reported the above issue."
HBASE-10542,"I got this in one of my test runs: 
{code}
<error type=""java.util.ConcurrentModificationException"">java.util.ConcurrentModificationException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:894)
        at java.util.HashMap$KeyIterator.next(HashMap.java:928)
        at org.cloudera.htrace.TraceTree.&lt;init&gt;(TraceTree.java:48)
        at org.apache.hadoop.hbase.trace.TestHTraceHooks.testTraceCreateTable(TestHTraceHooks.java:118)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
{code}

It looks like TraceTree ctor, clones the spans collection, but iterates over the original argument, rather than cloned. 

I don't know enough of HTrace to fix it, so just reporting it here. [~eclark] FYI. "
HBASE-10185,"Throwing a DoNotRetryIOException inside  Writable.write(Dataoutput) method doesn't prevent HBase from retrying. Debugging the code locally, I figured that the bug lies in the way HBaseClient simply throws an IOException when it sees that a connection has been closed unexpectedly.  

Method:
public Writable call(Writable param, InetSocketAddress addr,
                       Class<? extends VersionedProtocol> protocol,
                       User ticket, int rpcTimeout)

Excerpt of code where the bug is present:
while (!call.done) {
        if (connection.shouldCloseConnection.get()) {
          throw new IOException(""Unexpected closed connection"");
        }

Throwing this IOException causes the ServerCallable.translateException(t) to be a no-op resulting in HBase retrying. 

From my limited view and understanding of the code, one way I could think of handling this is by looking at the closeConnection member variable of a connection to determine what kind of exception should be thrown. 

Specifically, when a connection is closed, the current code does this: 

    protected synchronized void markClosed(IOException e) {
      if (shouldCloseConnection.compareAndSet(false, true)) {
        closeException = e;
        notifyAll();
      }
    }

Within HBaseClient's call method, the code could possibly be modified to:

while (!call.done) {
        if (connection.shouldCloseConnection.get() ) {
                 if(connection.closeException instanceof                   DoNotRetryIOException) {
throw closeException;
}
          throw new IOException(""Unexpected closed connection"");
        }
"
HBASE-11711,"Currently TestZooKeeper attempts to launch to masters and the info ports collide. This disables the info port for this test.
"
HBASE-3087,"This was discussed on an email thread and then summarized in a comment from stack over in HBASE-2888 (which is a more broad jira):

{quote}
Setting hbase.period in hadoop-metrics.properties doesn't seem to have an effect; counts are off. Here's what I noticed digging in code:
'hadoop-metrics.properties' gets read up into a metrics attributes map but nothing seems to be done w/ them subsequently. Reading up in hadoop, in branch-0.20/src/core/org/apache/hadoop/metrics/package.html, it seems to imply that we need to getAttribute and set them after we make a metrics Context; i.e. in this case, call setPeriod in RegionServerMetrics, etc.?

More broadly, need to make sure settings in hadoop-metrics.properties take effect when changed.
{quote}"
HBASE-3413,"I recently experienced a cluster malfunction which was caused by a change in DNS config for services co-hosted on the machines running region servers.

The RS are specified using IP addresses in the 'regionservers' file. Those machines are 1.example.com to N.example.com (there are A RRs for those names to each of the N IP addresses in 'regionservers').

Until recently, the PTR RRs for the RS IPs were those x.example.com names.

Then a service was deployed on some of the x.example.com machines, and new A RRs were added for svc.example.com which point to each of the IPs used for the service.

Jointly new PTR records were added too for the given IPs. Those PTR records have 'svc.example.com' as their PTRDATA, and this is causing the HBase cluster to get completely confused.

Since it is perfectly legal to have multiple PTR records, it seems important to make the canonicalization of RS more robust to DNS tweaks.

Maybe generating a UUID when a RS is started would help, this UUID could be used to register the RS in ZK and we would not rely on DNS for obtaining a stable canonical name (which may not even exist...).
"
HBASE-6768,"I have a CF with one qualifier, data size is > 5 MB, when i try to read the raw binary data as octet-stream using curl, rest server got crashed and curl throws exception as

{code}
 curl -v -H ""Accept: application/octet-stream"" http://abcdefgh-hbase003.test1.test.com:9090/table1/row_key1/cf:qualifer1 > /tmp/out

* About to connect() to abcdefgh-hbase003.test1.test.com port 9090
*   Trying xx.xx.xx.xxx... connected
* Connected to abcdefgh-hbase003.test1.test.com (xx.xxx.xx.xxx) port 9090
> GET /table1/row_key1/cf:qualifer1 HTTP/1.1
> User-Agent: curl/7.15.5 (x86_64-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5
> Host: abcdefgh-hbase003.test1.test.com:9090
> Accept: application/octet-stream
> 
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0< HTTP/1.1 200 OK
< Content-Length: 5129836
< X-Timestamp: 1347338813129
< Content-Type: application/octet-stream
  0 5009k    0 16272    0     0   7460      0  0:11:27  0:00:02  0:11:25 13872transfer closed with 1148524 bytes remaining to read
 77 5009k   77 3888k    0     0  1765k      0  0:00:02  0:00:02 --:--:-- 3253k* Closing connection #0

curl: (18) transfer closed with 1148524 bytes remaining to read

{code}

Couldn't find the exception in rest server log or no core dump either. This issue is constantly reproducible. Even i tried with HBase Rest client (HRemoteTable) and i could recreate this issue if the data size is > 10 MB (even with MIME_PROTOBUF accept header)
"
HBASE-8100,"The documentation on the Wiki for the Scan methods in Thrift are wrong.  The wiki page is http://wiki.apache.org/hadoop/Hbase/ThriftApi.  The openScanner, getScannerResult and closeScanner methods aren't methods in the Thrift interface.  They should be scannerOpen, scannerGet, and scannerClose.  Some of the method paramaters might need to be changed too."
HBASE-2110,Move to ivy broke pulling in hbase.css from the static webapp; investigate.
HBASE-10577,"In the new disruptor based FSHLog, the Syncer threads are handed a batch of SyncFuture objects from the RingBufferHandler. The Syncer then invokes a sync call on the current writer instance.
This handing of batch is done in serially in RingBufferHandler, that is, every syncer receives a non overlapping batch of SyncFutures. Once synced, Syncer thread updates highestSyncedSequence.

In the run method of Syncer, we have:
{code}
            long currentHighestSyncedSequence = highestSyncedSequence.get();
            if (currentSequence < currentHighestSyncedSequence) {
              syncCount += releaseSyncFuture(takeSyncFuture, currentHighestSyncedSequence, null);
              // Done with the 'take'.  Go around again and do a new 'take'.
              continue;
            }
{code}
I find this logic of polling the BlockingQueue again in this condition un-necessary. When the currentHighestSyncedSequence is already greater than currentSequence, then doesn't it mean some other Syncer has already synced SyncFuture of these ops ? And, we should just go ahead and release all the SyncFutures for this batch to unblock the handlers. That would avoid polling the Blockingqueue for all SyncFuture objects in this case."
HBASE-11570,"HBase provide an export snapshot command to MR copy the snapshot files into a remove cluster. However, if current cluster is not running MR, but target cluster is, we will need to export the list of files into the target cluster and run a distcp from there.

To do so, given a snapshot name we need HBase to provide the list of files belonging to it."
HBASE-7928,"{code}
    try {
      HTable metaTable = new HTable(config, Bytes.toBytes("".META.""));
      Scan scan = new Scan();
      scan.setStartRow(Bytes.toBytes(""e""));
      scan.setStopRow(Bytes.toBytes(""z""));
      ResultScanner scanner = metaTable.getScanner(scan);
      Result[] results = scanner.next(100);
      while (results.length > 0) {
        for (Result result : results) {
          System.out.println(Bytes.toString(result.getRow()));
        }
        results = scanner.next(100);
      }
      scanner.close();
      metaTable.close();
    } catch (Exception e) {
      e.printStackTrace();
    }
{code}

This code will not return any result even if there is 10 tables with names starting with ""d"" to ""w"", including one table called ""entry"". If you comment the setStopRow you will get results, but will still get rows starting with ""d"" even if setStartRow is set to ""e"".

Same code using with a user table is working fine.

Facing the same issue with the shell.

scan '.META.' , {STARTROW => 'e', LIMIT => 10} is returning rows starting by ""d"".

scan '.META.' , {STARTROW => 'e', STOPROW => 'v', LIMIT => 10} is not returning anything."
HBASE-3527,"Hi,
I am using 0.20.6 version of hbase. Got the following error while closing a table.

> Caused by: java.lang.IndexOutOfBoundsException: toIndex = 1
>        at java.util.SubList.<init>(AbstractList.java:602)
>        at java.util.RandomAccessSubList.<init>(AbstractList.java:758)
>        at java.util.AbstractList.subList(AbstractList.java:468)
>        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:668)
>        at org.apache.hadoop.hbase.client.HTable.close(HTable.java:682)
>
>
 Thanks,
 Murali Krishna"
HBASE-3046,We're seeing an EOFE playing recovered.edits file loading region.  See http://permalink.gmane.org/gmane.comp.java.hadoop.hbase.user/12312 thread.  I took a look.  It looks like last record in file is incomplete as though we're not flushing.
HBASE-3487,"while testing I was having problems with my master aborting early on, which causes trouble with the regionservers... they are SUPPOSED to wait forever for the master to come up, but they eventually 'give up' without saying anything helpful.  For example this was in the log:

2011-01-27 17:27:25,912 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:27:28,912 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:27:31,912 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:27:34,912 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:27:37,913 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:28:37,593 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: LRU Stats: total=3.26 MB, free=393.42 MB, max=396.68 MB, blocks=1, accesses=69, hits=64, hitRatio=92.75%%, cachingAccesses=65, cachingHits=64, cachingHitsRatio=98.46%%, evictions=0, evicted=0, evictedPerRun=NaN

then nothing else.  It had been well over 3 minutes at this point.  jstacking the process shows lots of threads running, but the process is effectively dead and only kill -9 will get rid of it."
HBASE-3477,"It seems that the filters will not be invoke when there are only a few data in the table.

I added some logs to the org.apache.hadoop.hbase.filte. PrefixFilter, and has a MyInputFormat extends hbase.mapred.TableInputFormat, the deprecated mapred APIs.

The log added to PrefixFilter
{noformat} 
  public boolean filterRowKey(byte[] buffer, int offset, int length) {
    log.info(""TODO: filterRowKey invoked"");
    if (buffer == null || this.prefix == null) {
        log.info(""TODO: #1 of filter"");
      return true;
    }
    if (length < prefix.length) {
   ...
  }
{noformat} 

This is the code in my InputFormat's configure method.
{noformat} 
byte[] prefix = Bytes.toBytes(""001"");
Filter filter = new PrefixFilter(prefix);
setRowFilter(filter);
{noformat} 

And the job setup code.
{noformat} 
job.setInputFormat(MyInputFormat.class);
FileInputFormat.addInputPaths(job, ""my_table_in_hbase"");
job.set(TableInputFormat.COLUMN_LIST, ""data:"");
{noformat} 

When I put lots of data (> 500,000) in the table, the filter works well, but when I put only a few data (<100) in the table, it seems that the filter will not be invoked,  and the log in the filter has no output either.

This is the log output when lots of data in the table
{noformat} 
2011-01-25 16:43:59,568 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: default constructor
2011-01-25 16:44:01,728 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: filterRowKey invoked
2011-01-25 16:44:01,728 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: #3 of filter
2011-01-25 16:44:01,728 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: filterAllRemaining invoked
2011-01-25 16:44:01,729 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: filterAllRemaining invoked
2011-01-25 16:44:01,729 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: filterAllRemaining invoked
{noformat} "
HBASE-3458,HBASE-3449 'Server shutdown handlers deadlocked waiting for META' describes case where we could block waiting on -ROOT- deploy but all of the handlers on master are occupied waiting on -ROOT- leaving none open to handle -ROOT-.  HBASE-3449 workaround makes the likelihood low.  This issue is about fixing it once and for all (cancel of the excecutor and requeuing or some such device).
HBASE-3390,"I see double-assign during a rolling restart test.  Its happening when master joins existing cluster... half the RSs have reported in but its taking on splits anyways (I have it splitting and balancing continuously).  A split comes in immediately followed by a balance.  What I think is happening is that the split comes in and clears a CLOSING from RIT as part of its cleanup of parent region references.  This is messing up the run of balancers' close somehow; we're getting node created and children changed zk events and this makes somehow for the double closed.

I'm enabling zk logging and will try harder to hunt this one down.

Not creating as BLOCKER on 0.90.0 because I think its ok to disable balancer while rolling restart is going on -- and the current rolling restart is a horror anyways doing its maximmal region moving."
HBASE-3197,"I created a DAO object for loading and storing data into HBase. The DAO has a HBaseConfiguration field, created inside the DAO constructor. Each DAO's method creates a new HTable using the class's HBaseConfiguration. The problem shows up when subsequent writings (using a put) are invoked, since not all the data is written. Moreover this behaviour is not deterministic: invoking the same writings never writes all the data, but the missing ones change every time.
I solved this situation removing the class's HBaseConfiguration and creating a new HBaseConfiguration inside each method."
HBASE-3190,"Table disabling was interrupted by kill -9 all part of hbase and now we cannot do anything with this table, disabling doesn't show any exception:
hbase(main):019:0> disable 'NGolden_CTU'
0 row(s) in 0.0250 seconds


but droping show this:
hbase(main):020:0> drop 'NGolden_CTU'   

ERROR: org.apache.hadoop.hbase.TableNotDisabledException: org.apache.hadoop.hbase.TableNotDisabledException: NGolden_CTU
        at org.apache.hadoop.hbase.master.HMaster.checkTableModifiable(HMaster.java:861)
        at org.apache.hadoop.hbase.master.handler.TableEventHandler.<init>(TableEventHandler.java:52)
        at org.apache.hadoop.hbase.master.handler.DeleteTableHandler.<init>(DeleteTableHandler.java:42)
        at org.apache.hadoop.hbase.master.HMaster.deleteTable(HMaster.java:779)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:570)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025)

Here is some help for this command:
          Drop the named table. Table must first be disabled. If table has
          more than one region, run a major compaction on .META.:

          hbase> major_compact "".META.""

after this nothing strange is in logs

when we restart hbase we get this:

2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.                                                        
2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780005 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING                                                         
2010-11-03 08:56:37,892 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_RS_OPEN_REGION                                                                                                                                                  
java.lang.NullPointerException                                                                                                                                                                                                                                                         
        at org.apache.hadoop.hbase.util.Writables.getWritable(Writables.java:75)                                                                                                                                                                                                       
        at org.apache.hadoop.hbase.executor.RegionTransitionData.fromBytes(RegionTransitionData.java:198)                                                                                                                                                                              
        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNode(ZKAssign.java:669)                                                                                                                                                                                                
        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNodeOpening(ZKAssign.java:549)                                                                                                                                                                                         
        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNodeOpening(ZKAssign.java:542)                                                                                                                                                                                         
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.transitionZookeeperOfflineToOpening(OpenRegionHandler.java:208)                                                                                                                                              
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:89)                                                                                                                                                                           
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)                                                                                                                                                                                                    
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)                                                                                                                                                                                         
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)                                                                                                                                                                                             
        at java.lang.Thread.run(Thread.java:619)                                                                              



Other logs with this region:

hbase@db2a:logs$ grep ""0c8579e52b0ea3f2dab5b6a857ad030b"" hbase-hbase-master-db2a.goldenline.pl.log 
2010-11-03 08:54:02,575 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Async create of unassigned node for 0c8579e52b0ea3f2dab5b6a857ad030b with OFFLINE state
2010-11-03 08:54:03,555 DEBUG org.apache.hadoop.hbase.master.AssignmentManager$CreateUnassignedAsyncCallback: rs=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=OFFLINE, ts=1288770842575, server=db2a.goldenline.pl,60020,1288770551154
2010-11-03 08:54:03,777 DEBUG org.apache.hadoop.hbase.master.AssignmentManager$ExistsUnassignedAsyncCallback: rs=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=OFFLINE, ts=1288770842575
2010-11-03 08:54:42,836 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=PENDING_OPEN, ts=1288770843777
2010-11-03 08:54:42,836 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_OPEN for too long, reassigning region=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=PENDING_OPEN, ts=1288770843777
2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. so generated a random one; hri=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b., src=, dest=db2b.goldenline.pl,60020,1288770553679; 2 (online=2, exclude=null) available servers
2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. to db2b.goldenline.pl,60020,1288770553679
2010-11-03 08:56:12,824 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=db2a.goldenline.pl,60020,1288770551154, region=0c8579e52b0ea3f2dab5b6a857ad030b
2010-11-03 08:56:12,975 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=db2a.goldenline.pl,60020,1288770551154, region=0c8579e52b0ea3f2dab5b6a857ad030b
2010-11-03 08:56:12,976 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for 0c8579e52b0ea3f2dab5b6a857ad030b; deleting unassigned node
2010-11-03 08:56:12,976 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Deleting existing unassigned node for 0c8579e52b0ea3f2dab5b6a857ad030b that is in expected state RS_ZK_REGION_OPENED
2010-11-03 08:56:12,978 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Successfully deleted unassigned node for region 0c8579e52b0ea3f2dab5b6a857ad030b in expected state RS_ZK_REGION_OPENED
2010-11-03 08:56:13,011 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Opened region NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. on db2a.goldenline.pl,60020,1288770551154





hbase@db2a:logs$ grep ""0c8579e52b0ea3f2dab5b6a857ad030b"" hbase-hbase-regionserver-db2a.goldenline.pl.log 
2010-11-03 08:54:04,470 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received request to open region: NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:12,770 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:12,770 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region: REGION => {NAME => 'NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.', STARTKEY => '3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E', ENDKEY => '3065-d_2010_9_11_47D955785DEC3CE95377D70F67BA5ABC', ENCODED => 0c8579e52b0ea3f2dab5b6a857ad030b, TABLE => {{NAME => 'NGolden_CTU', FAMILIES => [{NAME => 'c', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'LZO', VERSIONS => '1', TTL => '-1', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}]}}
2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Instantiated NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:12,939 INFO org.apache.hadoop.hbase.regionserver.StoreFile$Reader: Loaded row bloom filter metadata for hdfs://db2a:50001/hbase/NGolden_CTU/0c8579e52b0ea3f2dab5b6a857ad030b/c/561636411807463667
2010-11-03 08:56:12,939 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://db2a:50001/hbase/NGolden_CTU/0c8579e52b0ea3f2dab5b6a857ad030b/c/561636411807463667, isReference=false, isBulkLoadResult=false, seqid=1820373362, majorCompaction=true
2010-11-03 08:56:12,939 INFO org.apache.hadoop.hbase.regionserver.HRegion: Onlined NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.; next sequenceid=1820373363
2010-11-03 08:56:12,939 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2010-11-03 08:56:12,970 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2010-11-03 08:56:12,971 INFO org.apache.hadoop.hbase.catalog.MetaEditor: Updated row NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. in region .META.,,1 with server=db2a.goldenline.pl:60020, startcode=1288770551154
2010-11-03 08:56:12,971 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2010-11-03 08:56:12,973 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2010-11-03 08:56:12,973 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Opened NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.




hbase@db2b:logs$  grep ""0c8579e52b0ea3f2dab5b6a857ad030b"" hbase-hbase-regionserver-db2b.goldenline.pl.log
2010-11-03 08:54:42,840 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received request to open region: NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780005 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
"
HBASE-2959,"In HBASE-2248, the code in {{HRegion#get}} was changed like so:
{code}
-  private void get(final Store store, final Get get,
-    final NavigableSet<byte []> qualifiers, List<KeyValue> result)
-  throws IOException {
-    store.get(get, qualifiers, result);
+  /*
+   * Do a get based on the get parameter.
+   */
+  private List<KeyValue> get(final Get get) throws IOException {
+    Scan scan = new Scan(get);
+
+    List<KeyValue> results = new ArrayList<KeyValue>();
+
+    InternalScanner scanner = null;
+    try {
+      scanner = getScanner(scan);
+      scanner.next(results);
+    } finally {
+      if (scanner != null)
+        scanner.close();
+    }
+    return results;
   }
{code}
So instead of doing a {{get}} straight on the {{Store}}, we now open a scanner.  The problem is that we eventually end up in {{ScanQueryMatcher}} where the constructor does: {{this.startKey = KeyValue.createFirstOnRow(scan.getStartRow());}}.  This entails that if we have a very wide row (thousands of columns), the scanner will need to go through thousands of {{KeyValue}}'s before finding the right entry, because it always starts from the beginning of the row, whereas before it was much more straightforward.

This problem was under the radar for a while because the overhead isn't too unreasonable, but later on, {{incrementColumnValue}} was changed to do a {{get}} under the hood.  At StumbleUpon we do thousands of ICV per second, so thousand of times per second we're scanning some really wide rows.  When a row is contented, this results in all the IPC threads being stuck on acquiring a row lock, while one thread is doing the ICV (albeit slowly due to the excessive scanning).  When all IPC threads are stuck, the region server is unable to serve more requests.

As a nice side effect, fixing this bug will make {{get}} and {{incrementColumnValue}} faster, as well as the first call to {{next}} on a scanner."
HBASE-2848,"From an hbase admirer:

""t seems that having -verbose:gc in $HBASE_OPTS in
conf/hbase-env.sh is making some scripts unhappy:
$ ./bin/start-hbase.sh
[1: ssh: [1: Name or service not known
CMS-initial-mark:: ssh: CMS-initial-mark:: Name or service not known
6696K(83008K),: ssh: 6696K(83008K),: Name or service not known
0K(63872K)]: ssh: 0K(63872K)]: Name or service not known
secs]: ssh: secs]: Name or service not known
[Times:: ssh: [Times:: Name or service not known
....""

I've seen this myself."
HBASE-3077,"HBASE-3063 has a bit of detail.  The new master is better around disable, delete but still not good enough.  This issue is about digging in a bit.  While disable and enable are not just flags up in zk, setting either is followed by the actual open/close of regions.  We need to add support to the master where it can follow swift enabling/disabling.  HBASE-3063 add some lag to the delete so we'll wait on region close before we go ahead and remove the region but we should be able to do better here too... e.g.  make use of Nicolas's new interrupt compactions so delete doesn't ahve to wait on ongoing compactions... and we could add an abort of specific regions only so we could  just crash them closed rather than wait on flushes if they are going to be just deleted anyways."
HBASE-2929,"When HBaseAdmin.disableTable() was called for the following table, it seemed to hang:

NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479

This is jstack for client:

""main"" prio=10 tid=0x000000005c4ac800 nid=0x3ce9 in Object.wait() [0x0000000041060000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:485)
        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:721)
        - locked <0x00002aaabc6433a0> (a org.apache.hadoop.hbase.ipc.HBaseClient$Call)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:333)
        at $Proxy10.disableTable(Unknown Source)
        at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:467)
        at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:446)

Here is snippet from the region server log where the region is located:
http://pastebin.com/S1fHN7cM

Here is snippet from master log:
http://pastebin.com/8ZL7qihk

I found that only one region from NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479 (currently disabled) remained in the table as of now.

In master server log, I can see 3 actions on any of the other regions in the table:

2010-08-18 06:41:55,345 INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_CLOSE: NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,D68741A06F0EB8AF4D8579BF17864031,1282075349107 from us01-ciqps1-grid06.carrieriq.com,60020,1282088004819; 1 of 15
2010-08-18 06:41:55,345 DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: ProcessRegionClose of NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,D68741A06F0EB8AF4D8579BF17864031,1282075349107, true, reassign: false
2010-08-18 06:41:55,365 INFO org.apache.hadoop.hbase.master.ProcessRegionClose$1: region closed: NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,D68741A06F0EB8AF4D8579BF17864031,1282075349107

But for NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,74A6A44B129151AD71C061D100F5CFA3,1282075834828 I only see one action:

2010-08-18 06:41:56,105 INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_CLOSE: NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,74A6A44B129151AD71C061D100F5CFA3,1282075834828 from us01-ciqps1-grid04.carrieriq.com,60020,1282087981085; 1 of 5"
HBASE-2966,"We noticed in one case the HBase client program got stuck on Zookeeper.exists() call.
 
One of the threads was stuck here on the ZK call while holding an HBase level lock (regionLockObject in locateRegionInMeta()).

{code} 
""thrift-0-thread-8"" prio=10 tid=0x00007f189ca4c000 nid=0x550f in Object.wait() [0x0000000044241000]
   java.lang.Thread.State: WAITING (on object monitor)
                at java.lang.Object.wait(Native Method)
                at java.lang.Object.wait(Object.java:485)
                at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1278)
                - locked <0x00007f1903a0c280> (a org.apache.zookeeper.ClientCnxn$Packet)
                at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:804)
                at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:837)
                at org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.getRSDirectoryCount(ZooKeeperWrapper.java:765)
                at org.apache.hadoop.hbase.client.HTable.getCurrentNrHRS(HTable.java:173)
                at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:147)
                at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:124)
                at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:89)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.prefetchRegionCache(HConnectionManager.java:734)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:785)
                - locked <0x00007f190d868848> (a java.lang.Object)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:679)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:646)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionLocation(HConnectionManager.java:472)
                at org.apache.hadoop.hbase.client.ServerCallable.instantiateServer(ServerCallable.java:57)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:1147)
                at org.apache.hadoop.hbase.client.HTable.get(HTable.java:503)
{code} 

The remaining other threads are all waiting on the regionLockObject lock (held by the above thread) with stacks like:
 
{code}
thrift-0-thread-7"" prio=10 tid=0x00007f189ca4a800 nid=0x550e waiting for monitor entry [0x0000000044141000]
   java.lang.Thread.State: BLOCKED (on object monitor)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:783)
                - waiting to lock <0x00007f190d868848> (a java.lang.Object)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:679)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:646)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionLocation(HConnectionManager.java:472)
                at org.apache.hadoop.hbase.client.ServerCallable.instantiateServer(ServerCallable.java:57)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:1147)
                at org.apache.hadoop.hbase.client.HTable.get(HTable.java:503)
{code}

Any ideas?
 
Meanwhile, I'll look into the ZK logs from the relevant time some more and get back if I have more information.
 
"
HBASE-3011,"When NameNode is not available and HMaster detects it, it tries to shut down itself. However,the main thread stuck at waiting for other scanner threads to exit, which does not happen.

The main problem is that the shutdown request flag is not set to be true so other threads do not know that they need to exit."
HBASE-1746,"Workaround is restart all masters... Then the ones that failed will come up.  So not really an important issue, but its kinda cool one so filing anyway."
HBASE-2885,"As experienced by Karthik Kambatla, Vlad and Steve Kuo, HBase 0.20.5 exhibits inconsistent behavior when user tries to access data in a table.

One such case involves offline region for the underlying table.

See the following threads in hbase user mailing list:
How to delete an ""non-existent"" table
Flaky tableExists()

And this thread in hbase dev mailing list:
Data disappears and re-appears again after HBase cluster restart"
HBASE-2875,I was running for several days with small amounts of data before I started loading lots of data. Upon the first split the region server crashed unable to fine the LZO library.
HBASE-2833,Need a test case to verify the fix for HBASE-2781 ZKW.createUnassignedRegion doesn't make sure existing znode is in the right state
HBASE-2780,"This is on branch - I have 120 clients writing like crazy into a table, it's definitely not disabled. But the web UI says it is. Attaching meta scan."
HBASE-2759,"I deleted a node in the UNASSIGNED dir, and saw this in the logs. I think it's harmless, but worth fixing:

2010-06-20 21:16:15,008 DEBUG org.apache.hadoop.hbase.master.HMaster: Event NodeDeleted with state SyncConnected with path /hbase/UNASSIGNED/1028785192
2010-06-20 21:16:15,008 DEBUG org.apache.hadoop.hbase.master.ZKMasterAddressWatcher: Got event NodeDeleted with path /hbase/UNASSIGNED/1028785192
2010-06-20 21:16:15,008 DEBUG org.apache.hadoop.hbase.master.ZKMasterAddressWatcher: Master address ZNode deleted, notifying waiting masters
"
HBASE-2624,"Saw this test failure on my Hudson:

org.apache.hadoop.hbase.client.RetriesExhaustedException: Still had 11 puts left after retrying 4 times.
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.processBatchOfPuts(HConnectionManager.java:1428)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:540)
	at org.apache.hadoop.hbase.TestMultiParallelPut.doATest(TestMultiParallelPut.java:93)
	at org.apache.hadoop.hbase.TestMultiParallelPut.testParallelPutWithRSAbort(TestMultiParallelPut.java:65)"
HBASE-2723,Saw a timeout of this test on my Hudson (prior to the master ZK change)
HBASE-2563,"We've deprecated io.Cell, so we should probably deprecate methods which return or accept Cell values. See http://hadoop.apache.org/hbase/docs/r0.20.4/api/org/apache/hadoop/hbase/io/class-use/Cell.html for the complete list. Here are some selections:

* getCellValue(), getCellValue(byte[], byte[]), and getCellValues() methods of client.Result
* Entry.getValue() and Entry.setValue(Cell) methods of io.RowResult
* cellFromHBase(Cell[]) and cellFromHBase(Cell) methods of thrift.ThriftUtilities
* Writables.cellToLong(Cell), Writables.cellToString(Cell), and Writables.getHRegionInfo(Cell) methods of hbase.util

Also some hbase.rest stuff, but I don't know what's going on there."
HBASE-2505,"Was just testing the 0.20.4rc5 on a cluster that had a newer format of log files and noticed this:
- If an IOE occurs splitting one log, it will not continue trying to split other logs
- the IOEs are logged to stdout, not to log4j
"
HBASE-2106,"Here is a question from Adam Silberstein who is having trouble writing this list:

""I'm running on a particular cluster of machines and seeing worse than expected performance.  I've run on a different, but identical, cluster of machines and gotten about 2-4x better throughput and latency.  I've checked all of the configuration settings and they are all the same.  The only thing I observe that looks odd is the memory usage by each region server.  I've allocated 6 GB heap space to each.  There is a total of 20GB of records on each.  When I use ""top"" to observe memory usage, I see that the region server process does have 6GB of virtual memory.  When I start running a workload, I can see the amount of resident memory climbing.  However, it always stops at 2GB.  Since I have 20 GB on each region server, I'd expect the process to use all the memory allocated it

""Is there a reasonable explanation for why it stops at 2GB, and/or has anyone seen this happen""

I took a look at the cache code and I see that it has an int for maximum size in the constructor argument though internally its using a long for maximum size.  I wonder if this is the issue?"
HBASE-1948,"I have an existing hbase table with data in it. When I restart hadoop, hbase and zookeeper, I am able to read all of the data that existed in the table prior to the restart. However when I write data to the table, it does not get reflected. 

When I do a disable <table> and then an enable <table> on an hbase shell. The data that was written to the table now appears and the table is up to date. However, even after this my thrift client still sees the old data and not the updated values."
HBASE-1882,"Bits got flipped (it seems) on a read so a key going into hfile was < the previous.  We throw an exception that causes HRS restart.  Just put bad edits aside rather than die.

From elsif up on list:

{code}
Our HBase system ended up in a looping situation trying to continuously
re-assign a damaged region across the HBase cluster. We could not properly
scan or store data in the affected table.

The triggering event that caused this cascade of errors was an
java.io.IOException: Added a key not lexically larger than previous

From the HBase shell ""scan '.META.' command we confirmed the name of the
damaged encoded
region stored in hdfs. In an attempt to fix this, the data directory for
the impacted region
was moved off hdfs and the region was able to be restarted with a blank
slate.

Is there a better way to handle this type of failure?

Is there a way to generate an hlog to re-import the data files we moved
away?

HBase Version: 0.20.0, r805538
Hadoop Version: 0.20.0-plus4681, r767961

Here are the log entries leading up to the event:

2009-09-25 06:57:53,836 INFO org.apache.hadoop.hbase.regionserver.HLog:
Roll /hbase/.logs/hfs-030035,60020,1253122636703/hlog.dat.1253883473798,
entries=1479, calcsize=49659443, filesize=49589196. New hlog
/hbase/.logs/hfs-030035,60020,1253122636703/hlog.dat.1253887073833
2009-09-25 07:05:50,089 INFO
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Forced flushing of
fc_test,\x2Fdata\x2Fmalware\x2F873fc5b61af807827381f120ad7d746984d49426eb3c8b5523b6142285ee0844027f6b45eb8f18aff21b52071a9664e05ceca112a9ff5949c16cda3f27c9c7c2,1253728360248

because global memstore limit of 396.9m exceeded; currently 397.0m and
flushing till 24
8.1m


2009-09-25 07:05:53,294 INFO
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Forced flushing of
fc_test,\x2Fdata\x2Fdir\x2Fdfd2e9615461d03ba7c22d6d804ec23c3dba1587ffb91736d0e90df0b8aa659d6f55efe49552a83271d9e115bd1d706b865dc42008

52493400819628a7be0fc2\x2F2009-09-23_143101\x2Fxml,1253765882755 because
global memstore limit of 396.9m exceeded; currently 357.1m and flushing
till
248.1m

2009-09-25 07:05:55,583 FATAL
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Replay of hlog
required. Forcing serve
r
shutdown

org.apache.hadoop.hbase.DroppedSnapshotException: region:
fc_test,\x2Fdata\x2Fdir\x2Fdfd2e9615461d03ba7c22d6d804ec23c3dba1587ffb91736d0e90df0b8aa659d6f55efe49552a83271d9e115bd1d706b865dc4200852493400819628a7be0fc2\x2F2009-09-23_143101\

x2Fxml,1253765882755


at
org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:950)

at
org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:843)
   at
org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:241)

at
org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushSomeRegions(MemStoreFlusher.java:352)

at
org.apache.hadoop.hbase.regionserver.MemStoreFlusher.reclaimMemStoreMemory(MemStoreFlusher.java:321)

   at
org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1809)


   at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)
   at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
   at java.lang.reflect.Method.invoke(Unknown Source)
   at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
   at
org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
Caused by: java.io.IOException: Added a key not lexically larger than
previous
key=^@?/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4^D11ff79bb955c50b99c8f80fdff0b4beb413d8ea/2009-09-25_034206^Ejson:^@^@^A#?M?)^D,

lastkey=^@?/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4d11ff79bb955c50b99c8f80fdff0b4beb413d8ea^Ejson:^@^@^A#?M?#^D

   at
org.apache.hadoop.hbase.io.hfile.HFile$Writer.checkKey(HFile.java:517)
   at org.apache.hadoop.hbase.io.hfile.HFile$Writer.append(HFile.java:479)
   at org.apache.hadoop.hbase.io.hfile.HFile$Writer.append(HFile.java:447)
   at
org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:525)

   at
org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:489)
2009-09-25 07:05:55,608 INFO
org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics:
request=0.0, regions=15,
 stores=30, storefiles=43, storefileIndexSize=3, memstoreSize=396,
usedHeap=540, maxHeap=992, blockCacheSize=73256760, blo
ckCacheFree=967258312, blockCacheCount=1128, blockCacheHitRatio=90
2009-09-25 07:05:55,609 WARN
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Flush failed
2009-09-25 07:05:55,684 INFO org.apache.hadoop.ipc.HBaseServer: Stopping
server on 60020


Here are the log entries after restarting:

2009-09-28 11:36:16,608 INFO org.apache.hadoop.ipc.HBaseServer: IPC
Server handler 0 on 60020: starting
2009-09-28 11:36:16,620 ERROR
org.apache.hadoop.hbase.regionserver.HRegionServer:
org.apache.hadoop.hbase.NotServingRegionException:
[B@1a001ff               at
org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionS
erver.java:2263)

at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.
java:1767)

at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
       at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown
Source)                  at
sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
       at java.lang.reflect.Method.invoke(Unknown
Source)                              at
org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
       at
org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

{code}

....

and

{code}
stack wrote:
> On Mon, Sep 28, 2009 at 3:27 PM, elsif <elsif.then@gmail.com> wrote:
>
>
>> Our HBase system ended up in a looping situation trying to continuously
>> re-assign a damaged region across the HBase cluster. We could not properly
>> scan or store data in the affected table.
>>
>> The triggering event that caused this cascade of errors was an
>> java.io.IOException: Added a key not lexically larger than previous
>>
>>
>
>
> Here are the offending keys purportedly:
>
> key=^@?/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4^D11ff79bb955c50b99c8f80fdff0b4beb413d8ea/2009-09-25_034206^Ejson:^@^@^A#?M?)^D,
> lastkey=^@?/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4d11ff79bb955c50b99c8f80fdff0b4beb413d8ea^Ejson:^@^@^A#?M?#^D
>
>
>
> It seems like keys are fine till we get to '^D'.    Can you make these keys
> or comment on them?  The '^D' is a printable version of whatever the bit of
> binary was here.  Do you have an idea what it was?  Can you remanufacture
> this condition?  Something in our comparator is messing up?  Is that
> possible?
>
>

The keys are all plain text strings with no special characters.  Not
sure where the '^D' would come from since the same processes is used to
generate all the keys.
> This is in .META. table?
>

This is from a regular table.
>
>
>
>
>
> >From the HBase shell ""scan '.META.' command we confirmed the name of the
>
>> damaged encoded
>> region stored in hdfs. In an attempt to fix this, the data directory for
>> the impacted region
>> was moved off hdfs and the region was able to be restarted with a blank
>> slate.
>>
>> Is there a better way to handle this type of failure?
>>
>>
>>
>
> There is a script that will repair the broke files rewriting them removing
> the offending edit.  I'd point you at the script only its up in an Apache
> JIRA and thats sick at the moment.
>
> You could try running:
>
> ./bin/hbase org.apache.hadoop.hbase.io.hfile.HFile
>
> It has diagnostic and outputting facility.  Pass it the bad files.
>
>
>
I scanned each of the files with the -k option, no warnings were generated.

I also extracted all the key values from each file - none of them appear
to contain the key with the '^D'.

The 'key' and 'lastkey' listed above were contained in the
oldlogfile.log.  I opened the oldlogfile.log with a hex editor and
verified that the key does not contain any binary characters where the
'^D' is shown in the error log.  The character is actually a lowercase 'd':

/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4d11ff79bb955c50b99c8f80fdff0b4beb413d8ea/2009-09-25_034206

It would seem this was a read error of some kind.

>
>
>> Is there a way to generate an hlog to re-import the data files we moved
>> away?
>>
>>
>>
>
> Above mentioned script is probably the better way to go.
>
>
>
>
>> HBase Version: 0.20.0, r805538
>> Hadoop Version: 0.20.0-plus4681, r767961
>>
>>
>>
> Are these release 0.20.0?
>
The hadoop is release 0.20.0 - the hbase is a pre-release svn checkout.
> St.Ack
>
>
>
>
{code}"
HBASE-1894,"The region server appears to reference blocks from deleted log files after compaction.  Stopping the affected region server causes the region to be reassigned and appears to function properly again.

We have seen two instances this week where this caused the region server to get stuck with the following error:

hbase-root-regionserver-hfs-030015.log:2009-10-07 12:24:41,853 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_6092375271544310747_250240 from any node:  java.io.IOException: No live nodes contain current block
.
.
.
/opt/hbase/logs/hbase-root-regionserver-hfs-030015.log:java.io.IOException: Cannot open filename /hbase/fc_test/1209236691/json/9131415140626575165
/opt/hbase/logs/hbase-root-regionserver-hfs-030015.log:2009-10-07 13:09:47,343 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_6092375271544310747_250240 from any node:  java.io.IOException: No live nodes contain current block

From the hdfs log we can see that the block in question was part of a compaction log:

hadoop-root-namenode-hfs-030010.log:2009-10-07 08:48:31,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/fc_test/compaction.dir/1209236691/2099727166320402414. blk_6092375271544310747_250240
hadoop-root-namenode-hfs-030010.log:2009-10-07 08:48:31,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.4.30.39:50010 is added to blk_6092375271544310747_250240 size 360813
hadoop-root-namenode-hfs-030010.log:2009-10-07 08:48:31,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.4.30.23:50010 is added to blk_6092375271544310747_250240 size 360813
hadoop-root-namenode-hfs-030010.log:2009-10-07 08:48:31,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.4.30.16:50010 is added to blk_6092375271544310747_250240 size 360813

From the same log we see the block deleted:

hadoop-root-namenode-hfs-030010.log:2009-10-07 12:13:20,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.4.30.39:50010 to delete  blk_-8366798629992987785_250239 blk_-278212026264018289_224708 blk_4131756856877489141_230749 blk_6092375271544310747_250240 blk_-1303356519220271320_144130
hadoop-root-namenode-hfs-030010.log:2009-10-07 12:13:26,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.4.30.23:50010 to delete  blk_3405064566022477311_135928 blk_-7806500863137897827_139699 blk_6092375271544310747_250240
hadoop-root-namenode-hfs-030010.log:2009-10-07 12:13:29,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.4.30.16:50010 to delete  blk_-3938002954120963098_139149 blk_2284074818158875873_144134 blk_519099260905493191_222718 blk_7684159545746656462_144137 blk_7857071994919747100_144127 blk_6311161030310597085_135919 blk_-8366798629992987785_250239 blk_5638304438869005376_142347 blk_-1019479064035180992_143997 blk_4131756856877489141_230749 blk_6092375271544310747_250240 blk_-1520990752128999182_192595 blk_1714900485284856973_230761 blk_-1303356519220271320_144130

"
HBASE-1296,"From a private mail with J茅r么me Thi猫vre:

""Two times I got the same kind of problems described by schubert zhang in the thread *HDFS unbalance issue. (HBase over HDFS). *The first time, I found one of my regionserver  with a full disk, whereas the others were at 10% of their capacity. I saw a lot of move file command at hadoop level from the full regionserver to others, but after check on the hdfs, I can see that hadoop copies the file but fails to delete it.  As the regionserver disk was full, it didn't work anymore, even after hadoop and hbase restart. I had to delete all the data.

""The second time this problem occurs I stopped the row insertion process before the disk was full. After hadoop and hbase restart, hadoop has deleted the files and the system was operational.
It seems that in some cases where the system is heavily loaded with continuous writes and compactions, hadoop can't remove files.""

"
HBASE-1343,Generating thrift bindings with a current release of thrift breaks the python demo client. The attached patch fixes the demo client code.
HBASE-2104,"When a regionservers is stopped (shutdown or crash) and on the same moment a client performs a scan on that regionserver no exception is thrown at client side nor a reconnect toanother regionsserver is tried.
The ResultScanner.Iterator.hasNext ()just returns false, so the client assumes that there are no records anymore.


In the ScannerCallable.call I notice that the java.net.ConnectionException is catched and a empyt Result array is returned.
"
HBASE-2096,"When starting the regionserver (issue also reproduces on master), I get the following error: 

---
2010-01-06 15:10:48,208 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: vmInputArguments=[-Xmx1000m, -XX:+HeapDumpOnOutOfMemoryError, -XX:+UseConcMarkSweepGC, -XX:+CMSIncrementalMode, -Dhbase.log.dir=/Users/adragomi/hbase/bin/../logs, -Dhbase.log.file=hbase-adragomi-regionserver-adragomi-mac.corp.adobe.com.log, -Dhbase.home.dir=/Users/adragomi/hbase/bin/.., -Dhbase.id.str=adragomi, -Dhbase.root.logger=INFO,DRFA]
2010-01-06 15:10:48,211 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Can not start region server because java.lang.NoSuchMethodException: org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(org.apache.hadoop.hbase.HBaseConfiguration)
	at java.lang.Class.getConstructor0(Class.java:2706)
	at java.lang.Class.getConstructor(Class.java:1657)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.doMain(HRegionServer.java:2313)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2394)
---

"
HBASE-1775,"In http://wiki.apache.org/hadoop/Hbase/HowToContribute it clearly states:
{code}
 o All public classes and methods should have informative Javadoc comments. 
{code}

(it should probably read ""correct and informative"")

I have seen missing input parameters and return values. Paying attention to details like this will also lessen the number of questions seen on the hbase-user mailing list."
HBASE-1603,"Here is the master.  Region TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246462685358 was split at 16:11:42,865.  My MR job failed at 18:12:26,462 with this:

{code}
2009-07-01 18:12:26,462 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server Some server for region TestTable,锟?1246464670313, row '锟斤拷		', but failed after 10 attempts.
Exceptions:
...
{code}

Why after ten attempts did the client not find the region?

{code}
2009-07-01 16:11:42,865 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_SPLIT: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246462685358: Daughters; TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313, TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 1 of 3
2009-07-01 16:11:42,866 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 to aa0-000-15.u.powerset.com,60020,1246461673026
2009-07-01 16:11:42,866 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 to aa0-000-15.u.powerset.com,60020,1246461673026
2009-07-01 16:11:45,905 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_PROCESS_OPEN: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 1 of 3
2009-07-01 16:11:45,905 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 2 of 3
2009-07-01 16:11:45,906 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 3 of 3
2009-07-01 16:11:45,906 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 open on 208.76.44.142:60020
2009-07-01 16:11:45,906 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: updating row TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 in region .META.,,1 with startcode 1246461673026 and server 208.76.44.142:60020
2009-07-01 16:11:45,908 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 open on 208.76.44.142:60020
2009-07-01 16:11:45,908 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: updating row TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 in region .META.,,1 with startcode 1246461673026 and server 208.76.44.142:60020
2009-07-01 17:46:42,670 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_SPLIT: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313: Daughters; TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246470379467, TestTable,\x00\x00\x08\x04\x05\x07\x02\x05\x04\x08,1246470379467 from aa0-000-15.u.powerset.com,60020,1246461673026; 5 of 7
{code}

Here is over on the regionserver:

{code}
2009-07-01 16:11:42,865 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_SPLIT: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246462685358: Daughters; TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313, TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 1 of 3
2009-07-01 16:11:42,866 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 to aa0-000-15.u.powerset.com,60020,1246461673026
2009-07-01 16:11:42,866 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 to aa0-000-15.u.powerset.com,60020,1246461673026
2009-07-01 16:11:45,905 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_PROCESS_OPEN: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 1 of 3
2009-07-01 16:11:45,905 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 2 of 3
2009-07-01 16:11:45,906 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 3 of 3
2009-07-01 16:11:45,906 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 open on X.X.X.142:60020
2009-07-01 16:11:45,906 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: updating row TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 in region .META.,,1 with startcode 1246461673026 and server X.X.X4.142:60020
2009-07-01 16:11:45,908 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 open on X.X.X.142:60020
2009-07-01 16:11:45,908 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: updating row TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 in region .META.,,1 with startcode 1246461673026 and server X.X.X.142:60020
{code}"
HBASE-1469,"data4 in the test murmur hash is failing.  I commented out for now:

{code}
    // TODO: This if failing St.Ack
    // assertEquals(-969272041, hash.hash(data4, 4, data4.length-4, seed));
{code}"
HBASE-8900,"Failed here:

https://builds.apache.org/job/hbase-0.95-on-hadoop2/169/testReport/junit/org.apache.hadoop.hbase.regionserver/TestRSKilledWhenMasterInitializing/testCorrectnessWhenMasterFailOver/

and

http://54.241.6.143/job/HBase-0.95-Hadoop-2/579/org.apache.hbase$hbase-server/testReport/junit/org.apache.hadoop.hbase.regionserver/TestRSKilledWhenMasterInitializing/org_apache_hadoop_hbase_regionserver_TestRSKilledWhenMasterInitializing/

{code}
java.lang.Exception: test timed out after 120000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hbase.zookeeper.ZKAssign.blockUntilNoRIT(ZKAssign.java:1002)
	at org.apache.hadoop.hbase.regionserver.TestRSKilledWhenMasterInitializing.testCorrectnessWhenMasterFailOver(TestRSKilledWhenMasterInitializing.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}

and with this:

{code}
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.TestRSKilledWhenMasterInitializing.tearDownAfterClass(TestRSKilledWhenMasterInitializing.java:83)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)

{code}"
HBASE-11411,"In doing read operations with ACL we were checking there is read permission granted on the table
{code}
AuthResult authResult = permissionGranted(opType, user, env, families, Action.READ);
    HRegion region = getRegion(env);
    TableName table = getTableName(region);
    Map<ByteRange, Integer> cfVsMaxVersions = Maps.newHashMap();
    for (HColumnDescriptor hcd : region.getTableDesc().getFamilies()) {
      cfVsMaxVersions.put(new SimpleByteRange(hcd.getName()), hcd.getMaxVersions());
    }
{code}
If there is no permission then we were checking for the type of cell level permission 
{code}
case CHECK_CELL_DEFAULT: {
        if (authManager.authorize(user, table, family, qualifier, Permission.Action.READ) ||
            authManager.authorize(user, table, cell, Permission.Action.READ)) {
          return ReturnCode.INCLUDE;
        }
      }
      break;
      // Cell permissions must authorize
      case CHECK_CELL_FIRST: {
        if (authManager.authorize(user, table, cell, Permission.Action.READ) &&
            authManager.authorize(user, table, family, qualifier, Permission.Action.READ)) {
          return ReturnCode.INCLUDE;
        }
{code}
For CELL_FIRST_STRATEGY 
-> if the user had granted READ permission on the table itself then even if cell level was not granting access we were able to read the cell.
->If table level READ permission was not there then the && condition was failing from reading any cell even with READ permission. 
The 2nd one was an intended behaviour but for the first one I think we should see if really the cell was readable too."
HBASE-8479,"With Roman, am trying to set up a bigtop ci of hbase 0.95 only we fail to compile.  It is the exotic generics that are going on over in AggregateClient.  Here is how we fail:

{code}
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[135,59] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds Q,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[208,59] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds Q,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[328,57] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds T,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[390,57] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds T,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[489,59] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds T,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[591,59] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds T,com.google.protobuf.Message
[INFO] 6 errors 
{code}

I cannot reproduce locally but googling, I see that above is pretty common complaint when you move between compilers.  Various are the recommendations for fix but none definitive.  The easiest is dumbing down the generics which I tried but it only caused issues in other coprocessors.

If clues on how to fix this, I'm all ears.  Would like to get this bigtop ci build running.  Its cool."
HBASE-6577,RegionScannerImpl.nextRow() is called when a filter filters the entire row. In that case we should seek to the next row rather then iterating over all versions of all columns to get there.
HBASE-9980,"See HBASE-9834.

We should have a test that:
# generates a file with all kinds of objects serialized into it. Save that file as part of the HBase tests
# a test can then read the objects back from that file
# a test can regenerate that file

If both tests pass we can be reasonably sure that neither readFields nor write was changed in an incompatible way."
HBASE-11075,Latest precommit builds I could see TestVisibilityLabelsWithDistributedLogReplay failing frequently.  Need to identify the root cause and fix it.
HBASE-9729,"mvn site fails on hadoopqa runs, and also on fresh checkouts. The problem seems to be that mvn site somehow does not trigger a correct reactor ordering. hbase-server is built before other components, and thus throws dependency errors because the other modules are not build yet. 

An example from https://builds.apache.org/job/PreCommit-HBASE-Build/7491//consoleFull: 
{code}
/home/jenkins/tools/maven/latest/bin/mvn compile site -DskipTests -DHBasePatchProcess > /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/patchprocess/patchSiteOutput.txt 2>&1
{code}


"
HBASE-11146,"See HBASE-11096.

in 0.99, HRegionServer is the base class of HMaster. 
master and regionserver share the same run method, the master instantiates both MasterCoprocessorHost and RegionServerCoprocessorHost


below is example logs, a coprocessor is start/stop twice--one is for real regionserver, the other is for the RegionServerCoprocessorHost in master.

2014-05-08 00:33:51,632 INFO [M:0;bdvm135:36021] coprocessor.TestCoprocessorStop$FooCoprocessor(66): st
art coprocessor on regionserver

2014-05-08 00:33:51,633 INFO [RS:0;bdvm135:47513] coprocessor.TestCoprocessorStop$FooCoprocessor(66): s
tart coprocessor on regionserver

...
2014-05-08 00:34:03,166 INFO [main] regionserver.HRegionServer(1624): call stack of stop
java.io.IOException
at org.apache.hadoop.hbase.regionserver.HRegionServer.stop(HRegionServer.java:1624)
at org.apache.hadoop.hbase.master.ServerManager.shutdownCluster(ServerManager.java:975)
at org.apache.hadoop.hbase.master.HMaster.shutdown(HMaster.java:1623)
at org.apache.hadoop.hbase.util.JVMClusterUtil.shutdown(JVMClusterUtil.java:256)
at org.apache.hadoop.hbase.LocalHBaseCluster.shutdown(LocalHBaseCluster.java:437)
at org.apache.hadoop.hbase.MiniHBaseCluster.shutdown(MiniHBaseCluster.java:519)
at org.apache.hadoop.hbase.coprocessor.TestCoprocessorStop.testStopped(TestCoprocessorStop.java:
114)
...
2014-05-08 00:34:03,215 INFO [main] regionserver.HRegionServer(1629): rsHost code path called

2014-05-08 00:34:03,228 DEBUG [main] coprocessor.CoprocessorHost(258): Stop coprocessor org.apache.hadoo
p.hbase.coprocessor.TestCoprocessorStop$FooCoprocessor
2014-05-08 00:34:03,462 INFO [main] coprocessor.TestCoprocessorStop$FooCoprocessor(88): create file hdf
s://localhost:8155/user/tianq/test-data/f0c9423c-e505-4feb-907e-c7bd6e16545b/regionserver1399534399680 r
eturn rc true

...

2014-05-08 00:34:03,482 INFO [main] regionserver.HRegionServer(1624): call stack of stop
java.io.IOException
at org.apache.hadoop.hbase.regionserver.HRegionServer.stop(HRegionServer.java:1624)
at org.apache.hadoop.hbase.util.JVMClusterUtil.shutdown(JVMClusterUtil.java:264)
at org.apache.hadoop.hbase.LocalHBaseCluster.shutdown(LocalHBaseCluster.java:437)
at org.apache.hadoop.hbase.MiniHBaseCluster.shutdown(MiniHBaseCluster.java:519)
at org.apache.hadoop.hbase.coprocessor.TestCoprocessorStop.testStopped(TestCoprocessorStop.java:
114)
2014-05-08 00:34:03,485 INFO [main] regionserver.HRegionServer(1629): rsHost code path called

2014-05-08 00:34:03,485 DEBUG [main] coprocessor.CoprocessorHost(258): Stop coprocessor org.apache.hadoo
p.hbase.coprocessor.TestCoprocessorStop$FooCoprocessor
2014-05-08 00:34:03,493 INFO [main] coprocessor.TestCoprocessorStop$FooCoprocessor(88): create file hdf
s://localhost:8155/user/tianq/test-data/f0c9423c-e505-4feb-907e-c7bd6e16545b/regionserver1399534399680 r
eturn rc false"
HBASE-10076,MapReduce over Snapshots would be valuable on 0.94.
HBASE-9740,"As described in HBASE-9737, a corrupt HFile in a region could lead to an assignment storm in the cluster since the Master will keep trying to assign the region to each region server one after another and obviously none will succeed.

The region server, upon detecting such a scenario should mark the region as ""RS_ZK_REGION_FAILED_ERROR"" (or something to the effect) in the Zookeeper which should indicate the Master to stop assigning the region until the error has been resolved (via an HBase shell command, probably ""assign""?)"
HBASE-11041,"Just found a test failing like this:
{code}
Error Message

HTableDescriptor is read-only

Stacktrace

java.lang.UnsupportedOperationException: HTableDescriptor is read-only
	at org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.addFamily(UnmodifyableHTableDescriptor.java:64)
	at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1302)
	at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1291)
	at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1286)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.installTable(TestDistributedLogSplitting.java:485)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.testMasterStartsUpWithLogSplittingWork(TestDistributedLogSplitting.java:282)
{code}

The code that causes this looks like this:
{code}
    HTableDescriptor htd = table.getTableDescriptor();
    if(!htd.hasFamily(columnFamily)) {
      HColumnDescriptor hcd = new HColumnDescriptor(columnFamily);
      htd.addFamily(hcd);
    }
{code}

But note that table.getTableDescriptor() returns an UnmodifyableHTableDescriptor, so the add would *always* fail.

The specific test that failed was TestDistributedLogSplitting.testMasterStartsUpWithLogSplittingWork.
Looks like the HMaster did not have the last table descriptor state, yet.
"
HBASE-10235,Namespace level grants are not checked by the AccessController in 0.96 also.
HBASE-11067,"Due to HADOOP-10499, HBase cannot build against branch-2, I will upload patch shortly."
HBASE-5211,I can't seem to get this test to pass consistently on my laptop. Also my hudson occasionally tripps up on it.
HBASE-6169,"When RS got an ZK error when trying to create a ""CLOSING"" node in the process of closing a region, it hence aborts without completing closing of the region.
RS is then discovered dead by HMaster. ServerShutdownHandler does not try to reassign this region for it is in PENDING_CLOSE state; while all regions that originally belong to the dead RS get removed from the ""regions"" map.
TimeoutMonitor then endlessly tries to ""unassign"" this region with LOG message ""Region has been PENDING_CLOSE for too long"". The ""unassign"" returns without doing anything, for this region does not exist in the ""regions"" map:
  public void unassign(HRegionInfo region, boolean force, ServerName dest) {
    // TODO: Method needs refactoring.  Ugly buried returns throughout.  Beware!
    LOG.debug(""Starting unassignment of region "" +
      region.getRegionNameAsString() + "" (offlining)"");

    synchronized (this.regions) {
      // Check if this region is currently assigned
      if (!regions.containsKey(region)) {
        LOG.debug(""Attempted to unassign region "" +
          region.getRegionNameAsString() + "" but it is not "" +
          ""currently assigned anywhere"");
        return;
      }
    }
  ..."
HBASE-4064,"1. If there is a ""rubbish"" RegionState object with ""PENDING_CLOSE"" in regionsInTransition(The RegionState was remained by some exception which should be removed, that's why I called it as ""rubbish"" object), but the region is not currently assigned anywhere, TimeoutMonitor will fall into an endless loop:

2011-06-27 10:32:21,326 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=PENDING_CLOSE, ts=1309141555301
2011-06-27 10:32:21,326 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_CLOSE for too long, running forced unassign again on region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f.
2011-06-27 10:32:21,438 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining)
2011-06-27 10:32:21,441 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Attempted to unassign region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. but it is not currently assigned anywhere
2011-06-27 10:32:31,207 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=PENDING_CLOSE, ts=1309141555301
2011-06-27 10:32:31,207 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_CLOSE for too long, running forced unassign again on region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f.
2011-06-27 10:32:31,215 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining)
2011-06-27 10:32:31,215 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Attempted to unassign region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. but it is not currently assigned anywhere
2011-06-27 10:32:41,164 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=PENDING_CLOSE, ts=1309141555301
2011-06-27 10:32:41,164 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_CLOSE for too long, running forced unassign again on region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f.
2011-06-27 10:32:41,172 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining)
2011-06-27 10:32:41,172 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Attempted to unassign region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. but it is not currently assigned anywhere
.....

2  In the following scenario, two concurrent unassigning call of the same region may lead to the above problem:
the first unassign call send rpc call success, the master watched the event of ""RS_ZK_REGION_CLOSED"", process this event, will create a ClosedRegionHandler to remove the state of the region in master.eg.
while ClosedRegionHandler is running in  ""hbase.master.executor.closeregion.threads"" thread (A), another unassign call of same region run in another thread(B).
while thread B  run ""if (!regions.containsKey(region))"", this.regions have the region info, now  cpu switch to thread A.
The thread A will remove the region from the sets of ""this.regions"" and ""regionsInTransition"", then switch to thread B. the thread B run continue, will throw an exception with the msg of ""Server null returned java.lang.NullPointerException: Passed server is null for 9a6e26d40293663a79523c58315b930f"", but without removing the new-adding RegionState from ""regionsInTransition"",and it can not be removed for ever.


 public void unassign(HRegionInfo region, boolean force) {
    LOG.debug(""Starting unassignment of region "" +
      region.getRegionNameAsString() + "" (offlining)"");
    synchronized (this.regions) {
      // Check if this region is currently assigned
      if (!regions.containsKey(region)) {
        LOG.debug(""Attempted to unassign region "" +
          region.getRegionNameAsString() + "" but it is not "" +
          ""currently assigned anywhere"");
        return;
      }
    }
    String encodedName = region.getEncodedName();
    // Grab the state of this region and synchronize on it
    RegionState state;
    long stamp = -1;
    synchronized (regionsInTransition) {
      state = regionsInTransition.get(encodedName);
      if (state == null) {
        state = new RegionState(region, RegionState.State.PENDING_CLOSE);
        stamp =state.getStamp();               
        regionsInTransition.put(encodedName, state);
      } else if (force && state.isPendingClose()) {
        LOG.debug(""Attempting to unassign region "" +
            region.getRegionNameAsString() + "" which is already pending close ""
            + ""but forcing an additional close"");
        state.update(RegionState.State.PENDING_CLOSE);
      } else {
        LOG.debug(""Attempting to unassign region "" +
          region.getRegionNameAsString() + "" but it is "" +
          ""already in transition ("" + state.getState() + "")"");
        return;
      }
    }
    
    // Send CLOSE RPC
    HServerInfo server = null;
    synchronized (this.regions) {
      server = regions.get(region);
    }
}

2011-06-27 10:20:59,583 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining) 
2011-06-27 10:20:59,585 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Sent CLOSE to serverName=158-1-91-101,20020,1308983865292, load=(requests=0, regions=0, usedHeap=0, maxHeap=0) for region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. 
2011-06-27 10:22:15,299 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling new unassigned node: /hbase/unassigned/9a6e26d40293663a79523c58315b930f (region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f., server=158-1-91-101,20020,1308983865292, state=RS_ZK_REGION_CLOSED) 
2011-06-27 10:22:15,299 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_CLOSED, server=158-1-91-101,20020,1308983865292, region=9a6e26d40293663a79523c58315b930f 
2011-06-27 10:25:22,636 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out: test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=CLOSED, ts=1309141335247 
2011-06-27 10:25:22,636 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region 9a6e26d40293663a79523c58315b930f has been CLOSED for too long, waiting on queued ClosedRegionHandler to run or server shutdown 
2011-06-27 10:25:55,022 DEBUG org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED event for 9a6e26d40293663a79523c58315b930f 
2011-06-27 10:25:55,022 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. 
2011-06-27 10:25:55,022 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:20000-0x230ba8b85230036 Deleting existing unassigned node for 9a6e26d40293663a79523c58315b930f that is in expected state RS_ZK_REGION_CLOSED 
2011-06-27 10:25:55,101 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:20000-0x230ba8b85230036 Successfully deleted unassigned node for region 9a6e26d40293663a79523c58315b930f in expected state RS_ZK_REGION_CLOSED 
2011-06-27 10:25:55,301 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining) 
2011-06-27 10:25:55,302 INFO org.apache.hadoop.hbase.master.AssignmentManager: Server null returned java.lang.NullPointerException: Passed server is null for 9a6e26d40293663a79523c58315b930f 
2011-06-27 10:32:21,326 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out: test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=PENDING_CLOSE, ts=1309141555301 
2011-06-27 10:32:21,326 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_CLOSE for too long, running forced unassign again on region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. 
2011-06-27 10:32:21,438 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining) 
2011-06-27 10:32:21,441 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Attempted to unassign region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. but it is not currently assigned anywhere 

3  The following scenario shows how the above problem 2 happened:

(1)A table have a lot of regions, more than 70000 in my test. 
(2)Disable the table, if 'BulkDisabler.waitUntilDone' timeout, 'DisableTableHandler.process' will create another BulkDisabler object and start its thread pool. The region which was still online will call AssignmentManager.unassign again. so the same region ""AssignmentManager.unassign"" could be called concurrentlly more than 1. "
HBASE-10308,"Seen in 0.94 (both JDK6 and JDK7 builds)
{code}
Error Message

 Wanted but not invoked: procedure.sendGlobalBarrierComplete(); -> at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:344)  However, there were other interactions with this mock: -> at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:306) -> at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:311) -> at org.apache.hadoop.hbase.procedure.Procedure.call(Procedure.java:204) -> at org.apache.hadoop.hbase.procedure.Procedure.call(Procedure.java:204) -> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.memberAcquiredBarrier(ProcedureCoordinator.java:262) -> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.memberAcquiredBarrier(ProcedureCoordinator.java:262) -> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.abortProcedure(ProcedureCoordinator.java:217) -> at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:337) 

Stacktrace

Wanted but not invoked:
procedure.sendGlobalBarrierComplete();
-> at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:344)

However, there were other interactions with this mock:
-> at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:306)
-> at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:311)
-> at org.apache.hadoop.hbase.procedure.Procedure.call(Procedure.java:204)
-> at org.apache.hadoop.hbase.procedure.Procedure.call(Procedure.java:204)
-> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.memberAcquiredBarrier(ProcedureCoordinator.java:262)
-> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.memberAcquiredBarrier(ProcedureCoordinator.java:262)
-> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.abortProcedure(ProcedureCoordinator.java:217)
-> at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:337)

	at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:344)
	at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:319)
{code}"
HBASE-8256,"To make the Jenkin build more useful, it is good to keep it blue/green. We can mark those flaky tests flaky, and don't run them by default.  However, people can still run them.  We can also set up a Jekin build just for those flaky tests."
HBASE-9374,"Per this [thread|http://mail-archives.apache.org/mod_mbox/hbase-dev/201308.mbox/%3cCANZa=GuLO0jTLs1fF+5_NRDczO+M=SSqjeAGVEeiCY8injbP8w@mail.gmail.com%3e] from the dev list.

{quote}
It appears that as of HBASE-1936, we now require that client applications have write access to hbase.local.dir. This is because ProtobufUtil instantiates a DyanamicClassLoader as part of static initialization. This classloader is used for instantiating Comparators, Filters, and Exceptions.
{quote}

Client applications do not need to use DynamicClassLoader and so should not require this write access."
HBASE-9322,"I've been running tests on clusters with ""lots"" of regions, about 400, and I'm seeing weird contention in the client.

This one shows up a lot around the SoftValueSortedMap.

First I have this blocked thread on I'm not sure what:

{noformat}
""TestClient-12"" prio=10 tid=0x00007fb268872000 nid=0x3add waiting for monitor entry [0x00007fb251416000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.hadoop.hbase.util.SoftValueSortedMap.isEmpty(SoftValueSortedMap.java:210)
	- locked <0x00000000c1b70318> (a java.util.TreeMap)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getCachedLocation(HConnectionManager.java:1263)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1103)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1036)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:993)
{noformat}

This client waits on it:

{noformat}
""TestClient-14"" prio=10 tid=0x00007fb268876000 nid=0x3adf waiting for monitor entry [0x00007fb251214000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.hadoop.hbase.util.SoftValueSortedMap.lowerValueByKey(SoftValueSortedMap.java:189)
	- waiting to lock <0x00000000c1b70318> (a java.util.TreeMap)
	- locked <0x00000000c1b82120> (a org.apache.hadoop.hbase.util.SoftValueSortedMap)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getCachedLocation(HConnectionManager.java:1272)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1103)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1036)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:993)
{noformat}

As you can see it's also holding a lock, which I have 11 other clients waiting on:

{noformat}
""TestClient-13"" prio=10 tid=0x00007fb268874000 nid=0x3ade waiting for monitor entry [0x00007fb251315000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.hadoop.hbase.util.SoftValueSortedMap.lowerValueByKey(SoftValueSortedMap.java:189)
	- waiting to lock <0x00000000c1b82120> (a org.apache.hadoop.hbase.util.SoftValueSortedMap)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getCachedLocation(HConnectionManager.java:1272)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1103)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1036)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:993)
{noformat}"
HBASE-10172,"Hi, I want to upgrade hbase from 0.94 to 0.96. According to http://hbase.apache.org/book/upgrade0.96.html, I encountered a problem as follows:
{code}
Exception in thread ""main"" java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.
        at com.google.protobuf.GeneratedMessage.getUnknownFields(GeneratedMessage.java:180)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto.getSerializedSize(ClientNamenodeProtocolProtos.java:18005)
.....
{code}
hadoop version: hadoop-2.0.0-cdh4.2.1 
hbase version:hbase-0.94.0-cdh4.2.1
Thanks~"
HBASE-9680,See latest 0.94 patch on HBASE-7404.
HBASE-10102,"Example brought up by Niels Basjes on the user list:
If I do the following commands into the hbase shell
{code}
    create 't1', {NAME => 'c1', VERSIONS => 1}
    put 't1', 'r1', 'c1', 'One', 1000
    put 't1', 'r1', 'c1', 'Two', 2000
    put 't1', 'r1', 'c1', 'Three', 3000
    get 't1', 'r1'
    get 't1', 'r1' , {TIMERANGE => [0,1500]}

the result is this:

    get 't1', 'r1'
    COLUMN                     CELL
     c1:                       timestamp=3000, value=Three
    1 row(s) in 0.0780 seconds

    get 't1', 'r1' , {TIMERANGE => [0,1500]}
    COLUMN                     CELL
     c1:                       timestamp=1000, value=One
    1 row(s) in 0.1390 seconds
{code}
"
HBASE-9025,"I just saw this in a test run in 0.94:

{code}
Stacktrace

java.lang.NullPointerException
	at java.util.TreeMap.getEntry(TreeMap.java:324)
	at java.util.TreeMap.get(TreeMap.java:255)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testSplitDaughtersNotInMeta(TestHBaseFsck.java:1346)
...
{code}

The TreeMap in question here is actually returned from {{HTable.getRegionLocations()}}, which in turns calls {{MetaScanner.allTableRegions(getConfiguration(), getTableName(), false);}}"
HBASE-7347,"Currently each store file is read only through the single reader regardless of how many concurrent read requests access that file.

This issue is to explore alternate designs."
HBASE-9188,"From https://builds.apache.org/job/hbase-0.95-on-hadoop2/231/testReport/org.apache.hadoop.hbase.util/TestHBaseFsck/testNotInMetaOrDeployedHole/ (region tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153):

expected:<[NOT_IN_META_OR_DEPLOYED, HOLE_IN_REGION_CHAIN]> but was:<[NOT_IN_META_OR_DEPLOYED, NOT_DEPLOYED, HOLE_IN_REGION_CHAIN]>

Here is snippet of test output:
{code}
2013-08-10 11:53:16,941 DEBUG [RS_CLOSE_REGION-vesta:38578-1] handler.CloseRegionHandler(168): set region closed state in zk successfully for region tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153. sn name: vesta.apache.org,38578,1376135290018
2013-08-10 11:53:16,941 DEBUG [RS_CLOSE_REGION-vesta:38578-1] handler.CloseRegionHandler(177): Closed region tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
2013-08-10 11:53:16,942 DEBUG [AM.ZK.Worker-pool-2-thread-13] master.AssignmentManager(782): Handling transition=RS_ZK_REGION_CLOSED, server=vesta.apache.org,38578,1376135290018, region=3ec6178a369a899c007fd89807b37153, current state from region state map ={3ec6178a369a899c007fd89807b37153 state=PENDING_CLOSE, ts=1376135596730, server=vesta.apache.org,38578,1376135290018}
2013-08-10 11:53:16,942 WARN  [AM.ZK.Worker-pool-2-thread-13] master.RegionStates(245): Closed region 3ec6178a369a899c007fd89807b37153 still on vesta.apache.org,38578,1376135290018? Ignored, reset it to null
2013-08-10 11:53:16,942 INFO  [AM.ZK.Worker-pool-2-thread-13] master.RegionStates(260): Transitioned from {3ec6178a369a899c007fd89807b37153 state=PENDING_CLOSE, ts=1376135596730, server=vesta.apache.org,38578,1376135290018} to {3ec6178a369a899c007fd89807b37153 state=CLOSED, ts=1376135596942, server=null}
2013-08-10 11:53:16,942 DEBUG [AM.ZK.Worker-pool-2-thread-13] handler.ClosedRegionHandler(92): Handling CLOSED event for 3ec6178a369a899c007fd89807b37153
2013-08-10 11:53:16,942 DEBUG [AM.ZK.Worker-pool-2-thread-13] master.AssignmentManager(1462): Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
...
2013-08-10 11:53:17,319 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(1815): getMetaTableRows: row -> tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.{ENCODED => 3ec6178a369a899c007fd89807b37153, NAME => 'tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.', STARTKEY => 'B', ENDKEY => 'C'}
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(1815): getMetaTableRows: row -> tableNotInMetaOrDeployedHole,C,1376135595424.c2ae2bddbe9302c4344c13936248ac9d.{ENCODED => c2ae2bddbe9302c4344c13936248ac9d, NAME => 'tableNotInMetaOrDeployedHole,C,1376135595424.c2ae2bddbe9302c4344c13936248ac9d.', STARTKEY => 'C', ENDKEY => ''}
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] util.TestHBaseFsck(231): tableNotInMetaOrDeployedHole,,1376135595423.9df585f7f666e1cd55d7b875aae22ece.
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] util.TestHBaseFsck(231): tableNotInMetaOrDeployedHole,A,1376135595424.90a7d5f2211951d321c9f29f4059671f.
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] util.TestHBaseFsck(231): tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] util.TestHBaseFsck(231): tableNotInMetaOrDeployedHole,C,1376135595424.c2ae2bddbe9302c4344c13936248ac9d.
2013-08-10 11:53:17,326 DEBUG [pool-1-thread-1] client.ClientScanner(218): Finished region={ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2013-08-10 11:53:17,327 INFO  [pool-1-thread-1] util.TestHBaseFsck(319): {ENCODED => 9df585f7f666e1cd55d7b875aae22ece, NAME => 'tableNotInMetaOrDeployedHole,,1376135595423.9df585f7f666e1cd55d7b875aae22ece.', STARTKEY => '', ENDKEY => 'A'}vesta.apache.org,41438,1376135289941
2013-08-10 11:53:17,328 INFO  [pool-1-thread-1] util.TestHBaseFsck(319): {ENCODED => 90a7d5f2211951d321c9f29f4059671f, NAME => 'tableNotInMetaOrDeployedHole,A,1376135595424.90a7d5f2211951d321c9f29f4059671f.', STARTKEY => 'A', ENDKEY => 'B'}vesta.apache.org,38578,1376135290018
2013-08-10 11:53:17,328 INFO  [pool-1-thread-1] util.TestHBaseFsck(283): RegionName: tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
2013-08-10 11:53:17,328 INFO  [pool-1-thread-1] util.TestHBaseFsck(287): Undeploying region {ENCODED => 3ec6178a369a899c007fd89807b37153, NAME => 'tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.', STARTKEY => 'B', ENDKEY => 'C'} from server vesta.apache.org,38578,1376135290018
2013-08-10 11:53:17,328 INFO  [RpcServer.handler=1,port=38578] regionserver.HRegionServer(3612): Received close region: 3ec6178a369a899c007fd89807b37153Transitioning in ZK: no. Version of ZK closing node:-1. Destination server:null
2013-08-10 11:53:17,329 ERROR [RpcServer.handler=1,port=38578] regionserver.HRegionServer(2473): Received CLOSE for a region which is not online, and we're not opening.
2013-08-10 11:53:17,330 WARN  [pool-1-thread-1] util.HBaseFsckRepair(156): Exception when closing region: tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: The region 3ec6178a369a899c007fd89807b37153 is not online, and is not opening.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2476)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:3617)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:14458)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2147)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1854)
{code}
Region was not deployed after hbck run."
HBASE-6893,"In trunk build #3387 (https://builds.apache.org/view/G-L/view/HBase/job/HBase-TRUNK/3387/testReport/org.apache.hadoop.hbase/TestRegionRebalancing/testRebalanceOnRegionServerNumberChange_0_/):
{code}
java.lang.AssertionError: After 5 attempts, region assignments were not balanced.
	at org.junit.Assert.fail(Assert.java:93)
	at org.apache.hadoop.hbase.TestRegionRebalancing.assertRegionsAreBalanced(TestRegionRebalancing.java:219)
	at org.apache.hadoop.hbase.TestRegionRebalancing.testRebalanceOnRegionServerNumberChange(TestRegionRebalancing.java:139)
{code}"
HBASE-6928,"In build #3406, I saw:
{code}
java.lang.AssertionError: Column family prefix used twice: cf.cf.bt.Data.fsReadnumops
	at org.apache.hadoop.hbase.regionserver.metrics.SchemaMetrics.validateMetricChanges(SchemaMetrics.java:822)
	at org.apache.hadoop.hbase.regionserver.TestStoreFile.tearDown(TestStoreFile.java:89)
{code}"
HBASE-9223,"Observed behavior:

Command: hbase zkcli
There is an error message about a missing class:
{code}[root@data-compat-3 hbase]# hbase zkcli
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServerArg
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServerArg
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
{code}

It looks like this class is no longer in 0.95. 
ZKCli still continues in its startup and continues working (at least reads continue to work)

Expected behavior:
HBase Zkcli should not be looking for classes that are no longer part of HBase. This indicates an underlying issue."
HBASE-8919,"Looking at this build: https://builds.apache.org/job/hbase-0.95-on-hadoop2/173/testReport/org.apache.hadoop.hbase.replication/TestReplicationQueueFailoverCompressed/queueFailover/

The only thing I can find that went wrong is that the recovered queue was not completely done because the source fails like this:

{noformat}
2013-07-10 11:53:51,538 INFO  [Thread-1259] regionserver.ReplicationSource$2(799): Slave cluster looks down: Call to hemera.apache.org/140.211.11.27:38614 failed on local exception: java.nio.channels.ClosedByInterruptException
{noformat}

And just before that it got:
{noformat}
2013-07-10 11:53:51,290 WARN  [ReplicationExecutor-0.replicationSource,2-hemera.apache.org,43669,1373457208379] regionserver.ReplicationSource(661): Can't replicate because of an error on the remote cluster: 
org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException): org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1594 actions: FailedServerException: 1594 times, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:158)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:146)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:692)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:2106)
	at org.apache.hadoop.hbase.client.HTable.batchCallback(HTable.java:689)
	at org.apache.hadoop.hbase.client.HTable.batchCallback(HTable.java:697)
	at org.apache.hadoop.hbase.client.HTable.batch(HTable.java:682)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.batch(ReplicationSink.java:239)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.replicateEntries(ReplicationSink.java:161)
	at org.apache.hadoop.hbase.replication.regionserver.Replication.replicateLogEntries(Replication.java:173)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.replicateWALEntry(HRegionServer.java:3735)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:14402)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)

	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1369)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1573)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1630)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.replicateWALEntry(AdminProtos.java:15177)
	at org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.replicateWALEntry(ReplicationProtbufUtil.java:94)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.shipEdits(ReplicationSource.java:642)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:376)
{noformat}

I wonder what's closing the socket with an interrupt, it seems it still needs to replicate more data. I'll start by adding the stack trace for the message when it fails to replicate on a ""local exception"". Also I found a thread that wasn't shutdown properly that I'm going to fix to help with debugging."
HBASE-6620,"Test flaps in autobuilds with assertion failure.


org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor.testPoolBehavior

Failing for the past 1 build (Since #2602 )
Took 3 ms.
Error Message

expected:<3> but was:<4>
Stacktrace

java.lang.AssertionError: expected:<3> but was:<4>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.junit.Assert.assertEquals(Assert.java:456)
	at org.apache.hadoop.hbase.client.TestFromClientSide.testPoolBehavior(TestFromClientSide.java:4334)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:47)
	at org.junit.rules.RunRules.evaluate(RunRules.java:18)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
"
HBASE-7280,"in cluster replication, if the master cluster have 2 tables which have column-family declared with replication scope = 1, and add a peer cluster which has only 1 table with the same name as the master cluster, in the ReplicationSource (thread in master cluster) for this peer, edits (logs) for both tables will be shipped to the peer, the peer will fail applying the edits due to TableNotFoundException, and this exception will also be responsed to the original shipper (ReplicationSource in master cluster), and the shipper will fall into an endless retry for shipping the failed edits without proceeding to read the remained(newer) log files and to ship following edits(maybe the normal, expected edit for the registered table). the symptom looks like the TableNotFoundException incurs endless retry and blocking normal table replication"
HBASE-8614,"Running test suite on hadoop 2.0, I saw the following test failure:
{code}
testFavoredNodes(org.apache.hadoop.hbase.regionserver.TestRegionFavoredNodes)  Time elapsed: 0.106 sec  <<< ERROR!
org.apache.hadoop.hbase.exceptions.DroppedSnapshotException: region: table,rrr,1369355298031.1fdb1b446b02b497f0869a08adad7745.
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1568)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1429)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1347)
        at org.apache.hadoop.hbase.MiniHBaseCluster.flushcache(MiniHBaseCluster.java:531)
        at org.apache.hadoop.hbase.HBaseTestingUtility.flush(HBaseTestingUtility.java:961)
        at org.apache.hadoop.hbase.regionserver.TestRegionFavoredNodes.testFavoredNodes(TestRegionFavoredNodes.java:132)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.junit.runners.Suite.runChild(Suite.java:127)
        at org.junit.runners.Suite.runChild(Suite.java:26)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.util.FSUtils.create(FSUtils.java:293)
        at org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.createOutputStream(AbstractHFileWriter.java:268)
        at org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.create(HFile.java:427)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.<init>(StoreFile.java:791)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.<init>(StoreFile.java:733)
        at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:671)
        at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:799)
        at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:75)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:704)
        at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1813)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1543)
        ... 33 more
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1306)
        at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:283)
{code}
DistributedFileSystem#create() which supports favoredNodes parameter threw NullPointerException.
We should handle the NullPointerException and fall back to conventional DistributedFileSystem#create()"
HBASE-5754,"Keith Turner re-wrote the accumulo continuous ingest test using gora, which has both hbase and accumulo back-ends.

I put a billion entries into HBase, and ran the Verify map/reduce job.  The verification failed because about 21K entries were missing.  The goraci [README|https://github.com/keith-turner/goraci] explains the test, and how it detects missing data.

I re-ran the test with 100 million entries, and it verified successfully.  
Both of the times I tested using a billion entries, the verification failed.
If I run the verification step twice, the results are consistent, so the problem is
probably not on the verify step.

Here's the versions of the various packages:

||package||version||
|hadoop|0.20.205.0|
|hbase|0.92.1|
|gora|http://svn.apache.org/repos/asf/gora/trunk r1311277|
|goraci|https://github.com/ericnewton/goraci  tagged 2012-04-08|

The change I made to goraci was to configure it for hbase and to allow it to build properly.
"
HBASE-8626,"When RowMutations have a Delete followed by Put to same column family or columns or rows, only the Delete is happening while the Put is ignored so atomicity of RowMutations is broken for such cases.

Attached is a unit test where the following tests are failing:
- testDeleteCFThenPutInSameCF: Delete a column family and then Put to same column family.
- testDeleteColumnThenPutSameColumn: Delete a column and then Put to same column.
- testDeleteRowThenPutSameRow: Delete a row and then Put to same row
"
HBASE-8571,"Maybe it's just me, but I've been looking on trunk and I don't see where either RowCounter or CopyTable MapReduce can adjust the setCaching setting on the Scan instance.

Example from RowCounter...
{code}
   Job job = new Job(conf, NAME + ""_"" + tableName);
    job.setJarByClass(RowCounter.class);
    Scan scan = new Scan();
    scan.setCacheBlocks(false);
    Set<byte []> qualifiers = new TreeSet<byte[]>(Bytes.BYTES_COMPARATOR);
    if (startKey != null && !startKey.equals("""")) {
      scan.setStartRow(Bytes.toBytes(startKey));
    }
    if (endKey != null && !endKey.equals("""")) {
      scan.setStopRow(Bytes.toBytes(endKey));
    }
    scan.setFilter(new FirstKeyOnlyFilter());
    if (sb.length() > 0) {
      for (String columnName : sb.toString().trim().split("" "")) {
        String [] fields = columnName.split("":"");
        if(fields.length == 1) {
          scan.addFamily(Bytes.toBytes(fields[0]));
        } else {
          byte[] qualifier = Bytes.toBytes(fields[1]);
          qualifiers.add(qualifier);
          scan.addColumn(Bytes.toBytes(fields[0]), qualifier);
        }
      }
    }
    // specified column may or may not be part of first key value for the row.
    // Hence do not use FirstKeyOnlyFilter if scan has columns, instead use
    // FirstKeyValueMatchingQualifiersFilter.
    if (qualifiers.size() == 0) {
      scan.setFilter(new FirstKeyOnlyFilter());
    } else {
      scan.setFilter(new FirstKeyValueMatchingQualifiersFilter(qualifiers));
    }
    job.setOutputFormatClass(NullOutputFormat.class);
    TableMapReduceUtil.initTableMapperJob(tableName, scan,
      RowCounterMapper.class, ImmutableBytesWritable.class, Result.class, job);
    job.setNumReduceTasks(0);
    return job;

{code}

TableMapReduceUtil only serializes the Scan into the job, it doesn't adjust any of the settings.

Maybe I'm missing something, but this seems like a problem."
HBASE-5556,"I started seeing this problem on our Ubuntu servers since 0.92.0, ^H isn't detected correctly anymore in the readline rb version that's shipped with jruby 1.6.5

It works when I use the 1.6.0 jar."
HBASE-6417,"Trying to see what caused HBASE-6310, one of the things I figured is that the bad .META. row is actually one from the time that we were permitting meta splitting and that folder had just been staying there for a while.

So I tried to recreate the issue with -repair and it merged my good .META. region with the one that's 3 years old that also has the same start key. I ended up with a brand new .META. region!

I'll be attaching the full log in a separate file."
HBASE-6116,"In HDFS-1783 I adapted Dhrubas changes to be used in Hadoop trunk.
This issue will include the necessary reflection changes to optionally enable this for the WALs in HBase."
HBASE-7022,Bulk assigner needs to set regions offline in zookeeper one by one. I was wondering if we can have some performance improvement if we batch these operations using ZooKeeper#multi.
HBASE-3395,"In StoreScanner::next(List<KeyValue> outResult, int limit)

        case SEEK_NEXT_ROW:
          // This is just a relatively simple end of scan fix, to short-cut end us if there is a
          // endKey in the scan.
          if (!matcher.moreRowsMayExistAfter(kv)) {
            outResult.addAll(results);
            return false;
          }

close() is not being called before returning false. In all other cases close is called before returning false. May be this is a problem."
HBASE-6443,"Somehow, some WAL files have size 0. Distributed log splitting can't handle it.
HLogSplitter should ignore them."
HBASE-7607,"TestRegionServerCoprocessorExceptionWithAbort fails sometimes both on trunk and 0.94.X. The codebase is different in both. 

In 0.94.x, client retries to look at the root region, while the cluster is down and /hbase znode is no longer present.
""Check the value configured in 'zookeeper.znode.parent'. There could be a mismatch with the one configured in the master.""

I will file a separate jira for the trunk as the code is different there."
HBASE-7990,This was brought up in discussion entitled 'HRegionInfo was null or empty in Meta errors'
HBASE-4107,"An issue was observed where upon shutdown of a regionserver the regionserver log was corrupt.  It appears from the following stacktrace that an Java heap memory exception occurred while writing the checksum to the WAL.  Corrupting the WAL can potentially cause data loss. 

2011-07-14 14:54:53,741 FATAL org.apache.hadoop.hbase.regionserver.wal.HLog: Could not append. Requesting close of hlog
java.io.IOException: Reflection
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.sync(SequenceFileLogWriter.java:147)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.sync(HLog.java:987)
        at org.apache.hadoop.hbase.regionserver.wal.HLog$LogSyncer.run(HLog.java:964)
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.GeneratedMethodAccessor1336.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.sync(SequenceFileLogWriter.java:145)
        ... 2 more
Caused by: java.lang.OutOfMemoryError: Java heap space
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$Packet.<init>(DFSClient.java:2375)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:3271)
        at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:150)
        at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:132)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3354)
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
        at org.apache.hadoop.io.SequenceFile$Writer.syncFs(SequenceFile.java:944)
        ... 6 more
"
HBASE-7337,"put multi versions of a row.
r1 cf:q  version:1 value:1
r1 cf:q  version:2 value:3
r1 cf:q  version:3 value:2
the filter in scan is set as below:
SingleColumnValueFilter valueF = new SingleColumnValueFilter(
        family,qualifier,CompareOp.EQUAL,new BinaryComparator(Bytes
.toBytes(""2"")));

then i found all of the three versions will be emmitted, then i set latestVersionOnly to false, the result does no change.

{code}
  public ReturnCode filterKeyValue(KeyValue keyValue) {
    // System.out.println(""REMOVE KEY="" + keyValue.toString() + "", value="" + Bytes.toString(keyValue.getValue()));
    if (this.matchedColumn) {
      // We already found and matched the single column, all keys now pass
      return ReturnCode.INCLUDE;
    } else if (this.latestVersionOnly && this.foundColumn) {
      // We found but did not match the single column, skip to next row
      return ReturnCode.NEXT_ROW;
    }
    if (!keyValue.matchingColumn(this.columnFamily, this.columnQualifier)) {
      return ReturnCode.INCLUDE;
    }
    foundColumn = true;
    if (filterColumnValue(keyValue.getBuffer(),
        keyValue.getValueOffset(), keyValue.getValueLength())) {
      return this.latestVersionOnly? ReturnCode.NEXT_ROW: ReturnCode.INCLUDE;
    }
    this.matchedColumn = true;
    return ReturnCode.INCLUDE;
  }
{code}
From the code above, it seeems that version 3 will be first emmited, and set matchedColumn to true, which leads the following version 2 and 1 emmited too.

"
HBASE-7865,"I faced 3 regions (out of 8) never stopping today. This is pretty bad because the script is supposed to wait until all the RS stopped to re-start everything, therefor, servers are never going back online.

HBASE-7838 will help with that and will kill the RSs. But that will not really solve the root cause.

Attached are the jstack for the 3 servers."
HBASE-7287,"When regions merge is failing because the files have the same sequenceID, the expected region is still created even if it's not used, which leaves the system with inconsistencies. The new region creation should be moved after the sequenceID test to avoid this issue, until we find a way to merge regions with the same sequenceID."
HBASE-7696,"See here:
https://builds.apache.org/job/HBase-0.94/796/testReport/org.apache.hadoop.hbase.client/

and here:
https://builds.apache.org/job/HBase-0.94/794/testReport/org.apache.hadoop.hbase.client/"
HBASE-6666,"This is an idea I had some time back. It would be nice if a RegionObserver (or Endpoint) could get access to all other regions on the same RegionServer to efficiently make updates to those regions as well (instead of going through the standard HTable path).

Together with a smart region placement strategy this can lead to much better performance for some coprocessor tasks.
Maybe it could be abstracted in a special HTable implementation."
HBASE-7302,"c++ client requires HRegionThriftServer.
We need to port HRegionThriftServer to using thrift2."
HBASE-7155,"RootRegionTracker.getRootRegionLocation() declares that it can throw an InterruptedException, but it can't. This exception is rethrown by many other functions reaching the HBaseAdmin API.

If we remove the throws statement from the HBaseAdmin API libraries already compiled will work fine, but if the user is trying to catch an InterruptedException around one of those methods the compiler will complain.

Should we clean this up?"
HBASE-7136,"ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
java.lang.IllegalStateException: Schema metrics requested before table/CF name initialization: {""tableName"":""null"",""cfName"":""null""}
at org.apache.hadoop.hbase.regionserver.metrics.SchemaConfigured.getSchemaMetrics(SchemaConfigured.java:182)
at org.apache.hadoop.hbase.io.hfile.LruBlockCache.updateSizeMetrics(LruBlockCache.java:310)
at org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(LruBlockCache.java:274)
at org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(LruBlockCache.java:293)
at org.apache.hadoop.hbase.io.hfile.DoubleBlockCache.getBlock(DoubleBlockCache.java:102)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getBlockFromCache(HFileReaderV2.java:266)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:348)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.readNextDataBlock(HFileReaderV2.java:587)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.next(HFileReaderV2.java:996)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:233)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:145)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.enforceSeek(StoreFileScanner.java:351)
at org.apache.hadoop.hbase.regionserver.KeyValueHeap.pollRealKV(KeyValueHeap.java:333)
at org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:291)


When we put the hfile block to SlabCache, it will drop the SchemaMetrics, howerver, if we cache this block to LruBlockCache, it will throw above exception "
HBASE-4254,"Currently some 30 or so tests are failing on the ""HBase-trunk-on-hadoop-23"" build. It looks like most are reflection-based issues."
HBASE-2441,"If the RS loses its ZK session before it reports for duty, the abort() call will trigger an NPE, and then the stop boolean doesn't get toggled. The RS will then loop forever trying to register itself in the expired ZK session, and fill up the logs."
HBASE-6880,"In looking into a TestReplication failure, I found out sometimes assignRoot could fail, for example, RS is not serving traffic yet.  In this case, the master will keep waiting for root to be available, which could never happen.
 
Need to gracefully terminate master if root is not assigned properly."
HBASE-2271,tableindexed.TestIndexedTable is hanging on 0.20 branch. 
HBASE-3378,"We recently saw several occurrences of NPE. Here is one of them:
{noformat}
2010-12-20 08:57:14,214 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.io.IOException: java.io.IOException: java.lang.NullPointerException

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
	at org.apache.hadoop.hbase.client.HBaseAdmin.modifyTable(HBaseAdmin.java:887)
	at org.apache.hadoop.hbase.client.HBaseAdmin.modifyTable(HBaseAdmin.java:791)
	at org.apache.hadoop.hbase.client.HBaseAdmin.flush(HBaseAdmin.java:703)
{noformat}

In master server log, I only found:
{noformat}
2010-12-20 16:57:19,357 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 15 on 60000, call modifyTable([B@5b591d0b, TABLE_FLUSH, null) from 10.202.114.157:2760: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
2010-12-20 16:57:19,357 WARN org.apache.hadoop.ipc.HBaseServer: IPC Server Responder, call modifyTable([B@5b591d0b, TABLE_FLUSH, null) from 10.202.114.157:2760: output error
2010-12-20 16:57:19,357 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 17 on 60000, call modifyTable([B@3781ec07, TABLE_FLUSH, null) from 10.202.114.136:35448: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
2010-12-20 16:57:19,358 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 15 on 60000 caught: java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:126)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324)
        at org.apache.hadoop.hbase.ipc.HBaseServer.channelWrite(HBaseServer.java:1210)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Responder.processResponse(HBaseServer.java:698)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Responder.doRespond(HBaseServer.java:762)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1026)
{noformat}

RemoteExceptionHandler should be able to handle NPE.
"
HBASE-6111,"I have started seeing this issue in our environment.  HBASE-1672 was closed as non reproducible, so I cloned it here.

I have a 367M record table, compressed with snappy, and running a vanilla MR SCAN with no filters spawns 441 Mappers.  The cluster currently has 216 slots for mappers, and the first wave all report 100% data-local mappers.  As the second wave of mappers come up they don't get run locally to the RS and data locality drops.

This kills our environment, as it saturates the network at 120M which is very clear on ganglia.

I am really happy to help diagnose this, but need some guidance on what to do.  I don't know enough yet about how task assignment works in MR to determine why the machines are picking up random tasks for their second effort and not one for the local RS."
HBASE-1672,"The number of data local map tasks while scanning a table is only about 10% of the total map tasks...
My table had 280 regions and 13M records... The number of map tasks in the scan job were equal to the number of regions (280). Only 25 of them were data local tasks."
HBASE-6720,See discussion on HBASE-3866
HBASE-6668,"hbase(main):002:0> disable 'logTable'
0 row(s) in 2.0910 seconds

hbase(main):003:0> disable 'logTable'
0 row(s) in 0.0260 seconds

and we can found table are disabled in log when  disable first appears
but when i disable it again the client just return seemed to be sucessful and I can not find any log described it in the log.

look into the admin.rb, find below

    #----------------------------------------------------------------------------------------------
    # Disables a table
    def disable(table_name)
      tableExists(table_name)
      return if disabled?(table_name)
      @admin.disableTable(table_name)
    end

that would confuse us when we found it disabled already but returns nothing 
"
HBASE-6767,"in shell I issued:
{code}split 'TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4.'{code}

that resulted in the following error:
{code}2012-09-12 18:45:55,950 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4. not splittable because midkey=null
2012-09-12 18:46:04,267 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4. not splittable because midkey=null
2012-09-12 18:47:31,820 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4. not splittable because midkey=null
2012-09-12 18:47:35,028 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4. not splittable because midkey=null{code}"
HBASE-4952,"When I start the HBase trunk master on my five-node cluster, it gets stuck in the state ""initializing master service threads"" for a minute or two, then ""waiting for regionserver number to settle"", and only then starts log splitting. We don't have such delays in the 0.89-fb master, and I believe we can optimize the new master to eliminate these delays as well."
HBASE-3814,"Once abort() on a regionserver is called we should have a timeout thread that does Runtime.halt() if the rs gets stuck somewhere during abort processing.

===


Pumahbase132 has following the logs .. the dfsclient is not able to set up a write pipeline successfully ... it tries to abort ... but while aborting it gets stuck. I know there is a check that if we are aborting because filesystem is closed then we should not try to flush the logs while aborting. But in this case the fs is up and running, just that it is not functioning.

2011-04-21 23:48:07,082 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream 10.38.131.53:50010  for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280java.io.IOException: Bad connect ack with firstBadLink 10.38.133.33:50010
2011-04-21 23:48:07,082 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-8967376451767492285_6537229 for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280
2011-04-21 23:48:07,125 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream 10.38.131.53:50010  for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280java.io.IOException: Bad connect ack with firstBadLink 10.38.134.59:50010
2011-04-21 23:48:07,125 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_7172251852699100447_6537229 for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280 

2011-04-21 23:48:07,169 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream 10.38.131.53:50010  for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280java.io.IOException: Bad connect ack with firstBadLink 10.38.134.53:50010
2011-04-21 23:48:07,169 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-9153204772467623625_6537229 for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280
2011-04-21 23:48:07,213 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream 10.38.131.53:50010  for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280java.io.IOException: Bad connect ack with firstBadLink 10.38.134.49:50010
2011-04-21 23:48:07,213 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-2513098940934276625_6537229 for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280
2011-04-21 23:48:07,214 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:3560)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2700(DFSClient.java:2720)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2977)

2011-04-21 23:48:07,214 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_-2513098940934276625_6537229 bad datanode[1] nodes == null
2011-04-21 23:48:07,214 WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file ""/PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280"" - Aborting...
2011-04-21 23:48:07,216 FATAL org.apache.hadoop.hbase.regionserver.wal.HLog: Could not append. Requesting close of hlog

And then the RS gets stuck trying to roll the logs ...

"
HBASE-5340,"I was attempting to do a bulk load and got this error message.  Unfortunately it didn't tell me which file had the problem.

{code}
Exception in thread ""main"" java.io.IOException: Trailer 'header' is wrong; does the trailer size match content?
        at org.apache.hadoop.hbase.io.hfile.HFile$FixedFileTrailer.deserialize(HFile.java:1527)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readTrailer(HFile.java:885)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.loadFileInfo(HFile.java:819)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.tryLoad(LoadIncrementalHFiles.java:204)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(LoadIncrementalHFiles.java:173)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.run(LoadIncrementalHFiles.java:452)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.main(LoadIncrementalHFiles.java:457)
{code}"
HBASE-4001,"When the region server R1 and data node D1 running in the same machine and let's assuem this machine pub into repair,
the master will try to reassign all the regions in the region server to other region server R2. But at that time, the name node hasn't figure out the bad data node D1.
So the region server R2 will try to open the region from the D1, which will failed and retried. Then the master believes it took TOO LONG to open this region, so it reassign to R3...

The story continues until the name node figure out the bad datanode D1 and finally region server Rn opens the region and do the compaction for the store file. 
All previous region servers cannot the region later and find the file doesn't exist since it has been compacted.


So the solution is that when region has been OPENING for too long, the master should not reassign region."
HBASE-4183,The checkFileSystem() function in FSUtils closes down the FileSystem for the HRegionServer by default if the FileSystem is not available. Ideally we should let the the HRegionServer threads exit and then shutdown the FileSystem. The checkFileSystem() function should not by default kill the FileSystem.
HBASE-4702,"Doing a row count for a large table via Mapreduce may take long time.
Trying to set the default cache size but there is no knob to tune it.

See here for more details, http://search-hadoop.com/m/ECEs6237AIX&subj=Re+speeding+up+rowcount



"
HBASE-4659,"scan.addColumn(Bytes.toBytes(""Info""), Bytes.toBytes(""value""));
scan.setMaxVersions();
SingleColumnValueFilter scvf = new SingleColumnValueFilter(Bytes.toBytes(""Info""), Bytes.toBytes(""value""), CompareOp.EQUAL, Bytes.toBytes(""test""));
scvf.setLatestVersionOnly(false);
scan.setFilter(scvf);


it can not filter previous versions"
HBASE-5322,"I have a hbase table which holds data for more than 10GB. Now I used the same client scanner to scan which fails and reports,

""Could not seek StoreFileScanner[HFileScanner for reader reader=hdfs"".

This issue occurs only for the table which holds huge data and not for tables holding small data."
HBASE-6345,"HDFS uses fault injection to test pipeline failure in addition to mock, spy. HBase uses mock, spy. But there are cases where mock, spy aren't convenient.

Some example from DFSClientAspects.aj :
{code}
  pointcut pipelineInitNonAppend(DataStreamer datastreamer):
    callCreateBlockOutputStream(datastreamer)
    && cflow(execution(* nextBlockOutputStream(..)))
    && within(DataStreamer);

  after(DataStreamer datastreamer) returning : pipelineInitNonAppend(datastreamer) {
    LOG.info(""FI: after pipelineInitNonAppend: hasError=""
        + datastreamer.hasError + "" errorIndex="" + datastreamer.errorIndex);
    if (datastreamer.hasError) {
      DataTransferTest dtTest = DataTransferTestUtil.getDataTransferTest();
      if (dtTest != null)
        dtTest.fiPipelineInitErrorNonAppend.run(datastreamer.errorIndex);
    }
  }
{code}"
HBASE-6395,"MAPREDUCE-3451 added Fair Scheduler to MRv2

TestFSSchedulerApp was added under src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair but its package was declared to be org.apache.hadoop.yarn.server.resourcemanager.scheduler"
HBASE-6320,"After modularization, the command to build the tarball on wiki:
http://wiki.apache.org/hadoop/Hbase/HowToRelease

mvn clean site install assembly:single 

Doesn't work any more.

[ERROR] Failed to execute goal org.apache.maven.plugins:maven-assembly-plugin:2.3:single (default-cli) on project hbase: Failed to create assembly: Artifact: org.apache.hbase:hbase-common:jar:0.95-SNAPSHOT (included by module) does not have an artifact with a file. Please ensure the package phase is run before the assembly is generated. -> [Help 1]


Matteo told me we have to use 

mvn -DskipTests package assembly:assembly


I think we should make assembly:single work.

"
HBASE-6258,"Issue tracking backport of some relatively small region splitting fixes into 0.90.7:

HBASE-4816: Regionserver wouldn't go down because split happened exactly at same time we issued bulk user region close call on our way out - fixed in 0.92
HBASE-4881: Unhealthy region is on service caused by rollback of region splitting - fixed in 0.92
HBASE-5189: Add metrics to keep track of region-splits in RS - fixed in 0.94
HBASE-6158: Data loss if the words 'merges' or 'splits' are used as Column Family name - fixed in 0.92 and 0.94"
HBASE-6009,"The additions to add backup masters to ClusterStatus are technically incompatible between clients and servers.  Older clients will basically not read the extra bits that the newer server pushes for the backup masters, thus screwing up the serialization for the next blob in the pipe.

For the Writable, we can add a total size field for ClusterStatus at the beginning, or we can have start and end markers.  I can make a patch for either approach; interested in whatever folks have to suggest.  Would be good to get this in soon to limit the damage to 0.92.1 (don't know if we can get this in in time for 0.94.0).

Either change will make us forward-compatible starting with when the change goes in, but will not fix the backwards incompatibility, which we will have to mark with a release note as there have already been releases with this change.

Hopefully we can do this in a cleaner way when wire compat rolls around in 0.96."
HBASE-5856,"In HBaseAdmin 
  public void split(final String tableNameOrRegionName)
  throws IOException, InterruptedException {
    split(Bytes.toBytes(tableNameOrRegionName));  // string -> byte 
  }
In HRegionInfo
  this.regionNameStr = Bytes.toStringBinary(this.regionName);  // byte -> string
Should we use Bytes.toBytesBinary in HBaseAdmin 锛?,,,,,,,,,,,,,,,,,,,,,,24/Apr/12 09:36;aoxiang;HBASE-5856-0.92.patch;https://issues.apache.org/jira/secure/attachment/12523949/HBASE-5856-0.92.patch,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,2012-04-23 18:36:38.863,,false,,,,,,,,,,,,236743,,,,,Wed May 02 02:18:32 UTC 2012,,,,,,0|i068qn:,34347,,,,,,,,23/Apr/12 10:06;aoxiang;for example"
HBASE-1801,"If you have a cluster running for some time, you probably have more regions on DFS than in META. Here is a tool to remove them."
HBASE-5677,"If region be assigned When the master is doing initialization(before do processFailover),the region will be duplicate openhandled.
because the unassigned node in zookeeper will be handled again in AssignmentManager#processFailover()
it cause the region in RIT,thus the master never does balance.


"
HBASE-4311,"When refactoring TestHBaseFsckRepair to add more hbck test cases, I noticed that HBaseTestingUtility.createMultiRegions uses an existing table with empty region, adds more regions, and then attempts to remove the region.  The region remains in meta and is causes hbck to report at inconsistency. Ideally these test table generation utility functions should generate clean tables."
HBASE-3772,"I ran across this issue on a 0.20 based branch, so I'm not sure if this is still an issue for 0.90+.  However, 0.90 and current trunk do still make use of DNS.getDefaultHost(), so I wanted to open this for discussion.

In 0.20, the problem was:

 1. configure hbase-site.xml with hbase.regionserver.dns.interface=xxx
 2. IP bound on interface xxx has reverse DNS correctly configured
 3. DNS.getDefaultHost() calls DNS.reverseDns() for this IP, which does a JNDI bind to the DNS provider, returning the *absolute* hostname: host1.my.domain.
 4. RS reports startup to master as host1.my.domain.,60020,1234...
 5. BaseScanner when scanning .META. sees region assignments as not valid because the resolved hostname from IP goes through InetSocketAddress.getHostName() which returns the canonicalized form (host1.my.domain != host1.my.domain. though they are equivalent)

I know the master <-> RS negotiated hostname has completely changed for 0.90.  So hopefully this is no longer an issue and we can close as invalid and go have a beer.  But given the underlying problem in DNS.getDefaultHost(), I wanted to confirm this."
HBASE-1339,"{code}
2009-04-22 02:10:34,710 WARN /: /master.jsp:
java.lang.NullPointerException
    at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$1.processRow(HConnectionManager.java:344)
    at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:64)
    at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:29)
    at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.listTables(HConnectionManager.java:351)
    at org.apache.hadoop.hbase.client.HBaseAdmin.listTables(HBaseAdmin.java:121)
    at org.apache.hadoop.hbase.generated.master.master_jsp._jspService(master_jsp.java:121)
    at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:94)
    at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
    at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
    at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
    at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
    at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
    at org.mortbay.http.HttpServer.service(HttpServer.java:954)
    at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
    at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
    at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
    at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
    at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
    at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)
{code}"
HBASE-5106,"Old hbase client which talks to the new hbase server could not understand the new metadata.  We should re-think how to check setData BADVERSION error.

How about we check the full actual data?  If the actual data in ZK is what we want to set, then we are good.  Of course, this data could be set actually by someone else, in this case, is it safe not to throw a KeeperException?"
HBASE-3217,"I tried writing a few unit tests in the scope of HBASE-3216 since the previous one was only testing a best case scenario but it's at least currently not able to fix the case where .META. says the assignment is on server A when in fact it's on server B (the region gets closed but never reopened).

Stack says the breakage probably happened with the new master."
HBASE-3742,"We got this in the context of HBASE-3741, a region was closed by a region server but the master wasn't expecting it and didn't do anything about it. We had to force assign it back.

{quote}
2011-04-05 15:15:55,812 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: master:60000-0x42ec2cece810b68 Retrieved 93 byte(s) of data from znode /prodjobs/unassigned/1470298961 and set watcher; region=stumbles_by_userid2,'锟斤拷锟斤拷绌楋拷锟斤拷6,1266566087256, server=sv4borg42,60020,1300920459477, state=RS_ZK_REGION_CLOSING
2011-04-05 15:15:55,812 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling new unassigned node: /prodjobs/unassigned/1470298961 (region=stumbles_by_userid2,'锟斤拷锟斤拷绌楋拷锟斤拷6,1266566087256, server=sv4borg42,60020,1300920459477, state=RS_ZK_REGION_CLOSING)
2011-04-05 15:15:55,812 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_CLOSING, server=sv4borg42,60020,1300920459477, region=1470298961
2011-04-05 15:15:55,812 WARN org.apache.hadoop.hbase.master.AssignmentManager: Received CLOSING for region 1470298961 from server sv4borg42,60020,1300920459477 but region was in  the state null and not in expected PENDING_CLOSE or CLOSING states
2011-04-05 15:15:55,843 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher: master:60000-0x42ec2cece810b68 Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/prodjobs/unassigned/1470298961
2011-04-05 15:15:55,843 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: master:60000-0x42ec2cece810b68 Retrieved 93 byte(s) of data from znode /prodjobs/unassigned/1470298961 and set watcher; region=stumbles_by_userid2,'锟斤拷锟斤拷绌楋拷锟斤拷6,1266566087256, server=sv4borg42,60020,1300920459477, state=RS_ZK_REGION_CLOSED
2011-04-05 15:15:55,843 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_CLOSED, server=sv4borg42,60020,1300920459477, region=1470298961
2011-04-05 15:15:55,843 WARN org.apache.hadoop.hbase.master.AssignmentManager: Received CLOSED for region 1470298961 from server sv4borg42,60020,1300920459477 but region was in  the state null and not in expected PENDING_CLOSE or CLOSING states
{quote}"
HBASE-862,"Daniel Leffel has an install of 500 regions on 4 nodes.  He's running 0.2.0.

On restart, load balancing is running while the 600 regions are being initially opened.  Makes for churn.  Load balancing should wait before it cuts in.

Have also seen on occasion that it will not find equilibrium after a restart.

Adding a node is catastrophic.  >20% of the regions were closed and were taking the longest time to show up on the new server.  I would think that the region balancing would work in more sophisticated and gradual manner."
HBASE-1787,"Down in guts of TableServers is a static map keyed by HBaseConfiguration instance.  If in such as HTable constructor, you keep passing the same HBaseConfiguration instance, then you will get back a previously made TableServers with cached region locations, zk connection setup, etc.   If you pass a new HBaseConfiguration each time, then on each new HTable, a new TableServers instance will be built with attendant zk setup and resource costs etc.

Users are surprised by this behavior: ""What seems like a bug to me is that the configuration object is caching state.  I understand if HTable hangs on to connections until it is closed.  And I understand how calling new HTABLE twice might open a new connection.  That all seems okay.  What I wouldn't expect is that using an old configuration object will give me different behavior from using a new one.  A configuration seems like a static thing to me.  It should only change if I change it."" -- Our Jim Firby"
HBASE-1910,"From Tatsuya Kawano up on hbase-user@

{quote}
50 client threads who try to put millions of records, autoFlush(false), flushCommits() on every 5,000 put. After inserting about 3 million records, a deadlock occurred on a region server who has both the table and index regions loaded.

I have attached a full thread dump of the deadlocked region server, and you can see IPC Server handlers are blocked in org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.updateIndex().

I found the flowing FIXME comment on updateIndex() method, and it seems this is the deadlock I'm having.

{code}
  // FIXME: This call takes place in an RPC, and requires an RPC. This makes for
  // a likely deadlock if the number of RPCs we are trying to serve is >= the
  // number of handler threads.
  private void updateIndex(IndexSpecification indexSpec, byte[] row,
      SortedMap<byte[], byte[]> columnValues) throws IOException {
{code}

I use HBase 0.20.1 and my region servers were running with 10 RPC handler threads on each (default).

Maybe you can workaround this by adding more RPC handlers (increase the value of ""hbase.regionserver.handler.count"" in hbase-site.xml)
{quote}

Opening this issue to track the FIXME."
HBASE-2736,"When trying to disable a table, the shell exhausts the retries, then throws the following: 

{noformat}
ERROR: org.apache.hadoop.hbase.RegionException: Retries exhausted, it took too long to wait for the table t1 to be disabled.
{noformat}

in HBaseAdmin.java:disableTable, after disabling, the code checks again, using isTableDisabled, which always returns false. 

Also, after running a disable, in Zookeeper, in ""/hbase/UNASSIGNED"", I get an entry, which is exactly the name of the only region of the table I am trying to disable. This leads me to believe this bug is somehow linked to HBASE-2694.

This reproduces on my machine, our cluster, with freshly installed HBase, with new data, as well as with old one."
HBASE-2766,"If both -ROOT- and .META. are located on the same regionserver, and that regionserver crashes, the master is unable to reassign these tables to a new regionserver. 

Andrew writes:
""I ran a webtable scenario up on EC2 using the latest TM-2 and a cluster with 1 ZK, 1 master, 5 slaves, and 1 auxiliary node, using the HBase cluster scripts at  https://tm-files.s3.amazonaws.com/hbase-ec2.tar.bz2. On the aux node I uploaded the Faulkner utility --  https://tm-files.s3.amazonaws.com/faulkner.tar.gz  -- and ran the 'webtable.sh' script in that tarball. On the master I waited about 30 minutes for a fair amount of regions to proliferate and then ran:

    # nice -10 hbase shell
    hbase> count 'TestTable'

and walked away, leaving it to chew on the heavy write load and scan.

At some point during this test scenario a region server crashed, due to a JVM segfault. The client (Faulkner) never recovered.

As far as I can see, in this test scenario the master never reassigns regions away from a crashed RS."""
HBASE-3027,"Just ran into this up on Alexey's cluster.  He updated to SU github and it looks like some regions had recovered.edits files under them.  The newer code was trying to read the file as a directory and failing with the plain but at same time cryptic mssage:

{code}
Caused by: org.apache.hadoop.ipc.RemoteException: java.io.FileNotFoundException: Parent path is not a directory: /hbase/mysql_word_documents/c574e848df63a14054e054545da2d3f3/recovered.edits   
{code}

It'd be a small thing to add a check if 'recovered.edits' is a file and process it as such when reading in recovered edits."
HBASE-1459,"I just saw this on my 0.19.1 cluster:

2009-05-30 03:57:19,559 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: table,rowkey,1243547152622
    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:897)
    at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:790)
    at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:228)
    at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.run(MemcacheFlusher.java:138)
Caused by: java.util.ConcurrentModificationException
    at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)
    at java.util.TreeMap$EntryIterator.next(TreeMap.java:1136)
    at java.util.TreeMap$EntryIterator.next(TreeMap.java:1131)
    at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:678)
    at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:636)
    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:882)
    ... 3 more"
HBASE-1891,"I ran my program multiple times and this is happening almost all the time.

Basically, the ResultScanner is skipping a full cache of rows. I set my caching size to 1000, and when I expect to see row 60000 it gave me 60999.

My code (will attach here) is creating a new table with a single column family and qualifier, and then write 1 million rows with ascending keys, then immediately read them back to verify.


The HBase code is from:
http://svn.apache.org/repos/asf/hadoop/hbase/trunk at
Exported revision 821973.
"
HBASE-2079,"From hbase-user.  I'm putting it into 0.20.3   Shows when multiple concurrent threads.

{code}
On Wed, Dec 30, 2009 at 5:59 AM, Dmitriy Lyfar <dlyfar@gmail.com> wrote:

Exception in thread ""Thread-9"" java.util.ConcurrentModificationException
   at
java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)
   at java.util.AbstractList$Itr.next(AbstractList.java:343)
   at
org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1028)
   at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:979)
   at
org.apache.hadoop.conf.Configuration.iterator(Configuration.java:1015)
   at
org.apache.hadoop.hbase.HBaseConfiguration.hashCode(HBaseConfiguration.java:63)
   at java.util.WeakHashMap.get(WeakHashMap.java:348)
   at
org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:97)
   at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:123)
   at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:105)
   at InserterThread.run(hbase_client.java:53)
   at java.lang.Thread.run(Thread.java:619
{code}"
HBASE-2191,"I'm testing a simple bulk upload to HBase. Single table, single family. The aim is to upload 200M+ lines into HBase. I've  tried to commit the upload in various batches, from 1 line at time to 25000 lines at time. Each time, at seemingly random point, the upload fails in commit with a org.apache.hadoop.hbase.NotServingRegionException

Failure stack trace from the client:
---
10/02/07 16:38:40 DEBUG transactional.TransactionManager: Begining transaction 5311384003652808027
10/02/07 16:38:40 DEBUG transactional.TransactionState: Adding new hregion [db,,1265553236583] to transaction [5311384003652808027]
10/02/07 16:38:46 DEBUG transactional.TransactionManager: atempting to commit trasaction: id: 5311384003652808027, particpants: 1
10/02/07 16:38:46 DEBUG transactional.TransactionManager: Region [db,,1265553236583] votes to commit transaction 5311384003652808027
10/02/07 16:38:46 DEBUG transactional.TransactionManager: Commiting [5311384003652808027]
10/02/07 16:38:46 DEBUG transactional.TransactionManager: Committed transaction [5311384003652808027] in [379]ms
10/02/07 16:38:46 DEBUG transactional.TransactionManager: Begining transaction -5274908504613584338
10/02/07 16:38:46 DEBUG transactional.TransactionState: Adding new hregion [db,,1265553236583] to transaction [-5274908504613584338]
10/02/07 16:38:47 DEBUG client.HConnectionManager$TableServers: Removed db,,1265553236583 for tableName=db from cache because of \x00\x00\x01\x24\xAC\xC3\x98\x1C
10/02/07 16:38:47 DEBUG client.HConnectionManager$TableServers: Cached location for db,,1265553236583 is 1.1.1.1:43917
10/02/07 16:38:48 DEBUG client.HConnectionManager$TableServers: Removed db,,1265553236583 for tableName=db from cache because of \x00\x00\x01\x24\xAC\xC3\x98\x1C
10/02/07 16:38:48 DEBUG client.HConnectionManager$TableServers: Cached location for db,,1265553236583 is 1.1.1.1:43917
10/02/07 16:38:49 DEBUG client.HConnectionManager$TableServers: Removed db,,1265553236583 for tableName=db from cache because of \x00\x00\x01\x24\xAC\xC3\x98\x1C
10/02/07 16:38:49 DEBUG client.HConnectionManager$TableServers: locateRegionInMeta attempt 0 of 10 failed; retrying after sleep of 1000 because: No server address listed in .META. for region db,\x00\x00\x01\x24\xAC\xA5\xEAB,1265553527794
10/02/07 16:38:49 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 for tableName=.META. from cache because of db,\x00\x00\x01\x24\xAC\xC3\x98\x1C,99999999999999
10/02/07 16:38:49 DEBUG client.HConnectionManager$TableServers: Cached location for .META.,,1 is 1.1.1.1:43917
10/02/07 16:38:50 DEBUG client.HConnectionManager$TableServers: Cached location for db,\x00\x00\x01\x24\xAC\xA5\xEAB,1265553527794 is 1.1.1.1:43917
10/02/07 16:38:50 DEBUG transactional.TransactionState: Adding new hregion [db,\x00\x00\x01\x24\xAC\xA5\xEAB,1265553527794] to transaction [-5274908504613584338]
10/02/07 16:38:51 DEBUG transactional.TransactionManager: atempting to commit trasaction: id: -5274908504613584338, particpants: 2
10/02/07 16:38:51 DEBUG transactional.TransactionManager: Commit of transaction [-5274908504613584338] was unsucsessful
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: db,,1265553236583
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2266)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.getTransactionalRegion(TransactionalRegionServer.java:131)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.commitRequest(TransactionalRegionServer.java:179)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:723)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:333)
        at $Proxy0.commitRequest(Unknown Source)
        at org.apache.hadoop.hbase.client.transactional.TransactionManager.prepareCommit(TransactionManager.java:94)
        at org.apache.hadoop.hbase.client.transactional.TransactionManager.tryCommit(TransactionManager.java:151)
        at dbloader.dbLoader.run2(dbLoader.java:181)
        at dbloader.dbLoader.main(dbLoader.java:24)
Exception in thread ""main"" org.apache.hadoop.hbase.client.transactional.CommitUnsuccessfulException: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: db,,1265553236583
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2266)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.getTransactionalRegion(TransactionalRegionServer.java:131)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.commitRequest(TransactionalRegionServer.java:179)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at org.apache.hadoop.hbase.client.transactional.TransactionManager.prepareCommit(TransactionManager.java:135)
        at org.apache.hadoop.hbase.client.transactional.TransactionManager.tryCommit(TransactionManager.java:151)
        at dbloader.dbLoader.run2(dbLoader.java:181)
        at dbloader.dbLoader.main(dbLoader.java:24)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: db,,1265553236583
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2266)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.getTransactionalRegion(TransactionalRegionServer.java:131)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.commitRequest(TransactionalRegionServer.java:179)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:723)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:333)
        at $Proxy0.commitRequest(Unknown Source)
        at org.apache.hadoop.hbase.client.transactional.TransactionManager.prepareCommit(TransactionManager.java:94)
        ... 3 more
"
HBASE-2192,"After a commit has failed with org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: db,,1265553236583 (see HBASE-2191 for more information) any further transactions to the same table fail. (other tables untested)

Waiting for ~10 hours doesn't seem to clear the situation, neither does calling truncate and major_compact on the table and major_compact on .META.. only known way to resolve the situation is to restart hbase.

client end stack trace:
---
10/02/07 16:40:47 DEBUG transactional.TransactionState: Adding new hregion [db,,1265553637903] to transaction [6991420346725617933]
10/02/07 16:40:48 DEBUG client.HConnectionManager$TableServers: Removed db,,1265553637903 for tableName=db from cache because of \x00\x00\x01\x24\xAC\x9C\xAF,
10/02/07 16:40:48 DEBUG client.HConnectionManager$TableServers: locateRegionInMeta attempt 0 of 10 failed; retrying after sleep of 1000 because: No server address listed in .META. for region db,,1265553637903
10/02/07 16:40:48 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 for tableName=.META. from cache because of db,\x00\x00\x01\x24\xAC\x9C\xAF,,99999999999999
10/02/07 16:40:48 DEBUG client.HConnectionManager$TableServers: Cached location for .META.,,1 is 1.1.1.1:43917
10/02/07 16:40:49 DEBUG client.HConnectionManager$TableServers: Cached location for db,,1265553637903 is 1.1.1.1:43917
Exception in thread ""main"" org.apache.hadoop.hbase.client.transactional.UnknownTransactionException: org.apache.hadoop.hbase.client.transactional.UnknownTransactionException: transaction: [6991420346725617933], region: [db,,1265553637903]
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.getTransactionState(TransactionalRegion.java:574)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.put(TransactionalRegion.java:297)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.put(TransactionalRegionServer.java:241)
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:1041)
        at org.apache.hadoop.hbase.client.transactional.TransactionalTable.put(TransactionalTable.java:153)
        at dbloader.dbLoader.run2(dbLoader.java:179)
        at dbloader.dbLoader.main(dbLoader.java:24)
"
HBASE-2532,"For reading an object out a sequencefile, a no argument constructor is required... 
if not you end up with a  java.lang.NoSuchMethodException

From Owen O'Malley

Assumption for Writables that should be documented somewhere:
 * Each type must have a 0 argument constructor.
 * Each call to write must not assume any shared state.
 * Each call to readFields must consume exactly the number of bytes
produced by write.

SequenceFile also assumes:
 * All keys are exactly the same type (not polymorphic).
 * All values are exactly the same type.
 * Both types are specified by the writer in the create call.

"
HBASE-3427,"Is this a bug ?

example> hbase-site.xml is in conf/hbase-site.xml
so I wrote below.

HBaseConfiguration config = new HBaseConfiguration();
config.addResource(HBaseClient.class.getResource(""/conf/hbase-default.xml""));
config.addResource(HBaseClient.class.getResource(""/conf/hbase-site.xml""));

config.set(""hbase.zookeeper.quorum"", ""192.168.0.203"");
config.set(""hbase.zookeeper.property.clientPort"", ""2181"");

but, when I use IndexedTable, cannot create table(almost locking) because IndexedTableAdmin.reIndexTable

IndexedTableAdmin.java
 private void reIndexTable(byte[] baseTableName, IndexSpecification indexSpec) throws IOException {
    HTable baseTable = new HTable(baseTableName);
   .. ..
}

We should use HTable(String, HBaseConfiguration), I think.

because of that, I moved the config files to src/  not src/conf/ ***.xml

This is so confused. we should explain this more in java doc. or would be fixing it



"
HBASE-2881,"The TestAdmin test fails on trunk intermittently because it is unable to ""enable"" a ""disabled"" table. However, the root cause seems to be that much earlier, at ""createTable"" time the table's region got assigned to 2 region servers. And this later confuses the ""disable""/""enable"" code.

createTable goes down to RegionManager.java:createRegion:

{code}
public void createRegion(HRegionInfo newRegion, HRegionInterface server,
      byte [] metaRegionName)
  throws IOException {
    // 2. Create the HRegion
    HRegion region = HRegion.createHRegion(newRegion, this.master.getRootDir(),
      master.getConfiguration());

    // 3. Insert into meta
    HRegionInfo info = region.getRegionInfo();
    byte [] regionName = region.getRegionName();

    Put put = new Put(regionName);
    put.add(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER,
        Writables.getBytes(info));
    server.put(metaRegionName, put);

    // 4. Close the new region to flush it to disk.  Close its log file too.
    region.close();
    region.getLog().closeAndDelete();

    // 5. Get it assigned to a server
    setUnassigned(info, true);
  }
{code}

Between, after #3, but before #5, if the MetaScanner runs, it'll find this region in unassigned state and also assign it out.

And then #5 comes along at again ""force"" sets this region to be unassigned... causing it to get assigned again to a different region server (as part of the RegionManager's job of assigning out regions waiting to be assigned along with region server heart beats).

---

The test in question that diffs is TestAdmin:testHundredsOfTable(). I tried repro'ing this more reliable by modifying the test to have the metascanner run more frequently:

{code}
  TEST_UTIL.getConfiguration().setInt(""hbase.master.meta.thread.rescanfrequency"", 1000);// 1 seconds
{code}

(instead of the default 60seconds); but it didn't help improve the reproducibility.

---


"
HBASE-2911,"While working on the HBase Explorer front end in Hue I found a few inconsistencies between the plain text version of values versus the JSON representation. From an email conversation:

Plain Text
---------------

$ curl -H ""curl -H ""Accept: text/plain"" localhost:8888/status/cluster
1 live servers, 0 dead servers, 5.0000 average load

1 live servers
   de1-app-mbp-2.fritz.box:62884 1280924907616
       requests=0, regions=5
       heapSizeMB=27
       maxHeapSizeMB=995

       t2,,1280917558997
           stores=3
           storefiless=0
           storefileSizeMB=0
           memstoreSizeMB=0
           storefileIndexSizeMB=0
       usertable,,1280917566604
           stores=3
           storefiless=2
           storefileSizeMB=224
           memstoreSizeMB=0
           storefileIndexSizeMB=0
       .META.,,1
           stores=2
           storefiless=1
           storefileSizeMB=0
           memstoreSizeMB=0
           storefileIndexSizeMB=0
       t1,,1280917554475
           stores=3
           storefiless=0
           storefileSizeMB=0
           memstoreSizeMB=0
           storefileIndexSizeMB=0
       \-ROOT\-,,0
           stores=1
           storefiless=1
           storefileSizeMB=0
           memstoreSizeMB=0
           storefileIndexSizeMB=0

JSON
---------

And curling the JSON yields:

$ curl -H ""Accept: application/json"" localhost:8888/status/cluster
{""requests"":0,""regions"":5,""averageLoad"":5.0,""DeadNodes"":[null],""LiveNodes"":[{""Node"":{""startCode"":1280924907616,""requests"":0,""name"":""de1-app-mbp-2.fritz.box:62884"",""maxHeapSizeMB"":995,""heapSizeMB"":27,""Region"":[{""stores"":3,""storefiles"":0,""storefileSizeMB"":0,""storefileIndexSizeMB"":0,""name"":""dDIsLDEyODA5MTc1NTg5OTc="",""memstoreSizeMB"":0},{""stores"":3,""storefiles"":2,""storefileSizeMB"":224,""storefileIndexSizeMB"":0,""name"":""dXNlcnRhYmxlLCwxMjgwOTE3NTY2NjA0"",""memstoreSizeMB"":0},{""stores"":2,""storefiles"":1,""storefileSizeMB"":0,""storefileIndexSizeMB"":0,""name"":""Lk1FVEEuLCwx"",""memstoreSizeMB"":0},{""stores"":3,""storefiles"":0,""storefileSizeMB"":0,""storefileIndexSizeMB"":0,""name"":""dDEsLDEyODA5MTc1NTQ0NzU="",""memstoreSizeMB"":0},{""stores"":1,""storefiles"":1,""storefileSizeMB"":0,""storefileIndexSizeMB"":0,""name"":""LVJPT1QtLCww"",""memstoreSizeMB"":0}]}}]}


And another one:

I have another one with .META. and \-ROOT\-, in my small sample setup (all local, /tmp etc.) I see this in the master UI:

Name	 Region Server	 Encoded Name	 Start Key	 End Key
.META.,,1	10.0.0.43:60030	 -		

But running the same against Stargate I get:

$ curl -H ""Accept: application/json"" http://localhost:8888/.META./regions
{""name"":"".META.""}

while a ""normal"" user table with a single row has

Name	 Region Server	 Encoded Name	 Start Key	 End Key
t1,,1281111615489	10.0.0.43:60030	 1127696125		

and through Stargate:

$ curl -H ""Accept: application/json"" http://localhost:8888/t1/regions
{""name"":""t1"",""Region"":[{""location"":""10.0.0.43:54988"",""endKey"":"""",""startKey"":"""",""id"":1281111615489,""name"":""t1,,1281111615489""}]}

So the internal tables are not reported right.
"
HBASE-667,"Internally, came across a hung regionserver.  Here is relevant excerpt from thread dump:

{code}
""ResponseProcessor for block blk_-6991279486194843565"" daemon prio=1 tid=0x00002aab3ac13c50 nid=0x7ad7 runnable [0x0000000043080000..0x0000000043080d00]
        at java.net.SocketInputStream.socketRead0(Native Method)
        at java.net.SocketInputStream.read(Unknown Source)
        at java.io.DataInputStream.readFully(Unknown Source)
        at java.io.DataInputStream.readLong(Unknown Source)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:1734)

...

""IPC Server handler 3 on 60020"" daemon prio=1 tid=0x00002aab3c05abf0 nid=0x6b61 waiting for monitor entry [0x0000000042878000..0x0000000042878d00]
        at org.apache.hadoop.hbase.HLog.append(HLog.java:371)
        - waiting to lock <0x00002aaab69d1180> (a java.lang.Integer)
        at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1629)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1432)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1552)
        at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

.....

""IPC Server handler 1 on 60020"" daemon prio=1 tid=0x00002aab3c3220a0 nid=0x6b5f waiting for monitor entry [0x0000000042676000..0x0000000042676c00]
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:2126)
        - waiting to lock <0x00002aaab69d1a28> (a java.util.LinkedList)
        at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:141)
        at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:100)
        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:86)
        - locked <0x00002aaab69d15b0> (a org.apache.hadoop.dfs.DFSClient$DFSOutputStream)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:41)
        at java.io.DataOutputStream.write(Unknown Source)
        - locked <0x00002aaab69d1228> (a org.apache.hadoop.fs.FSDataOutputStream)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:990)
        - locked <0x00002aaab69d1050> (a org.apache.hadoop.io.SequenceFile$Writer)
        at org.apache.hadoop.hbase.HLog.append(HLog.java:387)
        - locked <0x00002aaab69d1180> (a java.lang.Integer)
        at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1629)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1432)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1552)
        at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

.....

""DataStreamer for file /hbase/aa0-005-2.u.powerset.com/log_208.76.45.223_1212443824255_60020/hlog.dat.000 block blk_-6991279486194843565"" daemon prio=1 tid=0x00002aab3c1b2e70 nid=0x6b50 runnable [0x0000000041969000..0x0000000041969c80]
        at java.net.SocketOutputStream.socketWrite0(Native Method)
        at java.net.SocketOutputStream.socketWrite(Unknown Source)
        at java.net.SocketOutputStream.write(Unknown Source)
        at java.io.BufferedOutputStream.write(Unknown Source)
        - locked <0x00002aaab7652b70> (a java.io.BufferedOutputStream)
        at java.io.DataOutputStream.write(Unknown Source)
        - locked <0x00002aaab7652288> (a java.io.DataOutputStream)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1631)
        - locked <0x00002aaab69d1a28> (a java.util.LinkedList)
{code}

I've seen this before.  I saw this this morning where a pure hadoop client was hung in same way.  This is hadoop 0.16.4.  Seems like a pure hadoop prob."
HBASE-1094,"After a large amount of file (~400,000) , once in a while during rapid inserts RegionServer returns NotServingRegionException when doing batchUpdate. 
A restart of the client usually fixes the problem , but it happens again after a while. 

LogFiles excerpts: 

*RegionServer*
2008-12-16 09:17:14,413 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1333
2008-12-16 09:17:14,413 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1334
2008-12-16 09:17:14,414 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_7750693789795884606_1536 wrote packet seqno:1333 size:65557 offsetInBlock:19507200 lastPacketInBlock:false
2008-12-16 09:17:14,439 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 in 2sec
2008-12-16 09:17:14,441 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting split of region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,442 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits: masked=rwxr-xr-x
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Compactions and cache flushes disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Scanners disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,462 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,462 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395. Current region memcache size 236.3k
2008-12-16 09:17:14,463 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960: masked=rwxr-xr-x
2008-12-16 09:17:14,484 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960/data: masked=rwxr-xr-x
2008-12-16 09:17:14,505 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960/index: masked=rwxr-xr-x
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 0
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.211:50010
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,527 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,530 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:0 size:65557 offsetInBlock:0 lastPacketInBlock:false
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 2
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:1 size:65557 offsetInBlock:65024 lastPacketInBlock:false
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 2
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 3
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:2 size:65557 offsetInBlock:130048 lastPacketInBlock:false
2008-12-16 09:17:14,533 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:3 size:49273 offsetInBlock:195072 lastPacketInBlock:true
2008-12-16 09:17:14,534 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:14,535 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 1
2008-12-16 09:17:14,536 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 2
2008-12-16 09:17:14,538 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 3
2008-12-16 09:17:14,538 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_4611894842462358439_1544
2008-12-16 09:17:14,557 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,557 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.211:50010
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,561 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-6152926948595840609_1544 wrote packet seqno:0 size:276 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:14,564 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:14,564 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-6152926948595840609_1544
2008-12-16 09:17:14,586 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/info/5474929915463365960: masked=rwxr-xr-x
2008-12-16 09:17:14,609 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,609 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,613 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_2767846628464404081_1545 wrote packet seqno:0 size:38 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:14,616 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:14,617 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_2767846628464404081_1545
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Added /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960 with 56 entries, sequence id 235152, data size 236.3k, file size 238.2k
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memcache flush for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 in 182ms, sequence id=235152, compaction requested=true
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 1608250010/obde_content
2008-12-16 09:17:14,644 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,649 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 60020, call batchUpdate([B@552a2a7d, row => f+C7Y24r+apSz+joQUhiQQ==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,651 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/mapfiles/1405033884904780036.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:14,694 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/info/1405033884904780036.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:14,717 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,717 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,719 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,721 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-4579777298287321197_1547 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:14,724 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:14,724 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-4579777298287321197_1547
2008-12-16 09:17:14,745 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate([B@18084038, row => hflk16ESykcggRSkrq7vgQ==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,746 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/mapfiles/215038473253378290.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:14,790 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/info/215038473253378290.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:14,813 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,837 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@74da3b58, row => rG4yO2bs4Rw+JU4QKY7X2w==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,847 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,849 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,864 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate([B@51575d48, row => aNq6QyMT+FePc7M78PaQMQ==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,885 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@63442ff5, row => iA4QenOmdZMbB8PTQPSnRw==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,998 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020, call batchUpdate([B@59eb5159, row => t5gRF1zQOrx27LTUS84ADA==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,023 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 60020, call batchUpdate([B@132fa7c8, row => Tu0dl1jFT2spZmEZundPoA==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,045 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 1333
2008-12-16 09:17:15,226 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@4696de68, row => Skj4FHgWdrR+DSOppIaG6Q==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,237 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call batchUpdate([B@16a3f072, row => gWd3yPCu6A9CxjBAhO3UPg==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,453 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1334
2008-12-16 09:17:15,453 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_7750693789795884606_1536 wrote packet seqno:1334 size:65557 offsetInBlock:19572224 lastPacketInBlock:false
2008-12-16 09:17:15,486 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate([B@171591e3, row => ddd8ecfGPwfgKzuLNMvOAw==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,498 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@452719a0, row => bJOTHv64AsNoFYsh7D0UyA==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,508 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate([B@6a76000a, row => XVNFoDhT1NeKnT0YwhopHg==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,548 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 60020, call batchUpdate([B@2b753bb9, row => jHxdShcit3A24oL3HHHgdg==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,557 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@7b4286a2, row => VYUtICqregww41FxZUJkig==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,558 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1335
2008-12-16 09:17:15,659 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-1532247345865982631_1549 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:15,661 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:15,661 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-1532247345865982631_1549
2008-12-16 09:17:15,679 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/mapfiles/4722584128214377088.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:15,721 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/info/4722584128214377088.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:15,744 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:15,745 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020, call batchUpdate([B@3f229bc1, row => WQXUl6gepHza8rVTmr8BSA==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,745 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:15,747 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:15,750 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_9044590686588152812_1551 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:15,752 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:15,752 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_9044590686588152812_1551
2008-12-16 09:17:15,774 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/mapfiles/6108448749728539444.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:15,797 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@74d3776e, row => hfCFR4B8pMF3mnY9mMnkDQ==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,817 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/info/6108448749728539444.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:15,841 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:15,841 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:15,848 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-3568743239673676944_1553 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:15,850 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:15,850 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-3568743239673676944_1553
2008-12-16 09:17:15,876 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/"
HBASE-1652,"Scanning a sparse column over a narrow range of rows can take far longer than expected because the check for the end of the range is not performed on new rows unless there is a column match, so it may end up scanning an entire region or table.

Background:
I have a table with 1 billion+ rows, and one cell in each row, generally small (10-1000 bytes).  The columns are all in a single family and fairly sparse.  For one query, I run scans on it to scan usually a narrow range of the table for the first 30 cells ina certain column.  I know that all the rows that contain that column lie within a certain range.  I use HTable.getScanner(byte[][] columns, byte[] startRow, RowFilterInterface filter) passing it the particular column I'm looking for, a startRow, and a filter set containing a StopRowFilter wrapped in a WhileMatchRowFilter to enforce the end of the range.  Sometimes the query is very fast (< 1 sec), but if the table doesn't contain 30 rows with that column, it can be very slow, a minute or two.  I expected that since the range was small, for example, just 120 rows, the query wouldn't take long to scan the rows.

After some pondering and perusing of the source code, I think I understand what is going on.  It looks like the Scanner is scanning the rest of the table to find rows containing the column without allowing the StopRowFilter to stop the scan at the end of the range.  I think I can work around this by not specifying the column I want in the getScanner() method and instead putting an additional filter in the filter set to filter out other columns."
HBASE-1325,"HBase wants to have large heaps - store lots of cached objects to make things faster in RAM.

But Java garbage collection wants to touch every object in heap.

How does this work at 3gb heaps?  6gb heaps?  The more ram we can use in HBase the better performance we can get.  If java GC holds us back, we might need to do something else."
HBASE-1806,"What I'm seeing is that BaseScanner misses updates made by an update milliseconds before -- even hundreds of milliseconds before.  See hbase-1784 where I'm seeing double-assignment of regions.

Scanners do not respect row locks.  They should else could return a row with partial updates committed.  What if a .META. region has tens of storefiles and a scan does a get full row which takes a long time.  Say an update comes in during this read.  First it will go in because no row lock is outstanding.  Second, we'll miss the edit given we look at things in order -- memstore, then each storefile down to the oldest.  What if the update is followed by an update of server state; e.g. region is moved out of intransition state?  And inside in same server, say the master, it makes decisions dependent on what it sees when it does a scanner#next; e.g. BaseScanner checking for assignment?

"
HBASE-1723,"The method getRowWithTimestampTs of the thrift interface changed behavior from version 0.19 to 0.20:

In 0.19, it returned only cells with exactly the given timestamp, 0.20 it to returns cells with a timestamp before (not including) the given timestamp.

It needs to be clearified, which one is the desired behavior.

I attach a patch to make 0.20 conform with 0.19 (only return cells with exactly the given timestamp), if this is what is wanted."
HBASE-1691,"When running MR jobs on 0.19.0 Hadoop, the hadoop core libraries get loaded by the classloader before 0.20 libraries included in the job jar.  HBaseClient makes a call to org.apache.hadoop.net.NetUtils.connect on line 305 which does not exist in previous versions of the hadoop jars and therefore results in NoSuchMethodErrors getting thrown.

As a simple workaround, you can replace the call

NetUtils.connect(socket, remoteId.getAddress(), 20000);

with

socket.connect(remoteId.getAddress(), 20000);

Note, however, that the javadoc on the NetUtils.connect() method makes mention of sun's implementation of stuff being less than wonderful, so the existence of this JIRA and this workaround should not be taken as meaning that this is actually a recommended solution.
"
HBASE-1601,"During an MR job, ZK expires one of the nodes. This results in losing contact with a region server and eventually the map task timing out and the job failing.

Attaching the following logs:
1. HBase master logs
2. Logs from the web UI
3. Logs from the particular RS that went down.
4. Logs from the particular node that ZK expired."
HBASE-488,"In hql.jsp, if I make hql that returns zero results, eg 'select nosuchcolumn from table', I get a 500 page with the text

HTTP ERROR: 500

getState() == BEFORE_XML_DECLARATION

The search returns zero results in the hbase shell."
HBASE-1555,"during a huge import (high concurrenty, 56 writers) I have seen:

java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:832)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:822)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1775)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.lang.NullPointerException
        at java.util.concurrent.ConcurrentHashMap$Segment.put(ConcurrentHashMap.java:426)
        at java.util.concurrent.ConcurrentHashMap.put(ConcurrentHashMap.java:883)
        at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1557)
        at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1610)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1225)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1197)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1768)
        ... 5 more
2009-06-19 20:13:55,672 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: java.lang.NullPointerException
2009-06-19 20:13:55,672 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 5 on 60020, call put([B@3160e069, [Lorg.apache.hadoop.hbase.client.Put;@4f2d26d2) from 10.10.20.226
:38741: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:832)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:822)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1775)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.lang.NullPointerException
        at java.util.concurrent.ConcurrentHashMap$Segment.put(ConcurrentHashMap.java:426)
        at java.util.concurrent.ConcurrentHashMap.put(ConcurrentHashMap.java:883)
        at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1557)
        at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1610)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1225)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1197)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1768)
        ... 5 more"
HBASE-1227,"When issuing a command like:

  POST /api/users/scanner?column=habbit:football&start_row=Alice&end_row=Bob

The resultant scanner appears to ignore the start_row and end_row constraints, so that a command like:

  POST /api/users/scanner/1?limit=1000

returns results outside of the specified range e.g. the row for ""William"" will be returned."
HBASE-1141,"While working on a Cell cache, we have found during random-read tests that the number of columns has an enormous impact on performance.  Accounting for increased HDFS access time, there is still a great deal of time being spent coming out of the Region and then across the wire to HTable.

Erik Holstad has done this testing and will post some of his results here when completed."
HBASE-958,"I got a couple of these just now:

{code}
2008-10-25 00:05:25,192 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: Processing message (Retry: 0)
java.io.IOException: java.io.IOException: java.lang.IllegalArgumentException: server cannot be null
        at org.apache.hadoop.hbase.master.MetaRegion.<init>(MetaRegion.java:42)
        at org.apache.hadoop.hbase.master.ProcessRegionStatusChange.<init>(ProcessRegionStatusChange.java:45)
        at org.apache.hadoop.hbase.master.ProcessRegionOpen.<init>(ProcessRegionOpen.java:50)
        at org.apache.hadoop.hbase.master.ServerManager.processRegionOpen(ServerManager.java:467)
        at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:340)
        at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:314)
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:233)
        at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:569)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:623)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:622)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:539)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:48)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:404)
        at java.lang.Thread.run(Thread.java:674)
{code}"
HBASE-856,"When data is inserted into Region that is on the different machine than the Master it is not immidiately available in the scanner that is using RowFilter
Here is the output of the test case on 3 nodes (tmptable_0 and tmptable_2 were placed on the region servers that are not running master server).
---------------DelayTest----------------
table tmptable_0 created
table tmptable_1 created
table tmptable_2 created
***********************************
table tmptable_0 test start
inserting some sample data into random row id (aaaaa-2108369209)
inserted
testing if the new row is available through get method
confirming that data:test value = test of row aaaaa-2108369209 is available
testing if the new row is available through scanner with filter
...................................
the new row has been found within 35 seconds
table tmptable_0 test finish
***********************************
***********************************
table tmptable_1 test start
inserting some sample data into random row id (aaaaa-20410017)
inserted
testing if the new row is available through get method
confirming that data:test value = test of row aaaaa-20410017 is available
testing if the new row is available through scanner with filter

the new row has been found within 0 seconds
table tmptable_1 test finish
***********************************
***********************************
table tmptable_2 test start
inserting some sample data into random row id (aaaaa1756705479)
inserted
testing if the new row is available through get method
confirming that data:test value = test of row aaaaa1756705479 is available
testing if the new row is available through scanner with filter
....................
the new row has been found within 20 seconds
table tmptable_2 test finish
***********************************
---------------DONE----------------

"
HBASE-1674,"when i suspend my system and resume it ... regionserver does not start back. looks like it actually shuts down completely. but the master and the zookeeper resume properly. 

i cannot stop-hbase.sh also properly. it goes on for a long time without doing anything. i have kill the master and zookeeper processes manually and do to ""start-hbase.sh"" to get back to the normal state.

irfan@damascus:~/qw/sandbox_7/qws$ stop-hbase.sh 
stopping master....................................................................................................

irfan@damascus:~$ jps
956 
11871 JobTracker
1816 HMaster
5908 Launcher
1742 HQuorumPeer
11790 SecondaryNameNode
3352 
32390 RunJar
11974 TaskTracker
4656 Child
11673 DataNode
6121 Jps
4669 Child
11568 NameNode
12770 PluginMain

irfan@damascus:~/apps/hbase-latest/logs$ tail -1000f hbase-irfan-regionserver-damascus.log
...
...
...
2009-07-19 11:48:59,538 INFO org.apache.hadoop.hbase.regionserver.HRegion: region site,,1247899770208/471872655 available; sequence id is 0
2009-07-19 11:48:59,539 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region site,,1247899770208
2009-07-19 11:48:59,542 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region site,,1247899770208 in 0sec
2009-07-19 11:58:09,369 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: compactions no longer limited
2009-07-19 12:47:59,493 INFO org.apache.hadoop.hbase.regionserver.HLog: Roll /hbase/.logs/damascus,60020,1247984279075/hlog.dat.1247984279311, entries=109890, calcsize=18397518, filesize=12396338. New hlog /hbase/.logs/damascus,60020,1247984279075/hlog.dat.1247987879487
2009-07-19 15:37:42,291 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12291a8d2be0001 to sun.nio.ch.SelectionKeyImpl@1542a75
java.io.IOException: TIMED OUT
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
2009-07-19 15:37:42,292 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 7207717ms, ten times longer than scheduled: 3000
2009-07-19 15:37:42,292 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: unable to report to master for 7207717 milliseconds - retrying
2009-07-19 15:37:42,294 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 7212721ms, ten times longer than scheduled: 10000
2009-07-19 15:37:42,295 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12291a8d2be0005 to sun.nio.ch.SelectionKeyImpl@628704
java.io.IOException: TIMED OUT
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
2009-07-19 15:37:42,296 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_5565548861312875890_4766java.net.SocketTimeoutException: 63000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:15928 remote=/127.0.0.1:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2369)

2009-07-19 15:37:42,297 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_5565548861312875890_4766 bad datanode[0] 127.0.0.1:50010
2009-07-19 15:37:42,298 FATAL org.apache.hadoop.hbase.regionserver.LogRoller: Log rolling failed with ioe: 
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2495)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$1600(DFSClient.java:2048)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2211)
2009-07-19 15:37:42,300 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics: request=0.0, regions=3, stores=6, storefiles=4, storefileIndexSize=0, memstoreSize=0, usedHeap=29, maxHeap=996, blockCacheSize=1961680, blockCacheFree=416131792, blockCacheCount=2, blockCacheHitRatio=99
2009-07-19 15:37:42,300 INFO org.apache.hadoop.hbase.regionserver.LogRoller: LogRoller exiting.
2009-07-19 15:37:42,300 INFO org.apache.hadoop.hbase.regionserver.LogFlusher: regionserver/127.0.1.1:60020.logFlusher exiting
2009-07-19 15:37:42,392 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: Disconnected, type: None, path: null
2009-07-19 15:37:44,192 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server localhost/127.0.0.1:2181
2009-07-19 15:37:44,193 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/127.0.0.1:55018 remote=localhost/127.0.0.1:2181]
2009-07-19 15:37:44,193 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-19 15:37:44,197 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12291a8d2be0005 to sun.nio.ch.SelectionKeyImpl@118cb72
java.io.IOException: Session Expired
	at org.apache.zookeeper.ClientCnxn$SendThread.readConnectResult(ClientCnxn.java:548)
	at org.apache.zookeeper.ClientCnxn$SendThread.doIO(ClientCnxn.java:661)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:897)
2009-07-19 15:37:44,198 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x12291a8d2be0005
2009-07-19 15:37:44,199 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn for session: 0x12291a8d2be0005
2009-07-19 15:37:44,199 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn for session: 0x12291a8d2be0005
2009-07-19 15:37:44,199 INFO org.apache.zookeeper.ZooKeeper: Session: 0x12291a8d2be0005 closed
2009-07-19 15:37:44,200 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-07-19 15:37:44,297 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server localhost/127.0.0.1:2181
2009-07-19 15:37:44,297 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/127.0.0.1:55020 remote=localhost/127.0.0.1:2181]
2009-07-19 15:37:44,297 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-19 15:37:44,298 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12291a8d2be0001 to sun.nio.ch.SelectionKeyImpl@d4b411
java.io.IOException: Session Expired
	at org.apache.zookeeper.ClientCnxn$SendThread.readConnectResult(ClientCnxn.java:548)
	at org.apache.zookeeper.ClientCnxn$SendThread.doIO(ClientCnxn.java:661)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:897)
2009-07-19 15:37:44,299 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: Expired, type: None, path: null
2009-07-19 15:37:45,302 INFO org.apache.hadoop.ipc.HBaseServer: Stopping server on 60020
2009-07-19 15:37:45,303 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 4 on 60020: exiting
2009-07-19 15:37:45,303 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Stopping infoServer
2009-07-19 15:37:45,314 INFO org.apache.hadoop.ipc.HBaseServer: Stopping IPC Server Responder
2009-07-19 15:37:45,352 INFO org.apache.hadoop.hbase.regionserver.MemStoreFlusher: regionserver/127.0.1.1:60020.cacheFlusher exiting
2009-07-19 15:37:45,353 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: regionserver/127.0.1.1:60020.compactor exiting
2009-07-19 15:37:45,353 INFO org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker: regionserver/127.0.1.1:60020.majorCompactionChecker exiting
2009-07-19 15:37:45,353 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: On abort, closed hlog
2009-07-19 15:37:45,354 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed .META.,,1
2009-07-19 15:37:45,354 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed site,,1247899770208
2009-07-19 15:37:45,354 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed -ROOT-,,0
2009-07-19 15:37:45,354 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: aborting server at: 127.0.1.1:60020
2009-07-19 15:37:45,362 INFO org.apache.hadoop.ipc.HBaseServer: Stopping IPC Server listener on 60020
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 3 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 2 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 0 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 9 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 8 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 7 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 6 on 60020: exiting
2009-07-19 15:37:45,373 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 5 on 60020: exiting
2009-07-19 15:37:45,373 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 1 on 60020: exiting
2009-07-19 15:37:52,295 INFO org.apache.hadoop.hbase.Leases: regionserver/127.0.1.1:60020.leaseChecker closing leases
2009-07-19 15:37:52,295 INFO org.apache.hadoop.hbase.Leases: regionserver/127.0.1.1:60020.leaseChecker closed leases
2009-07-19 15:37:52,295 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting
2009-07-19 15:37:52,295 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x12291a8d2be0001
2009-07-19 15:37:52,295 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn for session: 0x12291a8d2be0001
2009-07-19 15:37:52,296 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn for session: 0x12291a8d2be0001
2009-07-19 15:37:52,296 INFO org.apache.zookeeper.ZooKeeper: Session: 0x12291a8d2be0001 closed
2009-07-19 15:37:52,296 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-07-19 15:37:52,398 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/127.0.1.1:60020 exiting
2009-07-19 15:37:52,399 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Starting shutdown thread.
2009-07-19 15:37:52,400 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Shutdown thread complete

"
HBASE-1092,"This is an odd one.  We open a region and load up its store files.  Part of loading store files is confirming presence of MapFile index files (reconstituting them even if missing).  The below log is of region open and then seconds later, failing to find the index files when we go to look at them for sake of metrics:

{code}
2008-12-28 00:06:19,330 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_OPEN: content,10a1c144cf729885001e71a5ff5108dc,1230416158498
2008-12-28 00:06:19,330 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region content,10a1c144cf729885001e71a5ff5108dc,1230416158498/2030495720
2008-12-28 00:06:19,337 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/url/info/4139998553412763261, isReference=false, sequence id=13310628, length=54275, majorCompaction=false
2008-12-28 00:06:19,368 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/url/info/4467064002967944271, isReference=false, sequence id=9760762, length=432827, majorCompaction=false
2008-12-28 00:06:19,373 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/url/info/5563124412728188459, isReference=false, sequence id=12406630, length=22596, majorCompaction=false
2008-12-28 00:06:19,379 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/url/info/7040855870376599550, isReference=false, sequence id=12795530, length=4163, majorCompaction=false
2008-12-28 00:06:19,379 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 4 file(s) in hstore 2030495720/url, max sequence id 13310628
2008-12-28 00:06:19,496 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Applied 0, skipped 2078 because sequence id <= 13310628
2008-12-28 00:06:19,687 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/info/info/4076087643455354411, isReference=false, sequence id=9760762, length=1491212, majorCompaction=false
2008-12-28 00:06:19,691 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/info/info/4178444212265859440, isReference=false, sequence id=13310628, length=156148, majorCompaction=false
2008-12-28 00:06:19,697 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/info/info/7223110203696352566, isReference=false, sequence id=12406630, length=84614, majorCompaction=false
2008-12-28 00:06:19,703 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/info/info/8629305049543986640, isReference=false, sequence id=12795530, length=9293, majorCompaction=false
2008-12-28 00:06:19,704 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 4 file(s) in hstore 2030495720/info, max sequence id 13310628
2008-12-28 00:06:19,773 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /data/hbase/content/compaction.dir/888098363/content/mapfiles/3159110292991346789 to /data/hbase/content/888098363/content/mapfiles/6086595812879433437
2008-12-28 00:06:19,787 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed  compaction of 888098363/content store size is 172.4m
2008-12-28 00:06:19,791 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 888098363/info: 1.4m; Skipped 2 file(s), size: 1221094
2008-12-28 00:06:19,801 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Started compaction of 2 file(s)  into /data/hbase/content/compaction.dir/888098363/info/mapfiles/2317624608256855622
2008-12-28 00:06:19,821 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Applied 0, skipped 2078 because sequence id <= 13310628
2008-12-28 00:06:19,879 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /data/hbase/content/compaction.dir/888098363/info/mapfiles/2317624608256855622 to /data/hbase/content/888098363/info/mapfiles/2738033219360665217
2008-12-28 00:06:19,883 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/content/info/2253403598042963153, isReference=false, sequence id=13310628, length=12491312, majorCompaction=false
2008-12-28 00:06:19,887 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/content/info/4596284995168293361, isReference=false, sequence id=9760762, length=158138153, majorCompaction=false
2008-12-28 00:06:19,896 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed  compaction of 888098363/info store size is 1.4m
2008-12-28 00:06:19,898 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 888098363/url: 405.9k; Skipped 2 file(s), size: 339984
2008-12-28 00:06:19,904 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Started compaction of 2 file(s)  into /data/hbase/content/compaction.dir/888098363/url/mapfiles/1108952767537472093
2008-12-28 00:06:19,924 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/content/info/7464468628166271570, isReference=false, sequence id=12406630, length=11058492, majorCompaction=false
2008-12-28 00:06:19,930 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/content/info/7703689073557380324, isReference=false, sequence id=12795530, length=183695, majorCompaction=false
2008-12-28 00:06:19,931 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 4 file(s) in hstore 2030495720/content, max sequence id 13310628
2008-12-28 00:06:19,958 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /data/hbase/content/compaction.dir/888098363/url/mapfiles/1108952767537472093 to /data/hbase/content/888098363/url/mapfiles/4113677425818108069
2008-12-28 00:06:19,976 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed  compaction of 888098363/url store size is 403.6k
2008-12-28 00:06:19,978 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region content,846510f382e9a0ae5655f03cb772830d,1230384248550 in 0sec
2008-12-28 00:06:19,979 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting  compaction on region content,e2f10daf46269ad3cc25766aa3bf48c4,1230416165744
2008-12-28 00:06:19,981 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 2100409777/content: 170.2m; Skipped 1 file(s), size: 144757669
2008-12-28 00:06:19,996 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Started compaction of 2 file(s)  into /data/hbase/content/compaction.dir/2100409777/content/mapfiles/7166480659109830957
2008-12-28 00:06:20,033 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Applied 0, skipped 2078 because sequence id <= 13310628
2008-12-28 00:06:20,127 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Deleting old log file: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/2030495720/oldlogfile.log
2008-12-28 00:06:20,137 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Next sequence id for region content,10a1c144cf729885001e71a5ff5108dc,1230416158498 is 13310629
2008-12-28 00:06:20,138 INFO org.apache.hadoop.hbase.regionserver.HRegion: region content,10a1c144cf729885001e71a5ff5108dc,1230416158498/2030495720 available
....
2008-12-28 00:06:21,008 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Started compaction of 2 file(s)  into /data/hbase/content/compaction.dir/2100409777/url/mapfiles/744229794307693860
2008-12-28 00:06:21,030 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: error getting store file index size for 2030495720/content: java.io.FileNotFoundException: File does not exist: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/2030495720/content/mapfiles/7703689073557380324/index
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
        at org.apache.hadoop.hbase.regionserver.HStoreFile.indexLength(HStoreFile.java:488)
        at org.apache.hadoop.hbase.regionserver.HStore.getStorefilesIndexSize(HStore.java:2174)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doMetrics(HRegionServer.java:936)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:333)
        at java.lang.Thread.run(Thread.java:619)

2008-12-28 00:06:21,032 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: error getting store file index size for 2030495720/info: java.io.FileNotFoundException: File does not exist: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/2030495720/info/mapfiles/8629305049543986640/index
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
        at org.apache.hadoop.hbase.regionserver.HStoreFile.indexLength(HStoreFile.java:488)
        at org.apache.hadoop.hbase.regionserver.HStore.getStorefilesIndexSize(HStore.java:2174)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doMetrics(HRegionServer.java:936)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:333) 
        at java.lang.Thread.run(Thread.java:619)

2008-12-28 00:06:21,053 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: error getting store file index size for 2030495720/url: java.io.FileNotFoundException: File does not exist: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/2030495720/url/mapfiles/7040855870376599550/index
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
        at org.apache.hadoop.hbase.regionserver.HStoreFile.indexLength(HStoreFile.java:488)
        at org.apache.hadoop.hbase.regionserver.HStore.getStorefilesIndexSize(HStore.java:2174)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doMetrics(HRegionServer.java:936)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:333)
        at java.lang.Thread.run(Thread.java:619)
...
{code}"
HBASE-1472,"Attempting to connect to an HBase 0.19.1 server with the HBase 0.19.0 client jars raises an exception that states the HBase server is not running.

This is misleading; it should state that the server is running an incompatible version."
HBASE-1409,"When we create a table with the following schema:

{NAME => 'jobs_global', IS_ROOT => 'false', IS_META => 'false', MAX_FILESIZE => '134217728', FAMILIES => [{NAM
E => 'job', BLOOMFILTER => 'false', COMPRESSION => 'NONE', VERSIONS => '1', LENGTH => '2147483647', TTL => '86
400', IN_MEMORY => 'false', BLOCKCACHE => 'false'}], INDEXES => []}

The TTL is set to 86400 which should expire after 1 day, but the truth is that it expired before 86400 seconds.
To reproduce, create a table with the above schema and run some stress testing to create some splits and compaction,
usually in 4 - 5 hours, the row key will start missing from the Scanners.

By invoking HTable.get() and HTable.getRow(), the column appears to exist.
But if you launch a scanner or a MapReduce task to scan the table, the key will be missing.

By running a simple MapReduce task that prints out all the key value, you can tell some keys are already missing prior to its expiration time.

When we alter the table's TTL to a longer time, e.g. 604800, the row key appears in the scanner.

"
HBASE-888,"Might be related to HBASE-644?

In my regionserver log I see this:

2008-09-17 21:36:06,335 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@ff0be7b, row => Sn5MiT-wIYUoud4gqyj0r-==, {column => anchor:anchor_text, value => '...'}) f
rom 208.76.44.97:41671: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.io.SequenceFile$Writer.checkAndWriteSync(SequenceFile.java:970)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1012)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:979)
        at org.apache.hadoop.hbase.regionserver.HLog.append(HLog.java:395)
        at org.apache.hadoop.hbase.regionserver.HRegion.update(HRegion.java:1631)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1417)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1145)
        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-09-17 21:36:06,336 WARN org.apache.hadoop.ipc.Server: IPC Server Responder, call batchUpdate([B@ff0be7b, row => Sn5MiT-wIYUoud4gqyj0r-==, {column => anchor:anchor_text, value => '...'}) from x.x.44.97:41671: output error
2008-09-17 21:36:06,336 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020 caught: java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(Unknown Source)
        at sun.nio.ch.SocketChannelImpl.write(Unknown Source)
        at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:587)
        at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:651)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:909)

2008-09-17 21:36:06,336 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020: exiting
2008-09-17 21:37:06,312 FATAL org.apache.hadoop.hbase.regionserver.Flusher: Replay of hlog required. Forcing server restart
org.apache.hadoop.hbase.DroppedSnapshotException: region: enwiki3,4m7aFqMi8ijHEpBxTuzP3k==,1221687099180
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1079)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:977)
        at org.apache.hadoop.hbase.regionserver.Flusher.flushRegion(Flusher.java:174)
        at org.apache.hadoop.hbase.regionserver.Flusher.flushSomeRegions(Flusher.java:268)
        at org.apache.hadoop.hbase.regionserver.Flusher.reclaimMemcacheMemory(Flusher.java:253)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1144)
        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
Caused by: java.io.IOException: Call failed on local exception
        at org.apache.hadoop.ipc.Client.call(Client.java:718)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
        at org.apache.hadoop.dfs.$Proxy1.getFileInfo(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at org.apache.hadoop.dfs.$Proxy1.getFileInfo(Unknown Source)
        at org.apache.hadoop.dfs.DFSClient.getFileInfo(DFSClient.java:566)
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:390)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:667)
        at org.apache.hadoop.hbase.regionserver.HStoreFile.<init>(HStoreFile.java:149)
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:591)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:569)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1066)
        ... 10 more
Caused by: java.nio.channels.ClosedByInterruptException
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(Unknown Source)
        at sun.nio.ch.SocketChannelImpl.write(Unknown Source)
        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)
        at java.io.BufferedOutputStream.flush(Unknown Source)
        at java.io.DataOutputStream.flush(Unknown Source)
        at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:478)
        at org.apache.hadoop.ipc.Client.call(Client.java:705)
        ... 25 more
2008-09-17 21:37:06,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: coral-dfs.cluster.powerset.com/208.76.44.135:10000. Already tried 0 time(s).
2008-09-17 21:37:06,346 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate([B@52fac63b, row => 6PceOtjHe-VpiGbS5DZgMV==, {column => [..], value => '...'}) from x.x.44.96:44885: error: java.io.IOException: Cannot append; log is closed
java.io.IOException: Cannot append; log is closed
        at org.apache.hadoop.hbase.regionserver.HLog.append(HLog.java:376)
        at org.apache.hadoop.hbase.regionserver.HRegion.update(HRegion.java:1631)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1417)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1145)
        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-09-17 21:37:06,346 WARN org.apache.hadoop.ipc.Server: IPC Server Responder, call batchUpdate([B@52fac63b, row => 6PceOtjHe-VpiGbS5DZgMV==, {column => [...], value => '...'}) from 208.76.44.96:44885: output error
2008-09-17 21:37:06,346 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020 caught: java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(Unknown Source)
        at sun.nio.ch.SocketChannelImpl.write(Unknown Source)
        at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:587)
        at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:651)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:909)

2008-09-17 21:37:06,346 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020: exiting
2008-09-17 21:37:54,491 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 3236781325465377548 lease expired
2008-09-17 21:37:54,492 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region enwiki,MHw740LAdNxzM68Dn7LXs-==,1220059653599
2008-09-17 21:37:54,492 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region enwiki,MHw740LAdNxzM68Dn7LXs-==,1220059653599
2008-09-17 21:37:54,492 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region enwiki,MHw740LAdNxzM68Dn7LXs-==,1220059653599
2008-09-17 21:37:54,492 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/anchor
2008-09-17 21:37:54,493 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/misc
2008-09-17 21:37:54,493 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/alternate_title
2008-09-17 21:37:54,493 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/page
2008-09-17 21:37:54,493 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/alternate_url
2008-09-17 21:37:54,493 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed enwiki,MHw740LAdNxzM68Dn7LXs-==,1220059653599
2008-09-17 21:37:54,493 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting
2008-09-17 21:38:07,581 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: Shutting down HRegionServer: file system not available
java.io.IOException: File system is not available
        at org.apache.hadoop.hbase.util.FSUtils.checkFileSystemAvailable(FSUtils.java:82)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.checkFileSystem(HRegionServer.java:1484)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1150)
        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
Caused by: java.io.IOException: Call failed on local exception
        at org.apache.hadoop.ipc.Client.call(Client.java:718)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
        at org.apache.hadoop.dfs.$Proxy1.getFileInfo(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at org.apache.hadoop.dfs.$Proxy1.getFileInfo(Unknown Source)
        at org.apache.hadoop.dfs.DFSClient.getFileInfo(DFSClient.java:566)
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:390)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:667)
        at org.apache.hadoop.hbase.util.FSUtils.checkFileSystemAvailable(FSUtils.java:69)
        ... 7 more
:


The result is that every call to the regionserver hangs because the regionserver can't touch the DFS, because the DFSClient is closed.  The regionserver won't restart either."
HBASE-829,"Seen on a 4 node cluster during the reduce phase of a MR job that only deleteAll rows, one of the region server failed after a filesystem not available exception. When restarted, it got assigned some regions but in the web UI none was shown when clicking on the HRS address. Also in the master page 0 region was shown for that HRS so the total number of regions was under the real number."
HBASE-1080,"This lock assigning regions looks broad.

{code}
""IPC Server handler 6 on 60000"" daemon prio=10 tid=0x00007ff2d00ab400 nid=0x645b in Object.wait() [0x000000004330b000..0x000000004330cd70]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:695)
	- locked <0x00007ff2e8e2b3b0> (a org.apache.hadoop.hbase.ipc.HBaseClient$Call)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:321)
	at $Proxy2.batchUpdates(Unknown Source)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$2.call(HConnectionManager.java:916)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$2.call(HConnectionManager.java:914)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerForWithoutRetries(HConnectionManager.java:872)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.processBatchOfRows(HConnectionManager.java:913)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1270)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:1241)
	- locked <0x00007ff2e8c01b90> (a org.apache.hadoop.hbase.client.HTable)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:1221)
	- locked <0x00007ff2e8c01b90> (a org.apache.hadoop.hbase.client.HTable)
	at org.apache.hadoop.hbase.RegionHistorian.add(RegionHistorian.java:239)
	at org.apache.hadoop.hbase.RegionHistorian.add(RegionHistorian.java:218)
	at org.apache.hadoop.hbase.RegionHistorian.addRegionAssignment(RegionHistorian.java:142)
	at org.apache.hadoop.hbase.master.RegionManager.assignRegionsToMultipleServers(RegionManager.java:282)
	at org.apache.hadoop.hbase.master.RegionManager.assignRegions(RegionManager.java:220)
	- locked <0x00007ff2e895d3f8> (a java.util.Collections$SynchronizedSortedMap)
	at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:382)
	at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:324)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:240)
	at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:570)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:892)

....
{code}

Its messing up assigning root it seems.

We are stuck in here.  Doesn't look like we'll break out though maybe we time out?

{code}
  public Writable call(Writable param, InetSocketAddress addr, 
                       UserGroupInformation ticket)  
                       throws InterruptedException, IOException {
    Call call = new Call(param);
    Connection connection = getConnection(addr, ticket, call);
    connection.sendParam(call);                 // send the parameter
    synchronized (call) {
      while (!call.done) {
        try {
          call.wait();                           // wait for the result
        } catch (InterruptedException ignored) {}
      }
...
{code}

... down in HBaseClient. 

"
HBASE-935,"Our hdfs is having issues.  Not just hbase is complaining.  During a storm of downing regionservers because of failed flush attempts, master has gotten itself locked up over location of root region."
HBASE-870,"This morning, the pset master got into a locked up state.  Was stuck for tens of minutes doing the below logging.  Cluster was unusable during this time:

{code}
....
2008-09-04 18:06:45,893 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION => {NAME => 'enwiki,YSWgGYWLLur87bjpYfj5--==,1220070599758', STARTKEY => 'YSWgGYWLLur87bjpYfj5--==', ENDKEY => 'Y_dJHSiXE_hJ8jmGEgg1Dk==', ENCODED => 1060266767, TABLE => {{NAME => 'enwiki', IS_ROOT => 'false'
, IS_META => 'false', FAMILIES => [{NAME => 'alternate_title', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'anchor', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGT
H => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'alternate_url', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'page', BLOOMFILTER => 'false', VERSIONS => '21
47483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'misc', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}]}}}, SERVER => 'XX.XX.XX.1
83:60020', STARTCODE => 1219794634959
2008-09-04 18:06:45,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 1 time(s).
2008-09-04 18:06:46,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 2 time(s).
2008-09-04 18:06:47,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 3 time(s).
2008-09-04 18:06:48,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 4 time(s).
2008-09-04 18:06:49,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 5 time(s).
2008-09-04 18:06:50,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 6 time(s).
2008-09-04 18:06:51,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 7 time(s).
2008-09-04 18:06:52,398 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: <>, server: 208.76.44.68:60020}
2008-09-04 18:06:52,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 8 time(s).
2008-09-04 18:06:53,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 9 time(s).
2008-09-04 18:06:55,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 10 time(s).
2008-09-04 18:06:56,018 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: Connection refused
2008-09-04 18:06:56,045 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION => {NAME => '.META.,,1', STARTKEY => '', ENDKEY => '', ENCODED => 1028785192, TABLE => {{NAME => '.META.', IS_ROOT => 'false', IS_META => 'true', FAMILIES => [{NAME => 'info', BLOOMFILTER => 'false', COMPRESSI
ON => 'NONE', VERSIONS => '2147483647', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'historian', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}]}}}, SERVER => '
208.76.44.48:60020', STARTCODE => 1219794657357
2008-09-04 18:07:01,084 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 1917, Num Servers: 69, Avg Load: 28.0
2008-09-04 18:07:01,084 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Cache hit in table locations for row <> and tableName .META.: location server XX.XX.XX.253:60020, location region name .META.,,1
2008-09-04 18:07:01,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 1 time(s).
2008-09-04 18:07:02,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 2 time(s).
2008-09-04 18:07:03,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 3 time(s).
2008-09-04 18:07:04,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 4 time(s).
2008-09-04 18:07:05,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 5 time(s).
2008-09-04 18:07:06,038 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of shroomz_062108,a8XltuT_bfDh6RCYKWEf9-==,1215120916399
2008-09-04 18:07:06,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 6 time(s).
2008-09-04 18:07:07,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 7 time(s).
2008-09-04 18:07:08,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 8 time(s).
2008-09-04 18:07:09,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 9 time(s).
2008-09-04 18:07:10,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 10 time(s).
2008-09-04 18:07:11,218 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: Connection refused
2008-09-04 18:08:09,779 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 1917, Num Servers: 69, Avg Load: 28.0
2008-09-04 18:08:11,238 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:09:11,248 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:09:43,328 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.185:60020 lease expired
2008-09-04 18:09:43,348 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.183:60020 lease expired
2008-09-04 18:09:43,368 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.231:60020 lease expired
2008-09-04 18:09:43,438 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.127:60020 lease expired
2008-09-04 18:09:43,528 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.68:60020 lease expired
2008-09-04 18:10:11,258 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:11:11,278 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:12:11,298 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:13:11,318 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:14:11,338 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:15:11,358 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:16:11,368 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:17:11,378 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:18:11,388 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:19:11,398 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:20:11,408 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:21:11,418 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:22:11,428 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:23:11,438 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:23:28,291 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 1805, Num Servers: 65, Avg Load: 28.0
2008-09-04 18:24:11,458 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
....
{code}

Attached are thread dumps taking around this time."
HBASE-1006,"Here is the OOME:

{code}
#
2008-11-17 17:04:18,812 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown
#
org.apache.hadoop.hbase.DroppedSnapshotException: region: streamitems,^@^@^@^@^A茂驴陆?茂驴陆,1226968617756
#
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:865)
#
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:761)
#
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:179)
#
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushSomeRegions(MemcacheFlusher.java:232)
#
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.reclaimMemcacheMemory(MemcacheFlusher.java:213)
#
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdates(HRegionServer.java:1312)
#
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
#
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
#
        at java.lang.reflect.Method.invoke(Method.java:597)
#
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:634)
#
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
#
Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded
#
        at org.apache.hadoop.hbase.util.Bytes.readByteArray(Bytes.java:62)
#
        at org.apache.hadoop.hbase.HStoreKey.readFields(HStoreKey.java:589)
#
        at org.apache.hadoop.io.MapFile$Writer.checkKey(MapFile.java:213)
#
        at org.apache.hadoop.io.MapFile$Writer.append(MapFile.java:192)
#
        at org.apache.hadoop.hbase.io.BloomFilterMapFile$Writer.append(BloomFilterMapFile.java:201)
#
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:674)
#
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:627)
#
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:852)
#
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:852)
{code}

Looking in heap, the resevoir had not been released."
HBASE-915,"From AlphaOmega: 

{code}
   1.
      Caused by: java.lang.NullPointerException
   2.
              at java.lang.String.<init>(String.java:516)
   3.
              at org.apache.hadoop.hbase.util.Bytes.toString(Bytes.java:75)
   4.
              at org.apache.hadoop.hbase.client.RetriesExhaustedException.getMessage(RetriesExhaustedException.java:50)
   5.
              at org.apache.hadoop.hbase.client.RetriesExhaustedException.<init>(RetriesExhaustedException.java:40)
   6.
              at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)
   7.
              at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:56)
   8.
              at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:30)
   9.
              at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.listTables(HConnectionManager.java:297)
  10.
              at org.apache.hadoop.hbase.client.HBaseAdmin.listTables(HBaseAdmin.java:117)
  11.
              at com.company.app.manager.util.TableUtils.createHBaseTable(TableUtils.java:113)
  12.
              at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  13.
              at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
  14.
              at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
  15.
              at java.lang.reflect.Method.invoke(Method.java:597)
  16.
              at org.springframework.util.MethodInvoker.invoke(MethodInvoker.java:276)
  17.
              at org.springframework.beans.factory.config.MethodInvokingFactoryBean.doInvoke(MethodInvokingFactoryBean.java:160)
  18.
              at org.springframework.beans.factory.config.MethodInvokingFactoryBean.afterPropertiesSet(MethodInvokingFactoryBean.java:150)
  19.
              at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1368)
  20.
              at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1334)
  21.
              ... 65 more
{code}"
HBASE-724,"When deleting a row, that row seems to be deleted and everything to be normal but some time afterwards that row somehow reappears (HTable.get() and scanners find it again). Looking at the log files it seems like deleted rows reappear after a flush of the memcache or after the compaction..."
HBASE-713,"Internally, i'm trying to offline a 512 region table.  All but 30 offline.  If I try to online it, all but 2 go online.  Second time I try it, all but 41 offline.  Enabling, all but 2 online."
HBASE-673,"getRow often returns no results, even when a scanner returned results for the same row."
HBASE-594,"We are running HBase TRUNK (updated yesterday) and Hadoop TRUNK (updated a few days ago) on a 15 node cluster. One node doubles as master and region server. The remainder are region servers. 

I have been trying to use the HBase shell to drop tables for quite a few minutes now. 

The master schedules the table for deletion and the region server processes the deletion:

08/04/18 16:57:29 INFO master.HMaster: deleted table: content.20b16c29
08/04/18 16:57:34 INFO master.ServerManager: 10.30.94.35:60020 no longer serving regionname: content.20b16c29,,1208549961323, startKey: <>, endKey: <>, encodedName: 385178593, tableDesc: {name: content.20b16c29, families: {content:={name: content, max versions: 1, compression: RECORD, in memory: false, block cache enabled: true, max length: 2147483647, bloom filter: none}, info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: true, maxlength: 2147483647, bloom filter: none}}}
08/04/18 16:57:34 INFO master.ProcessRegionClose$1: region closed: content.20b16c29,,1208549961323

but then a META scan happens and the table is reassigned to another server to live on as a zombie:

08/04/18 16:57:48 INFO master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: <>, server: 10.30.94.37:60020}
08/04/18 16:57:48 INFO master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: <>, server: 10.30.94.37:60020} complete
08/04/18 16:57:48 INFO master.BaseScanner: all meta regions scanned
08/04/18 16:57:49 INFO master.RegionManager: assigning region content.20b16c29,,1208549961323 to server 10.30.94.39:60020
08/04/18 16:57:52 INFO master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: <>, server: 10.30.94.31:60020}
08/04/18 16:57:52 INFO master.BaseScanner: RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: <>, server: 10.30.94.31:60020} complete
08/04/18 16:57:52 INFO master.ServerManager: 10.30.94.39:60020 serving content.20b16c29,,1208549961323
08/04/18 16:57:52 INFO master.ProcessRegionOpen$1: regionname: content.20b16c29,,1208549961323, startKey: <>, endKey: <>, encodedName: 385178593, tableDesc: {name: content.20b16c29, families: {content:={name: content, max versions: 1, compression: RECORD, in memory: false, block cache enabled: true, max length: 2147483647, bloom filter: none}, info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: true, max length: 2147483647, bloom filter: none}}} open on 10.30.94.39:60020
08/04/18 16:57:52 INFO master.ProcessRegionOpen$1: updating row content.20b16c29,,1208549961323 in table .META.,,1 with startcode 1208552149355 and server 10.30.94.39:60020

Approximately 50 META region scans then happen, then the following occurs and reoccurs over many many subsequent META scans:

08/04/18 17:26:48 INFO master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: <>, server: 10.30.94.37:60020}
08/04/18 17:26:48 WARN master.HMaster: info:regioninfo is empty for row: content.20b16c29,,1208549961323; has keys: [info:server, info:serverstartcode]
08/04/18 17:26:48 WARN master.BaseScanner: Found 1 rows with empty HRegionInfo while scanning meta region .META.,,1
08/04/18 17:26:48 WARN master.HMaster: Removed region: content.20b16c29,,1208549
961323 from meta region: .META.,,1 because HRegionInfo was empty
08/04/18 17:26:48 INFO master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: <>, server: 10.30.94.37:60020} complete
08/04/18 17:26:48 INFO master.BaseScanner: all meta regions scanned

yet finally the table disappears for a reason that does not appear in the logs... at least for this particular example. There is another table that is simply refusing to die...

"
HBASE-499,"I'm afraid to touch the thing (No mention of the test in process listing).  Asking nigel how to kill the test.

It looks like the old problem where test was over but we'd hang on shutdown.... as though TTI is no longer doing the shutdown in the ordained sequence."
HBASE-445,"We've been dealing with a problem where regions go offline for no apparent reason.  Usually restarting the whole system clears things up, but that's not a desired workaround.  After some digging on one of the region servers with a region that is offline that should not be I found the following:

2008-02-13 17:43:31,357 INFO org.apache.hadoop.hbase.HRegion: starting compaction on region webdb,com.geocities.www/Paris/1685/,1202919182718
2008-02-13 17:45:09,004 INFO org.apache.hadoop.hbase.HRegionServer: Rolling hlog. Number of entries: 30006
2008-02-13 17:45:09,071 INFO org.apache.hadoop.hbase.HLog: new log writer created at hdfs://node-3-34.isc.swlabs.org:9000/u01/hbase-data/hbase/log_10.2
.3.32_1202914711919_60020/hlog.dat.010
2008-02-13 17:47:51,606 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region webdb,com.geocities.www/Paris/1685/,1202919182718. Took 4m
ins, 20sec
2008-02-13 17:48:20,273 INFO org.apache.hadoop.hbase.HRegionServer: Rolling hlog. Number of entries: 30007
2008-02-13 17:48:20,315 INFO org.apache.hadoop.hbase.HLog: new log writer created at hdfs://node-3-34.isc.swlabs.org:9000/u01/hbase-data/hbase/log_10.2
.3.32_1202914711919_60020/hlog.dat.011
2008-02-13 17:48:20,315 INFO org.apache.hadoop.hbase.HLog: removing old log file hdfs://node-3-34.isc.swlabs.org:9000/u01/hbase-data/hbase/log_10.2.3.3
2_1202914711919_60020/hlog.dat.008 whose highest sequence/edit id is 1286138
2008-02-13 17:48:34,959 ERROR org.apache.hadoop.hbase.HRegionServer: Cache flush failed for region webdb,com.geocities.www/Paris/1685/,1202919182718
java.lang.NullPointerException
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.close(DFSClient.java:2262)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:51)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:67)
        at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:932)
        at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:172)
        at org.apache.hadoop.hbase.HStore.internalFlushCache(HStore.java:1117)
        at org.apache.hadoop.hbase.HStore.flushCache(HStore.java:1081)
        at org.apache.hadoop.hbase.HRegion.internalFlushcache(HRegion.java:939)
        at org.apache.hadoop.hbase.HRegion.flushcache(HRegion.java:837)
        at org.apache.hadoop.hbase.HRegionServer$Flusher.run(HRegionServer.java:417)
2008-02-13 17:51:02,705 INFO org.apache.hadoop.hbase.HRegionServer: Rolling hlog. Number of entries: 30006
2008-02-13 17:52:07,221 INFO org.apache.hadoop.hbase.HRegion: starting compaction on region webdb,,1202919182716
2008-02-13 17:56:19,028 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region webdb,,1202919182716. Took 4mins, 11sec
2008-02-13 17:56:19,167 INFO org.apache.hadoop.hbase.HRegion: Splitting webdb,com.geocities.www/Paris/1685/,1202919182718 because largest aggregate siz
e is 264.7m and desired size is 256.0m
2008-02-13 17:57:36,060 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call batchUpdate(webdb,com.geocities.www/Paris/1685/,12029191
82718, 1202921443000, org.apache.hadoop.hbase.io.BatchUpdate@7262b6) from 10.2.3.34:43471: error: org.apache.hadoop.hbase.NotServingRegionException: we
bdb,com.geocities.www/Paris/1685/,1202919182718
org.apache.hadoop.hbase.NotServingRegionException: webdb,com.geocities.www/Paris/1685/,1202919182718
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1610)
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1582)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1431)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)
2008-02-13 17:57:46,082 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate(webdb,com.geocities.www/Paris/1685/,12029191
82718, 1202921443000, org.apache.hadoop.hbase.io.BatchUpdate@cac02f) from 10.2.3.34:43476: error: org.apache.hadoop.hbase.NotServingRegionException: we
bdb,com.geocities.www/Paris/1685/,1202919182718
org.apache.hadoop.hbase.NotServingRegionException: webdb,com.geocities.www/Paris/1685/,1202919182718
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1610)
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1582)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1431)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)

...

And so on.  The region has been offline for 2-3 hours now...so it's not a split that just taking too long.

I'm not much of a java developer, tho I'll attempt to dig into the code myself.  Please, any help here would really be appreciated. "
HBASE-411,"Currently, hadoop jar must be first on the CLASSPATH.  If its not found first, on startup we get complaint that the hadoop webapps can't be found.  Has to do w/ fact that the webapp is supposed to be in the jar thats doing the class loading (There was a fix up in core but needs fixup/cleanup)."
HBASE-177,"This error happened after a region tried to split before a complete compaction could be done on the region from the first split
I thank we should que up a compaction on loading of a region on a region server this should help keep this from happening but also we should have the split thread check to see if the region safe to split.


{code}
2008-01-30 00:07:34,250 ERROR org.apache.hadoop.hbase.HRegionServer: Split failed for region webdata,,1201671207519
java.io.FileNotFoundException: File hdfs://10.0.0.1:9000/gfs_storage/hadoop-root/hbase/webdata/1080614411/size/mapfiles/5351268197296217146/data does not exist.
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:341)
        at org.apache.hadoop.hbase.HStoreFile.length(HStoreFile.java:456)
        at org.apache.hadoop.hbase.HStore.loadHStoreFiles(HStore.java:876)
        at org.apache.hadoop.hbase.HStore.<init>(HStore.java:731)
        at org.apache.hadoop.hbase.HRegion.<init>(HRegion.java:286)
        at org.apache.hadoop.hbase.HRegion.splitRegion(HRegion.java:597)
        at org.apache.hadoop.hbase.HRegionServer$Splitter.split(HRegionServer.java:303)
        at org.apache.hadoop.hbase.HRegionServer$Splitter.run(HRegionServer.java:263)
{code}"
HBASE-692,"I see two tables of same name in an hbase instance.  The first was made with column familes 1, 2, 3.  I then dropped that table and made a new one with column family 4.  I notice now -- or rather Jim Firby noticed --  that two tables are showing in the UI, both named the same; one with familes 1, 2, and 3 with the other showing column family 4.

Scanning etc., seems to work properly.  Looking on disk, I see one subdir named for the table with all column families under it.

Haven't tried to reproduce."
HBASE-634,"On our internal cluster, noticed hung regionserver.  Hang manifest itself in log as thousands of lines of:

{code}
Call queue overflow discarding oldest call batchUpdate
{code}

Thread dumping, a bunch of threads are waiting to append to HLog:

{code}
     41 ""IPC Server handler 8 on 60020"" daemon prio=1 tid=0x00002aab40226770 nid=0x3890 waiting for monitor entry [0x0000000042d7d000..0x0000000042d7db00]
     42         at org.apache.hadoop.hbase.HLog.append(HLog.java:370)
     43         - waiting to lock <0x00002aaab7815d38> (a java.lang.Integer)
     44         at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1624)
     45         at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1427)
     46         at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1554)
     47         at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
     48         at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
     49         at java.lang.reflect.Method.invoke(Unknown Source)
     50         at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
     51         at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)
{code}

... but they can't because another thread is stuck trying to write the HLog:

{code}
     16 ""IPC Server handler 9 on 60020"" daemon prio=1 tid=0x00002aab402278d0 nid=0x3891 in Object.wait() [0x0000000042e7e000..0x0000000042e7eb80]
     17         at java.lang.Object.wait(Native Method)
     18         at java.lang.Object.wait(Unknown Source)
     19         at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:2131)
     20         - locked <0x00002aaab7ee5038> (a java.util.LinkedList)
     21         at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:141)
     22         at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:100)
     23         at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:86)
     24         - locked <0x00002aaab7ee4cb0> (a org.apache.hadoop.dfs.DFSClient$DFSOutputStream)
     25         at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:41)
     26         at java.io.DataOutputStream.write(Unknown Source)
     27         - locked <0x00002aaab7e73ea8> (a org.apache.hadoop.fs.FSDataOutputStream)
     28         at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:990)
     29         - locked <0x00002aaab7ee5200> (a org.apache.hadoop.io.SequenceFile$Writer)
     30         at org.apache.hadoop.hbase.HLog.append(HLog.java:387)
     31         - locked <0x00002aaab7815d38> (a java.lang.Integer)
     32         at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1624)
     33         at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1427)
     34         at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1554)
     35         at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
     36         at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
     37         at java.lang.reflect.Method.invoke(Unknown Source)
     38         at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
     39         at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)
{code}

Looking in code, the above sleep will be woken when we get response from datanode -- a response that never comes in this case.  The Responder thread itself is stuck trying to read a long from the datanode:

{code}
      3 ""ResponseProcessor for block blk_3392187502501092232"" daemon prio=1 tid=0x00002aab38cd8ba0 nid=0x7700 runnable [0x0000000043080000..0x0000000043080c80]
      4         at java.net.SocketInputStream.socketRead0(Native Method)
      5         at java.net.SocketInputStream.read(Unknown Source)
      6         at java.io.DataInputStream.readFully(Unknown Source)
      7         at java.io.DataInputStream.readLong(Unknown Source)
      8         at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:1734)
{code}

Related is the DFSClient DataStreamer, itself is in a sleep

{code}
     10 ""DataStreamer for file /hbase/aa0-005-2.u.powerset.com/log_208.76.44.96_1211224091595_60020/hlog.dat.004"" daemon prio=1 tid=0x00002aab38a34920 nid=0x6e1b in Object.wait() [0x0000000043484000..0x0000000043484b00]
     11         at java.lang.Object.wait(Native Method)
     12         at java.lang.Object.wait(Unknown Source)
     13         at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1656)
     14         - locked <0x00002aaab7ee5060> (a java.util.LinkedList)
{code}

The hang doesn't change after 5 or 6 thread dumps nor does it change though I shutdown the regionserver.

Would need to figure why the datanode stopped responding, why we haven't timedout our read at least."
HBASE-386,All regression tests should close any open HTables to speed up test exit.
HBASE-155,hbase.Leases has problems with concurrency because it's data structures are not volatile. Changing them so the are makes leases more reliable.
HBASE-21722,submit-patch.py now requries the future module
HBASE-9559,"See also HBASE-9503. Unless I'm missing something, getRowKeyAtOrBefore does not handle cross-file deletes correctly. It also doesn't handle timestamps between two candidates of the same row if they are in different file (latest by ts is going to be returned).
It is only used for meta, so it might be working due to low update rate, lack of anomalies and the fact that row values in meta are reasonably persistent, new ones are only added in split."
HBASE-15355,"After [HBASE-10569|https://issues.apache.org/jira/browse/HBASE-10569], master is also a regionserver and it will serve regions of system tables. The meta region info could be viewed on master at the address such as : http://localhost:16010/region.jsp?name=1588230740. The real path of region.jsp for the request will be hbase-webapps/master/region.jsp on master, however, the region.jsp is under the directory hbase-webapps/regionserver, so that can not be found on master."
HBASE-13676,"{noformat}
Running org.apache.hadoop.hbase.regionserver.TestRegionServerHostname
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 14.543 sec <<< FAILURE! - in org.apache.hadoop.hbase.regionserver.TestRegionServerHostname
testInvalidRegionServerHostnameAbortsServer(org.apache.hadoop.hbase.regionserver.TestRegionServerHostname)  Time elapsed: 6.845 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.testInvalidRegionServerHostnameAbortsServer(TestRegionServerHostname.java:57)


Results :

Failed tests: 
  TestRegionServerHostname.testInvalidRegionServerHostnameAbortsServer:57 null
{noformat}

The exception message is not what the test expects. We want a string containing ""Failed resolve of "" + invalidHostname. What I have is ""java.net.BindException: Problem binding to hostAddr.invalid/198.105.244.228:0 : Cannot assign requested address."" 

This is because my ISP is ""helpfully"" providing A records for invalid hostnames.

{noformat}
apurtell@aspire ~ $ dig hostAddr.invalid

; <<>> DiG 9.9.5-3ubuntu0.2-Ubuntu <<>> hostAddr.invalid
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 49027
;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;hostAddr.invalid.		IN	A

;; ANSWER SECTION:
hostAddr.invalid.	10	IN	A	198.105.244.228
hostAddr.invalid.	10	IN	A	198.105.254.228

;; Query time: 27 msec
;; SERVER: 127.0.1.1#53(127.0.1.1)
;; WHEN: Tue May 12 13:34:21 PDT 2015
;; MSG SIZE  rcvd: 66
{noformat}

The test should be made more general to capture this kind of failure too.
"
HBASE-12154,"It doesn't make sense to run a load test on a shared box where other tests are being run. We should probably move this to integration tests and make sure its covered. In cases where the jenkins machines are shared across several projects which are doing disk IO, I have observed that this test runs into slow syncs and eventually times out. And that being said, we can't increase the timeout on this test, since its already 3 minutes. This test being disk sensitive, might have better coverage on IT."
HBASE-11087,"If you try to import eclipse you will get some import errors about maven plugins. [1] So, in order to avoid the exceptions in Eclipse, looks like one needs to simply enclose all the plugin tags inside a <pluginManagement> tag. I create a patch for this problem. 

[1] http://mail-archives.apache.org/mod_mbox/hbase-dev/201404.mbox/%3CCAEz%2Byv-hMdjpue91TSh%2B1YdGW8oqo5TXPeH09Y4dntvtPro2bQ%40mail.gmail.com%3E"
HBASE-10977,"On our internal rig, ran into this failure:

{code}
java.lang.AssertionError: expected:<2> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.doQuarantineTest(TestHBaseFsck.java:1737)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testQuarantineMissingHFile(TestHBaseFsck.java:1781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}

This is what is failing:

      assertEquals(hfcc.getMissing().size(), missing);

The file remove has not run yet or, else, this complaint is related:

{code}
2014-04-12 23:24:57,638 WARN  [IPC Server handler 4 on 50919] security.UserGroupInformation(1551): PriviledgedActionException as:jenkins (auth:SIMPLE) cause:java.io.FileNotFoundException: File does not exist: /user/jenkins/hbase/data/default/testQuarantineMissingHFile/63cdcba1fc55ae6463463ae16f4e454e/fam/57a07eaac97e4acd8dc04e08d1950adc
{code}

Below is full log.  Will come back and add logging....

{code}
Regression

org.apache.hadoop.hbase.util.TestHBaseFsck.testQuarantineMissingHFile

Failing for the past 1 build (Since Failed#3 )
Took 10 ms.
add description
Error Message

expected:<2> but was:<1>
Stacktrace

java.lang.AssertionError: expected:<2> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.doQuarantineTest(TestHBaseFsck.java:1737)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testQuarantineMissingHFile(TestHBaseFsck.java:1781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Standard Output

Allow checking/fixes for table: testQuarantineMissingHFile
Checked 4 hfile for corruption
  HFiles corrupted:                  0
    HFiles successfully quarantined: 0
    HFiles failed quarantine:        0
    HFiles moved while checking:     2
      hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/63cdcba1fc55ae6463463ae16f4e454e/fam/57a07eaac97e4acd8dc04e08d1950adc
      hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/d383980be98665b638fd56bfac97a351/fam/9dd79f30f29e4cfeaa46f6e20b32e078
Summary: OK => OK
Version: 0.96.1.1-cdh5.0.1-SNAPSHOT
---- Table 'testQuarantineMissingHFile': region split map
:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/63cdcba1fc55ae6463463ae16f4e454e, deployed =>  }, A]	
A:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/a8a68d998d21b00499aca60887ae5aef, deployed =>  }, B]	
B:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/d383980be98665b638fd56bfac97a351, deployed =>  }, C]	
C:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/f9c185520bca999a753ee3ce0a244f6d, deployed =>  }, ]	
null:	
---- Table 'testQuarantineMissingHFile': overlap groups
There are 0 overlap groups with 0 overlapping regions
---- Table 'hbase:meta': region split map
:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/hbase/meta/1588230740, deployed =>  }, ]	
null:	
---- Table 'hbase:meta': overlap groups
There are 0 overlap groups with 0 overlapping regions
Number of live region servers: 3
  p0419.mtv.cloudera.com,41017,1397370264982
  p0419.mtv.cloudera.com,39010,1397370264935
  p0419.mtv.cloudera.com,32877,1397370265023
Number of dead region servers: 0
Master: p0419.mtv.cloudera.com,33001,1397370264247
Number of backup masters: 0
Average load: 2.0
Number of requests: 655
Number of regions: 6
Number of regions in transition: 0
RegionServer: p0419.mtv.cloudera.com,32877,1397370265023 number of regions: 0
RegionServer: p0419.mtv.cloudera.com,39010,1397370264935 number of regions: 0
RegionServer: p0419.mtv.cloudera.com,41017,1397370264982 number of regions: 1
  hbase:meta,,1.1588230740 id: 1 encoded_name: 1588230740 start:  end: 
Number of empty REGIONINFO_QUALIFIER rows in hbase:meta: 0
Number of Tables: 0
Number of Tables in flux: 1
---- Table 'hbase:meta': region split map
:	[ { meta => hbase:meta,,1.1588230740, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/hbase/meta/1588230740, deployed => p0419.mtv.cloudera.com,41017,1397370264982;hbase:meta,,1.1588230740 }, ]	
null:	
---- Table 'hbase:meta': overlap groups
There are 0 overlap groups with 0 overlapping regions
Summary:
  testQuarantineMissingHFile is okay.
    Number of regions: 0
    Deployed on: 
  hbase:meta is okay.
    Number of regions: 1
    Deployed on:  p0419.mtv.cloudera.com,41017,1397370264982
0 inconsistencies detected.
Status: OK
Standard Error

2014-04-12 23:24:54,802 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: util.TestHBaseFsck#testQuarantineMissingHFile Thread=410, OpenFileDescriptor=691, MaxFileDescriptor=32768, SystemLoadAverage=422, ProcessCount=485, AvailableMemoryMB=3139, ConnectionCount=5
2014-04-12 23:24:54,809 INFO  [RpcServer.handler=0,port=33001] master.HMaster(1748): Client=jenkins//172.29.122.11 create 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2014-04-12 23:24:54,886 DEBUG [RpcServer.handler=0,port=33001] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/testQuarantineMissingHFile/write-master:330010000000000
2014-04-12 23:24:54,960 INFO  [MASTER_TABLE_OPERATIONS-p0419:33001-0] handler.CreateTableHandler(148): Create table testQuarantineMissingHFile
2014-04-12 23:24:55,060 INFO  [IPC Server handler 6 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,061 INFO  [IPC Server handler 3 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,062 INFO  [IPC Server handler 5 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741867_1043 size 305
2014-04-12 23:24:55,185 DEBUG [MASTER_TABLE_OPERATIONS-p0419:33001-0] util.FSTableDescriptors(640): Wrote descriptor into: hdfs://localhost:50919/user/jenkins/hbase/.tmp/data/default/testQuarantineMissingHFile/.tabledesc/.tableinfo.0000000001
2014-04-12 23:24:55,188 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(3969): creating HRegion testQuarantineMissingHFile HTD == 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://localhost:50919/user/jenkins/hbase/.tmp Table name == testQuarantineMissingHFile
2014-04-12 23:24:55,188 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(3969): creating HRegion testQuarantineMissingHFile HTD == 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://localhost:50919/user/jenkins/hbase/.tmp Table name == testQuarantineMissingHFile
2014-04-12 23:24:55,188 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(3969): creating HRegion testQuarantineMissingHFile HTD == 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://localhost:50919/user/jenkins/hbase/.tmp Table name == testQuarantineMissingHFile
2014-04-12 23:24:55,188 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(3969): creating HRegion testQuarantineMissingHFile HTD == 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://localhost:50919/user/jenkins/hbase/.tmp Table name == testQuarantineMissingHFile
2014-04-12 23:24:55,378 INFO  [IPC Server handler 2 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,379 INFO  [IPC Server handler 0 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,379 INFO  [IPC Server handler 1 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,386 INFO  [IPC Server handler 9 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,387 INFO  [IPC Server handler 2 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,388 INFO  [IPC Server handler 1 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741868_1044 size 61
2014-04-12 23:24:55,410 INFO  [IPC Server handler 9 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,410 INFO  [IPC Server handler 2 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,411 INFO  [IPC Server handler 4 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741871_1047 size 61
2014-04-12 23:24:55,418 INFO  [IPC Server handler 8 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,418 INFO  [IPC Server handler 9 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,419 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,419 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(988): Closing testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.: disabling compactions & flushes
2014-04-12 23:24:55,419 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(1010): Updates disabled for region testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,419 INFO  [IPC Server handler 4 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741870_1046 size 60
2014-04-12 23:24:55,419 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(1068): Closed testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,458 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.
2014-04-12 23:24:55,458 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,459 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(988): Closing testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.: disabling compactions & flushes
2014-04-12 23:24:55,459 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(988): Closing testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.: disabling compactions & flushes
2014-04-12 23:24:55,459 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(1010): Updates disabled for region testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.
2014-04-12 23:24:55,459 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(1010): Updates disabled for region testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,459 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(1068): Closed testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.
2014-04-12 23:24:55,459 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(1068): Closed testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,460 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.
2014-04-12 23:24:55,461 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(988): Closing testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.: disabling compactions & flushes
2014-04-12 23:24:55,461 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(1010): Updates disabled for region testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.
2014-04-12 23:24:55,461 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(1068): Closed testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.
2014-04-12 23:24:55,502 INFO  [MASTER_TABLE_OPERATIONS-p0419:33001-0] catalog.MetaEditor(278): Added 4
2014-04-12 23:24:55,503 INFO  [MASTER_TABLE_OPERATIONS-p0419:33001-0] master.AssignmentManager(2506): Bulk assigning 4 region(s) across 3 server(s), round-robin=true
2014-04-12 23:24:55,503 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] master.AssignmentManager(1451): Assigning 1 region(s) to p0419.mtv.cloudera.com,32877,1397370265023
2014-04-12 23:24:55,503 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] master.AssignmentManager(1451): Assigning 1 region(s) to p0419.mtv.cloudera.com,39010,1397370264935
2014-04-12 23:24:55,503 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.AssignmentManager(1451): Assigning 2 region(s) to p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,504 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] zookeeper.ZKAssign(175): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Async create of unassigned node a8a68d998d21b00499aca60887ae5aef with OFFLINE state
2014-04-12 23:24:55,504 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] zookeeper.ZKAssign(175): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Async create of unassigned node d383980be98665b638fd56bfac97a351 with OFFLINE state
2014-04-12 23:24:55,503 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] zookeeper.ZKAssign(175): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Async create of unassigned node 63cdcba1fc55ae6463463ae16f4e454e with OFFLINE state
2014-04-12 23:24:55,503 DEBUG [MASTER_TABLE_OPERATIONS-p0419:33001-0] master.GeneralBulkAssigner(177): Timeout-on-RIT=152000
2014-04-12 23:24:55,504 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] zookeeper.ZKAssign(175): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Async create of unassigned node f9c185520bca999a753ee3ce0a244f6d with OFFLINE state
2014-04-12 23:24:55,510 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(310): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2014-04-12 23:24:55,510 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback(69): rs={a8a68d998d21b00499aca60887ae5aef state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,39010,1397370264935
2014-04-12 23:24:55,511 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback(69): rs={d383980be98665b638fd56bfac97a351 state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,518 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback(69): rs={63cdcba1fc55ae6463463ae16f4e454e state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,32877,1397370265023
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback(69): rs={f9c185520bca999a753ee3ce0a244f6d state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback$ExistCallback(106): rs={a8a68d998d21b00499aca60887ae5aef state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,39010,1397370264935
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback$ExistCallback(106): rs={d383980be98665b638fd56bfac97a351 state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,519 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] master.AssignmentManager(1502): p0419.mtv.cloudera.com,39010,1397370264935 unassigned znodes=1 of total=1
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback$ExistCallback(106): rs={63cdcba1fc55ae6463463ae16f4e454e state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,32877,1397370265023
2014-04-12 23:24:55,519 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] master.RegionStates(316): Transitioned {a8a68d998d21b00499aca60887ae5aef state=OFFLINE, ts=1397370295504, server=null} to {a8a68d998d21b00499aca60887ae5aef state=PENDING_OPEN, ts=1397370295519, server=p0419.mtv.cloudera.com,39010,1397370264935}
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback$ExistCallback(106): rs={f9c185520bca999a753ee3ce0a244f6d state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,519 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] master.AssignmentManager(1502): p0419.mtv.cloudera.com,32877,1397370265023 unassigned znodes=1 of total=1
2014-04-12 23:24:55,520 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.AssignmentManager(1502): p0419.mtv.cloudera.com,41017,1397370264982 unassigned znodes=2 of total=2
2014-04-12 23:24:55,520 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] master.RegionStates(316): Transitioned {63cdcba1fc55ae6463463ae16f4e454e state=OFFLINE, ts=1397370295503, server=null} to {63cdcba1fc55ae6463463ae16f4e454e state=PENDING_OPEN, ts=1397370295520, server=p0419.mtv.cloudera.com,32877,1397370265023}
2014-04-12 23:24:55,520 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.RegionStates(316): Transitioned {d383980be98665b638fd56bfac97a351 state=OFFLINE, ts=1397370295504, server=null} to {d383980be98665b638fd56bfac97a351 state=PENDING_OPEN, ts=1397370295520, server=p0419.mtv.cloudera.com,41017,1397370264982}
2014-04-12 23:24:55,520 INFO  [Priority.RpcServer.handler=1,port=39010] regionserver.HRegionServer(3513): Open testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,520 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.RegionStates(316): Transitioned {f9c185520bca999a753ee3ce0a244f6d state=OFFLINE, ts=1397370295504, server=null} to {f9c185520bca999a753ee3ce0a244f6d state=PENDING_OPEN, ts=1397370295520, server=p0419.mtv.cloudera.com,41017,1397370264982}
2014-04-12 23:24:55,521 INFO  [Priority.RpcServer.handler=1,port=32877] regionserver.HRegionServer(3513): Open testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.
2014-04-12 23:24:55,521 INFO  [Priority.RpcServer.handler=1,port=41017] regionserver.HRegionServer(3513): Open testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,525 DEBUG [RS_OPEN_REGION-p0419:39010-1] zookeeper.ZKAssign(832): regionserver:39010-0x14559c215740001, quorum=localhost:53570, baseZNode=/hbase Transitioning a8a68d998d21b00499aca60887ae5aef from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,526 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] master.AssignmentManager(1626): Bulk assigning done for p0419.mtv.cloudera.com,39010,1397370264935
2014-04-12 23:24:55,526 DEBUG [RS_OPEN_REGION-p0419:41017-0] zookeeper.ZKAssign(832): regionserver:41017-0x14559c215740002, quorum=localhost:53570, baseZNode=/hbase Transitioning d383980be98665b638fd56bfac97a351 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,526 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] master.AssignmentManager(1626): Bulk assigning done for p0419.mtv.cloudera.com,32877,1397370265023
2014-04-12 23:24:55,526 INFO  [Priority.RpcServer.handler=1,port=41017] regionserver.HRegionServer(3513): Open testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.
2014-04-12 23:24:55,526 DEBUG [RS_OPEN_REGION-p0419:32877-0] zookeeper.ZKAssign(832): regionserver:32877-0x14559c215740003, quorum=localhost:53570, baseZNode=/hbase Transitioning 63cdcba1fc55ae6463463ae16f4e454e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,527 DEBUG [RS_OPEN_REGION-p0419:41017-2] zookeeper.ZKAssign(832): regionserver:41017-0x14559c215740002, quorum=localhost:53570, baseZNode=/hbase Transitioning f9c185520bca999a753ee3ce0a244f6d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,527 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.AssignmentManager(1626): Bulk assigning done for p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,527 DEBUG [MASTER_TABLE_OPERATIONS-p0419:33001-0] master.GeneralBulkAssigner(153): bulk assigning total 4 regions to 3 servers, took 23ms, with 4 regions still in transition
2014-04-12 23:24:55,527 INFO  [MASTER_TABLE_OPERATIONS-p0419:33001-0] master.AssignmentManager(2513): Bulk assigning done
2014-04-12 23:24:55,535 DEBUG [RS_OPEN_REGION-p0419:39010-1] zookeeper.ZKAssign(907): regionserver:39010-0x14559c215740001, quorum=localhost:53570, baseZNode=/hbase Transitioned node a8a68d998d21b00499aca60887ae5aef from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,535 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(310): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/a8a68d998d21b00499aca60887ae5aef
2014-04-12 23:24:55,536 DEBUG [RS_OPEN_REGION-p0419:39010-1] regionserver.HRegion(4153): Opening region: {ENCODED => a8a68d998d21b00499aca60887ae5aef, NAME => 'testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.', STARTKEY => 'A', ENDKEY => 'B'}
2014-04-12 23:24:55,536 DEBUG [RS_OPEN_REGION-p0419:39010-1] regionserver.MetricsRegionSourceImpl(64): Creating new MetricsRegionSourceImpl for table testQuarantineMissingHFile a8a68d998d21b00499aca60887ae5aef
2014-04-12 23:24:55,536 DEBUG [RS_OPEN_REGION-p0419:39010-1] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,577 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(310): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/d383980be98665b638fd56bfac97a351
2014-04-12 23:24:55,577 DEBUG [RS_OPEN_REGION-p0419:41017-0] zookeeper.ZKAssign(907): regionserver:41017-0x14559c215740002, quorum=localhost:53570, baseZNode=/hbase Transitioned node d383980be98665b638fd56bfac97a351 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,578 DEBUG [RS_OPEN_REGION-p0419:41017-0] regionserver.HRegion(4153): Opening region: {ENCODED => d383980be98665b638fd56bfac97a351, NAME => 'testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.', STARTKEY => 'B', ENDKEY => 'C'}
2014-04-12 23:24:55,578 DEBUG [RS_OPEN_REGION-p0419:41017-0] regionserver.MetricsRegionSourceImpl(64): Creating new MetricsRegionSourceImpl for table testQuarantineMissingHFile d383980be98665b638fd56bfac97a351
2014-04-12 23:24:55,579 DEBUG [RS_OPEN_REGION-p0419:41017-0] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,594 INFO  [StoreOpener-a8a68d998d21b00499aca60887ae5aef-1] compactions.CompactionConfiguration(85): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2014-04-12 23:24:55,598 DEBUG [RS_OPEN_REGION-p0419:39010-1] regionserver.HRegion(2822): Found 0 recovered edits file(s) under hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/a8a68d998d21b00499aca60887ae5aef
2014-04-12 23:24:55,600 INFO  [RS_OPEN_REGION-p0419:39010-1] regionserver.HRegion(637): Onlined a8a68d998d21b00499aca60887ae5aef; next sequenceid=1
2014-04-12 23:24:55,600 DEBUG [RS_OPEN_REGION-p0419:39010-1] zookeeper.ZKAssign(644): regionserver:39010-0x14559c215740001, quorum=localhost:53570, baseZNode=/hbase Attempting to retransition opening state of node a8a68d998d21b00499aca60887ae5aef
2014-04-12 23:24:55,644 INFO  [StoreOpener-d383980be98665b638fd56bfac97a351-1] compactions.CompactionConfiguration(85): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2014-04-12 23:24:55,648 DEBUG [RS_OPEN_REGION-p0419:41017-0] regionserver.HRegion(2822): Found 0 recovered edits file(s) under hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/d383980be98665b638fd56bfac97a351
2014-04-12 23:24:55,650 INFO  [RS_OPEN_REGION-p0419:41017-0] regionserver.HRegion(637): Onlined d383980be98665b638fd56bfac97a351; next sequenceid=1
2014-04-12 23:24:55,650 DEBUG [RS_OPEN_REGION-p0419:41017-"
,
HBASE-11829,"Test fails with an exception:
java.lang.Exception: Unexpected exception, expected<org.apache.hadoop.hbase.regionserver.RegionServerStoppedException> but was<junit.framework.AssertionFailedError>
	at org.junit.internal.runners.statements.ExpectException.evaluate(ExpectException.java:28)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)

Note: the failure usually reproduces on the machines where openvpn is installed. "
HBASE-21037,"In certain cases, hbck issues a RS.closeRegion() to close a region from RS. It does not clean up in-memory state from master for the offlined region and balancer will bring back the closed region, causing region inconsistency. certain codes needs to be reexamined to see a Master.offlineRegion() is needed."
HBASE-11653,"Due to a bug in {{HRegion.internalPut()}}, any modifications that a {{RegionObserver}} makes to a Put's family map in the {{prePut()}} hook are lost.

This prevents coprocessors from modifying the values written by a {{Put}}."
HBASE-19466,"I think we just need to increase the timeout interval to deal with occasional slowdowns on test executors. 1998 ms is a pretty short timeout.

By the way ""rpcTimetout"" in the exception message is a misspelling.

[ERROR] Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 37.412 s <<< FAILURE! - in org.apache.hadoop.hbase.regionserver.TestScannerCursor
[ERROR] testHeartbeatWithSparseFilter(org.apache.hadoop.hbase.regionserver.TestScannerCursor)  Time elapsed: 35.604 s  <<< ERROR!
org.apache.hadoop.hbase.client.RetriesExhaustedException: 
Failed after attempts=36, exceptions:
Thu Dec 07 22:27:16 UTC 2017, null, java.net.SocketTimeoutException: callTimeout=4000, callDuration=4108: Call to ip-172-31-47-35.us-west-2.compute.internal/172.31.47.35:35690 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=52, waitTime=2002, rpcTimetout=1998 row '' on table 'TestScannerCursor' at region=TestScannerCursor,,1512685598567.1d4e59215a881d6ccbd0b5b5bdec5587., hostname=ip-172-31-47-35.us-west-2.compute.internal,35690,1512685593244, seqNum=2

        at org.apache.hadoop.hbase.regionserver.TestScannerCursor.testHeartbeatWithSparseFilter(TestScannerCursor.java:154)
Caused by: java.net.SocketTimeoutException: callTimeout=4000, callDuration=4108: Call to ip-172-31-47-35.us-west-2.compute.internal/172.31.47.35:35690 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=52, waitTime=2002, rpcTimetout=1998 row '' on table 'TestScannerCursor' at region=TestScannerCursor,,1512685598567.1d4e59215a881d6ccbd0b5b5bdec5587., hostname=ip-172-31-47-35.us-west-2.compute.internal,35690,1512685593244, seqNum=2
Caused by: java.io.IOException: Call to ip-172-31-47-35.us-west-2.compute.internal/172.31.47.35:35690 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=52, waitTime=2002, rpcTimetout=1998
Caused by: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=52, waitTime=2002, rpcTimetout=1998
"
HBASE-18100,"https://builds.apache.org/job/HBASE-Flaky-Tests/lastCompletedBuild/testReport/org.apache.hadoop.hbase.client/TestBlockEvictionFromClient/testBlockRefCountAfterSplits/
{code}
java.lang.AssertionError: expected:<0> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.iterateBlockCache(TestBlockEvictionFromClient.java:1215)
	at org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.testBlockRefCountAfterSplits(TestBlockEvictionFromClient.java:607)
{code}
The test failed on May 16th as well."
HBASE-19854,"Many a times, users want to have an offline copy of Ref Guide.聽 Some people prefer to save HTML, and some people prefer it in PDF format.聽 Hence, Apache HBase team generates PDF version of document periodically and keeps it available at: [https://hbase.apache.org/apache_hbase_reference_guide.pdf]

It would be good if a link to this URL is available in the online guide so that users would become aware that there is a PDF version.聽 Right now, unless some one explicitly looks for it using Google/Bing search, they would not know.

聽

As the PDF URL is fixed for latest documentation, it can be a static href.聽 However, I don't have any clues about how to make sure to get ""version-relevant"" PDF link for archived ref guides.

聽"
HBASE-19662,"In recent trunk builds, there were the following errors:
{code}
[ERROR] src/main/java/org/apache/hadoop/hbase/metrics/MetricRegistriesLoader.java:[31] (imports) ImportOrder: Wrong order for 'org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting' import.
[ERROR] src/test/java/org/apache/hadoop/hbase/metrics/TestMetricRegistriesLoader.java:[28] (imports) ImportOrder: Wrong order for 'org.apache.hbase.thirdparty.com.google.common.collect.Lists' import.
{code}"
HBASE-18858,"{code}
  public static void tearDownAfterClass() throws Exception {
    htable2.close();
    htable1.close();
    admin.close();
    utility2.shutdownMiniCluster();
    utility1.shutdownMiniCluster();
  }
{code}
If the setUpBeforeClass() fail, some members will be NULL. We need to ensures all resources are closed at the end of tests."
HBASE-19161,"For system tables, if config 'hbase.systemtables.compacting.memstore.type' is not specified then code default 'NONE' is used which causes instantiation of DefaultMemStore class. That means for everyone to use  CompactingMemStore they need to specify this config value. Reversing it will help i.e. if user explicitly specifies 'hbase.systemtables.compacting.memstore.type' to 'NONE' then only DefaultMemStore class is used."
HBASE-19517,"When running test against hadoop-3, I observe the following:
{code}
org.apache.hadoop.hbase.zookeeper.TestZKMulti  Time elapsed: 1.327 sec  <<< ERROR!
java.lang.RuntimeException: Could not create  interface org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource Is the hadoop compatibility jar on the classpath?
	at org.apache.hadoop.hbase.zookeeper.TestZKMulti.setUpBeforeClass(TestZKMulti.java:71)
Caused by: java.util.ServiceConfigurationError: org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource: Provider org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl could not be instantiated
	at org.apache.hadoop.hbase.zookeeper.TestZKMulti.setUpBeforeClass(TestZKMulti.java:71)
Caused by: java.lang.NoClassDefFoundError: org/apache/commons/beanutils/DynaBean
	at org.apache.hadoop.hbase.zookeeper.TestZKMulti.setUpBeforeClass(TestZKMulti.java:71)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.beanutils.DynaBean
	at org.apache.hadoop.hbase.zookeeper.TestZKMulti.setUpBeforeClass(TestZKMulti.java:71)
{code}
I used hadoop-3.0 profile"
HBASE-18841,"If I run the below out of a built checkout, it fails unable to find the main in named LoadTestTool class:

./bin/hbase ltt

Ditto for:

./bin/hbase pe

The main classes are in *-test.jars which we do not include in our cached_classpath.txt file that is our trick for making stuff work in dev context.

Investigate."
HBASE-14242,"Flaked tests: 
org.apache.hadoop.hbase.security.access.TestAccessController.testMergeRegions(org.apache.hadoop.hbase.security.access.TestAccessController)
  Run 1: TestAccessController.testMergeRegions:687->SecureTestUtil.verifyAllowed:176->SecureTestUtil.verifyAllowed:168 Expected action to pass for user 'owner' but was denied
  Run 2: PASS

{noformat}
java.lang.AssertionError: Expected action to pass for user 'owner' but was denied
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.security.access.SecureTestUtil.verifyAllowed(SecureTestUtil.java:168)
	at org.apache.hadoop.hbase.security.access.SecureTestUtil.verifyAllowed(SecureTestUtil.java:176)
	at org.apache.hadoop.hbase.security.access.TestAccessController.testMergeRegions(TestAccessController.java:687)
{noformat}
"
HBASE-16137,"From stack:

""Lads. This patch makes for a new findbugs warning: https://builds.apache.org/job/PreCommit-HBASE-Build/2390/artifact/patchprocess/branch-findbugs-hbase-server-warnings.html
If you are good w/ the code, i can fix the findbugs warning... just say."""
HBASE-13944,"When using any DBE other than Prefix_Tree when the internal scanners seek to a key greater than the last key in the file, when we do scanner.getKeyValue() we get the last key in the file, whereas PrefixTree seeks to null.  This is a behaviour change.  May be in the actual scan case we may not end up in this scenario, need to check with a testcase.  But the test in TestSeekTo.testSeekTo() has a clear illustration of this problem. 
Will take this up after the current activities."
HBASE-4738,"Ambiguous invocations of varargs methods with non-varargs arguments relied on the compiler to implicitly cast the arguments to Object[]. Some compilers apparently do not make this implicit cast, but instead wrap the arguments in another Object[] causing them to be interpreted incorrectly."
HBASE-8249,"Provide a Context object for all the HBase API call, which contains the Row, CF, Region, RegionServer, RetryNumbers and LastPotentialExceptions"
HBASE-7903,Need to add configuration support for large rows/ scan prefetching for the hadoop hbase streaming. Modifications are in the TableInputFormat
HBASE-7732,"we found a bug in the latest HBase code which ""hfile.io.bytes.per.checksum"" does not take effect. Because we have never call HFile.getBytesPerChecksum()  when creating a HFile.

Fix this issue by calling the correct bytes/checksum (from HFile.getBytesPerChecksum) for HFile creating ?
"
HBASE-8467,"Add an API to blacklist a region server. The master should not assign any new regions to the blacklisted region server. This will help in Rolling Restart of HBase, where one can blacklist a regionserver, drain all the regions(which should be fast), restart the regionserver, assign the regions backs and then remove the region server from the blacklist"
HBASE-8223,"The RegionServer was performing a shutdown as it got YouAreDeadException. It closed the HLog and was waiting to close all the regions where it got stuck.

The reason region close is stuck because it's trying to obtain a lock which is occupied by the put op, which in turn is waiting for append to HLog to complete.

There is race condition here is between append/sync and HLog.close() work flow. 

Scenario:

Thread 1 => doing the append
Thread 2 => doing HregionServer shutdown

Timeline:

t1> 1: Verifies that LogSyncer is not shutting down and HLog is not closed and calls sync()
t2> 2: HRegionServer issued HLog.close()
t3> 2: In HLog.close(), it joins the LogSyncer thread, which signals all the threads waiting on syncDone and exits.
t4> 1: In sync, it sees that the sync has not complete until its txd, hence adds itself to the syncDone.await queue.

Note: at t4, it does not check whether the LogSyncer Thread is alive or not, which caused this hang."
HBASE-8371,"RegionException was derived from IOError to capture the backoff timeout,
information required by the thrift clients to reduce the load on the
overloaded region servers. The exception was derived from IOError to
make it compatible with thrift. When this change was ported to neptune,
it created a new dependency on the thrift package."
HBASE-13627,"Noticed while testing the 1.1.0RC0 bits. It seems we're issuing a redundant close RPC during shutdown. This results in a logging warning for each region.

{noformat}
2015-05-06 00:07:19,214 INFO  [RS:0;ndimiduk-apache-1-1-dist-6:56371] regionserver.HRegionServer: Received CLOSE for the region: 19cbe4fe2fe5335e7aace05e10e36ede, which we are already trying to CLOSE, but not completed yet
2015-05-06 00:07:19,214 WARN  [RS:0;ndimiduk-apache-1-1-dist-6:56371] regionserver.HRegionServer: Failed to close cluster_test,66666666,1430869443384.19cbe4fe2fe5335e7aace05e10e36ede. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 19cbe4fe2fe5335e7aace05e10e36ede was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2769)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2695)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2327)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:937)
	at java.lang.Thread.run(Thread.java:745)
{noformat}

1. launch a standalone cluster from tgz (./bin/start-hbase.sh)
2. load some data (ie, run bin/hbase ltt)
3. terminate cluster (./bin/stop-hbase.sh)"
HBASE-9764,"In PerformanceEvaluation, htable AutoFlush option is hardcoded as false

{code:title=PerformanceEvaluation.java|borderStyle=solid}

    void testSetup() throws IOException {
      this.admin = new HBaseAdmin(conf);
      this.table = new HTable(conf, tableName);
      this.table.setAutoFlush(false);
      this.table.setScannerCaching(30);
    }
{code}
This makes the write performace unreal. 

Should we add an autoflush option in PerformanceEvaluation?"
HBASE-10540,"{code}
public void createTable(final HTableDescriptor desc, byte [][] splitKeys)
  throws IOException {
    HTableDescriptor.isLegalTableName(desc.getName());
    try {
      createTableAsync(desc, splitKeys);
    } catch (SocketTimeoutException ste) {
      LOG.warn(""Creating "" + desc.getNameAsString() + "" took too long"", ste);
    }
{code}
crateTable calls isLegalTableName and few lines after, createTableAsync. However, createTableAsync also calls isLegalTableName which results to a double call.

Therefor, we can remove the call to isLegalTableName from crateTable.
Trunk does'nt call isLegalTableName (Should it?).  Nor is 0.96.
"
HBASE-7456,"Please allow the Configuration to override the hard-coded maxSize of 10 for its HTablePool.  Under high loads, 10 is too small."
HBASE-10145,"HBASE-7600 fixed a race condition where concurrent attempts to create the same table could succeed.
An unfortunate side effect is that it is now impossible to create a table as long as the table's znode is around, which is an issue when a cluster was wiped at the HDFS level.

Minor issue as we have discussed this many times before, but it ought to be possible to check whether the table directory exists and if not either create it or remove the corresponding znode."
HBASE-14609,"The offpeak hours is [startHour, endHour) and endhour is exclusive. But endHour is not valid when config as 24, so we can't config all day as OffPeakHours.
{code}
  private static boolean isValidHour(int hour) {
    return 0 <= hour && hour <= 23; 
  }
{code}
Let endHour=24 is valid or  enable startHour==endHour can fix this."
HBASE-16295,"The column family exists and is actually deleted, the regions are also reopened. But, the following exception is thrown in the shell:

{code}
alter 't1', 'delete' => 'cf'

ERROR: org.apache.hadoop.hbase.InvalidFamilyOperationException: Family 'cf' does not exist, so it cannot be deleted
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)
	at org.apache.hadoop.hbase.util.ForeignExceptionUtil.toIOException(ForeignExceptionUtil.java:45)
	at org.apache.hadoop.hbase.procedure2.RemoteProcedureException.fromProto(RemoteProcedureException.java:114)
	at org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.waitForProcedureToComplete(ProcedureSyncWait.java:85)
	at org.apache.hadoop.hbase.master.HMaster.deleteColumn(HMaster.java:1916)
	at org.apache.hadoop.hbase.master.MasterRpcServices.deleteColumn(MasterRpcServices.java:474)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:55658)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2170)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:137)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:112)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hbase.InvalidFamilyOperationException): Family 'cf' does not exist, so it cannot be deleted
	at org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.prepareDelete(DeleteColumnFamilyProcedure.java:281)
	at org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.executeFromState(DeleteColumnFamilyProcedure.java:93)
	at org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.executeFromState(DeleteColumnFamilyProcedure.java:48)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:119)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:465)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1061)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:856)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:809)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$400(ProcedureExecutor.java:75)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$2.run(ProcedureExecutor.java:495)
{code}"
HBASE-6675,"On trunk, as of today:

Running org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 652.393 sec

Target beeing less than 3 minutes."
HBASE-5024,"There is no cleanup function in hbase.io.hfile.CacheConfig. The cache is a singleton, shared by all cluster if we launch more than one cluster on a test.

Related code is:

{noformat}
  /**
   * Static reference to the block cache, or null if no caching should be used
   * at all.
   */
  private static BlockCache globalBlockCache;

  /** Boolean whether we have disabled the block cache entirely. */
  private static boolean blockCacheDisabled = false;

  /**
   * Returns the block cache or <code>null</code> in case none should be used.
   *
   * @param conf  The current configuration.
   * @return The block cache or <code>null</code>.
   */
  private static synchronized BlockCache instantiateBlockCache(){
     // initiate globalBlockCache
{noformat}


"
HBASE-4947,"Using CopyTable with two clusters, test01 and test02.

cluster cluster01 has a table called 'table' which has a little bit of data in it.
cluster cluster02 has a table called 'table2' which have the same schema as cluster01's 'table'

Here's the command line used from a machine in cluster01
{code}
$ hbase org.apache.hadoop.hbase.mapreduce.CopyTable --peer.adr=cluster02:2181:/hbase --new.name=table2 table
{code}

Job succeeds, but gives a scary extraneous warning:
{code}
11/12/04 10:26:10 WARN client.HConnectionManager$HConnectionImplementation: Encountered problems when prefetch META table:
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in .META. for table: table2, row=table2,,99999999999999
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:136)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:95)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:649)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:703)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:594)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:559)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:173)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:147)
        at org.apache.hadoop.hbase.mapreduce.TableOutputFormat.setConf(TableOutputFormat.java:198)
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:869)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:833)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Unknown Source)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1127)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:833)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:476)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:506)
        at org.apache.hadoop.hbase.mapreduce.CopyTable.main(CopyTable.java:201)
11/12/04 10:26:10 ERROR mapreduce.TableOutputFormat: org.apache.hadoop.hbase.TableNotFoundException: table2
{code}
"
HBASE-14276,"If an insecure client contacts a secure cluster we can get an NPE when setting up the stub for the master connection. We should throw an IOException with a clear message, and not retry if possible to distinguish this case.

Found in 0.98 but might be relevant for later branches

{noformat}
Aug 20, 2015 12:04:31 AM org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper <init>
INFO: Process identifier=hconnection-0x3c1e23ff connecting to ZooKeeper ensemble=x.x.x.x:2181,x.x.x.x:2181,x.x.x.x:2181
Aug 20, 2015 12:04:31 AM org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation makeStub
INFO: getMaster attempt 1 of 35 failed; retrying after sleep of 100, exception=com.google.protobuf.ServiceException: java.lang.NullPointerException
Aug 20, 2015 12:04:31 AM org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation makeStub
INFO: getMaster attempt 2 of 35 failed; retrying after sleep of 200, exception=com.google.protobuf.ServiceException: java.io.IOException: Call to xxxx/x.x.x.x:60000 failed on local exception: java.io.EOFException
Aug 20, 2015 12:04:31 AM org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation makeStub
{noformat}"
HBASE-14792,"For releasing 0.98 we typically copy back the latest docs from master and then build.

When I try generating the latest docs, I get:
{noformat}
[INFO] >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[INFO] Forking Apache HBase - Assembly 0.98.16-hadoop2
[INFO] >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[INFO] 
[INFO] --- maven-enforcer-plugin:1.0.1:enforce (enforce) @ hbase-assembly ---
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.3:create-timestamp (default) @ hbase-assembly ---
[INFO] 
[INFO] <<< maven-javadoc-plugin:2.9.1:aggregate (report:aggregate) < generate-sources @ hbase <<<
[INFO] configuring report plugin org.apache.maven.plugins:maven-checkstyle-plugin:2.13
[INFO] Parent project loaded from repository: org.apache:apache:pom:12
[INFO] Relativizing decoration links with respect to project URL: http://hbase.apache.org
[INFO] Rendering site with org.apache.maven.skins:maven-fluido-skin:jar:1.4 skin.
[INFO] Skipped ""About"" report, file ""index.html"" already exists for the English version.
[INFO] Skipped ""Source Xref"" report, file ""xref/index.html"" already exists for the English version.
[INFO] Skipped ""Test Source Xref"" report, file ""xref-test/index.html"" already exists for the English version.
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.3:site (default-site) on project hbase: Error during page generation: Could not find the template 'META-INF/maven/site.vm: Encountered ""source"" at META-INF/maven/site.vm[line 1162, column 52]
[ERROR] Was expecting one of:
[ERROR] "","" ...
[ERROR] "")"" ...
[ERROR] <WHITESPACE> ...
{noformat}

Do I need to make POM updates?"
HBASE-11441,"jenkinsEnv paths are off.

We moved to jdk1.7 for master branch.  Though we'd set hadoopqa to run with java 1.7, the jenkinsEnv overrides what jenkins sets for JAVA_HOME so we've been running 1.6 java over this last couple of months rather than 1.7.

Trying to work around jenkinsEnv settings reveals that there is no 1.7 at the location jenkins goes to find it at (""Latest JDK 7"" option):

{code}
ls: cannot access /home/hudson/tools/java/latest1.7/..: No such file or directory
{code}

Messing w/ the options in the jenkins UI and then putting script in text box to expose paths, almost none of the advertised options are available.

Something changed.

I got a 1.7 working by setting jdk7-u51 explicitly and then setting PATH and JAVA_HOME just before our test script runs (it downloaded it)
{code}
...
ls $JAVA_HOME/..
which java
java -version
echo $JAVA_HOME
saveJavaHome=$JAVA_HOME
$JAVA_HOME/bin/java -version
ulimit -a
set +x
source ${WORKSPACE}/dev-support/jenkinsEnv.sh
export JAVA_HOME=""$saveJavaHome""
export PATH=$JAVA_HOME/bin:$PATH
which java
java -version
echo ""Resetting java_home -- FIX jenkinsEnv.sh!!! $JAVA_HOME""
....
{code}

HBase builds on hadoop1||hadoop2||hadoop3||hadoop8

I ain't sure how this stuff is supposed to be set.  Asking Andrew Bayer on our end (He said 'credits' needed refresh last night but that doesn't seem to have helped here)."
HBASE-12855,"IntegrationTestsDriver gets unhappy if you pass in ChaosMonkey options via -m:
{code}
sudo -u hbase hbase org.apache.hadoop.hbase.IntegrationTestsDriver -r 'IntegrationTestIngest$' -m calm
15/01/14 06:44:06 ERROR util.AbstractHBaseTool: Error when parsing command-line arguemnts
org.apache.commons.cli.UnrecognizedOptionException: Unrecognized option: -m
	at org.apache.commons.cli.Parser.processOption(Parser.java:363)
	at org.apache.commons.cli.Parser.parse(Parser.java:199)
	at org.apache.commons.cli.Parser.parse(Parser.java:85)
	at org.apache.hadoop.hbase.util.AbstractHBaseTool.parseArgs(AbstractHBaseTool.java:135)
	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:94)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.hbase.IntegrationTestsDriver.main(IntegrationTestsDriver.java:46)
usage: bin/hbase org.apache.hadoop.hbase.IntegrationTestsDriver <options>
Options:
 -h,--help          Show usage
 -r,--regex <arg>   Java regex to use selecting tests to run: e.g. .*TestBig.*
                    will select all tests that include TestBig in their name.
                    Default: .*IntegrationTest.*
{code}"
HBASE-7010,"Currently a PrefixFilter will happily scan all KVs < prefix.
If should seek forward to the prefix if the current KV < prefix."
HBASE-9876,"The main benefit brought by HBASE-4285 was removing the dependency on a symlink. Instead, it sets the partitions file path explicitly. Would be nice to have on 0.94.

(cc [~alexandre.normand])"
HBASE-15790,"When a user different than ""hbase"" bulkload files, in general we end up with files owned by a user different than hbase. sometimes this causes problems with hbase not be able to move files around archiving/deleting.

A simple solution is probably to change the ownership of the files to ""hbase"" during bulkload."
HBASE-14279,"{{ConcurrentIndex.put}} and {{remove}} are in race condition. It is possible to remove a non-empty set, and to add a value to a removed set. Also {{ConcurrentIndex.values}} is vague in sense that the returned set sometimes trace the current state and sometimes doesn't.
"
HBASE-12733,"When ingesting with the WAL bypassed, the RegionServer will log the following at every flush:
{noformat}
2014-12-19 16:58:24,630 WARN  [MemStoreFlusher.0] wal.FSHLog: Couldn't find oldest seqNum for the region we are about to flush: [86fc8c1374ebc29cc4a39a78966d48e0]
{noformat}

The WAL won't find a seqnum for the region until the first edit which does not bypass the WAL. That might not be for hundreds or thousands of flushes. This shouldn't be at WARN level since ingest with WAL bypass is legal if a bit unusual. It's concerning that the FSHLog code that emits that warning has a TODO above suggesting the warning should instead be an assertion."
HBASE-11299,"Our javadoc generation is taking a long time.  Also, when we go to update our site, the javadoc changes are so many -- the date has changed on generated doc -- that it takes for ever to commit (it is frighteningly long and noobs can only think they've done something wrong).

I have been trying various tricks to get javadoc tool to ignore the generated protobuf classes but am not having much success (it is a background process and the distractions don't help).  Stashing here changes I have so far to the javadoc pom which excludes some of the unneeded files."
HBASE-10578,"When multiple scanners have the same KV, HBase should pick the ""newest"" one.
i.e. pick the KV from the store file with the largest seq id.

In the KeyValueHeap generalizedSeek implementation, we seem to prefer the ""current""
scanner over the scanners in the heap -- THIS IS WRONG.

The diff adds a unit test to make sure that bulk loads correctly. And fixes the issue."
HBASE-11528,"We take a snapshot: ""rollbackSnapshot"" prior to doing a restore such that if the restore fails we can revert the table back to its pre-restore state.  If we are successful in restoring the table, we should delete the ""rollbackSnapshot"" when the restoreSnapshot operation successfully completes."
HBASE-13972,"I was looking at https://builds.apache.org/job/PreCommit-HBASE-Build/14576/console and found that findHangingTests.py didn't report any hanging / failing test.
{code}
Running org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker
Killed
{code}
It turns out that findHangingTests.py didn't distinguish the state for tests that were killed.
Patch coming shortly which allows printing of killed test(s)"
HBASE-5929,"I have been noticing that calls to HBaseAdmin.majorCompact throws exceptions randomly for some regions.  I could not find a pattern to these exception.  The code I have simply does this admin.majorCompact(region.getRegionNameAsString()).  admin is an instance of HBaseAdmin and region is an instance of HRegionInfo.  The exception I get is 

org.apache.hadoop.hbase.TableNotFoundException: -ROOT-,,0
        at org.apache.hadoop.hbase.client.HBaseAdmin.tableNameString(HBaseAdmin.java:1473) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.compact(HBaseAdmin.java:1235) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.majorCompact(HBaseAdmin.java:1209) ~[hbase-0.92.1.jar:0.92.1]
        at com.stumbleupon.hbaseadmin.HBaseCompact.compactAllServers(Unknown Source) [hbase_compact.jar:na]


In this case it's the root region, but I get similar exceptions for other tables, like this.


2012-05-03 19:03:42,994 WARN  [main] HBaseCompact: Could not compact:
org.apache.hadoop.hbase.TableNotFoundException: ad_daily,49842:2009-07-10,1269763588508.1997607018
        at org.apache.hadoop.hbase.client.HBaseAdmin.tableNameString(HBaseAdmin.java:1473) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.compact(HBaseAdmin.java:1235) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.majorCompact(HBaseAdmin.java:1209) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.majorCompact(HBaseAdmin.java:1196) ~[hbase-0.92.1.jar:0.92.1]
        at com.stumbleupon.hbaseadmin.HBaseCompact.compactAllServers(Unknown Source) [hbase_compact.jar:na]
        at com.stumbleupon.hbaseadmin.HBaseCompact.main(Unknown Source) [hbase_compact.jar:na]


I see this on hbase shell as well.  However, I don't see these exceptions if I use admin.majorCompact(region.getRegionName()), so it looks like something gets lost when I use getRegionNameAsString().

Let me know if I can provide more information.
"
HBASE-5752,"When creating a new table with the hbase shell, and specifying a SPLITS_FILE with a blank line in it will cause the master to crash.

Uploading a sample splits file, here are the commands to test the split.

create 'testTable', {NAME => 'a', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', MIN_VERSIONS => '3', TTL => '2147483647', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {SPLITS_FILE => '/tmp/test.txt'}"
HBASE-5247,"The ColumnPaginationFilter doesn't return the correct number of columns when the limit is less than the total number of columns.  I don't know much about the internals of Hbase, but it appears that the problem is more re-producible when a table is split accross at least 2 regions.  I have created a unit test which can re-produce the issue which is now attached."
HBASE-4543,"major_compact '.META.' has no effect, although major_compact 'any_other_table' works fine from the shell.

This issue seems to only affect 0.89. The apache-trunk seems to handle this case properly.


The issue is that getTableRegions() in HMaster.java only works if the tableName given is a ""normal"" table.
The methodology (using a MetaScanner to look through the .META. table for the tableName) does not work if
the tableName is .META.

The fix modifies getTableRegions() to check if the tableName is .META.; and if so, handle it accordingly."
HBASE-6456,"The command I ran is as below:
""bin/hbase org.apache.hadoop.hbase.mapreduce.Driver export t1 ./t1""

And I got the following exceptions:

attempt_201207261322_0002_m_000000_0, Status : FAILED
Error: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.util.Bytes
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:150)
        at org.apache.hadoop.hbase.mapreduce.TableInputFormat.setConf(TableInputFormat.java:100)
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:767)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:371)
        at org.apache.hadoop.mapred.Child$4.run(Child.java:266)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.au
...

This exception can be resolved by adding hbase common jar into HADOOP_CLASSPATH. But this is an extra step for users and not so convenient. 

We could add Bytes.class into dependency Jars of the MapReduce job.  

"
HBASE-11336,Show region sizes in table page of master info server
HBASE-13220,set_quota command to should throw exception to user when trying to set quota on a non-existing table or namespace same like grant command.
HBASE-9790,"'Alter' was issued with wrong (negative) max_file_size. At some moment regionservers begin to split regions producing zero size regions. Table won't to delete, even can't disable it.

Solution: stop cluster, delete table from hdfs, use with care  
{{hbase org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair}}"
HBASE-12284,"This test seems to be failing occassionaly, like once in 30 times. Maybe the test needs some love ?"
HBASE-6753,"I'm a newbie to HBase.

I implemented a coprocessor which is pretty nice with Cloudera version 4.0.1.


Testing my copressor evolved a problem, because everytime I inserted logging into my prePut-method, the Put object was not stored anymore into HBase.

I analyzed the code and could reduce the problem to the fact, that calling the toString-method on the Put object alone, is the reason for this behaviour.

There seems to be a problem with the serialization of the object.

Serialization seems to modifiy the object with the result, that it is not inserted in HBase anymore.

"
HBASE-4567,"When doing a rolling split of existing regions using RegionSplitter, a divide by zero exception occurs.

I'll be posting a junit test soon that reproduces the problem."
HBASE-5299,"RSA, RS B and RS C are 3 region servers.
RS A -> META
RS B -> ROOT
RS C -> NON META and NON ROOT

Kill RS B and wait for server shutdown handler to start.  
Start RS B again before assigning ROOT to RS C.
Now the cluster will try to assign new regions to RS B.  
But as ROOT is not yet assigned the OpenRegionHandler.updateMeta will fail to update the regions just because ROOT is not online.
{code}
a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:23:25,126 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Attempting to transition node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:23:25,159 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Successfully transitioned node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:23:35,385 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Attempting to transition node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:23:35,449 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Successfully transitioned node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:24:16,666 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Attempting to transition node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:24:16,701 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Successfully transitioned node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:24:20,788 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Interrupting thread Thread[PostOpenDeployTasks:a87109263ed53e67158377a149c5a7be,5,main]
2012-01-30 16:24:30,699 WARN org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Exception running postOpenDeployTasks; region=a87109263ed53e67158377a149c5a7be
org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException: Interrupted
	at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMetaServerConnectionDefault(CatalogTracker.java:439)
	at org.apache.hadoop.hbase.catalog.MetaEditor.updateRegionLocation(MetaEditor.java:142)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1382)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:221)
{code}

So we need to wait for TM to assign the regions again. "
HBASE-8310,"There are a few timeout values and defaults being used by HBase snapshot.
DEFAULT_MAX_WAIT_TIME (60000 milli sec, 1 min) for client response
TIMEOUT_MILLIS_DEFAULT (60000 milli sec, 1 min) for Procedure timeout
SNAPSHOT_TIMEOUT_MILLIS_DEFAULT (60000 milli sec, 1 min) for region server subprocedure  

There is also other timeout involved, for example, 
DEFAULT_TABLE_WRITE_LOCK_TIMEOUT_MS (10 mins) for TakeSnapshotHandler#prepare()

We could have this case:
The user issues a sync snapshot request, waits for 1 min, and gets an exception.
In the meantime the snapshot handler is blocked on the table lock, and the snapshot may continue to finish after 10 mins.
But the user will probably re-issue the snapshot request during the 10 mins.
This is a little confusing and messy when this happens.
To be more reasonable, we should either increase the DEFAULT_MAX_WAIT_TIME or decrease the table lock waiting time."
HBASE-12594,With this fix one behavior change a non-super user will notice is that he/she will be able to see only tables to which they have create/admin permissions
HBASE-6142,"The javadoc on some of the filter is somewhat confusing.
The main Filter interface has methods that behave like a sieve; when filterRowKey returns true, that means that the row is filtered _out_ (not included).

Many of the Filter implementations work the other way around. When the condition is met the value passes (ie, the row is returned).

Most Filters make it clear when a values passes (passing through the filter meaning the values are returned from the scan).
Some are less clear in light of how the Filter interface works: WhileMatchFilter and SingleColumnValueFilter are examples."
HBASE-10832,"IntegrationTestIngestStripeCompactions timed out when executing in local mode, failed to shut down cleanly (LoadTestTool worker threads were trying to finish, master's catalog scanner was trying to scan a meta table that had gone away, etc.), and became a zombie. "
HBASE-11313,"RpcClient.getPoolType check the pool choice against ThreadLocal and RoundRobin. However, we have a 3rd pooltype already in, Reusable. We should allow in this getPoolType check."
HBASE-3123,"The constructor in ZooKeeperWatcher does too much.  It does things like create the layout in ZK.  It's probably not harmful but it's unnecessary.  It should ensure that the basenode is created.  Other stuff should at least be stuffed into an initializeNodes() method or the like and only called by the first active master on cluster startup.

Other components in HBase that want to also access ZK, things like rest, should be able to reuse ZKW and ZKUtil easily."
HBASE-2229,"what we are doing right now is wonky, we should use jopt simple, which attempts to emulate ye olde classic opt parsers from C in their brevity and terseness.

http://jopt-simple.sourceforge.net/"
HBASE-7138,"The 'splitCount' in this line is zero in some scenario, then throw ArithmeticException: / by zero, and the '_balancedSplit' file was not deleted:
{code:java}
      LOG.debug(""Avg Time / Split = ""
          + org.apache.hadoop.util.StringUtils.formatTime(tDiff / splitCount));
{code}

Steps to reproduce:

{code}
shell> create 'test2', 'i'
shell> for i in 'a'..'z' do for j in 'a'..'z' do put 'test2', ""#{i}#{j}"", ""i:#{j}"", ""#{j}"" end end
{code}

{noformat}
$ bin/hbase org.apache.hadoop.hbase.util.RegionSplitter -r -o 2 test2 HexStringSplit
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.3-1240972, built on 02/06/2012 10:48 GMT
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:host.name=dev-vm0
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.version=1.6.0_29
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/jdk1.6.0_29/jre
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/usr/lib/jvm/default-java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../hbase-0.94.1.jar:/opt/hbase/bin/../hbase-0.94.1-tests.jar:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.5.3.jar:/opt/hbase/bin/../lib/avro-ipc-1.5.3.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.4.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.1.jar:/opt/hbase/bin/../lib/commons-lang-2.5.jar:/opt/hbase/bin/../lib/commons-logging-1.1.1.jar:/opt/hbase/bin/../lib/commons-math-2.1.jar:/opt/hbase/bin/../lib/commons-net-1.4.1.jar:/opt/hbase/bin/../lib/core-3.1.1.jar:/opt/hbase/bin/../lib/guava-11.0.2.jar:/opt/hbase/bin/../lib/hadoop-core-1.0.3.jar:/opt/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/opt/hbase/bin/../lib/httpclient-4.1.2.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/opt/hbase/bin/../lib/jackson-xc-1.8.8.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/jaxb-api-2.1.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jersey-core-1.8.jar:/opt/hbase/bin/../lib/jersey-json-1.8.jar:/opt/hbase/bin/../lib/jersey-server-1.8.jar:/opt/hbase/bin/../lib/jettison-1.1.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.5.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.10-HBASE-1.jar:/opt/hbase/bin/../lib/libthrift-0.8.0.jar:/opt/hbase/bin/../lib/log4j-1.2.16.jar:/opt/hbase/bin/../lib/metrics-core-2.1.2.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/protobuf-java-2.4.0a.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/slf4j-api-1.4.3.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.4.3.jar:/opt/hbase/bin/../lib/snappy-java-1.0.3.2.jar:/opt/hbase/bin/../lib/stax-api-1.0.1.jar:/opt/hbase/bin/../lib/velocity-1.7.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/zookeeper-3.4.3.jar:/opt/hbase/bin/../libextra/mybk-commons-cc.jar:/opt/hbase/bin/../libextra/hbase.jar:/opt/hbase/bin/../libextra/sfdcloud-hbase.jar:
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hbase/bin/../lib/native/Linux-i386-32
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:os.name=Linux
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:os.arch=i386
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:os.version=2.6.32-33-generic
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:user.name=pcer
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:user.home=/home/pcer
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase-0.94.1
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=dev-vm0:2181 sessionTimeout=60000 watcher=hconnection
12/11/08 19:20:40 INFO zookeeper.ClientCnxn: Opening socket connection to server /172.16.20.140:2181
12/11/08 19:20:40 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 28728@dev-vm0
12/11/08 19:20:40 WARN client.ZooKeeperSaslClient: SecurityException: java.lang.SecurityException: Unable to locate a login configuration occurred when trying to find JAAS configuration.
12/11/08 19:20:40 INFO client.ZooKeeperSaslClient: Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration.
12/11/08 19:20:40 INFO zookeeper.ClientCnxn: Socket connection established to dev-vm0/172.16.20.140:2181, initiating session
12/11/08 19:20:40 INFO zookeeper.ClientCnxn: Session establishment complete on server dev-vm0/172.16.20.140:2181, sessionid = 0x13ad3e9ba700150, negotiated timeout = 40000
12/11/08 19:20:40 DEBUG client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a; serverName=dev-vm0,46871,1352175042380
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for .META.,,1.1028785192 is dev-vm0:46871
12/11/08 19:20:41 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=10 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for test2,,1352373607304.8341524d6c8b105b1722961ebda3a048. is dev-vm0:46871
12/11/08 19:20:41 DEBUG util.RegionSplitter: No _balancedSplit file.  Calculating splits...
12/11/08 19:20:41 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=2147483647 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 DEBUG util.RegionSplitter: Table test2 has 1 regions that will be split.
12/11/08 19:20:41 DEBUG util.RegionSplitter: Will Split [00000000 , ffffffff) at 7fffffff
12/11/08 19:20:41 DEBUG util.RegionSplitter: Bucketing regions by regionserver...
12/11/08 19:20:41 DEBUG util.RegionSplitter: Done with bucketing.  Split time!
12/11/08 19:20:41 DEBUG util.RegionSplitter: 1 RS have regions to splt.
12/11/08 19:20:41 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=2147483647 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 DEBUG util.RegionSplitter: Finding a region on dev-vm0:46871
12/11/08 19:20:41 DEBUG util.RegionSplitter: Splitting at 7fffffff
12/11/08 19:20:41 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=dev-vm0:2181 sessionTimeout=60000 watcher=catalogtracker-on-org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 INFO zookeeper.ClientCnxn: Opening socket connection to server /172.16.20.140:2181
12/11/08 19:20:41 WARN client.ZooKeeperSaslClient: SecurityException: java.lang.SecurityException: Unable to locate a login configuration occurred when trying to find JAAS configuration.
12/11/08 19:20:41 INFO client.ZooKeeperSaslClient: Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration.
12/11/08 19:20:41 INFO zookeeper.ClientCnxn: Socket connection established to dev-vm0/172.16.20.140:2181, initiating session
12/11/08 19:20:41 INFO zookeeper.ClientCnxn: Session establishment complete on server dev-vm0/172.16.20.140:2181, sessionid = 0x13ad3e9ba700151, negotiated timeout = 40000
12/11/08 19:20:41 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 28728@dev-vm0
12/11/08 19:20:41 DEBUG catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@29c58e
12/11/08 19:20:41 DEBUG client.ClientScanner: Creating scanner over .META. starting at key 'test2,,'
12/11/08 19:20:41 DEBUG client.ClientScanner: Advancing internal scanner to startKey at 'test2,,'
12/11/08 19:20:41 DEBUG client.ClientScanner: Creating scanner over .META. starting at key 'test2,,'
12/11/08 19:20:41 DEBUG client.ClientScanner: Advancing internal scanner to startKey at 'test2,,'
12/11/08 19:20:41 DEBUG client.ClientScanner: Finished with scanning at {NAME => '.META.,,1', STARTKEY => '', ENDKEY => '', ENCODED => 1028785192,}
12/11/08 19:20:41 DEBUG catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@29c58e
12/11/08 19:20:41 INFO zookeeper.ZooKeeper: Session: 0x13ad3e9ba700151 closed
12/11/08 19:20:41 INFO zookeeper.ClientCnxn: EventThread shut down
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a; serverName=dev-vm0,46871,1352175042380
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for .META.,,1.1028785192 is dev-vm0:46871
12/11/08 19:20:41 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=10 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for test2,,1352373607304.8341524d6c8b105b1722961ebda3a048. is dev-vm0:46871
12/11/08 19:20:41 DEBUG util.RegionSplitter: Split Scan: 0 finished / 1 split wait / 0 reference wait
12/11/08 19:21:11 DEBUG client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a; serverName=dev-vm0,46871,1352175042380
12/11/08 19:21:11 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for .META.,,1.1028785192 is dev-vm0:46871
12/11/08 19:21:11 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,7fffffff,00000000000000 for max=10 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:21:11 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for test2,7fffffff,1352373641571.d56fbb146b77bbc87c294766fabcb3c4. is dev-vm0:46871
12/11/08 19:21:11 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=10 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:21:11 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for test2,,1352373641571.4e805892dd68d69ba02f72303973ee0e. is dev-vm0:46871
12/11/08 19:21:12 DEBUG util.RegionSplitter: Split Scan: 1 finished / 0 split wait / 0 reference wait
12/11/08 19:21:12 DEBUG util.RegionSplitter: All regions have been successfully split!
12/11/08 19:21:12 DEBUG util.RegionSplitter: TOTAL TIME = 30sec
12/11/08 19:21:12 DEBUG util.RegionSplitter: Splits = 0
Exception in thread ""main"" java.lang.ArithmeticException: / by zero
	at org.apache.hadoop.hbase.util.RegionSplitter.rollingSplit(RegionSplitter.java:576)
	at org.apache.hadoop.hbase.util.RegionSplitter.main(RegionSplitter.java:349)

{noformat}

The attached patch was tested and worked well.
"
HBASE-10816,"In reviewing patch for HBASE-10569, Stack pointed out some existing issue with CatalogTracker. I looked into it and I think the abortable usage can be improved.

* If ZK is null, when a new one is created, the abortable could be null. We need consider this.
* The throwableAborter is to abort the process in case some ZK exception in MetaRegionTracker. In case the tracker is in a server, we don't need to do this, we can use the server as the abortable. In case the tracker is in a client, we can just abort the connection. Right?"
HBASE-10617,"When post following json data to rest server, it return 200, but the value is null in HBase
{code}
{""Row"": { ""key"":""cjI="", ""Cell"": {""$"":""ZGF0YTE="", ""column"":""ZjE6YzI=""}}}
{code}

From rest server log, we found the length of value is null after the server paste the json to RowModel object
{code}
14/02/26 17:52:14 DEBUG rest.RowResource: PUT {""totalColumns"":1,""families"":{""f1"":[{""timestamp"":9223372036854775807,""qualifier"":""c2"",""vlen"":0}]},""row"":""r2""}
{code}

When the order is that ""column"" before ""$"",  it works fine.
{code}
{""Row"": { ""key"":""cjI="", ""Cell"": {""column"":""ZjE6YzI="", ""$"":""ZGF0YTE="" }}}
{code}

DIfferent json libs may have different order of this two elements even if ""column"" is put before ""$"".

"
HBASE-10509,"Seen with IBM JDK 7:

{noformat}
Caused by: com.google.protobuf.UninitializedMessageException: Message missing required fields: row_processor_result
	at com.google.protobuf.AbstractMessage$Builder.newUninitializedMessageException(AbstractMessage.java:770)
	at org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos$ProcessResponse$Builder.build(RowProcessorProtos.java:1301)
	at org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos$ProcessResponse$Builder.build(RowProcessorProtos.java:1245)
	at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:5482)
{noformat}
"
HBASE-10444,"hbase RS logs show an NPE in shutdown; no other info

{code}
14/01/30 14:18:25 INFO ipc.RpcServer: Stopping server on 57186
Exception in thread ""regionserver57186"" java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:897)
	at java.lang.Thread.run(Thread.java:744)
14/01/30 14:18:25 ERROR regionserver.HRegionServerCommand
{code}"
HBASE-5000,"With block caching, when one client starts reading a block and another one comes around asking for the same block, the second client waits for the first one to finish reading and returns the block from cache. This is achieved by locking on the block offset using IdLock, a ""sparse lock"" primitive allowing to lock on arbitrary long numbers. However, in case there is no block caching, there is no reason to wait for other clients that are reading the same block. One challenge optimizing this that we don't necessary have accurate information about whether other HFile API clients interested in the block would cache it.

Setting priority as minor, as it is very unusual to turn off block caching.
"
HBASE-6476,"There are still some areas where System.currentTimeMillis() is used in HBase. In order to make all parts of the code base testable and (potentially) to be able to configure HBase's notion of time, this should be generally be replaced with EnvironmentEdgeManager.currentTimeMillis().

How hard would it be to add a maven task that checks for that, so we do not introduce System.currentTimeMillis back in the future?"
HBASE-9781,"Each time I use HRegion.merge(HRegion a, HRegion b) method to merge some regions, it makes crazy that there would always be some temporary directories left on hdfs because of merging's ""Files have same sequenceid"" exceptions. I have to clean them by hand."
HBASE-6487,"Tried to assign a region already assigned somewhere from hbase shell, the region is assigned to a different place but the previous assignment is not closed.  So it causes double assignments.  In such a case, it's better to issue a warning instead."
HBASE-6755,"I was looking at HBase's implementation of locks and saw that is unnecessarily uses an AtomicInteger to obtain a unique lockid.
The observation is that we only need a unique one and don't care if we happen to skip one.
In a very unscientific test I saw the %system CPU reduced when the AtomicInteger is avoided."
HBASE-7140,"seems like building hadoop-one-snapshot is failing.  See error log

[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] HBase
[INFO] HBase - Common
[INFO] HBase - Hadoop Compatibility
[INFO] HBase - Hadoop One Compatibility
[INFO] HBase - Server
[INFO] HBase - Hadoop Two Compatibility
[INFO] HBase - Integration Tests
[INFO] HBase - Examples
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase 0.95-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase >>>
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.1:process (default) @ hbase ---
[INFO] Setting property: classpath.resource.loader.class => 'org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader'.
[INFO] Setting property: velocimacro.messages.on => 'false'.
[INFO] Setting property: resource.loader => 'classpath'.
[INFO] Setting property: resource.manager.logwhenfound => 'false'.
[INFO] 
[INFO] <<< maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase <<<
[INFO] 
[INFO] --- maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase ---
[INFO] Not running eclipse plugin goal for pom project
[INFO] Using Eclipse Workspace: null
[INFO] Adding default classpath container: org.eclipse.jdt.launching.JRE_CONTAINER
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase - Common 0.95-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-common >>>
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.1:process (default) @ hbase-common ---
[INFO] 
[INFO] <<< maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-common <<<
[INFO] 
[INFO] --- maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-common ---
[INFO] Using Eclipse Workspace: null
[INFO] Adding default classpath container: org.eclipse.jdt.launching.JRE_CONTAINER
[INFO] File /Users/sujee/dev/hadoop/hbase-src/hbase-common/.project already exists.
       Additional settings will be preserved, run mvn eclipse:clean if you want old settings to be removed.
[INFO] Wrote Eclipse project for ""hbase-common"" to /Users/sujee/dev/hadoop/hbase-src/hbase-common.
[INFO] 
       Sources for some artifacts are not available.
       Please run the same goal with the -DdownloadSources=true parameter in order to check remote repositories for sources.
       List of artifacts without a source archive:
         o com.google.guava:guava:12.0.1
         o junit:junit:4.10-HBASE-1
         o org.apache.hadoop:hadoop-core:1.1.0
         o commons-io:commons-io:2.4
         o commons-httpclient:commons-httpclient:3.0.1
         o commons-codec:commons-codec:1.7
         o commons-lang:commons-lang:2.6
         o commons-net:commons-net:1.4.1
         o org.mortbay.jetty:jsp-api-2.1:6.1.14
         o org.mortbay.jetty:servlet-api-2.5:6.1.14
         o org.mortbay.jetty:jsp-2.1:6.1.14
         o org.apache.hadoop:hadoop-test:1.1.0
         o org.apache.ftpserver:ftplet-api:1.0.0
         o org.apache.mina:mina-core:2.0.0-M5
         o org.slf4j:slf4j-api:1.4.3
         o org.apache.ftpserver:ftpserver-core:1.0.0
         o org.apache.ftpserver:ftpserver-deprecated:1.0.0-M2
         o org.mockito:mockito-all:1.9.0
         o org.slf4j:slf4j-log4j12:1.4.3

       Javadoc for some artifacts is not available.
       Please run the same goal with the -DdownloadJavadocs=true parameter in order to check remote repositories for javadoc.
       List of artifacts without a javadoc archive:
         o com.google.guava:guava:12.0.1
         o com.google.code.findbugs:jsr305:1.3.9
         o commons-logging:commons-logging:1.1.1
         o junit:junit:4.10-HBASE-1
         o org.apache.hadoop:hadoop-core:1.1.0
         o commons-cli:commons-cli:1.2
         o xmlenc:xmlenc:0.52
         o commons-io:commons-io:2.4
         o commons-httpclient:commons-httpclient:3.0.1
         o commons-codec:commons-codec:1.7
         o org.apache.commons:commons-math:2.1
         o commons-configuration:commons-configuration:1.6
         o commons-collections:commons-collections:3.2.1
         o commons-lang:commons-lang:2.6
         o commons-digester:commons-digester:1.8
         o commons-beanutils:commons-beanutils:1.7.0
         o commons-beanutils:commons-beanutils-core:1.8.0
         o commons-net:commons-net:1.4.1
         o org.mortbay.jetty:jetty:6.1.26
         o org.mortbay.jetty:jetty-util:6.1.26
         o tomcat:jasper-runtime:5.5.23
         o commons-el:commons-el:1.0
         o tomcat:jasper-compiler:5.5.23
         o org.mortbay.jetty:jsp-api-2.1:6.1.14
         o org.mortbay.jetty:servlet-api-2.5:6.1.14
         o org.mortbay.jetty:jsp-2.1:6.1.14
         o org.codehaus.jackson:jackson-mapper-asl:1.8.8
         o org.codehaus.jackson:jackson-core-asl:1.8.8
         o org.apache.hadoop:hadoop-test:1.1.0
         o org.apache.ftpserver:ftplet-api:1.0.0
         o org.apache.mina:mina-core:2.0.0-M5
         o org.slf4j:slf4j-api:1.4.3
         o org.apache.ftpserver:ftpserver-core:1.0.0
         o org.apache.ftpserver:ftpserver-deprecated:1.0.0-M2
         o org.mockito:mockito-all:1.9.0
         o org.slf4j:slf4j-log4j12:1.4.3
         o log4j:log4j:1.2.17

[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase - Hadoop Compatibility 0.95-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-hadoop-compat >>>
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.1:process (default) @ hbase-hadoop-compat ---
[INFO] 
[INFO] <<< maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-hadoop-compat <<<
[INFO] 
[INFO] --- maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-hadoop-compat ---
[INFO] Using Eclipse Workspace: null
[INFO] Adding default classpath container: org.eclipse.jdt.launching.JRE_CONTAINER
[INFO] File /Users/sujee/dev/hadoop/hbase-src/hbase-hadoop-compat/.project already exists.
       Additional settings will be preserved, run mvn eclipse:clean if you want old settings to be removed.
[INFO] Wrote Eclipse project for ""hbase-hadoop-compat"" to /Users/sujee/dev/hadoop/hbase-src/hbase-hadoop-compat.
[INFO] 
       Sources for some artifacts are not available.
       Please run the same goal with the -DdownloadSources=true parameter in order to check remote repositories for sources.
       List of artifacts without a source archive:
         o junit:junit:4.10-HBASE-1
         o org.mockito:mockito-all:1.9.0

       Javadoc for some artifacts is not available.
       Please run the same goal with the -DdownloadJavadocs=true parameter in order to check remote repositories for javadoc.
       List of artifacts without a javadoc archive:
         o commons-logging:commons-logging:1.1.1
         o junit:junit:4.10-HBASE-1
         o org.mockito:mockito-all:1.9.0

[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase - Hadoop One Compatibility 0.95-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-hadoop1-compat >>>
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.1:process (default) @ hbase-hadoop1-compat ---
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] HBase ............................................. SUCCESS [1.534s]
[INFO] HBase - Common .................................... SUCCESS [1.173s]
[INFO] HBase - Hadoop Compatibility ...................... SUCCESS [0.058s]
[INFO] HBase - Hadoop One Compatibility .................. FAILURE [0.098s]
[INFO] HBase - Server .................................... SKIPPED
[INFO] HBase - Hadoop Two Compatibility .................. SKIPPED
[INFO] HBase - Integration Tests ......................... SKIPPED
[INFO] HBase - Examples .................................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 4.894s
[INFO] Finished at: Fri Nov 09 14:49:27 PST 2012
[INFO] Final Memory: 17M/81M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.1:process (default) on project hbase-hadoop1-compat: Failed to resolve dependencies for one or more projects in the reactor. Reason: Missing:
[ERROR] ----------
[ERROR] 1) org.apache.hbase:hbase-hadoop-compat:jar:0.95-SNAPSHOT
[ERROR] 
[ERROR] Try downloading the file manually from the project website.
[ERROR] 
[ERROR] Then, install it using the command:
[ERROR] mvn install:install-file -DgroupId=org.apache.hbase -DartifactId=hbase-hadoop-compat -Dversion=0.95-SNAPSHOT -Dpackaging=jar -Dfile=/path/to/file
[ERROR] 
[ERROR] Alternatively, if you host your own repository you can deploy the file there:
[ERROR] mvn deploy:deploy-file -DgroupId=org.apache.hbase -DartifactId=hbase-hadoop-compat -Dversion=0.95-SNAPSHOT -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id]
[ERROR] 
[ERROR] Path to dependency:
[ERROR] 1) org.apache.hbase:hbase-hadoop1-compat:jar:0.95-SNAPSHOT
[ERROR] 2) org.apache.hbase:hbase-hadoop-compat:jar:0.95-SNAPSHOT
[ERROR] 
[ERROR] 2) org.apache.hbase:hbase-hadoop-compat:test-jar:tests:0.95-SNAPSHOT
[ERROR] 
[ERROR] Try downloading the file manually from the project website.
[ERROR] 
[ERROR] Then, install it using the command:
[ERROR] mvn install:install-file -DgroupId=org.apache.hbase -DartifactId=hbase-hadoop-compat -Dversion=0.95-SNAPSHOT -Dclassifier=tests -Dpackaging=test-jar -Dfile=/path/to/file
[ERROR] 
[ERROR] Alternatively, if you host your own repository you can deploy the file there:
[ERROR] mvn deploy:deploy-file -DgroupId=org.apache.hbase -DartifactId=hbase-hadoop-compat -Dversion=0.95-SNAPSHOT -Dclassifier=tests -Dpackaging=test-jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id]
[ERROR] 
[ERROR] Path to dependency:
[ERROR] 1) org.apache.hbase:hbase-hadoop1-compat:jar:0.95-SNAPSHOT
[ERROR] 2) org.apache.hbase:hbase-hadoop-compat:test-jar:tests:0.95-SNAPSHOT
[ERROR] 
[ERROR] ----------
[ERROR] 2 required artifacts are missing.
[ERROR] 
[ERROR] for artifact:
[ERROR] org.apache.hbase:hbase-hadoop1-compat:jar:0.95-SNAPSHOT
[ERROR] 
[ERROR] from the specified remote repositories:
[ERROR] cloudbees netty (http://repository-netty.forge.cloudbees.com/snapshot/, releases=true, snapshots=true),
[ERROR] apache release (https://repository.apache.org/content/repositories/releases/, releases=true, snapshots=true),
[ERROR] java.net (http://download.java.net/maven/2/, releases=true, snapshots=false),
[ERROR] codehaus (http://repository.codehaus.org/, releases=true, snapshots=false),
[ERROR] repository.jboss.org (http://repository.jboss.org/nexus/content/groups/public-jboss/, releases=true, snapshots=false),
[ERROR] ghelmling.testing (http://people.apache.org/~garyh/mvn/, releases=true, snapshots=true),
[ERROR] apache.snapshots (http://repository.apache.org/snapshots, releases=false, snapshots=true),
[ERROR] central (http://repo1.maven.org/maven2, releases=true, snapshots=false)
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hbase-hadoop1-compat
"
HBASE-7713,"build fails with following error message ""org.codehaus.plexus.resource.loader.ResourceNotFoundException: Could not find resource 'dev-support/findbugs-exclude.xml'"
HBASE-7638,See HBASE-7268. 
HBASE-6988,"Thru the cycle of restarting HBase and shell, I was somehow able to get into this state (on trunk):

{noformat}
hbase(main):020:0> describe 'test'
DESCRIPTION                                                                                ENABLED                                          
 'test', {METHOD => 'table_att', CONFIG => {'Key' => 'Value2', 'Key2' => 'Value2'}}, {NAME true                                             
  => 'cf', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0',                                                  
  COMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_D                                                  
 ELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'fa                                                  
 lse', BLOCKCACHE => 'true'}                                                                                                                
1 row(s) in 0.0420 seconds

hbase(main):021:0> disable 'test'

ERROR: Table test does not exist.'

Here is some help for this command:
Start disable of named table: e.g. ""hbase> disable 't1'""


hbase(main):022:0> create 'test', 'cf2'
0 row(s) in 1.0900 seconds

=> Hbase::Table - test
hbase(main):023:0> describe 'test'
DESCRIPTION                                                                                ENABLED                                          
 'test', {METHOD => 'table_att', CONFIG => {'Key' => 'Value2', 'Key2' => 'Value2'}}, {NAME true                                             
  => 'cf', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0',                                                  
  COMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_D                                                  
 ELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'fa                                                  
 lse', BLOCKCACHE => 'true'}                                                                                                                
1 row(s) in 0.0440 seconds

hbase(main):024:0> disable 'test'
0 row(s) in 7.0590 seconds

hbase(main):026:0> alter 'test', METHOD => 'table_att', CONFIG => { 'Key' => 'Value3' }, MAX_FILESIZE => 1234567
Updating all regions with the new schema...
1/1 regions updated.
Done.
0 row(s) in 1.1210 seconds

hbase(main):027:0> describe 'test'
DESCRIPTION                                                                                ENABLED                                          
 'test', {METHOD => 'table_att', MAX_FILESIZE => '1234567', CONFIG => {'Key' => 'Value3',  false                                            
 'Key2' => 'Value2'}}, {NAME => 'cf', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE'                                                  
 , REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647',                                                   
 MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK                                                   
 => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'true'}                                                                                     
1 row(s) in 0.0400 seconds

hbase(main):029:0> enable 'test'
0 row(s) in 7.0710 seconds

hbase(main):030:0> put 'test', 'row1', 'cf:foo', 'bar'
0 row(s) in 0.0240 seconds

hbase(main):031:0> put 'test', 'row1', 'cf2:foo', 'bar'

ERROR: org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family cf2 does not exist in region test,,1350063293064.7867533297035efe96611b5bcc54f332. in table 'test', {METHOD => 'table_att', MAX_FILESIZE => '1234567', CONFIG => {'Key' => 'Value3', 'Key2' => 'Value2'}}, {NAME => 'cf', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
{noformat}

"
HBASE-5845,"In HBASE-5824, attempt was made to handle single Put execution separately. Put has two exception paths thereafter. It's better to keep one exception for easy exception handling."
HBASE-6878,"The code in SplitLogManager# getDataSetWatchSuccess is:
{code}
if (slt.isDone()) {
      LOG.info(""task "" + path + "" entered state: "" + slt.toString());
      if (taskFinisher != null && !ZKSplitLog.isRescanNode(watcher, path)) {
        if (taskFinisher.finish(slt.getServerName(), ZKSplitLog.getFileName(path)) == Status.DONE) {
          setDone(path, SUCCESS);
        } else {
          resubmitOrFail(path, CHECK);
        }
      } else {
        setDone(path, SUCCESS);
      }
{code}

          resubmitOrFail(path, CHECK);

should be 
          resubmitOrFail(path, FORCE);

Without it, the task won't be resubmitted if the delay is not reached, and the task will be marked as failed.

"
HBASE-14,"Running a simple, fairly large job on the cluster, a few of the reduce steps failed; all that did are effectively hung.  Looking at failures, I see this strange output:

{code}
2007-11-13 02:09:09,606 DEBUG org.apache.hadoop.hbase.HTable: reloading table servers because: java.io.IOException: Region triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610 closed
	at org.apache.hadoop.hbase.HRegion.startUpdate(HRegion.java:1142)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1239)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

2007-11-13 02:09:19,778 DEBUG org.apache.hadoop.hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.NotServingRegionException: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1325)
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1297)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1238)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

2007-11-13 02:09:30,039 DEBUG org.apache.hadoop.hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.NotServingRegionException: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1325)
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1297)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1238)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

2007-11-13 02:09:40,275 DEBUG org.apache.hadoop.hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.NotServingRegionException: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1325)
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1297)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1238)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

2007-11-13 02:09:55,379 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1325)
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1297)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1238)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
	at org.apache.hadoop.hbase.HTable.commit(HTable.java:734)
	at org.apache.hadoop.hbase.HTable.commit(HTable.java:706)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter.write(TableOutputFormat.java:89)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter.write(TableOutputFormat.java:63)
	at org.apache.hadoop.mapred.ReduceTask$2.collect(ReduceTask.java:308)
	at TriplesTest$TestReducer.reduce(TriplesTest.java:66)
	at TriplesTest$TestReducer.reduce(TriplesTest.java:51)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:326)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1935)
{code}

Why is the reducer client being pig-headed trying to go against a region that has been closed?  Why not recalibrate?

Here is master log from around same time on the problem region:

{code}
...
2007-11-13 02:10:17,867 INFO org.apache.hadoop.hbase.HMaster: region triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610 split. New regions are: triples,http://purl.org/dc/terms/bibliographicCitation,1194919707661, triples,http://purl.org/dc/terms/references,1194919707661
...
2007-11-13 02:11:47,313 DEBUG org.apache.hadoop.hbase.HMaster: HMaster.metaScanner scanner: -3075797136896920808 regioninfo: {regionname: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610, startKey: <http://purl.org/dc/terms/bibliographicCitation>, offline: true, split: true, tableDesc: {name: triples, families: {triples:={name: triples, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}}}}, server: 208.76.44.140:60010, startCode: -647590197693256616
...
2007-11-13 02:11:47,317 INFO org.apache.hadoop.hbase.HMaster: Deleting region triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610 because daughter splits no longer hold references
{code}"
HBASE-3546,"There are possibilities of XSS in the WebUI.

If ColumnFamily or Region splitting keys are like

Bytes.toBytes(""<script>alert('js')</script>"")

then browsers run the JavaScript code.
I tested on HBase-0.90.0 .
"
HBASE-6159,"ZK connection count always goes up by one when running shell command:

{code}
hbase(main):001:0> truncate 'table'
{code}

This can be fixed with the change in admin.rb:

{code}
- h_table = org.apache.hadoop.hbase.client.HTable.new(table_name)
- table_description = h_table.getTableDescriptor()
+ table_description = @admin.getTableDescriptor(table_name.to_java_bytes)
{code}"
HBASE-6467,"After restart a cluster, all region servers checked into master but the master stuck in assigning forever.

Master log shows it keeps trying connect to one region server for ROOT table, while that region server's log shows it keeps printing out NotServingRegionException.

After restart the master, things are ok now."
HBASE-2073,"After a regionserver went down last night, I checked its logs and found the following exception:

2009-12-29 00:17:27,663 INFO org.apache.hadoop.hbase.regionserver.HLog: Roll /hbase/amsterdam_factory/.logs/factory05.lab.mtl,60020,1262042255724/hlog.dat.1262060247637, entries=1830, calcsize=22946017, filesize=22758899. New hlog /hbase/amsterdam_factory/.logs/factory05.lab.mtl,60020,1262042255724/hlog.dat.1262063847659
2009-12-29 00:34:36,210 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
java.lang.IllegalArgumentException
	at java.nio.Buffer.position(Buffer.java:218)
	at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1114)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:58)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:189)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:106)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.nextInternal(HRegion.java:1776)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.next(HRegion.java:1719)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1944)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:648)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
2009-12-29 00:34:36,214 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 0 on 60020, call next(4170645244799815171, 1) from 192.168.1.108:53401: error: java.io.IOException: java.lang.IllegalArgumentException
java.io.IOException: java.lang.IllegalArgumentException
	at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:869)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:859)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1965)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:648)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
Caused by: java.lang.IllegalArgumentException
	at java.nio.Buffer.position(Buffer.java:218)
	at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1114)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:58)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:189)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:106)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.nextInternal(HRegion.java:1776)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.next(HRegion.java:1719)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1944)
	... 5 more

Looks like this bug was encountered before at https://issues.apache.org/jira/browse/HBASE-1495 and spanned a few JIRAs. It's supposed to be resolved as of 0.20.0, but we're running 0.20.2 and it took down one of our regionservers.

I'm also attaching more of the log."
HBASE-1559,"IllegalThreadStateException during LocalHBaseCluster shutdown if more than one regionserver is started:

{noformat}
Thread [RegionServer:1] (Suspended (exception IllegalThreadStateException))
    FileSystem$ClientFinalizer(Thread).start() line: 595
    HRegionServer.runThread(Thread,long) line: 691
    HRegionServer.run() line: 675
    LocalHBaseCluster$RegionServerThread(Thread).run() line: 691
{noformat}

If started with only one region server, shut down is clean.
"
HBASE-4178,"ScannerIds are currently assigned by getting a random long. While it would be a rare occurrence that two scanners received the same ids on the same region server the results would seem to be... Bad.
A client scanner would get results from a different server scanner, and maybe only from some of the region servers.

A safer approach would be using an AtomicLong. We do not have to worry about running of numbers: If we got 10000 scanners per second it'd take > 2.9m years to reach 2^63.

Then again the same reasoning would imply that this collisions would be happening too rarely to be of concern (assuming a good random number generator). So maybe this is a none-issue.

AtomicLong would also imply a minor performance hit on multi core machines, as it would force a memory barrier."
HBASE-2102,We are hard coding the package version in src/contrib/build-contrib.xml and it has been out of sync with the package version in the top level build.xml file since 0.20.0. Maybe it would be better to keep the package version in a single separate file (/version.xml?) and include it from all build files?
HBASE-1475,"This does not happen every time I run a cluster test, but probably 75% of the time.

{noformat}
2009-06-02 09:58:32.365::INFO:  Logging to STDERR via org.mortbay.log.StdErrLog
2009-06-02 09:58:32.425::INFO:  jetty-6.1.14
2009-06-02 09:58:32.454::WARN:  Web application not found file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/hdfs
2009-06-02 09:58:32.454::WARN:  Failed startup of context org.mortbay.jetty.webapp.WebAppContext@7ed75415{/,file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/hdfs}
java.io.FileNotFoundException: file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/hdfs
	at org.mortbay.jetty.webapp.WebAppContext.resolveWebApp(WebAppContext.java:959)
	at org.mortbay.jetty.webapp.WebAppContext.getWebInf(WebAppContext.java:793)
	at org.mortbay.jetty.webapp.WebInfConfiguration.configureClassLoader(WebInfConfiguration.java:62)
	at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:456)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
	at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
	at org.mortbay.jetty.Server.doStart(Server.java:222)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:453)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:246)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:202)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:955)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:275)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:119)
	at org.apache.hadoop.hbase.HBaseClusterTestCase.setUp(HBaseClusterTestCase.java:122)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
2009-06-02 09:58:32.497::INFO:  Started SelectChannelConnector@localhost:34719
Starting DataNode 0 with dfs.data.dir: /home/jgray/src/hbase-0.20.0-1304/hbase/build/hbase/test/dfs/data/data1,/home/jgray/src/hbase-0.20.0-1304/hbase/build/hbase/test/dfs/data/data2
2009-06-02 09:58:32.678::INFO:  jetty-6.1.14
2009-06-02 09:58:32.683::WARN:  Web application not found file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/datanode
2009-06-02 09:58:32.683::WARN:  Failed startup of context org.mortbay.jetty.webapp.WebAppContext@6f7cf6b6{/,file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/datanode}
java.io.FileNotFoundException: file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/datanode
	at org.mortbay.jetty.webapp.WebAppContext.resolveWebApp(WebAppContext.java:959)
	at org.mortbay.jetty.webapp.WebAppContext.getWebInf(WebAppContext.java:793)
	at org.mortbay.jetty.webapp.WebInfConfiguration.configureClassLoader(WebInfConfiguration.java:62)
	at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:456)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
	at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
	at org.mortbay.jetty.Server.doStart(Server.java:222)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:453)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:375)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1283)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1238)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:414)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:119)
	at org.apache.hadoop.hbase.HBaseClusterTestCase.setUp(HBaseClusterTestCase.java:122)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
2009-06-02 09:58:32.688::INFO:  Started SelectChannelConnector@localhost:47838
{noformat}

It holds there for about 30 seconds.  If I rerun the test, the delay usually goes away.  Even when there is no delay, I still get this error at the beginning of the cluster spin up."
HBASE-568,"I have a very simple table named 'titles' that I'm playing around with.
After entering

	hql > DELETE * FROM titles;

I get the following output:

08/04/07 15:09:15 INFO hbase.HBaseAdmin: Disabled table titles
Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.hadoop.io.Text.set(Text.java:181)
        at org.apache.hadoop.io.Text.<init>(Text.java:76)
        at
org.apache.hadoop.hbase.hql.DeleteCommand.getColumnList(DeleteCommand.java:106)
        at
org.apache.hadoop.hbase.hql.DeleteCommand.execute(DeleteCommand.java:67)
        at
org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)

Every succeeding attempt to query the table results in the following output:

Exception in thread ""main"" java.lang.IllegalStateException: region
offline: titles,,1207564179189
        at
org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:438)
        at
org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:350)
        at
org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:313)
        at org.apache.hadoop.hbase.HTable.<init>(HTable.java:91)
        at
org.apache.hadoop.hbase.hql.SelectCommand.execute(SelectCommand.java:90)
        at
org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)


Deleting a specific column on the other hand, as in:

	hql> DELETE document:title FROM titles;

is no problem - I get this output:

08/04/07 17:08:02 INFO hbase.HBaseAdmin: Disabled table titles
08/04/07 17:08:02 INFO hbase.HBaseAdmin: Enabled table titles

and everything's all right ever after.
"
HBASE-503,"Master is stuck trying to shutdown.  It gets confused if its not running the shutdown.  Scenario is cluster is being monitored by a watcher process.  When a server goes down, its restarted.  In this environment, all hbase was updated then each server was restarted.  The regionservers bounced fine but the master won't go down.  Its stuck servicing reports of newly started regionservers to whom it sends a shutdown.... but cluster is of such a size that the master hasn't gone down by the time the regionserver starts again.  Here is how the master log looks for one server:

{code}
2008-03-11 20:47:08,198 INFO org.apache.hadoop.hbase.HMaster: Cancelling lease for XX.XX.XX.122:60020
2008-03-11 20:47:08,198 INFO org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- lease cancelled
2008-03-11 20:47:08,398 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
2008-03-11 20:47:16,421 INFO org.apache.hadoop.hbase.HMaster: received start message from: XX.XX.XX.122:60020
2008-03-11 20:47:20,163 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
2008-03-11 20:47:20,163 INFO org.apache.hadoop.hbase.HMaster: Cancelling lease for XX.XX.XX.122:60020
2008-03-11 20:47:20,163 INFO org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- lease cancelled
2008-03-11 20:47:20,393 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
2008-03-11 20:47:28,374 INFO org.apache.hadoop.hbase.HMaster: received start message from: XX.XX.XX.122:600
202008-03-11 20:47:32,095 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
2008-03-11 20:47:32,095 INFO org.apache.hadoop.hbase.HMaster: Cancelling lease for XX.XX.XX.122:60020
2008-03-11 20:47:32,095 INFO org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- lease cancelled
2008-03-11 20:47:32,274 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
{code}"
HBASE-1103,"hbase.client.rpc.maxattempts is defined as configurable in HConnectionManager , but is not present in the hbase-default.xml"
HBASE-520,"Build fails due to invalid output by saveVersion.sh:

user=`whoami` results in the string ""domain\user"" which is an invalid escape sequence down the line (or something else bad). I tried to figure out how to use sed to escape the backslash, but failed miserably and just removed the whoami altogether to workaround."
HBASE-18,"Marking as minor issue since its a concurrency issue in admin function.  Though that said, this is a guaranteed way to generate rows in META that are without their regioninfo (Looks like we might add startcode and servername after a row has had its regioninfo removed).

Issue was found by Dave Simpson running a create/delete/create sequence.  Attaching log."
HBASE-723,"cachedRegionLocation stores region locations of tables whenever new region is looked up. However, the enties are deleted only when TableServers object is closed or locateRegion is called with false useCache argument. Therefore, it seems to grow without limit and cause out of memory exception. 

"
HBASE-13,"I got this this evening:

{code}
08/01/17 05:57:06 ERROR hbase.PerformanceEvaluation: Failed
org.apache.hadoop.hbase.WrongRegionException: org.apache.hadoop.hbase.WrongRegionException: Requested row out of range for HRegion TestTable,0000103481,1200548919843, startKey='0000103481', getEndKey()='0000163328', row='0000163328'
        at org.apache.hadoop.hbase.HRegion.checkRow(HRegion.java:1491)
        at org.apache.hadoop.hbase.HRegion.obtainRowLock(HRegion.java:1536)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1231)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1497)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:908)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
        at org.apache.hadoop.hbase.HTable.commit(HTable.java:968)
        at org.apache.hadoop.hbase.HTable.commit(HTable.java:939)
        at org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest.testRow(PerformanceEvaluation.java:461)
        at org.apache.hadoop.hbase.PerformanceEvaluation$Test.test(PerformanceEvaluation.java:329)
        at org.apache.hadoop.hbase.PerformanceEvaluation.runOneClient(PerformanceEvaluation.java:525)
        at org.apache.hadoop.hbase.PerformanceEvaluation.runNIsOne(PerformanceEvaluation.java:546)
        at org.apache.hadoop.hbase.PerformanceEvaluation.runTest(PerformanceEvaluation.java:568)
        at org.apache.hadoop.hbase.PerformanceEvaluation.doCommandLine(PerformanceEvaluation.java:663)
        at org.apache.hadoop.hbase.PerformanceEvaluation.main(PerformanceEvaluation.java:682)
..
{code}

We seem to be asking for the endkey on a region rather than asking for the next region, the one that has the asked-for row as its start key."
HBASE-705,"I get a RegionOfflineException error when trying to use the list command with a region offline

{code}
hbase(main):005:0* list
08/06/25 02:43:30 DEBUG client.HConnectionManager$TableServers: Cache hit in table locations for row <> and tableName .META.: location server 64.69.33.211:60020, location region name .META.,,1
08/06/25 02:43:30 DEBUG client.HConnectionManager$TableServers: reloading table servers because: region offline: webdata,,1214377950920
08/06/25 02:43:30 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of webdata,,99999999999999
08/06/25 02:43:30 DEBUG client.HConnectionManager$TableServers: Found ROOT REGION => {NAME => '-ROOT-,,0', STARTKEY => '', ENDKEY => '', ENCODED => 70236052, TABLE => {NAME => '-ROOT-', FAMILIES => [{NAME => 'info', VERSIONS => 1, COMPRESSION => 'NONE', IN_MEMORY => false, BLOCKCACHE => false, LENGTH => 2147483647, TTL => FOREVER, BLOOMFILTER => NONE}]}
08/06/25 02:43:40 DEBUG client.HConnectionManager$TableServers: reloading table servers because: region offline: webdata,,1214377950920
08/06/25 02:43:40 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of webdata,,99999999999999
08/06/25 02:43:40 DEBUG client.HConnectionManager$TableServers: Found ROOT REGION => {NAME => '-ROOT-,,0', STARTKEY => '', ENDKEY => '', ENCODED => 70236052, TABLE => {NAME => '-ROOT-', FAMILIES => [{NAME => 'info', VERSIONS => 1, COMPRESSION => 'NONE', IN_MEMORY => false, BLOCKCACHE => false, LENGTH => 2147483647, TTL => FOREVER, BLOOMFILTER => NONE}]}
NativeException: org.apache.hadoop.hbase.client.RegionOfflineException: region offline: webdata,,1214377950920
        from org/apache/hadoop/hbase/client/HConnectionManager.java:446:in `locateRegionInMeta'
        from org/apache/hadoop/hbase/client/HConnectionManager.java:377:in `locateRegion'
        from org/apache/hadoop/hbase/client/HConnectionManager.java:338:in `locateRegion'
        from org/apache/hadoop/hbase/client/MetaScanner.java:68:in `metaScan'
        from org/apache/hadoop/hbase/client/MetaScanner.java:32:in `metaScan'
        from org/apache/hadoop/hbase/client/HConnectionManager.java:295:in `listTables'
        from org/apache/hadoop/hbase/client/HBaseAdmin.java:127:in `listTables'
        from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0'
        from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke'
        from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke'
        from java/lang/reflect/Method.java:597:in `invoke'
        from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling'
        from org/jruby/javasupport/JavaMethod.java:219:in `invoke'
        from org/jruby/javasupport/JavaClass.java:416:in `execute'
        from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call'
        from org/jruby/internal/runtime/methods/DynamicMethod.java:70:in `call'
... 128 levels...
        from ruby.hbase_minus_671438.bin.hirbInvokermethod__23$RUBY$startOpt:-1:in `call'
        from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call'
        from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call'
        from org/jruby/runtime/CallSite.java:123:in `cacheAndCall'
        from org/jruby/runtime/CallSite.java:298:in `call'
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:340:in `__file__'
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:-1:in `__file__'
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:-1:in `load'
        from org/jruby/Ruby.java:512:in `runScript'
        from org/jruby/Ruby.java:432:in `runNormally'
        from org/jruby/Ruby.java:312:in `runFromMain'
        from org/jruby/Main.java:144:in `run'
        from org/jruby/Main.java:89:in `run'
        from org/jruby/Main.java:80:in `main'
        from /hbase/bin/hirb.rb:227:in `list'
        from (hbase):6:in `binding'hbase(main):006:0>
{code}"
HBASE-400,"HQL commands have been implemented through the issue 
[HADOOP-1720|https://issues.apache.org/jira/browse/HADOOP-1720]. Unit tests that test these newly 
implemented HQL commands  are needed to make sure that those commands 
are correctly implemented. 

In this issue, we are going to provide unit tests that set up a minibase cluster, 
execute various commands, and verify the results, as Stack suggested in the issue
HADOOP-1720 as follows:

Stack said:
{quote}
This is a large amount of new functionality but it is without unit tests. Regression in something as complicated as a shell is a real danger. Do you have any objection to adding at least a basic test that does a setup of a minihbasecluster adding a table using your create command (with assertion that add was successful, and that all options specified were enabled, perhaps using your describe command), and then disable, enable, input, select, and drop asserting each of the steps has happened as you go? (I can help out if you'd like).
{quote}"
HBASE-385,"In the past, the lock id returned by HTable.startUpdate was a real lock id from a remote server. However, that has been superceeded by the BatchUpdate process, so now the lock id is just an arbitrary value. More, it doesn't actually add any value, because while it implies that you could start two updates on the same HTable and commit them separately, this is in fact not the case. Any attempt to do a second startUpdate throws an IllegalStateException. 

Since there is no added functionality afforded by the presence of this parameter, I suggest that we overload all methods that use it to ignore it and print a deprecation notice. startUpdate can just return a constant like 1 and eventually turn into a boolean or some other useful value."
HBASE-359,"There are a number of deprecated APIs in HRegionInterface (the interface used by the client to communicate with the HRegionServer). Although none of the APIs are used by the current client classes or by other HBase code, we do know that some HBase users have subclassed both the client and HRegionServer. What we do not know is if their changes make use of the deprecated APIs.

In addition, we would like to make an incompatible change to HRegionInterface.batchUpdate in order to support HADOOP-1724. (It would return either an enum or boolean instead of void).

If these changes would effect you, please let us know and also give us a time frame when this change could be implemented. Thanks!
"
HBASE-341,"Profiling, we create a bunch of short-lived objects in hbase around lease creation, renewal and release by doing 'new Text(Long.toString(someLong)))'."
HBASE-330,"
It would be better if 'ant clean' does not remove build directory. Many projects do not remove this dir. One advantage of not removing is that, I can symlink the build to another place (e.g. /mnt/scratch/) and keep the source code in more reliable place. I will submit a patch if this sounds ok."
HBASE-321,TableMapRunnable for Multi-Threaded HBase Map Jobs
HBASE-262,"Watching hudson, I happened to catch a hung TestCleanRegionServerExit.  The test had done a join onto the server it'd asked shutdown only the server wasn't going down because it was stuck trying to get a memcache write lock so it could finish the last flush on regions before close.  Somehow, a read (or write) lock is not being cleaned up.  Scanners are the suspect but looking at the code, scanners should be getting closed on expiration of their lease."
HBASE-157,"Watching the hbase webUI, the request counter in the load column reported in the list of regionservers doesn't make sense.  Refreshing, the request count will tend to rise for a while as you'd expect but then they'll start to fall and will often drop to zero.  This is on regionservers with constant count of regions (I'd expect load to be zero on a new region after a split)."
HBASE-126,Holger Stenzhorn has been having issues running a mapreduce job that dumps into a 'local' mode hbase.  Use this issue to figure whats going on.
HBASE-86,"From the list this morning from Josh Wills:

{code}
Date: Mon, 22 Oct 2007 12:04:01 -0500
From: ""Josh Wills"" ....
To: hadoop-user@lucene.apache.org
Subject: Re: A basic question on HBase

...

> >
> > 2)  I was running one of these batch-style uploads last night on an
> > HTable that I configured w/BloomFilters on a couple of my column
> > families.  During one of the compaction operations, I got the
> > following exception--
> >
> > FATAL org.apache.hadoop.hbase.HRegionServer: Set stop flag in
> > regionserver/0:0:0:0:0:0:0:0:60020.splitOrCompactChecker
> > java.lang.ArrayIndexOutOfBoundsException
> >         at java.lang.System.arraycopy(Native Method)
> >         at sun.security.provider.DigestBase.engineUpdate(DigestBase.jav=
a:102)
> >         at sun.security.provider.SHA.implDigest(SHA.java:94)
> >         at sun.security.provider.DigestBase.engineDigest(DigestBase.jav=
a:161)
> >         at sun.security.provider.DigestBase.engineDigest(DigestBase.jav=
a:140)
> >         at java.security.MessageDigest$Delegate.engineDigest(MessageDig=
est.java:531)
> >         at java.security.MessageDigest.digest(MessageDigest.java:309)
> >         at org.onelab.filter.HashFunction.hash(HashFunction.java:125)
> >         at org.onelab.filter.BloomFilter.add(BloomFilter.java:99)
> >         at org.apache.hadoop.hbase.HStoreFile$BloomFilterMapFile$Writer=
.append(HStoreFile.java:895)
> >         at org.apache.hadoop.hbase.HStore.compact(HStore.java:899)
> >         at org.apache.hadoop.hbase.HStore.compact(HStore.java:728)
> >         at org.apache.hadoop.hbase.HStore.compactHelper(HStore.java:632=
)
> >         at org.apache.hadoop.hbase.HStore.compactHelper(HStore.java:564=
)
> >         at org.apache.hadoop.hbase.HStore.compact(HStore.java:559)
> >         at org.apache.hadoop.hbase.HRegion.compactStores(HRegion.java:7=
17)
> >         at org.apache.hadoop.hbase.HRegionServer$SplitOrCompactChecker.=
checkForSplitsOrCompactions(HRegionServer.java:198)
> >         at org.apache.hadoop.hbase.HRegionServer$SplitOrCompactChecker.=
chore(HRegionServer.java:188)
> >         at org.apache.hadoop.hbase.Chore.run(Chore.java:58)
> >
> > Note that this wasn't the first compaction that was run (there were
> > others before it that ran successfully) and that the region hadn't
> > been split at this point.  I defined the BloomFilterType.BLOOMFILTER
> > on a couple of the columnfamilies, w/the largest one having ~100000
> > distinct entries.  I don't know which of these caused the failure, but
> > I noticed that 100000 is quite a bit larger than the # of entries used
> > in the testcases, so I'm wondering if that might be the problem.
...
{code}

Poking around, could be a concurrency issue -- see http://forum.java.sun.com/thread.jspa?threadID=700440&messageID=4117706 -- but Jim and I chatting can't figure how since there should be one thread only running at compaction time....

Plan is to try and reproduce on local cluster...."
HBASE-20994,Remove for loops adding to collections.  (Style)
HBASE-7737,"There is a serious bug in HServerAddress, who depends on the stringValue [class variable] for comparison. This variable is supposed to be host_ip_address:port. 

However, there is one constructor which allows user to pass a string as host_ip_address directly. This constructor is buggy because some caller may pass the host name instead of host ip address. And we found out one case in the HBase client.

The fix is to normalize the stringValue generation by calling the existing function getHostAddressWithPort.

For example:
this.stringValue = getHostAddressWithPort();
"
HBASE-16346,"{code:title=Increment.java|borderStyle=solid}
 // Is it necessary to prevent the null qualifier
  public Increment addColumn(byte [] family, byte [] qualifier, long amount) {
    if (family == null) {
      throw new IllegalArgumentException(""family cannot be null"");
    }
    if (qualifier == null) {
      throw new IllegalArgumentException(""qualifier cannot be null"");
    }
    List<Cell> list = getCellList(family);
    KeyValue kv = createPutKeyValue(family, qualifier, ts, Bytes.toBytes(amount));
    list.add(kv);
    familyMap.put(CellUtil.cloneFamily(kv), list);
    return this;
  }
{code}

I use the add(Cell) method to add the cell with null qualifier and it works fine.
It seems to me that the check should be removed
any command? thanks"
HBASE-13272,"Via [~larsgeorge]

Get.setClosestRowBefore() is breaking a specific Get that specifies a column. If you set the latter to ""true"" it will return the _entire_ row!"
HBASE-12530,"TestStatusResource can fail if run in parallel with other tests, fix this."
HBASE-4202,"We added a new node to a 44 node cluster starting the datanode, mapred and regionserver processes on it. The Unix filesystem was configured incorrectly, i.e. /tmp was not writable to processes. All three processes had issues with this. Datanode and mapred shutdown on exception.
Regionserver did not stop, in fact reported to master that its up without regions. So master assigned regions to it. Regionserver would not accept them, resulting in a constant assign, reject, reassign cycle, that put many regions into a state of not being available. There are no logs about this, but we could observer the regioncount fluctuate by hundredths of regions and the application throwing many NotServingRegion exceptions.  

In fact to the master process the regionserver looked fine, so it was trying to send regions its way. Regionserver rejected them. So the master/balancer was going into a assign/reassign cycle destabilizing the cluster. Many puts and gets simply failed with NotServingRegionExceptions and took a long time to complete.

Exception from regionserver:
2011-08-06 23:57:13,953 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: SyncConnected, type: NodeCreated, path: /hbase/master
2011-08-06 23:57:13,957 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Telling master at 17.1.0.1:60000 that we are up
2011-08-06 23:57:13,957 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Telling master at 17.1.0.1:60000 that we are up
2011-08-07 00:07:39.648::INFO:  Logging to STDERR via org.mortbay.log.StdErrLog
2011-08-07 00:07:39.712::INFO:  jetty-6.1.14
2011-08-07 00:07:39.742::WARN:  tmpdir
java.io.IOException: Permission denied
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.checkAndCreate(File.java:1704)
        at java.io.File.createTempFile(File.java:1792)
        at java.io.File.createTempFile(File.java:1828)
        at org.mortbay.jetty.webapp.WebAppContext.getTempDirectory(WebAppContext.java:745)
        at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:458)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
        at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
        at org.mortbay.jetty.Server.doStart(Server.java:222)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.apache.hadoop.http.HttpServer.start(HttpServer.java:461)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.startServiceThreads(HRegionServer.java:1168)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:792)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:430)
        at java.lang.Thread.run(Thread.java:619)

Exception from datanode:
2011-08-06 23:37:20,444 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50075
2011-08-06 23:37:20,444 INFO org.mortbay.log: jetty-6.1.14
2011-08-06 23:37:20,469 WARN org.mortbay.log: tmpdir
java.io.IOException: Permission denied
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.checkAndCreate(File.java:1704)
        at java.io.File.createTempFile(File.java:1792)
        at java.io.File.createTempFile(File.java:1828)
        at org.mortbay.jetty.webapp.WebAppContext.getTempDirectory(WebAppContext.java:745)
        at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:458)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
        at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
        at org.mortbay.jetty.Server.doStart(Server.java:222)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.apache.hadoop.http.HttpServer.start(HttpServer.java:463)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:384)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:225)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1309)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1264)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1272)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1394)
2011-08-06 23:37:20,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hdp1122/17.1.0.22
************************************************************/

Exception from tasktracker:
2011-08-06 23:33:50,380 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50060
2011-08-06 23:33:50,380 INFO org.mortbay.log: jetty-6.1.14
2011-08-06 23:33:50,415 WARN org.mortbay.log: tmpdir
java.io.IOException: Permission denied
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.checkAndCreate(File.java:1704)
        at java.io.File.createTempFile(File.java:1792)
        at java.io.File.createTempFile(File.java:1828)
        at org.mortbay.jetty.webapp.WebAppContext.getTempDirectory(WebAppContext.java:745)
        at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:458)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
        at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
        at org.mortbay.jetty.Server.doStart(Server.java:222)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.apache.hadoop.http.HttpServer.start(HttpServer.java:463)
        at org.apache.hadoop.mapred.TaskTracker.<init>(TaskTracker.java:935)
        at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:2837)
2011-08-06 23:33:50,416 INFO org.apache.hadoop.mapred.TaskTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down TaskTracker at hdp1122/17.1.0.22
************************************************************/


"
HBASE-6678,"In TestMergeTool, we pick an ""unlikely"" port for zookeeper to be on.  Perhaps it would be better if this was a privileged port < 1024.

{code}
    // Make it so we try and connect to a zk that is not there (else we might
    // find a zk ensemble put up by another concurrent test and this will
    // mess up this test.  Choose unlikely port. Default test port is 21818.
    // Default zk port is 2181.
    this.conf.setInt(HConstants.ZOOKEEPER_CLIENT_PORT, 10001);
{code}"
HBASE-2894,"{code:title=MultiPut.java}
public class MultiPut implements Writable {
  public HServerAddress address; // client code ONLY                                              
        
  // map of regions to lists of puts for that region.                                             
  public Map<byte[], List<Put> > puts = new TreeMap<byte[], List<Put>>(Bytes.BYTES_COMPARATOR);
[...]
{code}
I don't see any reason for those fields to be public.  Let's make sure this doesn't leak to a stable release, otherwise it becomes part of the API.

Fixing this issue may be pointless if this ever happens: http://su.pr/1SG7fB

_edit:_ Similarly, {{MultiPutResponse}} has two fields that are {{protected}}, but need not to be:
{code:title=MultiPutResponse.java}
public class MultiPutResponse implements Writable {
                
  protected MultiPut request; // used in client code ONLY
                  
  protected Map<byte[], Integer> answers = new TreeMap<byte[], Integer>(Bytes.BYTES_COMPARATOR);
[...]
{code}"
HBASE-5559,"HBASE-4440 adds a 'presplit' option to PerformanceEvaluation utility.

when the splits are generated, the first split has row-end-key=0 (zero).  Hence this split doesn't get any data.

For example, 
if total keyspace is 100, and splits requested are 5, 
generated splits => [0, 20, 40, 60, 80]
it should be => [20, 40, 60, 80, 100]"
HBASE-7640,"ERROR: Found lingering reference file
hdfs://node3:9000/hbase/entry_proposed/fbd1735591467005e53f48645278b006/recovered.edits/0000000000091843039.temp

recovered.edits is not a column family."
HBASE-10515,"Here is related code:
{code}
    if (tableDir == null || regionDir == null) {
      LOG.error(""No archive directory could be found because tabledir ("" + tableDir
          + "") or regiondir ("" + regionDir + ""was null. Deleting files instead."");
      deleteRegionWithoutArchiving(fs, regionDir);
{code}
When regionDir is null, calling deleteRegionWithoutArchiving() would lead to NPE in FileSystem.delete()."
HBASE-5285,"#On YCSB client machine:
/usr/local/bin/java -cp ""build/ycsb.jar:db/hbase/lib/*:db/hbase/conf/"" com.yahoo.ycsb.Client -load -db com.yahoo.ycsb.db.HBaseClient -P workloads/workloada -p columnfamily=family1 -p recordcount=5000000 -s > load.dat

loaded 5mil records, that created 8 regions. (balanced all onto the same RS)

/usr/local/bin/java -cp ""build/ycsb.jar:db/hbase/lib/*:db/hbase/conf/"" com.yahoo.ycsb.Client -t -db com.yahoo.ycsb.db.HBaseClient -P workloads/workloada -p columnfamily=family1 -p operationcount=5000000 -threads 10 -s > transaction.dat



#On RS that was holding the 8 regions above. 
2012-01-25 23:23:51,556 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x134f70a343101a0 Successfully transitioned node 162702503c650e551130e5fb588b3ec2 from RS_ZK_REGION_SPLIT to RS_ZK_REGION_SPLIT
2012-01-25 23:23:51,616 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
java.lang.RuntimeException: Cached an already cached block
at org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(LruBlockCache.java:268)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:276)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:487)
at org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(HalfStoreFileReader.java:168)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:181)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:111)
at org.apache.hadoop.hbase.regionserver.StoreScanner.<init>(StoreScanner.java:83)
at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1721)
at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.<init>(HRegion.java:2861)
at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1432)
at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1424)
at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1400)
at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3688)
at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3581)
at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1771)
at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1325)
2012-01-25 23:23:51,656 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x134f70a343101a0 Attempting to transition node 162702503c650e551130e5fb588b3ec2 from RS_ZK_REGION_SPLIT to RS_ZK_REGION_SPLIT"
HBASE-1037,"I've been running tests under Windows/Cygwin while on the road. Meanwhile they are not failing on Hudson. 

* TestInfoServers and TestTableMapReduce fail with timeout.

* TestThriftServer fails with an assertion failure related to timestamps.
"
HBASE-9657,"In FSHLog#syncer(), we have this comment:
{code}
      // TODO: preserving the old behavior for now, but this check is strange. It's not
      //       protected by any locks here, so for all we know rolling locks might start
      //       as soon as we enter the ""if"". Is this best-effort optimization check?
      if (!this.logRollRunning) {
        checkLowReplication();
{code}
The implication is that checkLowReplication() may be running when FSHLog#rollWriter() is also running."
HBASE-9,"I got this exception using a post-0.15.0 hbase trunk:

Caused by: java.io.IOException: java.io.IOException: java.lang.ArrayIndexOutOfBoundsException

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
	at java.lang.reflect.Constructor.newInstance(Unknown Source)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
	at org.apache.hadoop.hbase.HTable.commit(HTable.java:904)
	at org.apache.hadoop.hbase.HTable.commit(HTable.java:875)
	at xxx.PutHbase$HbaseUploader.writeHbaseNoRetry(PutHbase.java:107)


Where writeHbaseNoRetry looks like:

    private void writeHbaseNoRetry(HTable table, String column, String row, File contents) throws IOException {
      long lockid = table.startUpdate(new Text(row));
      try {
        table.put(lockid, new Text(column), FileUtil.readFile(contents));
        table.commit(lockid);
      } finally {
        table.abort(lockid);
      }
    }

I found this in my error logs -- it is rare, and I am not sure how to reproduce it.  Contents could be 1kb-100kb long.
"
HBASE-3667,"Last night on one of our clusters I ran into the strange problem where metrics were showing in jmx, all but request rate seemingly.  Then, I restarted a single cluster member and it started reporting requests/second.  I did a few others and they started working.  Its strange.  Gary was helping out and noted that requests is only metric to use new MetricsRate otherwise, its not clear why it'd go wonky.  This issue is placeholder for figuring out whats up here."
HBASE-22,"Here's a couple of exceptions thrown by hql that should be fixed as we go:

{code}
08/01/24 10:39:42 INFO hbase.HConnectionManager$TableServers: Attempt 3 of 5 failed with <java.net.ConnectException: Connection refused>. Retrying after sleep of 10000 
08/01/24 10:39:52 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 1 time(s).08/01/24 10:39:53 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 2 time(s).
08/01/24 10:39:54 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 3 time(s).08/01/24 10:39:55 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 4 time(s).
08/01/24 10:39:56 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 5 time(s).08/01/24 10:39:57 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 6 time(s).
08/01/24 10:39:58 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 7 time(s).08/01/24 10:39:59 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 8 time(s).
08/01/24 10:40:00 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 9 time(s).
08/01/24 10:40:02 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 10 time(s).
08/01/24 10:40:03 WARN hbase.HConnectionManager$TableServers: Testing for table existence threw exception
org.apache.hadoop.hbase.MasterNotRunningException
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.getMaster(HConnectionManager.java:202)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRootRegion(HConnectionManager.java:691)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:329)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.relocateRegion(HConnectionManager.java:311)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:476)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:339)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.relocateRegion(HConnectionManager.java:311)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.listTables(HConnectionManager.java:291)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.tableExists(HConnectionManager.java:227)
        at org.apache.hadoop.hbase.hql.CreateCommand.execute(CreateCommand.java:49)
        at org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)
Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.hadoop.hbase.hql.BasicCommand.extractErrMsg(BasicCommand.java:62)
        at org.apache.hadoop.hbase.hql.BasicCommand.extractErrMsg(BasicCommand.java:68)
        at org.apache.hadoop.hbase.hql.CreateCommand.execute(CreateCommand.java:67)
        at org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)
{code}

or


{code}
Hbase> create table log(uname, uid);
Creating table... Please wait.
Exception in thread ""main"" java.lang.StringIndexOutOfBoundsException: String index out of range: -1
        at java.lang.String.substring(String.java:1938)
        at org.apache.hadoop.hbase.shell.BasicCommand.extractErrMsg(BasicCommand.java:60)
        at org.apache.hadoop.hbase.shell.BasicCommand.extractErrMsg(BasicCommand.java:64)
        at org.apache.hadoop.hbase.shell.CreateCommand.execute(CreateCommand.java:61)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:96)
[hadoop@latewhatgrow-lx bin]$ 
{code}
{code}"
HBASE-15,"I've spent some time looking into this issue but there are not enough clues in the logs to tell where the problem is. Here's what I know.

Two region servers went down last night, a minute apart, during Paul Saab's 6hr run inserting 300million rows into hbase. The regionservers went down to force rerun of hlog and avoid possible data loss after a failure writing memory flushes to hdfs.

Here is the lead up to the failed flush:

...
2007-11-28 22:40:02,231 INFO  hbase.HRegionServer - MSG_REGION_OPEN : regionname: postlog,img149/4699/133lm0.jpg,1196318393738, startKey: <img149/4699/133lm0.jpg>, tableDesc: {name: postlog, families: {cookie:={name: cookie, max versions: 1, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, ip:={name: ip, max versions: 1, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}}}
2007-11-28 22:40:02,242 DEBUG hbase.HStore - starting 1703405830/cookie (no reconstruction log)
2007-11-28 22:40:02,741 DEBUG hbase.HStore - maximum sequence id for hstore 1703405830/cookie is 29077708
2007-11-28 22:40:03,094 DEBUG hbase.HStore - starting 1703405830/ip (no reconstruction log)
2007-11-28 22:40:03,852 DEBUG hbase.HStore - maximum sequence id for hstore 1703405830/ip is 29077708
2007-11-28 22:40:04,138 DEBUG hbase.HRegion - Next sequence id for region postlog,img149/4699/133lm0.jpg,1196318393738 is 29077709
2007-11-28 22:40:04,141 INFO  hbase.HRegion - region postlog,img149/4699/133lm0.jpg,1196318393738 available
2007-11-28 22:40:04,141 DEBUG hbase.HLog - changing sequence number from 21357623 to 29077709
2007-11-28 22:40:04,141 INFO  hbase.HRegionServer - MSG_REGION_OPEN : regionname: postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739, startKey: <img149/7512/dscn4444lightenedfi3.jpg>, tableDesc: {name: postlog, families: {cookie:={name: cookie, max versions: 1, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, ip:={name: ip, max versions: 1, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}}}
2007-11-28 22:40:04,145 DEBUG hbase.HStore - starting 376748222/cookie (no reconstruction log)
2007-11-28 22:40:04,223 DEBUG hbase.HStore - maximum sequence id for hstore 376748222/cookie is 29077708
2007-11-28 22:40:04,277 DEBUG hbase.HStore - starting 376748222/ip (no reconstruction log)
2007-11-28 22:40:04,353 DEBUG hbase.HStore - maximum sequence id for hstore 376748222/ip is 29077708
2007-11-28 22:40:04,699 DEBUG hbase.HRegion - Next sequence id for region postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739 is 29077709
2007-11-28 22:40:04,701 INFO  hbase.HRegion - region postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739 available
2007-11-28 22:40:34,427 DEBUG hbase.HRegionServer - flushing region postlog,img143/1310/yashrk3.jpg,1196317258704
2007-11-28 22:40:34,428 DEBUG hbase.HRegion - Not flushing cache for region postlog,img143/1310/yashrk3.jpg,1196317258704: snapshotMemcaches() determined that there was nothing to do
2007-11-28 22:40:55,745 DEBUG hbase.HRegionServer - flushing region postlog,img142/8773/1001417zc4.jpg,1196317258703
2007-11-28 22:40:55,745 DEBUG hbase.HRegion - Not flushing cache for region postlog,img142/8773/1001417zc4.jpg,1196317258703: snapshotMemcaches() determined that there was nothing to do
2007-11-28 22:41:04,144 DEBUG hbase.HRegionServer - flushing region postlog,img149/4699/133lm0.jpg,1196318393738
2007-11-28 22:41:04,144 DEBUG hbase.HRegion - Started memcache flush for region postlog,img149/4699/133lm0.jpg,1196318393738. Size 74.7k
2007-11-28 22:41:04,764 DEBUG hbase.HStore - Added 1703405830/ip/610047924323344967 with sequence id 29081563 and size 53.8k
2007-11-28 22:41:04,902 DEBUG hbase.HStore - Added 1703405830/cookie/3147798053949544972 with sequence id 29081563 and size 41.3k
2007-11-28 22:41:04,902 DEBUG hbase.HRegion - Finished memcache flush for region postlog,img149/4699/133lm0.jpg,1196318393738 in 758ms, sequenceid=29081563
2007-11-28 22:41:04,902 DEBUG hbase.HStore - compaction for HStore postlog,img149/4699/133lm0.jpg,1196318393738/ip needed.
2007-11-28 22:41:04,903 DEBUG hbase.HRegion - 1703405830/ip needs compaction
2007-11-28 22:41:04,903 INFO  hbase.HRegion - starting compaction on region postlog,img149/4699/133lm0.jpg,1196318393738
2007-11-28 22:41:04,903 DEBUG hbase.HStore - started compaction of 4 files in /hbase/compaction.dir/hregion_1703405830/ip
2007-11-28 22:41:04,905 DEBUG hbase.HRegionServer - flushing region postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739
2007-11-28 22:41:04,906 DEBUG hbase.HRegion - Started memcache flush for region postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739. Size 133.1k
2007-11-28 22:41:05,087 DEBUG hbase.HStore - Added 376748222/ip/8686640221458382286 with sequence id 29081604 and size 95.8k
2007-11-28 22:41:05,419 FATAL hbase.HRegionServer - Replay of hlog required. Forcing server restart
org.apache.hadoop.hbase.DroppedSnapshotException: java.io.IOException: Could not complete write to file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data by DFSClient_-1010714652
	at org.apache.hadoop.dfs.NameNode.complete(NameNode.java:323)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

	at org.apache.hadoop.hbase.HRegion.internalFlushcache(HRegion.java:920)
	at org.apache.hadoop.hbase.HRegion.flushcache(HRegion.java:807)
	at org.apache.hadoop.hbase.HRegionServer$Flusher.run(HRegionServer.java:451)
...

Over in the namenode, I see the following related to the deleted file:

2007-11-28 22:40:48,546 DEBUG dfs.StateChange - *DIR* NameNode.mkdirs: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,546 DEBUG dfs.StateChange - DIR* NameSystem.mkdirs: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,546 DEBUG dfs.StateChange - DIR* FSDirectory.mkdirs: created directory /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,552 DEBUG dfs.StateChange - *DIR* NameNode.create: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652 at XX.XX.XX.29
2007-11-28 22:40:48,552 DEBUG dfs.StateChange - DIR* NameSystem.startFile: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652 at XX.XX.XX.29
2007-11-28 22:40:48,552 DEBUG dfs.StateChange - DIR* FSDirectory.addFile: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data is added to the file system
2007-11-28 22:40:48,552 DEBUG dfs.StateChange - DIR* NameSystem.startFile: add /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data to namespace for DFSClient_-1010714652
2007-11-28 22:40:48,557 DEBUG dfs.StateChange - *DIR* NameNode.create: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/index for DFSClient_-1010714652 at XX.XX.XX.29
2007-11-28 22:40:48,557 DEBUG dfs.StateChange - DIR* NameSystem.startFile: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/index for DFSClient_-1010714652 XX.XX.XX.29
2007-11-28 22:40:48,558 DEBUG dfs.StateChange - DIR* FSDirectory.addFile: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/index is added to the file system
2007-11-28 22:40:48,558 DEBUG dfs.StateChange - DIR* NameSystem.startFile: add /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/index to namespace for DFSClient_-1010714652
2007-11-28 22:40:48,573 DEBUG dfs.StateChange - *BLOCK* NameNode.addBlock: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652
2007-11-28 22:40:48,573 DEBUG dfs.StateChange - BLOCK* NameSystem.getAdditionalBlock: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652
2007-11-28 22:40:48,573 DEBUG dfs.StateChange - DIR* FSDirectory.addFile: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data with blk_-6398846109350112398 block is added to the in-memory file system
2007-11-28 22:40:48,573 INFO  dfs.StateChange - BLOCK* NameSystem.allocateBlock: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data. blk_-6398846109350112398
.....
2007-11-28 22:40:48,717 DEBUG dfs.StateChange - *DIR* NameNode.delete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,717 DEBUG dfs.StateChange - DIR* NameSystem.delete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,717 DEBUG dfs.StateChange - DIR* FSDirectory.delete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,717 DEBUG dfs.StateChange - DIR* FSDirectory.unprotectedDelete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411 is removed
....
2007-11-28 22:40:48,826 DEBUG dfs.StateChange - *DIR* NameNode.complete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652
2007-11-28 22:40:48,826 DEBUG dfs.StateChange - DIR* NameSystem.completeFile: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652
2007-11-28 22:40:48,827 WARN  dfs.StateChange - DIR* NameSystem.completeFile: failed to complete /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data because dir.getFileBlocks() is null  and pendingFile is null

Only delete I see is on compaction completion but reading code doesn't look like its possible for deletes to be confused.

Will add extra logging to see if I can figure how the delete is coming about.

(We've fixed a similar problem before when compactions were done at region level)"
HBASE-235,"I dropped a table with 121 regions, ans read from the web UI. Afterwards, most of the regions went away, but 6 remained counted and listed in the web UI. select * from .META. shows no rows, so in reality the regions are gone. This inconsistency gives a poor sense of the consistency of HBase."
HBASE-404,"Before HADOOP-2738, it was impossible to subclass Text and have it obey the ISA semantics because Text instances would directly access other instances private members. Now that this has been fixed, fix TextSequence so it really can be used wherever a Text can be used."
HBASE-26,"See 'stack - 30/Oct/07 09:51 PM' comment over in HADOOP-2083 for description of an error or see here: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/970/testReport/org.apache.hadoop.hbase.mapred/TestTableIndex/testTableIndex/

Seems like its a rare occurrence."
HBASE-6966,"This jira will address the port of the compressed RPC implementation to trunk. I am expecting the patch to be significantly different due to the PB stuff in trunk, and hence filed a separate jira."
HBASE-13459,"We have done quite a bit of data center migration work in the past year.  We modified verify replication a bit to help us out.

Things like:
Ignoring timestamps when comparing Cells
More detailed counters when discrepancies are reported between rows added the following counters: 
SOURCEMISSINGROWS,TARGETMISSINGROWS,SOURCEMISSINGKEYS, TARGETMISSINGKEYS
Also added the ability to run this job on any pair of tables and clusters.

If folks are interested I can put up the patch and backport.
"
HBASE-13031,"Posted on the mailing list and seems like some people are interested.  A little background for everyone.

We have a very large table, we would like to snapshot and transfer the data to another cluster (compressed data is always better to ship).  Our problem lies in the fact it could take many weeks to transfer all of the data and during that time with major compactions, the data stored in dfs has the potential to double which would cause us to run out of disk space.

So we were thinking about allowing the ability to snapshot a specific key range.  

Ideally I feel the approach is that the user would specify a start and stop key, those would be associated with a region boundary.  If between the time the user submits the request and the snapshot is taken the boundaries change (due to merging or splitting of regions) the snapshot should fail.

We would know which regions to snapshot and if those changed between when the request was submitted and the regions locked, the snapshot could simply fail and the user would try again, instead of potentially giving the user more / less than what they had anticipated.  I was planning on storing the start / stop key in the SnapshotDescription and from there it looks pretty straight forward where we just have to change the verifier code to accommodate the key ranges.  

If this design sounds good to anyone, or if I am overlooking anything please let me know.  Once we agree on the design, I'll write and submit the patches.
"
HBASE-5338,"It'd be nice to have support for ""SKIP"" mappings so that you can omit columns from the TSV during the import. For example

{code}
-Dimporttsv.columns=SKIP,HBASE_ROW_KEY,cf1:col1,cf1:col2,SKIP,SKIP,cf2:col1...
{code}

Or maybe HBASE_SKIP_COLUMN to be less ambiguous. "
HBASE-5585,"From IRC 

{noformat}
sulabhc	St^Ack: that fixed most of the issue, just one last question, I removed some META entries how do I put it back ?
sulabhc	St^Ack: putting from Hbase-shell does not seem to be possible
St^Ack	sulabhc: it is but the content in .META. is serialized Writable of HRegionInfo.
St^Ack	Can you find the region in the fs that you want to put back?
St^Ack	If so, cat its .regioninfo
St^Ack	it has binary format of the HRegionInfo that needs to be in .META. and a txt version.
St^Ack 	You'll need to create an HRegionInfo, serialize it as bytes, and then put that into .META.
St^Ack	Look around in the catalog package, the MetaEditor class, for how to do this from java.
St^Ack	We should really make this easier to do in shell...
St^Ack	or look in bin to see how we do some of this via (j)ruby
{noformat}"
HBASE-5993,"HBASE-4102 added an atomic append.  For high performance situations, it would be helpful to be able to do appends that don't actually require a read of the existing value.  This would be useful in building a growing set of values.  Our original use case was for implementing a form of search in HBase where a cell would contain a list of document ids associated with a particular keyword for search.  However it seems like it would also be useful to provide substantial performance improvements for most Append scenarios.

Within the client API, the simplest way to implement this would be to leverage the existing Append api.  If the Append is marked as setReturnResults(false), use this code path.  If result return is requested, use the existing Append implementation.  

"
HBASE-7890,Add an index number before each region would make it easier to locate a region on the page.
HBASE-7891,Adding an index number for each table region in table.jsp would make it easier to locate a region or to count regions.
HBASE-2325,"In order to run jcarder on the unit tests, it's handy to be able to add jvm args to the junit test runner. This trivial patch adds a hook for this. Unfortunately I don't know much about maven, someone will have to help me for trunk."
HBASE-2143,This was discussed in HBASE-2021. The compaction queue details is only exposed on RegionServer level but should be aggregated to the master metrics so that the total current status can be graphed. Since we change the RPC version anyways it is easy to add the to HServerLoad.
HBASE-5268,"This is another part missing in the ""wide row challenge"".
Currently entire families of a row can be deleted or individual columns or versions.
There is no facility to mark multiple columns for deletion by column prefix.

Turns out that be achieve with very little code (it's possible that I missed some of the new delete bloom filter code, so please review this thoroughly). I'll attach a patch soon, just working on some tests now.
"
HBASE-13879,
HBASE-1990,"Consider the following client code...

	byte b[] = result.getValue( Bytes.toBytes(""family""), Bytes.toBytes(""qualifier"") );
        put.add( Bytes.toBytes(""family""), Bytes.toBytes(""qualifer""), Bytes.toBytes( ""value"")  );

... the requirement to supply family and qualifiers as bytes causes code to get cluttered and verbose.  At worst, it scares peoples un-necessarily about HBase development, and at best, developers inevitably will get tired of doing all this casting and then add their own wrapper classes around the HBase client to make their code more readable.

I would like to see something like this in the API...

	byte b[] = result.getValue( ""family""), ""qualifier"" );
        put.add( ""family"", ""qualifer"", Bytes.toBytes( ""value"")  );

... where the Hbase client can perform the required Bytes.toBytes() conversion behind the scenes.




"
HBASE-12494,
HBASE-3157,"New Increment class from HBASE-2946 is not exactly the same as the existing ICV call.  It does not iterate the snapshot and check for existing columns with the same version number.  Instead we rely on correct ordering from our read operations.

Should add a good unit test to verify this works as advertised."
HBASE-14356,Parent issue added a timeout rule. The rule needs to be mentioned in all tests to take effect. Add it.
HBASE-3616,"HBASE-3507 added per region request count.
We should utilize this information so that HServerLoad can provide moving average of request counts to load balancer.
We can update this method in HRegionServer:
{code}
  private HServerLoad buildServerLoad() {
{code}
The above method can aggregate request counts from HRegions and store it in HServerLoad.RegionLoad"
HBASE-5601,In addition to the overall block cache hit ratio it would be extremely useful to have per-column-family data block cache hit ratio metrics.
HBASE-3840,"A common user error (and even hbase dev error) is to pass a vanilla Hadoop Configuration into HBase methods that expect to see all of the relevant hbase defaults from hbase-default.xml. This often results in NPE or issues locating ZK.

We should add a method like HBaseConfiguration.verify(conf) which ensures that the conf has incorporated hbase-default.xml. We can do this by checking for existence of hbase.defaults.for.version."
HBASE-12889,We use the copy table job to ship data between clusters.  Sometimes we have very wide rows and it is nice to be able to set the batching and caching.  I'll attach trivial patches for you guys.
HBASE-2434,"An option of number of rows to fetch every time we hit a region server should be added to mapreduce.Export so that createSubmittableJob() calls s.setCaching() with the specified value.

Also, an option of write buffer size should be added to mapreduce.Import so that we can set write buffer. Sample calls:
+    table.setAutoFlush(false);
+    table.setWriteBufferSize(desired_buffer_size);
"
HBASE-5512,"This came up from HBASE-2038
From Anoop:

- What we wanted from the filter is include a row and then seek to the next row which we are interested in. I cant see such a facility with our Filter right now. Correct me if I am wrong. So suppose we already seeked to one row and this need to be included in the result, then the Filter should return INCLUDE. Then when the next next() call happens, then only we can return a SEEK_USING_HINT. So one extra row reading is needed. This might create even one unwanted HFileBlock fetch (who knows).
Can we add reseek() at higher level?

From Lars:
Yep, for that we'd need to add INCLUDE_AND_SEEK_USING_HINT (similar to the INCLUDE_AND_SEEK_NEXT_ROW that we already have). Shouldn't be hard to add, I'm happy to do that, if that's the route we want to go with this."
HBASE-15175,"Currently JavaHBaseContext has methods for bulkPut, bulkDelete, etc

It is desirable to add support for checkAndPut, checkAndMutate, checkAndDelete as well.

See related thread:
http://search-hadoop.com/m/YGbbt3Szd24Vtpr&subj=Re+HBase+atomic+update

Thanks [~zzhan] for offline discussion"
HBASE-7846,"Currently org.apache.hadoop.hbase.util.Merge needs 2 region names to be explicitly specified to perform a merge.  This can be cumbersome.
One idea for improvement is to have Merge to figure out all the adjacent regions and perform the merges.  

For example:
regions before merge: row-10, row-20, row-30, row-40, row-50
regions after merge: row-10, row-30, row-50

In the above example, region names of ""row-10"" and ""row-20"" are merged to become a new bigger region of ""row-10""."
HBASE-2991,"-refreshNodes capabilities should be added to bin/hbase (or to a new script called `hbaseadmin`, if we want to maintain command name consistency) with cluster exclusion functionality similar to the capabilities of dfsadmin and mradmin. For ease of adminis"
HBASE-7358,
HBASE-765,"Spring can configure classes/object graphs via xml.  I am pretty much able to configure the entire MR object graph to launch MR jobs via spring except class IndexConfiguration.java. So instead of only using addFromXML() to configure IndexConfiguration, it would be nice to add support so Spring could set all class variables needed for initialization in IndexConfiguration without invoking addFromXML().  

Since the class IndexConfiguration already has setters and getters for almost all its members, it's almost compliant for a spring configuration bean except one issue: no ability to configure columnMap outside of calling addFromXML().  The easiest way i can figure is to allow a setter for the column map and put any logic for checking the map integrity there.  By adding a few methods to IndexConfiguration.java , it should solve the issue.


"
HBASE-7169,"HTableMultiplexer is a useful client library for isolating regionserver failures, especially for clients that talk to several regionservers at a high throughput. It exposes useful metrics to the client on how many puts failed per regionserver. This patch adds average/max latency counters as well."
HBASE-470,"{code}
Problem 1.

hql > help enable;
Syntax error : Type 'help;' for usage.
hql > help disable;
Syntax error : Type 'help;' for usage.
..... ???

Added Feature 1.

hql > disable all;
hql > enable all;
hql > drop all;
{code}"
HBASE-4612,"When having a lot of columns grouped by name I've found that it would be very useful to be able to scan them using multiple prefixes, allowing to fetch specific groups in one scan, without fetching the entire row. This is impossible to achieve using a FilterList, so I've added such support to the existing ColmnPrefixFilter while keeping backward compatibility.
The attached patch is based on 0.90.4, I noticed that the 0.92 branch has a new method to support instantiating filters using Thrift. I'm not sure how the serialization works there so I didn't implement that, but the rest of my code should work in 0.92 as well.
"
HBASE-10681,"pom.xml in hbase write as

 <distributionManagement>
    <site>
      <id>hbase.apache.org</id>
      <name>HBase Website at hbase.apache.org</name>
      <!-- On why this is the tmp dir and not hbase.apache.org, see
               https://issues.apache.org/jira/browse/HBASE-7593?focusedCommentId=13555866&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13555866
               -->
      <url>file:///tmp</url>
    </site>

We expect pom.xml in hbase like hadoop can be:

 <distributionManagement>
  <repository>
      <id>${distMgmtStagingId}</id>
      <name>${distMgmtStagingName}</name>
      <url>${distMgmtStagingUrl}</url>
    </repository>
    <snapshotRepository>
      <id>${distMgmtSnapshotsId}</id>
      <name>${distMgmtSnapshotsName}</name>
      <url>${distMgmtSnapshotsUrl}</url>
    </snapshotRepository>
    <site>
      <id>hbase.apache.org</id>
      <name>HBase Website at hbase.apache.org</name>
      <!-- On why this is the tmp dir and not hbase.apache.org, see
               https://issues.apache.org/jira/browse/HBASE-7593?focusedCommentId=13555866&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13555866
               -->
      <url>file:///tmp</url>
    </site>
  </distributionManagement>
"
HBASE-5475,"Currently importtsv (and now also Import with HBASE-5440) support using HFileOutputFormat for later bulk loading.
However, currently that cannot be without having access to the table we're going to import to, because both importtsv and Import need to lookup the split points, and find the compression setting.
It would be nice if there would be an offline way to provide the split point and compression setting.
"
HBASE-5311,"Just like we periodically compact the StoreFiles we should also periodically compact the MemStore.
During these compactions we eliminate deleted cells, expired cells, cells to removed because of version count, etc, before we even do a memstore flush.

Besides the optimization that we could get from this, it should also allow us to remove the special handling of ICV, Increment, and Append (all of which use upsert logic to avoid accumulating excessive cells in the Memstore).

Not targeting this."
HBASE-5954,At least get recommendation into 0.96 doc and some numbers running w/ this hdfs feature enabled.
HBASE-15075,"During the process of improving region normalization feature, I found that if region split request triggered by the execution of SplitNormalizationPlan fails, there is no way of knowing whether the failed split originated from region normalization.

The association of particular split request with outcome of split would give RegionNormalizer information so that it can make better normalization decisions in the subsequent invocations.

One approach is to embed metadata, such as a UUID, in SplitRequest which gets passed through RegionStateTransitionContext when RegionServerServices#reportRegionStateTransition() is called.
This way, RegionStateListener can be notified with the metadata (id of the requester).

See discussion on dev mailing list
http://search-hadoop.com/m/YGbbCXdkivihp2"
HBASE-2817,"Right now we have a single HBASE_HEAPSIZE configuration. This isn't that great, since the HMaster doesn't really need much ram compared to the region servers. We should allow different java options and heapsize for the different daemon types.

Probably worth breaking out THRIFT, REST, AVRO, etc, as well."
HBASE-3150,"We have this unique requirement where some column families hold data that is indexed from other existing column families. The index data is very large, and we end up writing these inserts into the WAL and then into the store files. In addition to taking more iops, this also slows down splitting files for recovery, etc.

Creating this task to have an option to suppress WAL logging on a per CF basis."
HBASE-3779,"Currently daughter regions are placed on the same region server where the parent region was.
Stanislav Barton mentioned the idea that load information should be considered when placing the daughter regions.
The rationale is that the daughter regions tend to receive more writes. So it would be beneficial to place at least one daughter region on a different region server."
HBASE-10947,To extend functionality of HTable and HBaseAdmin we may need to subclass them. This JIRA allows to add a default constructor and probably remove the final variables in them so that we could subclass them.
HBASE-610,"HBASE-609 has an example of clock skew making it so master scanner missed edits placed there by a regionserver whose clock was in advance of the masters.  There may be other cases lurking where this kind of issue -- two servers are updating a particular row with off-clocks -- may bite us.  Could a regionserver that has a clock a long ways behind the running master's clock enter a split record that went in behind the current inforegion cell's version?  If so, the master wouldn't see the split.

One fix would be a new feature where cells had a version that autoincremented."
HBASE-21150,"After HBASE-15728 is integrated, the lazy table metrics registration results in penalty for the first flushes.
Excerpt from log shows delay (note the same timestamp 08:18:23,234) :
{code:java}
2018-09-02 08:18:23,232 DEBUG [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-2] regionserver.MetricsTableSourceImpl(124): Creating new                      MetricsTableSourceImpl for table 'testtb-1535901500805'
2018-09-02 08:18:23,233 DEBUG [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-2] regionserver.MetricsTableSourceImpl(137): registering metrics for testtb-   1535901500805
2018-09-02 08:18:23,234 INFO  [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-1] regionserver.HRegion(2822): Finished flush of dataSize ~2.29 KB/2343,       heapSize ~5.16 KB/5280, currentSize=0 B/0 for fa403f6a4fb8dbc1a1c389744fce2d58 in 280ms, sequenceid=5, compaction requested=false
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52758,1535901497238)-snapshot-pool11-thread-1] regionserver.MetricsTableAggregateSourceImpl(84): it took 6 ms to register  testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52758,1535901497238)-snapshot-pool11-thread-1,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-1] regionserver.MetricsTableAggregateSourceImpl(84): it took 0 ms to register  testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-1,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52762,1535901497314)-snapshot-pool9-thread-1] regionserver.MetricsTableAggregateSourceImpl(84): it took 6 ms to register   testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52762,1535901497314)-snapshot-pool9-thread-1,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52762,1535901497314)-snapshot-pool9-thread-2] regionserver.MetricsTableAggregateSourceImpl(84): it took 6 ms to register   testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52762,1535901497314)-snapshot-pool9-thread-2,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52758,1535901497238)-snapshot-pool11-thread-2] regionserver.MetricsTableAggregateSourceImpl(84): it took 5 ms to register  testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52758,1535901497238)-snapshot-pool11-thread-2,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-2] regionserver.MetricsTableAggregateSourceImpl(84): it took 6 ms to register  testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-2,5,FailOnTimeoutGroup]
{code}
This is a regression in that there were multiple (6 ms) delays before the flush can finish, waiting for the metrics table to be registered.

When first region of the table is opened on region server, we can proactively register table metrics.
This would avoid the penalty on first flushes for the table."
HBASE-16888,"a) If the delta has tags and the mutation doesn鈥檛 apply the TTL, we shouldn鈥檛 create the TagRewriteCell.
{noformat}

    List<Tag> tags = TagUtil.carryForwardTags(delta);
    long ts = now;
    Cell newCell = null;
    byte [] row = mutation.getRow();
    if (currentValue != null) {
     ...
    } else {
      // Append's KeyValue.Type==Put and ts==HConstants.LATEST_TIMESTAMP
      CellUtil.updateLatestStamp(delta, now);
      newCell = delta;
      tags = TagUtil.carryForwardTTLTag(tags, mutation.getTTL());
      if (tags != null) {
        newCell = CellUtil.createCell(delta, tags);
      }
    }

{noformat}

b) If the cell has tags, the ShareableMemoryTagRewriteCell will make duplicate copy of tags. 
{noformat}

      Cell clonedBaseCell = ((ShareableMemory) this.cell).cloneToCell();
      return new TagRewriteCell(clonedBaseCell, this.tags);

{noformat}

"
HBASE-10174,"On user mailing list under the thread 'Guava 15', Kristoffer Sj枚gren reported NoClassDefFoundError when he used Guava 15.

The issue has been fixed in 0.96 + by HBASE-9667

This JIRA ports the fix to 0.94 branch"
HBASE-13017,Lets backport that feature to branch-1.0 adapting HBASE-12035 
HBASE-14289,"The default HBase load balancer (the Stochastic load balancer) is cost function based. The cost function weights are tunable but no visibility into those cost function results is directly provided.

This issue backports HBASE-13965 to 0.98 branch to provide visibility via JMX into each cost function of the stochastic load balancer, as well as the overall cost of the balancing plan."
HBASE-18029,
HBASE-5231,This JIRA backports per-table load balancing to 0.90
HBASE-8752,"0.94 already supports multi-thread compaction. It will be good it also supports multi-thread memstore flush, so that users can tune the number of threads for both compaction and flushing when running a heavy-write load."
HBASE-10071,"Users tend to run hbase shell to query hbase quickly. The result will be shown as binary format which may not look clear enough when users write columns using specified types, such as long/int/short. Therefore, it may be helpful if the results could be shown as specified format. We make a patch to extend get/scan in hbase shell in which user could specify the data type in get/scan for each column as:
{code}
scan 'table', {COLUMNS=>['CF:QF:long']}
get 'table', 'r0', {COLUMN=>'CF:QF:long'}
{code}
Then, the result will be shown as Long type. The result of above get will be:
{code}
COLUMN                                        CELL                                                                                                           
 CF:QF                                timestamp=24311261, value=24311229
{code}
This extended format is compatible with previous format, if users do not specify the data type, the command will also work and output binary format."
HBASE-17145,Is there any plan to backport the fix for hbase-6721 to any future 1.1.x releases. Is there a patch available for the same?
HBASE-9830,"Backport HBASE-9605 which is about ""Allow AggregationClient to skip specifying column family for row count aggregate"""
HBASE-1456,"Since so much in thrift has changed between the ancient version used in this branch and thrift 0.1.0, it will be useful to have a backport patch of all the changes so far.
There are some api tweaks. Like, gets returning lists, and just being empty when nothing was found instead of throwing NotFound.
"
HBASE-3645,"Dmitriy was getting whack responses from his shell... NoSuchMethodException, etc., and it turned out that it was a long running shell that had run over a cluster restart.  We should at least fail if we've lost our zk session or reconnect."
HBASE-9679,"It's not a top priority issue, seems to me.
Right now hbase do a linear scan to search a key within a hfile block on interst, in special case, e.g. 100% read scenario or high read/write ratio scanario, it's useful to do a binary search improvement to reduce the CPU cost and response time,  i think the biggest benefit should be the cpu:)"
HBASE-12259,"HydraBase ( https://code.facebook.com/posts/321111638043166/hydrabase-the-evolution-of-hbase-facebook/ ) Facebook's implementation of HBase with Raft for consensus will be going open source shortly. We should pull in the parts of that fb-0.89 based implementation, and offer it as a feature in whatever next major release is next up. Right now the Hydrabase code base isn't ready to be released into the wild; it should be ready soon ( for some definition of soon).

Since Hydrabase is based upon 0.89 most of the code is not directly applicable. So lots of work will probably need to be done in a feature branch before a merge vote.

Is this something that's wanted?

Is there anything clean up that needs to be done before the log implementation is able to be replaced like this?

What's our story with upgrading to this? Are we ok with requiring down time ?"
HBASE-3288,HBASE-3287 introduced two new configuration parameters.  These should both be optionally configurable at the family level.
HBASE-3014,"I see a lot of UnknownScannerException messages in the log at ERROR level when I'm running a MapReduce job that scans an HBase table.  These messages are logged under normal conditions, and according to [~jdcryans], should probably be logged at a less severe log level like WARN.  

Example error message:
{code}
2010-09-16 09:20:52,398 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
org.apache.hadoop.hbase.UnknownScannerException: Name: -8711007779313115048
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1880)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
{code}

Reference to the HBase users mailing list thread where this was originally discussed:
http://markmail.org/thread/ttzbi6c7et6mrq6o

This is a simple, change, so I didn't include a formal patch.  If one is required, I will gladly create and attach one."
HBASE-6976,"As JD and Elliot mentioned, turning off ZKAssign logging can improve AM performance a lot.  During the testing, I also noticed that: after all regions are already opened, master UI still shows lots of regions in transition. It is because AM hasn't finished the ZK event processing yet.

Changing the logging level from debug to trace will improve AM performance. With HBASE-6611, I think AM is getting stable and reliable. I hope we don't need to see these logging any more.

The logging is still available after turning trace logging level on for AM and ZKAssign class."
HBASE-1619,"While working on the HBase tap and scheme for Cascading I came across a situation where you want to add a bunch of KeyValues to a Put object.
Looking at the code for putting KeyValues in put we copy the family from the KeyValue and use that as a key. So I was thinking that it might be a good idea to just ""point""
into the KV by using a ImmutableBytesWritable and use that as the key instead. This is going to be good when working with MR jobs."
HBASE-9265,Could we simplify the installation process for Windows users by providing a Chocolatey package?
HBASE-20995,Clean up manual array copies in code.
HBASE-7794,"Currently the CompactionTool requires an HStore to run the compaction, 
but with the StorageEngine (HBASE-7678) in place we can cleanup this code
{code}
return new HStore(tmpDir, region, hcd, fs, conf) {
  @Override
  public FileStatus[] getStoreFiles() throws IOException {
    return this.fs.listStatus(getHomedir());
  }

  @Override
  Path createStoreHomeDir(FileSystem fs, Path homedir) throws IOException {
    return storeDir;
  }
};
{code}"
HBASE-4631,"There were some good comments in the review of HBASE-4460.

Cleanup the code and look at potential optimizations."
HBASE-1095,"There is no facility for tracking clients and their use of HRS, tables, etc. other entities of interest over time. Would be useful to track down heavy users, periodic spikes, and the like. Could be implemented as per-user (need concept and definition of user/session) metrics collected by HRS and periodically entered into a history table. "
HBASE-12338,"Since server side prefetching was not proved to be a good way to prefetch, we need to do it on client side.
This is a wrapper class that takes any instance of `ResultScanner` as the underneath scanning component. The class will schedule the scanning in a background thread. There is a buffering queue storing prefetched results, whose's length is configurable. The prefetcher will release the thread if the queue is full and wait for results to be consumed."
HBASE-823,"Over in HBASE-745, Luo Ning profiling found that the number of open Readers has direct impact on memory used.  This issue is about putting an upper bound on the number of open Readers doing something like a bounded pool w/ a LRU eviction policy."
HBASE-18708,"Currently heap allocations for RS memory structures like {{memstore}} and {{lruCache}} are configured as percentage of total RS heap size. Since on-heap bucketCache uses RS heap, configuring it as a percentage of heap size will improve usability. Currently this can be configured either as a percentage of heap or a memory size in MiB and we can remove the latter option which is applicable to external or off-heap bucketCache."
HBASE-606,"Many user problems can be traced back to misconfiguring either Hadoop or HBase. Create a ""wizard"" script that helps them get off the ground.

Once a base configuration is generated, users can customize appropriately."
HBASE-2751,"Having a lot of regions per region server could be considered harmless if most of them aren't used, but that's not really true at the moment. We keep all files opened all the time (except for rolled HLogs). I'm thinking of 2 solutions

 # Lazy open the store files, or at least close them down after we read the file info. Or we could do this for every file except the most recent one.
 # Close files when they're not in use. We need some heuristic to determine when is the best moment to declare that a file can be closed. 

Both solutions go hand in hand, and I think it would be a huge gain in order to lower the ulimit and xceivers-related issues."
HBASE-10113,"DoubleBlockCache is a BlockCache that combines the LruBlockCache and SlabCache. CombinedBlockCache that combines LruBlockCache and BucketCache. These behaviors are (almost entirely) redundant. Consolidate the implementations into a single implementation, or reduce code duplication."
HBASE-16078,"This ticket is result of discussion in [HBASE16044|https://issues.apache.org/jira/browse/HBASE-16044] to avoid ""hbase shell"" output parsing hacks. "
HBASE-3730,"The current DEFAULT_VERSIONS (in HColumnDescriptor) is 3, but there is no particular reason for this.  Many uses require only 1, and having a default that is different makes people confused (e.g., ""Do I need multiple versions to support deletes properly?"").

Reasonable values for the default are 1 and max int.  1 is the better choice.

Discussion on the mailing list suggests that the current value of 3 may have been derived from an example in the Bigtable paper.  The example does not suggest that there is anything special about 3, it's just an illustration."
HBASE-3754,There's a number of unit tests that implement their own Server just to pass it to some other class without implementing anything specific except getting the Configuration. We should define one that all could use and refactor the others out.
HBASE-8635,"Currently ""hbase.hregionserver.prefetcher.resultsize.max"" defines global limit for prefetching.
The default value is 256MB.

It would be more flexible to define this measure as a percentage of the heap."
HBASE-8721,"this fix aims for bug mentioned in http://hbase.apache.org/book.html 5.8.2.1:

""Deletes mask puts, even puts that happened after the delete was entered. Remember that a delete writes a tombstone, which only disappears after then next major compaction has run. Suppose you do a delete of everything <= T. After this you do a new put with a timestamp <= T. This put, even if it happened after the delete, will be masked by the delete tombstone. Performing the put will not fail, but when you do a get you will notice the put did have no effect. It will start working again after the major compaction has run. These issues should not be a problem if you use always-increasing versions for new puts to a row. But they can occur even if you do not care about time: just do delete and put immediately after each other, and there is some chance they happen within the same millisecond."""
HBASE-2472,Yesterday it was suggested that we ship with a directory laden with the ordained patches needed for hdfs.  Assigning myself.
HBASE-11504,"today we flush the socket buffer after each response.

The server maintains a queue of the calls to write. If this queue is not empty, we should not flush. We should do that only when the queue is empty. This will save some packets when nagle is disabled and we have a list of small responses to send (for example responses to puts, or small gets). This is linked to HBASE-11492.

The client has a queue as well, so we could do the same thing there.

There could be some drawbacks (if the server is overloaded between multiple channel for example writing the next response may take time), but it seems a good thing to do. For example, if the server if overloaded saving on buffer flush seems to be a nice thing to do.

Any opinion?
It's something I plan to do if I don't find a major drawback.


"
HBASE-3281,"On cluster here, I see a log replay on a region taking about 28 seconds.  It does a replay of approximately 750,000 edits.  Since this can run for a while, we have a Progress By default we have:

{noformat}
      int interval = this.conf.getInt(""hbase.hstore.report.interval.edits"", 2000);
{noformat}

This led to about 300 ZK node re-transitions (from OPENING to OPENING) in about 30 seconds.  I haven't measured the operation in ZK but it's certainly several millis.

Seems like we could be adding a significant amount of overheard here (5ms * 300 = 1.5 seconds = 5%).  But I think some of these could be >5ms so we could be adding 10% or more.

One way to address this would be to do it based on size not entries (this region only had increments, so lots of small edits).  Another way would be to do it based on time instead of entries (check-in every 5 seconds, for example)."
HBASE-6940,I think we should enable gc by default.  Its pretty frictionless apparently and could help in the case where folks are getting off the ground.
HBASE-3786,
HBASE-11356,"When using uniform splitter to create a table, the start/endKey and region names can contain characters that break HTML, like <j, or "" ."
HBASE-16370,"Getting this message trying to do a build with -Prelease:

{noformat}
[INFO] Restricted to JDK 1.7 yet jdk.tools:jdk.tools:jar:1.8:system contains org/relaxng/datatype/DatatypeLibrary.class targeted to JDK 1.8
[WARNING] Rule 3: org.apache.maven.plugins.enforcer.EnforceBytecodeVersion failed with message:
HBase has unsupported dependencies.
  HBase requires that all dependencies be compiled with version 1.7 or earlier
  of the JDK to properly build from source.  You appear to be using a newer dependency. You can use
  either ""mvn -version"" or ""mvn enforcer:display-info"" to verify what version is active.
  Non-release builds can temporarily build with a newer JDK version by setting the
  'compileSource' property (eg. mvn -DcompileSource=1.8 clean package).
Found Banned Dependency: jdk.tools:jdk.tools:jar:1.8
Use 'mvn dependency:tree' to locate the source of the banned dependencies.
[INFO] ------------------------------------------------------------------------
{noformat}

My JDK is 1.8.  But I wanted to build to target 1.7.  So I didn't' have the -DcompileSource=1.8.

The enforcer checks the jdk tools.jar and causes the error because the system JDK is 1.8.

This is a valid build/release use case as long as we support both 1.8 and 1.7.

We should exclude jdk tools.jar from the enforcer."
HBASE-20654,"Currently only the count of regions in transition is exposed thru JMX.
Here is a sample snippet of the /jmx output:
{code}
{
  ""beans"" : [ {
...
  }, {
    ""name"" : ""Hadoop:service=HBase,name=Master,sub=AssignmentManager"",
    ""modelerType"" : ""Master,sub=AssignmentManager"",
    ""tag.Context"" : ""master"",
...
    ""ritCount"" : 3
{code}
It would be desirable to expose region name, state for the regions in transition as well.
We can place configurable upper bound on the number of entries returned in case there're a lot of regions in transition."
HBASE-11993,"TableStateManager has the full set of TableNames already in memory,
we should expose the set of table names and use it instead of going to query the fs descriptors.

(Is there any reason why we don't have the descriptors in-memory too? saving memory with tons of tables? do we even support tons of tables?)"
HBASE-4058,"We should have a unit test that launches a minicluster and constructs a few tables, then deletes META files on disk, then bounces the master, then recovers the result with HBCK. Perhaps it is possible to extend TestHBaseFsck to do this."
HBASE-1590,"As discussed in HBASE-1554 there is a bit of a disconnect between how ClassSize calculates the heap size and how we need to calculate heap size in our implementations.

For example, the LRU block cache can be sized via ClassSize, but it is a shallow sizing.  There is a backing ConcurrentHashMap that is the largest memory consumer.  However, ClassSize only counts that as a single reference.  But in our heapSize() reporting, we want to include *everything* within that Object.

This issue is to resolve that dissonance.  We may need to create an additional ClassSize.estimateDeep(), we may need to rethink our HeapSize interface, or maybe just leave it as is.  The two primary goals of all this testing is to 1) ensure that if something is changed and the sizing is not updated, our tests fail, and 2) ensure our sizing is as accurate as possible."
HBASE-2512,2414 made RSOQueue.  Need to continue work of making it so I can do testing of this component independent of a live cluster.  Need to remove master from RSO instances and make it so RegionServerOperations are not responsible for puttint themselves back on the queue.  In involution is hard to follow.
HBASE-3129,"Currently RegionServer FS latency metrics are a little deceiving.  Because fs*Latency is only updated during RegionServerMetrics::doUpdates, you are really getting the min/max of the latency average over 'hbase.period' instead of the actual min/max outliers.  We should refactor the code so we can display these outliers and reset them every 'hbase.period'"
HBASE-3682,"We currently make source jars for the main artifact, but not the test artifact."
HBASE-17249,"Going through the code, found For Get/Scan's setTimeRange/setColumnFamilyTimeRange, it can use  TimeRange as reference instead of creating a new one.

Reference:
https://github.com/apache/hbase/blob/master/hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java#L500

https://github.com/apache/hbase/blob/master/hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java#L506

We can implement this in a similar way as filter:

https://github.com/apache/hbase/blob/master/hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java#L510

I checked it is same with branch-1."
HBASE-17382,"Pointed out by [~tedyu] that 'Locate' is a verb and usually we need a noun here. 'Locating' or 'Location'?

Suggestion are welcomed."
HBASE-2681,"stack's word: ""Fellas have complained about the way broke lzo manifests itself. HBase will actually take on writes. Its only when it goes to flush that it drops the edits and in a way that is essentially hidden to the client - exceptions are thrown in the regionserver log. So, i'd say, make another issue if you don't mind but its not for you to fix, not unless you are inclined. It'd be about better user experience around choosing a compression that is not supported or not properly installed."""
HBASE-1843,"The ability to set the number of retries and the pause length between them on the HBaseClient through HBaseConfiguration.

I am working on an application that utilizes Hbase for real-time queries.  The dependency on Hbase is not critical so if HBase is not available for any reason the application should continue on doing its job without the data from Hbase.  Essentially I want HBase Client to fail quickly if the request to Hase is going to fail or take a long time to respond.  I have tested various scenarios with Zookeeper running/not running and the master running/not running.
 
Configuration:
Hbase 0.20.0 & Hadoop 0.20.1
Pseudo distributed mode
Java client using HTablePool
 
 
When ZK, Master, Regionserver and my app are running, I stop the Hbase master/regionserver.  The HBaseClient then begins to complain:
16:26:51,273 INFO [HBaseClient] Retrying connect to server: /192.168.1.55:44808. Already tried 0 time(s).
16:26:53,274 INFO [HBaseClient] Retrying connect to server: /192.168.1.55:44808. Already tried 1 time(s).
...already tried 9 time(s)....
16:27:10,294 INFO [HbaseRPC] Server at /192.168.1.55:44808 not available yet, Zzzzz...

**** This is despite the fact that I set hbase.pause to be 25 ms and the retries.number = 2.  ****

I restart the Master and RegionServer and then send more client requests through HTablePool.  It has the same ""Retrying to connect to server:"" messages.  I noticed that the port number it is using is the old port for the region server and not the new one assigned after the restart.  The HbaseClient does not seem to recover unless I restart the client app.  When I do not use HTablePool and only Htable it works fine.

Issue:
Setting and using hbase.client.pause and hbase.client.retries.number parameters.  I have rarely gotten them to work.  It seems to default to 2 sec and 10 retries no matter if I overwrite the defaults on the client and the server.  Yes, I made sure my client doesn't have anything in the classpath it might pick-up.
<property>
<name>hbase.client.pause</name>
<value>20</value>
</property>
<property>
<name>hbase.client.retries.number</name>
<value>2</value>
</property>"
HBASE-4818,"As many HBase users use binary row keys rather than strings to optimize memory consumption displaying an escaped string in the HBase shell isn't useful (and takes a lot of screen space)
Allowing user to provide a row key formatter as part of the scan\get commands would allow developers to display the row key in a way thats makes sense for them.

Example:
scan 'stats', { ROWFORMATTER => MyRowFormatter.new }

The row formatter simply gets the bytes array key and formats it to a string.
Its an easy change tomake with simple monkey-patching of the shell commands but I would be happy to see it as part of the shell itself."
HBASE-8777,"HBase currently determines which server to go to, then creates delayed callable with pre-determined server and goes there. For later 16-32-... second retries this approach is suboptimal, the cluster could have seen massive changes in the meantime, so retry might be completely useless.
We should re-locate regions after the delay, at least for longer retries. Given how grouping is currently done it would be a bit of a refactoring.

The effect of this is alleviated (to a degree) on trunk by server-based retries (if we fail going to the pre-delay server after delay and then determine the server has changed, we will go to the new server immediately, so we only lose the failed round-trip time); on 94, if the region is opened on some other server during the delay, we'd go to the old one, fail, then find out it's on different server, wait a bunch more time because it's a late-stage retry and THEN go to the new one, as far as I see. "
HBASE-2921,"When you start the HBase shell from bash, you see the following prompt:

hbase(main):001:0>

And typing in ""conf"" as the command yields the following prompt-related information:

conf.prompt_c=""%N(%m):%03n:%i* ""
conf.prompt_i=""%N(%m):%03n:%i> ""
conf.prompt_mode=:DEFAULT
conf.prompt_n=""%N(%m):%03n:%i> ""
conf.prompt_s=""%N(%m):%03n:%i%l ""

On the other hand, opening the HBase shell as python subprocess yields an empty string as the prompt string. Furthermore, sending it the ""conf"" command through a pipe yields the following output:

conf.prompt_c=nil
conf.prompt_i=nil
conf.prompt_mode=:NULL
conf.prompt_n=nil
conf.prompt_s=nil

This occurs because irb checks if stdout is a tty and changes the prompt configuration in case it is.  It would be very useful for the hbase shell to have a --force-tty option that overrides this check."
HBASE-8193,Currently HBaseAdmin.isTableAvailable() only checks in META to say if a  table is available or not. It should also check with the zkTable state if it is ENABLED before returning true.
HBASE-4448,"Setting up and tearing down HBaseTestingUtility instances in unit tests is very expensive.  On my MacBook it takes about 10 seconds to set up a MiniCluster, and 7 seconds to tear it down.  When multiplied by the number of test classes that use this facility, that's a lot of time in the build.

This factory assumes that the JVM is being re-used across test classes in the build, otherwise this pattern won't work. 

I don't think this is appropriate for every use, but I think it can be applicable in a great many cases - especially where developers just want a simple MiniCluster with 1 slave."
HBASE-3504,The HLog.updateLock protects the rolling of logs with concurrent writes to the HDFS log file. This is a scalability bottleneck for a workload that comprises mostly of counter-increments.
HBASE-10424,"Often there are cases of a region not getting assigned due to timeouts (while others do go through). In this case, the Master does appear to enter a never-ending retry operation where it retries each chosen server several times before moving to another.

For debugging in such a scenario, where the master is best aware of the situation, it could use that to its advantage and help capture issues better if it probably setup an N retry threshold (for # of servers tried) and run a HTTP GET on the current timing out RS's info port, to capture its /stacks end point and dump the output in its logs for investigation later."
HBASE-2465,"On startup, in verifyClusterState, the master contacts each region server serially. If a region server is down it will retry for several minutes (if the client retry setting is high). During this period, the master cannot be shut down, and also isn't processing real work."
HBASE-6273,"This JIRA is in reference to JD's comments regarding the clean up needed in isMasterRunning().  Refer to 
https://issues.apache.org/jira/browse/HBASE-6240?focusedCommentId=13400772&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13400772"
HBASE-3886,"This is an interesting one.  HServerInfo is deprecated in TRUNK and replaced effectively by a new class ServerName.  Both equate instances of HSI or SN if the two instances have the same hostname and port.  Well, thats well and good but what if we are getting signals from a server whose IP has changed?  In this case, we'll see the server in its new location come in but we'll treat it as though we'd seen it already, thought its IP had changed.  We don't want this.

This facility is needed for rare case where a server is moved from one IP to another."
HBASE-7085,"An HTableInterface with isAutoFlush()==false does not currently automatically flushCommits when unlockRow is is called.  

In our system this means that we must issue the flushCommits when we run in isAutoFlush()==false mode. 

The API will automatically flush when closing the table interface but since it unlocks before flushing we have a problem.  

I can't see any logic in releasing locks without first flushing the commits and as such suggest that including an automatic flush before unlocking would improve the API.   "
HBASE-7292,"The class description javadoc for HTablePool contains a sentence that makes no sense in the context (it appears to be part of an incorrectly-applied patch from the past). The sentence references the correct way of returning HTables to the pool, but it actually makes it more difficult to understand what the correct way of returning tables to the pool actually is."
HBASE-3692,"A user on IRC yesterday had an issue with RejectedExecutionException coming out of HTable sometimes. Apart from being very confusing to the user as it comes with no message at all, it exposes the HTable internals. 

I think we should handle it and instead throw something like DontUseHTableInMultipleThreadsException or something more clever. In his case, the user had a HTable leak with the pool that he was able to figure out once I told him what to look for.

It could be an unchecked exception and we could consider adding in 0.90 but marking for 0.92 at the moment."
HBASE-4198,"As I mentioned on the mailing list, the way HBA.flush behaves is different from what is used to be. Right now here's how flush and compact work:

 - When calling HBA.flush it will fetch the list of regions then will contact their owners directly one by one and the flush will be done inline. The major issue here is flushing a big table will take a *long* time, but it does give some guarantee that all the flushes are done. The old behavior was that all flushes were done async.

 - For compactions it also calls every regions' owners one by one and instead of being inline the compactions are queued. This is not very different from the old behavior, except that the master has nothing to do now.

What I believe we need to do:

 - Both methods should have the same guarantees, either they return when everything is flushed/compacted or they don't.
 - If we do inlining, we should issue the requests in parallel a la HTable.batch.
 - We definitely need to offer an async version."
HBASE-1863,"o.a.h.h.i.HbaseObjectWritable does not support read/write of unknown Writable object (will throw UnsupportedIoerationException); 
in addition, writing a known Writable object, e.g., HColumnDescriptor, will write the code twice.
furthermore, it may be useful to change addToMap from private to public.

not causing any problem with hbase, but will be nice to have the above corrected, especially part of the code is already there."
HBASE-2816,"Implementing Object.equals() and hashCode() for Get, Put, etc, would be handy. The particular use case is using Mockito to verify operations on mock HTable objects."
HBASE-2689,
HBASE-1388,"It would be useful to have a suite of performance tests so that HBase can be compared to other similar projects. This could then be automated on the same hardware (perhaps even EC2?).

There is a project called Vpork, developed by Jon Travis to test Voldemort that would be a good starting point. It is written in Groovy and can use the Java client libs. This version has been slightly refactored and also supports Cassandra:
http://github.com/johanoskarsson/vpork/tree/master"
HBASE-3718,"The regionserver uses a ConcurrentSkipList to store the KVs in the memstore. Although the order complexity of a lookup is O(n), still the latency to lookup a specific key in the memstore is very large, especially when the memstore is large and the KV.compare() method is costly.

One optimization is to investigate using a ConcurrentHashMap (instead of ConcurrentSkipList). The lookup and insertion cost is minimized. We can do it only for column-families that are marked as ""do not support rangescans"". "
HBASE-975,"Keeping a MapFile's start and end key in cache would save us some seeks, see if it can be done."
HBASE-10932,"The typical use case of RowCounter is to do some kind of data integrity checking, like after exporting some data from RDBMS to HBase, or from one HBase cluster to another, making sure the row(record) number matches. Such check commonly won't require much on response time.
Meanwhile, based on current impl, RowCounter will launch one mapper per region, and each mapper will send one scan request. Assuming the table is kind of big like having tens of regions, and the cpu core number of the whole MR cluster is also enough, the parallel scan requests sent by mapper would be a real burden for the HBase cluster.
So in this JIRA, we're proposing to make rowcounter support an additional option ""--maps"" to specify mapper number, and make each mapper able to scan more than one region of the target table."
HBASE-15630,"Trying to verify latest release (1.2.1), and I found it a bit inconvenient to parse the *.mds checksum file. The line wrapping, white space, and the general format of the file does not lend itself for easy verification.

I suggest using the standard ""coreutils"" format for md5sum, sha*sum, etc., instead: <lowercase-hash><space><asterisk(binary-flag)><filename>
{code}
# md5
3d66c0dd4f38fa881046fe64dd680a7a *hbase-1.2.1-src.tar.gz
# sha1
3666a4829d9a8d9285173bfa8e8d0ff5423a22d6 *hbase-1.2.1-src.tar.gz
# rmd160
#fb318e84b6256492cfb990aec2238a64c2da21ad *hbase-1.2.1-src.tar.gz
# sha224
89d341a55069e4875f9e6859737062fd7a4c11596811731c4ba95ca0 *hbase-1.2.1-src.tar.gz
# sha256
e8000a65e98d4c5db7bab54da99a57209fe4ea777ab41e91ae8ccf7bfa2d50dd *hbase-1.2.1-src.tar.gz
# sha384
49aa0620bf0fbe20bbde66cecabb76b22defb9ee609936edc3952889e6484e55c88f1c93d6258a2eaab4a9d5188b6170 *hbase-1.2.1-src.tar.gz
# sha512
28956a35a01ae87e9f733664c52c6fd25f9a60a1ff7047bbf306cd433c2a5b863c9bf05aba1d58792b86eec9943ae00e772c4b76fb81c5d210cf256cd074189b *hbase-1.2.1-src.tar.gz
{code}
(comment lines added for humans, but ignored by tools; commented out rmd160, because not a coreutils supported algorithm; binary flag optional, could use another space instead... probably only matters for some dos tools)

This makes it very easy to verify multiple files and hashes using: {{shasum -c file.mds}} or {{sha1sum -c file.mds}} or {{md5sum -c file.mds}}.

In addition to the file format change, I suggest these two additional changes:

1. Drop rmd160. It's not nearly as popular as the others, and it doesn't lend itself to easy verification (no coreutils equivalent command like md5sum, sha1sum, etc.)
2. Concatenate hashes from all files into a single file. This makes it easier to verify all downloads at once.
"
HBASE-2165,"Improve by 

- moving the ""blocking"" FS scan into a thread so that the UI loads fast and initially displays ""n/a"" but once it has completed the scan it displays the proper numbers
- explaining what fragmentation means to the user (better hints or help text in UI)
- Switch -ROOT- (and maybe even .META.?) to simply say ""Yes"" or a tick that it is fragmented as it only has 0% or 100% available (since it has only a single region)
- also computing the space occupied by each table and the total and - if easily done - add a graph to display it (Google Pie Chart would be nice but is an external link)"
HBASE-21066,"聽
{code:java}
public boolean isTableState(TableName tableName, TableState.State... states) {
 try {
 TableState tableState = getTableState(tableName);
 return tableState.isInStates(states);
 } catch (IOException e) {
 LOG.error(""Unable to get table "" + tableName + "" state"", e);
 // XXX: is it safe to just return false here?
 return false;
 }
 }
聽
{code}
聽

When cannot get table state, returning false is not always safe or correct."
HBASE-17383,"Currently we get this log
{code}
2016-12-28 21:11:14,349 INFO  [RpcServer.deafult.FPBQ.Fifo.handler=39,queue=9,port=16041] regionserver.MemStoreFlusher: Blocking updates on stobdtserver5,16041,1482938527980: the global offheap memstore size 12.6 G + global memstore heap overhead 4.0 G is >= than blocking 12.6 G size
{code}
Here the global offheap memstore size is greater than the blocking size. The memstore heap overhead need not be included in this log unless the higher water mark breach is only due to the heap overhead."
HBASE-5826,"HBASE-5782 solved the correctness issue for the sync of HLog edits.
Todd provided a patch that would achieve higher throughput.

This JIRA is a continuation of Todd's work submitted there."
HBASE-3055,"Working on the failed hbase-3019 some improvements were made to bulk assignment:

1. Temporarily disabling timeout on regions in transition
2. A executor service running assignments per server rather than a thread for every server (if big cluster thread-per could be OTT).

"
HBASE-1158,"If we do not take the startcode into consideration when recovering from a server death, then we cannot know if the data in ROOT or META pertains to the the current instance or the previous one.

With ZK this should be easier if we modify HServerAddress to contain the startCode of a HRegionServer instance. It would be immediately visible whether or not the region was on the dead server or the new server."
HBASE-12713,"I find that the policy of region split which in IncreasingToUpperBoundRegionSplitPolicy will be use the value of ""maxfilesize"" when the count of region is greater than 100. But sometimes 100 regions is not too much for a cluster that has 50 or more regionservers.
So i think this policy should consider the density of the regions but not the total count of the regions."
HBASE-635,"Currently, the TableMap spawns a number of Map tasks matching the number of regions being served. However, each task reports 0% complete until the task is fully complete and jumps to 100%. It would be ideal if each task accurately reported it's percentage complete."
HBASE-7349,The javadoc check should look for an increase in the number of warnings. It can do so by running javadoc against trunk before running it for the patch. This will increase build times.
HBASE-17392,"When user misconfigures 'hbase.hstore.engine.class', region server complains ""Class not found"" and gives up. In this case, we need to load the DefaultStoreEngine to avoid that. Sanity check needs to be done to prevent user from misconfiguration as well.

https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreEngine.java#L121"
HBASE-3945,"Keeping a region on the same region server would give good stability for active scanners.
We shouldn't reassign the same region in two successive calls to balanceCluster()."
HBASE-3551,"I hung with a user Marc and we were looking over configs and his cluster profile up on ec2.  One thing we noticed was that his 100+ 1G regions of two families had ~2.5G of heap resident.  We did a bit of math and couldn't get to 2.5G so that needs looking into.  Even still, 2.5G is a bunch of heap to give over to indices (He actually OOME'd when he had his RS heap set to just 3G; we shouldn't OOME, we should just run slower).  It sounds like he needs the indices loaded but still, for some cases we should drop indices for unaccessed files."
HBASE-17926,
HBASE-20837,"While working on HBASE-20557 contribution, we figured out that the checkstyle build target (ImportOrder's `groups` [http://checkstyle.sourceforge.net/config_imports.html] ) was different from the development supported IDE (e.g. IntelliJ and Eclipse) formatter, we would provide a fix here to sync between聽[dev-support/hbase_eclipse_formatter.xml|https://github.com/apache/hbase/blob/master/dev-support/hbase_eclipse_formatter.xml] and [hbase/checkstyle.xml|https://github.com/apache/hbase/blob/master/hbase-checkstyle/src/main/resources/hbase/checkstyle.xml]

This might need to backport the changes of master to branch-1 and branch-2 as well.

Before this change, this is what checkstyle is expecting for import order

聽
{code:java}
import com.google.common.annotations.VisibleForTesting;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.classification.InterfaceAudience;
import org.apache.hadoop.hbase.conf.ConfigurationObserver;{code}
聽

And the proposed import order with the respect to HBASE-19262 and HBASE-19552 should be

聽
聽聽 !IDEA import layout.png!"
HBASE-16803,"HBASE-16773 fixed a case where PriorityRpcServer handler threads are all occupied accessing hbase:acl table.

However, the fix relies on the fact that there is single region in hbase:acl table so that the access can be local.

As discussed at the end of HBASE-16773, we should disable split of hbase:acl table as well.
hbase:meta is normally much larger than hbase:acl table and it has only one region."
HBASE-12463,"By default Memstore uses MSLAB. For each of the Cell added to memstore, we will allocate area in MSLAB and return the area in BR wrapper. So each time a new BR object is created. Instead of this we can have ThreadLocal level BR instance and each time when allocate() API return the BR, we can set the byte[], offset, length on this ThreadLocal level BR instance. So totally only those many objects as the threads count (max handler count)"
HBASE-7978,"I would like to discuss the possibility of merging the prefix tree module into the hbase-server module. 

Ideally, I think we should have hbase-mapreduce and hbase-storage modules, the latter one containing most of HFile code. hbase-mapreduce depends on hbase-storage so that it knows how to encode hfiles. prefix-tree belongs to hbase-storage. 

prefix tree is just another DBE, although a big one, and it rightfully belongs with her sisters. The fact that the code is independent from the rest of the code base does not mean that it should have it's own module. We should keep the number of modules manageable, and stay away from hadoop trunk's one-module-per-package policy. 

Related: HBASE-7936"
HBASE-2970,"Bloom filters are currently using the LRU block cache.  They are being treated as normal data blocks, however, it would be advantageous if we could treat me separately and give them their own portion of the LRU.

What we've seen in practice is that some blooms get very big and are accessed frequently.  This leads to blooms consuming a majority of the cache so lots of churn on data blocks.

In any case, I think it is desirable in general to be able to control how much memory is used for blooms and other meta data."
HBASE-6841,"I got myself into a situation where I needed to truncate a massive table while it was getting hits and surprisingly the clients were not recovering. What I see in the logs is that every time we prefetch .META. we setup a new HConnection because we close it on the way out. It's awfully slow.

We should just turn it off or make it useful. jstacks coming up."
HBASE-11334,"Migrating to new log implementations is underway as in HBASE-10092. 
Next step would be to abstract them so that the hadoop community can standardize on a logging layer that is easy for end users to tune.

Simplest way to do this is use SLF4j APIs as the main interface and binding/ implementation details in the docs as necessary.

"
HBASE-3361,"There's a few reasons to break tests out into their own module:
1. Allowing maven users to easily re-consume test utilities as part of a ""test"" package which doesn't pollute the runtime classpath
2. Putting integration tests (tests that create or require a cluster) in their own module allows users to easily rebuild and test the core of HBase without running long-running tests, reducing the developer iteration loop

After some discussions with Stack on IRC, it sounds like there was some historic investigation of this which was abandoned because the module system was becoming too complex. I'd suggest that rather than trying to break out components all at once into their modules, evaluate creation of modules on a case-by-case basis and only create them when there's a significant use case justification.

I created a sample of what I'm thinking about (based on the current trunk) and posted it on github
git://github.com/ekohlwey/modularized-hbase.git"
HBASE-2598,As described in the TODOs in HConstants.java
HBASE-21664,"When trying to minimize the number of methods in ClusterConnection, I found that QuotaStatusCalls uses several methods in ClusterConnection, and it is not under the client package. And finally I found that, only QuotaTableUtil uses it, and all the methods which reference it is used for testing.

 So let's move these methods to the test code base, so we are free to move it anywhere, so we do not need to declare the methods in ClusterConnection any more."
HBASE-1846,Move thrift to contrib
HBASE-2814,"Hello, i have create small patch for thrift interface to increament many columns in many rows in many tables, but im not a hbase or even java developer so if someone want to look at this and create somethink better i would be appreciate.

thanks
S.Bauer

PS. sorry for my bad english ;) "
HBASE-1521,"There are some additional optimizations in the specialized StoreScanner and also in HFile for minor compactions.  For example, there is some KV disassembling and sanity checking in HFile even though in a minor compaction these checks have already been run during the flush.

Another area to discuss is whether we should actually process deletes during minor compactions.  It's not especially expensive (ScanDeleteTracker is quite simple) but it requires looking at both the row and the qualifier value of every single KV.  Removing this would drop our axiom that ""Deletes only apply to later storefiles"", which is used during Get processing to have more efficient delete handling."
HBASE-11601,"Although HBASE-11185 exists, it is geared towards the snapshot manifest code.  We have used snapshots to ship our two largest tables across the country and while doing so found a few potential optimizations where doing things in parallel helped quite a bit.  I can attach a patch containing changes I've made and we can discuss if these are changes worth getting pushed to 0.94.  "
HBASE-1255,"Current Process command-line args is very simple in master and Region Server.
There is a comment
    // Process command-line args. TODO: Better cmd-line processing
    // (but hopefully something not as painful as cli options).

So we still can use CLI http://commons.apache.org/cli/usage.html or someone from list of alternatives http://jopt-simple.sourceforge.net/

What is disadvantage of CLI ?

"
HBASE-6744,"Per table balancing just balances regions based on tables.  However, overall, regions could be seriously unbalanced.

For example, if you shutdown all most all region serves in a cluster, then create tons of new tables (no region pre-split), then start up all region servers.  You will see the regions won't move to other region servers since they are balanced per table (only one region for a table at this moment).

If we can make the balance algorithm sophisticated enough, we don't need the configuration hbase.master.loadbalance.bytable.  We can do the regular and bytable balancing at the same time.
"
HBASE-18370,"Currently once a region goes into FAILED_OPEN state this requires operator intervention. With some underlying causes, this is necessary. With others, the master could eventually successfully deploy the region without humans in the loop. The master should optionally attempt automatic resolution of FAILED_OPEN states with a strategy of: delay, unassign, reassign. "
HBASE-8196,"There has been some interest in porting region merge (HBASE-7403), and making splits more stable in 0.94. For online merge, we depend on HBASE-7721, thus we might need the backport. "
HBASE-21011,"There is a corner case when cleaner chore for HFiles and oldwals is disabled, admin/user needs to manually execute admin command {{cleaner_chore_run}} to clean the old HFiles and oldwals. Existing logic of {{cleaner_chore_run}} is to [firstly trigger the HFiles cleaner and then oldwals cleaner|https://github.com/taklwu/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java#L1414-L1420], and only return succeed if both completes.聽

but when running this {{cleaner_chore_run}} command, there is a potential use case that admin would like trigger the cleaner for only oldwals or hfiles but still keep the automatic cleaner chore disabled. So, this change aims to provide support for this corner case, and provide flexibility for those user with cleaner chore disabled by default to execute admin CLI to run oldwals and HFiles cleaning procedure individually.

NOTE that {{cleaner_chore_run}} was introduced in HBASE-17280, this patch added options 'hfiles' and 'oldwals' to it. Also fix default behavior of {{cleaner_chore_run}} will be only ran when cleaner chore is set to disabled, e.g. the proposed admin CLI options are
{noformat}
hbase> cleaner_chore_run               # this was introduced in HBASE-17280, but changed the behavior to only ran when cleaner chore is set to disabled

hbase> cleaner_chore_run 'hfiles'      # added, ran when cleaner chore is set to disabled
hbase> cleaner_chore_run 'oldwals'     # added, ran when cleaner chore is set to disabled
{noformat}"
HBASE-5273,"While reworking on the coprocessor blog, I start to realize that we should have a template of coprocessor that helps users to quickly start to develop, test a customized coprocessors. Currently there are some built-in coprocessors but all over the code base, and a user has to search around the code to see how to develop a new one."
HBASE-12890,We have a very large cluster and we frequently add remove quite a few regionservers from our cluster.  Whenever we do this the balancer moves thousands of regions at once.  Instead we provide a configuration parameter: hbase.balancer.max.regions.  This limits the number of regions that are balanced per iteration.  
HBASE-4991,"See discussion titled 'Able to control routing to Solr shards or not' on lily-discuss
User may want to quickly dispose of out of date records by deleting specific regions. "
HBASE-5341,"Hbase 0.92.0 was released with two artifacts, plain and security. The security code is built with -Psecurity. There are two tarballs, but only the plain jar in maven repo at repository.a.o. 

I see no reason to do a separate artifact for the security related code, since 0.92 already depends on secure Hadoop 1.0.0, and all of the security related code is not loaded by default. In this issue, I propose, we merge the code under /security to src/ and remove the maven profile. 

Edit: after some discussion, and the plans for modularizing the build to include a security module, we changed the issue description to push the security jars in 0.92.1 to maven repo. "
HBASE-1755,Moving to 0.22.0
HBASE-4274,"If you restart HDFS underneath HBase, when HBase isn't taking any write load, the region servers won't ""notice"" that there's any problem until the next time they take a write, at which point they will abort (because the pipeline is gone from beneath them). It would be better if they wrote some garbage to their HLog once every few seconds as a sort of keepalive, so they will aggressively abort as soon as there's an issue."
HBASE-1839,"Currently, the methods are misnamed.  Fix for 0.21."
HBASE-1406,"The current HRS implementation is a mess, especially after ZooKeeper additions to handle Session Expired events. See HBASE-1311.
It contains logic to restart itself which caused a lot of fields to be non-final that can be. It should be split out to two separate class, one that runs HRS duties and one that watches over the first in a join/restart loop. Using this means a special event like a ZooKeeper Session Expired wouldn't require special restart code, just an abort. The new wrapper class will handle restarting."
HBASE-7449,"we encountered a hung issue, the thread dump shows:
most of threads waiting to a lock but there isn't lock holder be found

We know there were some discuss before, e.g:
https://issues.apache.org/jira/browse/HBASE-3622
http://bugs.sun.com/view_bug.do?bug_id=6822370
http://cs.oswego.edu/pipermail/concurrency-interest/2012-August/009635.html
https://blogs.oracle.com/dave/entry/a_race_in_locksupport_park

My point is that the JVM bug is still not fixed(at least for latest 1.6.0_37, the hotspot version: 20.12-b01), it's not just a old JVM issue, let's update the trouble shooting document firstly if possible. I'm trying to reproduce with a debug openjdk version in-house."
HBASE-5517,"Originated from the discussion under HBASE-2038 [Coprocessor based IHBase]

Currently preNext() and postNext() will be called once for a next() call into HRegionServer.
But if the next() is being called with nbRows>1, co processor should provide a chance to do some operation before, after every next() calls into region as part of call next(int scannerId, int nbRows).

In case of usage of coprocessor with IHBase, before making any calls of next() into a Region, we need to make a reseek() to a row based on the index information."
HBASE-10270,"When a block is added to the BlockCache its DataBlockEncoding is stored on the BlockCacheKey. This block encoding is used in the calculation of the hashCode and as such matters when cache lookups are done. Because the keys differ for encoded and unencoded (data) blocks, there is a potential for caching them twice or missing the cache. This happens for example when using Scan preloading as AbstractScannerV2.readNextDataBlock() does a read without knowing the block type or the encoding.

This patch removes the block encoding from the key and forces the caller of HFileReaderV2.readBlock() to specify the expected BlockType as well as the expected DataBlockEncoding when these matter. This allows for a decision on either of these at read time instead of cache time, puts responsibility where appropriate, fixes some cache misses when using the scan preloading (which does a read without knowing the type or encoding), allows for the BlockCacheKey to be re-used by the L2 BucketCache and sets us up for a future CompoundScannerV2 which can read both un-encoded and encoded data blocks.

A gotcha here: ScannerV2 and EncodedScannerV2 expect BlockType.DATA and BlockType.ENCODED_DATA respectively and will throw when given a block of the wrong type. Adding the DataBlockEncoding on the cache key caused a cache miss if the block was cached with the wrong encoding, implicitly defining the BlockType and thus keeping this from happening. It is now the scanner's responsibility to specify both the expected type and encoding (which is more appropriate)."
HBASE-6492,"In 0.96 we now have the Hadoop1-compat and Hadoop2-compat projects.
The reflection we're using to deal with different versions of Hadoop should be removed in favour of using the compact projects."
HBASE-1001,If a delete cell has been entered but there is no corresponding deleted item -- or the deleted item has been expunged because > VERSIONS -- then there is no reason keeping the delete cell when compacting.
HBASE-5587,"Are the {{hbase.*.dns.interface}} configuration options used or needed?  Per HBASE-4109 it looks like these never really worked, at least in cases where the hostname with a trailing dot doesn't resolve. The reason I asked is that while these were introduced in Hadoop, I don't think they're actually used, nor am I convinced bypassing the host for DNS lookups is a good idea (leads to painful bugs where default Java DNS lookups differ with these lookups). HBase started using these via a similar feature in HBASE-1279 and HBASE-1279.

I filed HADOOP-8156 to remove the API which HBase uses, which is obviously an incompatible change and would need to be worked around here if you wanted to keep this functionality in HBase, ie *if* that were to get checked into Hadoop we'd first need to get you on your own DNS class. Either way I'll update DNS' InterfaceAudience annotation to indicate HBase is a user."
HBASE-1465,"Eclipse on my Mac is showing some errors when an @Override is used when a class implements an interface rather than extends.

Not a big deal but I want to keep this patch around anyways for personal use."
HBASE-3274,See HBASE-2721 for details. We have fixed the default values in HBASE-3272 but we should also follow Hadoop to remove all hardcoded strings that refer to configuration properties and move them to HConstants. 
HBASE-12602,"Currently, we can't call hasNext() from ResultScanner directly. I think It is convenient that ResultScanner implements Iterator.
"
HBASE-16410,"Currently when copyService.copy() returns non-zero return value, we throw exception:
{code}
        throw new IOException(""Failed of Hadoop Distributed Copy from ""+
            StringUtils.join(incrBackupFileList, "","") +"" to ""
          + backupContext.getHLogTargetDir());
{code}
We should retry distcp job when the return value is non-zero instead of throwing IOException immediately."
HBASE-2888,"HBase publishes a bunch of metrics, some useful some wasteful, that should be improved to deliver a better ops experience. Examples:

 - Block cache hit ratio converges at some point and stops moving
 - fsReadLatency goes down when compactions are running
 - storefileIndexSizeMB is the exact same number once a system is serving production load

We could use new metrics too."
HBASE-2462,"Anything that improves our i/o profile makes hbase run smoother.  Over in HBASE-2457, good work has been done already describing the tension between minimizing compactions versus minimizing count of store files.  This issue is about following on from what has been done in 2457 but also, breaking the hard-to-read compaction code out of Store.java out to a standalone class that can be the easier tested (and easily analyzed for its performance characteristics).

If possible, in the refactor, we'd allow specification of alternate merge sort implementations. "
HBASE-3178,"Stack recommended in HBASE-3126 that: ""We should kill all inheritance in our scripts (except JAVA_HOME?)""

This jira is about doing that."
HBASE-2375,"Currently we will make the decision to split a region when a single StoreFile in a single family exceeds the maximum region size.  This issue is about changing the decision to split to be based on the aggregate size of all StoreFiles in a single family (but still not aggregating across families).  This would move a check to split after flushes rather than after compactions.  This issue should also deal with revisiting our default values for some related configuration parameters.

The motivating factor for this change comes from watching the behavior of RegionServers during heavy write scenarios.

Today the default behavior goes like this:
- We fill up regions, and as long as you are not under global RS heap pressure, you will write out 64MB (hbase.hregion.memstore.flush.size) StoreFiles.
- After we get 3 StoreFiles (hbase.hstore.compactionThreshold) we trigger a compaction on this region.
- Compaction queues notwithstanding, this will create a 192MB file, not triggering a split based on max region size (hbase.hregion.max.filesize).
- You'll then flush two more 64MB MemStores and hit the compactionThreshold and trigger a compaction.
- You end up with 192 + 64 + 64 in a single compaction.  This will create a single 320MB and will trigger a split.
- While you are performing the compaction (which now writes out 64MB more than the split size, so is about 5X slower than the time it takes to do a single flush), you are still taking on additional writes into MemStore.
- Compaction finishes, decision to split is made, region is closed.  The region now has to flush whichever edits made it to MemStore while the compaction ran.  This flushing, in our tests, is by far the dominating factor in how long data is unavailable during a split.  We measured about 1 second to do the region closing, master assignment, reopening.  Flushing could take 5-6 seconds, during which time the region is unavailable.
- The daughter regions re-open on the same RS.  Immediately when the StoreFiles are opened, a compaction is triggered across all of their StoreFiles because they contain references.  Since we cannot currently split a split, we need to not hang on to these references for long.

This described behavior is really bad because of how often we have to rewrite data onto HDFS.  Imports are usually just IO bound as the RS waits to flush and compact.  In the above example, the first cell to be inserted into this region ends up being written to HDFS 4 times (initial flush, first compaction w/ no split decision, second compaction w/ split decision, third compaction on daughter region).  In addition, we leave a large window where we take on edits (during the second compaction of 320MB) and then must make the region unavailable as we flush it.


If we increased the compactionThreshold to be 5 and determined splits based on aggregate size, the behavior becomes:
- We fill up regions, and as long as you are not under global RS heap pressure, you will write out 64MB (hbase.hregion.memstore.flush.size) StoreFiles.
- After each MemStore flush, we calculate the aggregate size of all StoreFiles.  We can also check the compactionThreshold.  For the first three flushes, both would not hit the limit.  On the fourth flush, we would see total aggregate size = 256MB and determine to make a split.
- Decision to split is made, region is closed.  This time, the region just has to flush out whichever edits made it to the MemStore during the snapshot/flush of the previous MemStore.  So this time window has shrunk by more than 75% as it was the time to write 64MB from memory not 320MB from aggregating 5 hdfs files.  This will greatly reduce the time data is unavailable during splits.
- The daughter regions re-open on the same RS.  Immediately when the StoreFiles are opened, a compaction is triggered across all of their StoreFiles because they contain references.  This would stay the same.

In this example, we only write a given cell twice (instead of 4 times) while drastically reducing data unavailability during splits.  On the original flush, and post-split to remove references.  The other benefit of post-split compaction (which doesn't change) is that we then get good data locality as the resulting StoreFile will be written to the local DataNode.  In another jira, we should deal with opening up one of the daughter regions on a different RS to distribute load better, but that's outside the scope of this one."
HBASE-3866,"When a new region server is brought online, the current balancer kicks off a whole bunch of region moves and causes a lot of regions to be un-available right away.  A slower balancer that gradually balances the cluster is probably a good script to have.  I have an initial version that mooches off the region_mover script to do this.

"
HBASE-633,Compacting into local fs and then copying the resulting file up into hdfs rather than writing compacted file directly to hdfs may run faster.  Try it.
HBASE-3649,"In this thread on user@hbase: http://search-hadoop.com/m/WUnLM6ojHm1 J-D conjectures that compressing flush files leads to a suboptimal situation where ""the puts are sometimes blocked on the memstores which are blocked by the flusher thread which is blocked because there's too many files to compact because the compactor is given too many small files to compact and has to compact the same data a bunch of times.""

We have a separate compression setting already for major compaction vs store files written during minor compaction, for background/archival apps. Add a separate compression setting for flush files, default to none, to avoid the above condition."
HBASE-3917,"The Avro schema files are in the src/main/java path, but should be in /src/main/resources just like the Hbase.thrift is. Makes the separation the same and cleaner."
HBASE-14040,Move distributed log roll procedure call to BackupHandler.call from IncrementalBackupManager.getLogFilesForNewBackup.
HBASE-2480,Balancer is really basic; it just looks at counts of regions at the moment.  It also as it currently works has loads of issues (See the linked issues) including a lack of testibility.  This issue acts as the umbrella issue to collect all balancer improvements under.
HBASE-484,"Right now we keep our HRegionInfos stored as a stream of bytes in a single column in the META and ROOT tables. This is convenient to build and write in code under normal circumstances, and we've made the shell deserialize the binary into human readable data for display purposes.

However, we really don't have much flexibility to edit the info through the shell since it's binary. This means that when we need some latitude to reach in and tweak some stuff because of bugs or just for experimental purposes, we have to go and write custom tools in Java to achieve anything.

One way to mitigate this problem would be to stop storing HRIs as binary data and start putting each field into separate first-class columns in META and ROOT. This would let us do whatever we want in terms of single-row operations in the shell. We wouldn't have to make a special case for reading the data in those circumstances then, either."
HBASE-6704,"StoreScanner#next tries to ensure that the KVs are pulled from the heap in-order. The prevKV is used for this and is compared with the latest KV pulled from the heap. Since copyKV can be modified by ScanQueryMatcher, prevKV should track the KV pulled from the heap, and not copyKV. This is a one-line fix."
HBASE-3700,"I once had an issue of ""Too many connections"" in ZooKeeper while running a MapReduce job where tables are used in my own classes instead of the interface provided by HBase (e.g. TableInputFormat and TableOutputFormat etc).  Investigation suggests this is due to many ZooKeeper's connection slots are occupied by remaining connections after clients exit, so that the free slots are not enough.

Discussed with Lars George, I suggest we note the need of explicit close of connections (to ZooKeepers) in HBase book.  Lars also suggests we improve TableOutputFormat by adding explicit calls to close methods."
HBASE-18360,{{Table}} doesn't have {{flushCommits}} method to explicitly flush mutations which is required for certain scenarios. This was a method available to users when {{HTable}} was accessible to users. Can we add {{flushCommits}} to {{Table}}. I can provide a patch if there are no objections to include this method.
HBASE-5847,The Thrift API does not allow a user to create a table with multiple split keys.  This is needed for a handful of new internal projects that are written in PHP/C++.
HBASE-2841,"HBASE-1511 added psuedo-distributed support for RegionServers and backup Masters, however there were some obstacles preventing the last piece: psuedo-distributed ZooKeeper clients (HQuorumPeer).  No major obstacles, just enough that I don't have time to work on them immediately.  This would be a great noob task to get familiar with how our ZooKeeper code works and make minor changes that will greatly help us test this product.  Note that if you're feeling extra ambitious, you could work on adding startZkCluster(int), killZkPeer(int), and restartZkPeer(int) to HBaseTestingUtility.java for JUnit test goodness."
HBASE-2608,"There are 2 compelling reasons to switch from log4j to slf4j:
* HBase provides a client library that is going to be embedded in another application.  Using SLF4J lets the application chose whatever logging library it wants instead of imposing log4j.
* When using SLF4J, we should use logback by default as it is basically a better, faster, stronger log4j.  Same author, new design / new code.  See http://logback.qos.ch/reasonsToSwitch.html"
HBASE-8309,"Currently the lock timeout values and defaults are set and shared at the TableLockManager level.
One TableLockManager is shared on the master. We should allow the lock timeout to be set at individual lock level when we instantiate the lock. Components using the locks may have different timeout preferences. 
"
HBASE-8124,"When users invoke TableMapReduceUtils#addDependencyJars, directly or indirectly, the discovered jars are added to the jobconf via the configuration point ""tmpjars"". That means that, if I want to use one jobconf as the basis of another, and I blanket copy all ""hbase.*"" confs, the dependency jar list will be missed. Since the dependency jars are critical for successful execution of the job, and not an internal API passed between different MR components, this config point should be renamed to something starting with ""hbase."""
HBASE-6627,"org.apache.hadoop.hbase.TestMultiVersions.testGetRowVersions


Shutting down

Stacktrace

java.io.IOException: Shutting down
	at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:229)
	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:92)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:688)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:661)
	at org.apache.hadoop.hbase.TestMultiVersions.testGetRowVersions(TestMultiVersions.java:143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:47)
	at org.junit.rules.RunRules.evaluate(RunRules.java:18)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run"
HBASE-1307,"I created this issue to be the overall issue for threading to increase read and write performance in HBase and to keep it as a discussion place about threading of these elements in general. Today we are doing batching of  writes and from 0.20 you will be able to do that for reads too. The thing is that the batching procedure doesn't use the ability to run these different queries at the same time, but more like a series of queries. I think that after getting a good stable 0.20 system down we should try to add threading to increase throughput for both reading and writing. At the top level of these calls I don't think that is is goin gto be to hard to do this in parallel, where it gets a little bit more complicated is when you get down to running a get query on memcache and all the storefiles at the same time, but above that I don't see it being to hard. I do think that this should not be a part of 0.20 but rather an optimization in 0.21 or so."
HBASE-2623,"I witnessed a case last night where a region open got stuck -- it was an idx hbase region running on 0.20.5, seems like this combo doesn't work -- and it prevented our opening other regions behind it.  We never recovered.  Both the table that had the stuck region and all tables that had regions that were in the queue behind this stuck region were now borked.  There was no way out.

Add a timeout on region open.  If a region open fails N times, put it aside."
HBASE-16327,Bufferchain is nothing but a collection of Bytebuffers. We already have MultiBytebuff. May be we can unify both and add the Bufferchain#write() to ByteBuff abstract class. 
HBASE-12002,The feature introduced in HBASE-11990 should be reflected in the HBase book.
HBASE-11808,We should update the jdiffHBasePublicAPI script in hbase/dev-support to be a bit more user-friendly.
HBASE-13689,Try to bring down the time on our post-commit tests using [the parallel test executor plugin|https://wiki.jenkins-ci.org/display/JENKINS/Parallel+Test+Executor+Plugin] for jenkins.
HBASE-2597,"We've got a lot of objects that have a ton of different constructors with a huge number of parameters. Whenever we add a new parameter, existing callers break, and it's sometimes difficult to keep track of which booleans/nulls correspond to which parameter.

I'd like to consider moving to the ""Builder"" pattern in some of these cases. See http://guava-libraries.googlecode.com/svn/trunk/javadoc/com/google/common/collect/MapMaker.html for an example of this pattern in action. Another good example is the builder API generated by protocol buffers (search for ""builder"" on http://code.google.com/apis/protocolbuffers/docs/javatutorial.html )

I think this pattern makes code more readable and also allows us to more easily change around the number of arguments in our constructors."
HBASE-6058,"We use async API today. This is already much much faster than the sync API. Still, it makes sense to use the 'multi' function: this will decrease the network & zookeeper load at startup/rolling restart.

On a 500 nodes cluster, we see 3 that 3 seconds are spent on updating ZK per bulk assignment. This should cut it in half (+ the benefits on the network/zk load)."
HBASE-2459,"Currently we synchronize within HConnectionManager.locateRegionInMeta() when looking up the cached location (and querying meta if not cached).  We use the same lock for every user-space region.

We really only need per-region synchronization here."
HBASE-10938,"In case the namespace table is assigned to the master, TableNamespaceManager should use the shortcut connection."
HBASE-2895,"I'd love to use some annotations to document some common things. In particular I'd love to see @ThreadSafe and @NotThreadSafe. If not for all classes it would at least be nice to have this for all the client classes that a user might see.

http://jcip.net/annotations/doc/index.html
Those can be easily pulled in via Maven.

Should we do it?

Hadoop common also started using  InterfaceAudience and InterfaceStability annotations which might be nice."
HBASE-16506,"Currently for SNAPSHOT_TABLES stage, we loop through the tables and take snapshot for each table.
If the master restarts in the middle of this stage, we would restart taking snapshot from the first table.

This issue would use subprocedure for each snapshot so that we don't need to take snapshot for the table(s) whose snapshot is complete before the master restart."
HBASE-9416,"Nasty & hacky patch on top of the 0.96 to get some feedback on adding this third party.
I ran a test doing ""gets"" on an empty region.
With the current implementation, we're spending time in the LinkedBlockingQueue#put. I was able to do 150K operations per second.

Using the disruptor allowed me to go to 190 ops/s, i.e. a little be more than a 25% improvement.

Likely there are other improvements in this class as well."
HBASE-6128,Thanks to HBASE-5739 we can now specify a max weight instead of a maximum number of blocks in the DoubleBlockCache. This will give a more accurate control over its memory usage.
HBASE-7623,"Sometimes, some non-IOException prevents User.getCurrent() to get a username.  It makes it impossible to create a HConnection.  We should catch all exception here:

{noformat}
      try {
        User currentUser = User.getCurrent();
        if (currentUser != null) {
          username = currentUser.getName();
        }
      } catch (IOException ioe) {
        LOG.warn(""Error obtaining current user, skipping username in HConnectionKey"",
            ioe);
      }
{noformat}

Not just IOException, so that client can move forward.
"
HBASE-7015,"Having major_compact --force would have some advantages:

1.) Changing compression type and making sure all storefiles are written with the new value

2.) Can help with TTL and expiring all old data

"
HBASE-59,"mapreduce has a configuration property called ""mapred.system.dir"" which determines where in the DFS a jobtracker stores its data.  Similarly, hbase has a configuration property called ""hbase.rootdir"" which does something very similar.

These should have the same name, eg. ""hbase.system.dir"" and ""mapred.system.dir""
"
HBASE-16817,"Current we write length header before KeyValueUtil#oswrite, it is more efficient to  write length header inside it, so we only to calculate the length only once."
HBASE-7348,"DFSClient actually collected a number of useful statistics such as bytesLocalRead, bytesLocalRackRead and so on. So this diff is going to merge these metrics into the RegionServerMetrics."
HBASE-10784,"For adding/querying rowcol and deleteColumn BF, there are multiple unnecessary memory copy operations. This jira is to address the concern and avoid creating these dummy bloom keys as much as possible."
HBASE-10083,"When RegionServer failed to load a bloom block from HDFS due to any timeout or other reasons, it threw out the exception and disable the entire bloom filter for this HFile. This behavior does not make too much sense, especially for the compound bloom filter. 

Instead of disabling the bloom filter for the entire file, it could just return a potentially false positive result (true) and keep the bloom filter available."
HBASE-8083,"Currently, HBaseClient would throw retry_exhausted_exception to the client, which is not very informative to debug the reliability issues. So the plan is the HBaseClient could expose more details information in these exceptions. For example, what's the region server or region for the exception ? What's the server side exception in details ?

Most the information might be already there but we need to expose them in a uniform format."
HBASE-10360,"HTable.getHRegionInfo() will return all the RegionServer address for each HRegion by scanning the META table. Actually, the HConnectionManger could cache these data and refresh the client location cache directly. Also, HTable could expose another API to return these cached HRegionLocation directly without scanning the META table."
HBASE-7106,"In JDK7, it will throw out NPE if put a NULL into a TreeSet. And in the unit tests, user can add a NULL as qualifier into the family map for GET or SCAN. 
So we shall do the followings: 

1) Make sure the semantics of NULL column qualifier is equal to that of the EMPYT_BYTE_ARRAY column qualifier.

2) An easy fix is to use the EMPYT_BYTE_ARRAY qualifier to replace NULL qualifier in the family map for the GET or SCAN objects, and everything else shall be backward compatible.

3) Add a jdk option in the pom.xml (Assuming user installed the fb packaged jdk)
eg: mvn test -Dtest=TestFromClientSide -Pjdk7"
HBASE-12280,"This change allows us to change the number of blocking store files on-line. This is already done, and should appear in the 89-fb branch soon. For context, see: HBASE-8544, HBASE-8576, HBASE-8805"
HBASE-7276,"In HBase, each RegionServer will host a set of Regions and both of them keep track of the read/write requests metrics. So total number of read/write requests among all the Regions shall be equal to the total number from the RegionServer. We shall optimize the code to remove the redundant metrics in the RegionServer level, and merge the Region level metrics into the RegionServer level."
HBASE-7193,"The hbase client only prints the name of exception for the RetriesExhaustedException logging purpose, which failed to provide any useful debug information.

So this jira is to enhance the logging to print the entire stack track of the exception to help on issue investigation."
HBASE-6911,It is too much logging for each row-location cache hit in the hbase client. So set it as the trace level. 
HBASE-7266,"There are 2 kinds of read operations in HBase: pread and seek+read.
Pread, positional read, is stateless and create a new connection between the DFSClient and DataNode for each operation. While seek+read is to seek to a specific postion and prefetch blocks from data nodes. The benefit of seek+read is that it will cache the prefetch result but the downside is it is stateful and needs to synchronized.

So far, both compaction and scan are using seek+read, which caused some resource contention. So using the pread for the scan request can avoid the resource contention. In addition, the region server is able to do the prefetch for the scan request (HBASE-6874) so that it won't be necessary to let the DFSClient to prefetch the data any more.

I will run through the scan benchmark (with no block cache) with verify the performance."
HBASE-2239,"One of the requirements of IHBase is that the a filter should be provided that at least matches the index expression hint.  The IHBase expression classes could easily be used to generate a filter that can be used on the scan...

For example: 
{code}
Expression expression = Expression
    .or(
        Expression.comparison(columnName1, qualifer1, operator1, value1)
    )
    .or(
        Expression.and()
            .and(Expression.comparison(columnName2, qualifer2, operator2, value2))
            .and(Expression.comparison(columnName3, qualifer3, operator3, value3))
    );

Filter filter  = expression.toFilter();
{code}"
HBASE-8682,The data ingestion integration test almost always fails on us due to region is not available.  I'd like to add some information before killing a region server so that we have a better idea about what's going on.
HBASE-2367,
HBASE-685,"Over in HBASE-684, LN suggests that we should find alternative to synchronized sortedmap; its used all over the place in hbase so a faster alternative should improve thoughput.  That synchronized sortedmap is less than perfect has been known from earliest days (see cafarella comment at head of HStore#internalGet in 0.1 branch."
HBASE-15453,"In HBASE-10015 back then I found that intrinsic locks (synchronized) in StoreScanner are slower that explicit locks.

I was surprised by this. To make sure I added a simple perf test and many folks ran it on their machines. All found that explicit locks were faster.

Now... I just ran that test again. On the latest JDK8 I find that now the intrinsic locks are significantly faster:
(OpenJDK Runtime Environment (build 1.8.0_72-b15))

Explicit locks:
10 runs  mean:2223.6 sigma:72.29412147609237

Intrinsic locks:
10 runs  mean:1865.3 sigma:32.63755505548784

I confirmed the same with timing some Phoenix scans. We can save a bunch of time by changing this back 

Arrghhh... So maybe it's time to revert this now...?

(Note that in trunk due to [~ram_krish]'s work, we do not lock in StoreScanner anymore)

I'll attach the perf test and a patch that changes lock to synchronized, if some folks could run this on 0.98, that'd be great.
"
HBASE-72,"Region server and client logs will have lots of the following when a cluster is being loaded:
{code}
org.apache.hadoop.hbase.NotServingRegionException: hbaserepository,,7144829661993961256
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1208)
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1180)
        at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1122)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:985)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:340)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:566)
{code}

The NotServingRegionException exception is thrown when the remote server is no longer serving the asked-for region (usually because its been split).  The server throws the exception to provoke the client into making a new interrogation of region locations.

It would be an improvement if such 'normal' operation was not built atop exceptions.  For example, commits might return a 'region moved' message."
HBASE-80,
HBASE-73,"As is, generated code goes into o.a.h.h.thrift.generated, o.a.h.h.hql.generated, etc.  Rather, have it all go into the one package, o.a.h.h.generated."
HBASE-69,"When flusher runs -- its triggered when the sum of all Stores in a Region > a configurable max size -- we flush all Stores though a Store memcache might have but a few bytes.

I would think Stores should only dump their memcache disk if they have some substance.

The problem becomes more acute, the more families you have in a Region.

Possible behaviors would be to dump the biggest Store only, or only those Stores > 50% of max memcache size.  Behavior would vary dependent on the prompt that provoked the flush.  Would also log why the flush is running: optional or > max size.

This issue comes out of HADOOP-2621.

"
HBASE-1306,"There are multiple places where we can make an update run in parallel when inserting into HBase. Two of these points are making every row get it's own thread and then every family, store, get it's own thread when you are in the right region."
HBASE-4044,"    We found that the hlog flush to disk would block other write threads. When one thread exec ""doWrite(info, logKey, edit);"", the others wait for ""updateLock"" in HLog.java.

    Why not the others add their edits into a list and wait. When sync's time, the whole list sync to disk once. I think it will decrease the IO calls. 

    So Maybe we will make two lists for edits. Each thread write to the ""waledits"" and wait for ""updateLock"". Each thread can copy the ""waledits"" to ""flushedits"" and flush the ""flushedits"" to disk once it gets ""updateLock"".

    In my test, it can increase the write speed of 100% when I set ""hbase.regionserver.handler.count""=100."
HBASE-2910,"I am working on the Hue based front end called the ""HBase Explorer"". It would be good to be able to also display the current cluster configuration."
HBASE-1690,"Support a simple access control mechanism via HTTP basic authentication.  Allow definition of authorized users and assignment of ACLs to those users backed by an HBase table. A first cut might just be to control table accesses -- a user will either be allowed any access to a table or nothing. Subsequently, supporting the granting or revocation of various combinations of create, update, read, and delete privileges on tables or column families can be considered. "
HBASE-1113,"I think there was a reason for why closes' were not recorded but can't remember what it was.

We should try and figure a way of adding it because its disorientating looking at a regions history seeing it opened multiple times with a close in between.  Would be sweet if could record too why closed; e.g. load balancing.

W/o the recording of 'close', I find I have to go to master logs to get a regions history.  I'd like to not have to."
HBASE-10886,"Once htrace-zipkin was removed from depencencies in HBASE-9700. Because all of the depencencies of htrace-zipkin is bundled with HBase now, it is good to add it for the ease of use."
HBASE-8220,"In HTablePool, we have a method getCurrentPoolSize(...) to get how many opened HTable has been pooled. However, we don't know ConcurrentOpenedHTable which means the count of HTable get from HTablePool.getTable(...) and don't return to HTablePool by PooledTable.close(). The ConcurrentOpenedHTable may be meaningful because it indicates how many HTables should be opened for the application which may help us set the appropriate MaxSize of HTablePool. Therefore, we can and a ConcurrentOpenedHTable as a counter in HTablePool."
HBASE-6045,In discussion of HBASE-6013 it was suggested that we change --peer.adr to the more english centric --peer.addr.  We would keep the old value present in 0.90/0.92/0.94 and remove from 0.96/trunk.
HBASE-7708,"We noticed high CPU utilization while using region_mover.rb to unload regions.  Consulted with Stack, who suggested changing a line in region_mover.rb from (the deprecated):
{code}
  table = getTable(admin.getConfiguration(), r.getTableDesc().getName())
{code}
to:
{code}
  table = getTable(admin.getConfiguration(), r.getTableName())
{code}
In our tests this dropped CPU utilization from ~200% over the course of the unload to ~0.5% after startup, and allowed unload of ~200 regions to complete in ~7 minutes instead of the original ~18 minutes, so the change seems to fix the CPU utilization issue with no untoward side effects we could find."
HBASE-2170,"As a wish - it would be nice to have a hbase client library (subset of the current hbase distribution) that needs to be present at the hbase client level to interact with the master/region servers. 

From an app integration - users of hbase can just link against the client library as opposed to getting the entire library to link against. 





"
HBASE-1814,"as per #hbase:

12:22 < larsgeorge> you gueys should not be allowed in the same car - ever
12:22 < larsgeorge> *guys
12:22 < dj_ryan> yeah
12:22 < larsgeorge> too dangerous for the project
12:22 < dj_ryan> it was pretty much some of the core hbase braintrust in 1 car
12:22 < rpaddock> I'd file a jira about that

The risk is clearly too great. "
HBASE-749,"a patch, for anyone need 0.1.x running on hadoop 0.17.x

only 0.1.3 with hadoop 0.17.1 tested."
HBASE-10096,"As [https://issues.apache.org/jira/browse/HBASE-6942] introduced, BulkDeleteEndpoint provides 'delete' method which performs like sql : ""delete from table where ..."". BulkDeleteEndpoint is efficient because it can complete scan and delete in one rpc and also could be implemented parallelly in different regions using coprocessor. BulkDeleteResponse is represents the result of BulkDeleteEndpoint.delete and will be serialized using a standard java serializable way. However, the serialized length of BulkDeleteResponse will be longer than one hundred byte length and may be not efficient enough to pass  on the network. Therefore, is it better to make BulkDeleteResponse implement Writable interface and provide more efficient serialize method?"
HBASE-10790,"Now to compile a HBase tar release package, we should use
the cmd: 
{code}
 mvn clean package assembly:single
{code}, which is not convenient. We can make assembly:single as a default option and run the assembly plugin in maven package phase. Then we can just use the cmd {code} mvn clean package {code} to get a release package.

Other suggestions are welcomed.
"
HBASE-775,Currently we compact all map files with no upper limit this could cause a regionserver to OOME if the compaction get behind and the number of mapfiles build up.
HBASE-7922,"Removed several warnings in eclipse editor.  no new test cases be added, since no semantics changed"
HBASE-10468,"Followup for HBASE-10277.
Further work can be done, as discussed in comments, such as moving ""global"" error management for streaming use case from AsyncProcess to HTable."
HBASE-5075,"regionserver crashed,it is too long time to notify hmaster.when hmaster know regionserver's shutdown,it is long time to fetch the hlog's lease.
hbase is a online db, availability is very important.
i have a idea to improve availability, monitor node to check regionserver's pid.if this pid not exsits,i think the rs down,i will delete the znode,and force close the hlog file.
so the period maybe 100ms.
"
