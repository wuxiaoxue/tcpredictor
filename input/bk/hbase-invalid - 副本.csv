HBASE-1249,"To discuss all the new and potential issues coming out of the change in key format (HBASE-1234): zero-copy reads, client binary protocol, update of API (HBASE-880), server optimizations, etc...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18472,"When I run mvn clean install -DskipTests on my local machine, lt always shows error below 
{quote}
WARNING] Rule 0: org.apache.maven.plugins.enforcer.EvaluateBeanshell failed with message:
License errors detected, for more detail find ERROR in hbase-assembly/target/maven-shared-archive-resources/META-INF/LICENSE

Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce (check-aggregate-license) on project hbase-assembly: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed.
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18413,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17874,"HBASE-14978 added this size limiting so as to make sure the multi read requests do not retain two many blocks. This works well when the blocks are obtained from any where other than memory mode BucketCache. In case of on heap or off heap Bucket Cache, the entire cache area is split into N ByteBuffers each of size 4 MB. When we hit a block in this cache, we no longer do copy data into temp array. We use the same shared memory (BB).  Its  capacity is 4 MB.
The block size accounting logic is RSRpcServices is like below
{code}
 if (c instanceof ByteBufferCell) {
          ByteBufferCell bbCell = (ByteBufferCell) c;
          ByteBuffer bb = bbCell.getValueByteBuffer();
          if (bb != lastBlock) {
            context.incrementResponseBlockSize(bb.capacity());
            lastBlock = bb;
          }
        } else {
          // We're using the last block being the same as the current block as
          // a proxy for pointing to a new block. This won't be exact.
          // If there are multiple gets that bounce back and forth
          // Then it's possible that this will over count the size of
          // referenced blocks. However it's better to over count and
          // use two rpcs than to OOME the regionserver.
          byte[] valueArray = c.getValueArray();
          if (valueArray != lastBlock) {
            context.incrementResponseBlockSize(valueArray.length);
            lastBlock = valueArray;
          }
        }
		{code}
We take the BBCell's value buffer and takes its capacity. The cell is backed by the same BB that backs the HFileBlock. When the HFileBlock is created from the BC, we do as below duplicating and proper positioning and limiting the BB
{code}
 ByteBuffer bb = buffers[i].duplicate();
      if (i == startBuffer) {
        cnt = bufferSize - startBufferOffset;
        if (cnt > len) cnt = len;
        bb.limit(startBufferOffset + cnt).position(startBufferOffset);
		{code}
Still this BB's capacity is 4 MB.
This will make the size limit breach to happen too soon. What we expect is block size defaults to 64 KB and so we here by allow cells from different blocks to appear in response. We have a way to check whether we move from one block to next.
{code}
if (bb != lastBlock) {
...
            lastBlock = bb;
}
{code}
But already just by considering the 1st cell, we added 4 MB size!",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15573,"Can't retrieve any information with hbase  rpc java client.
With hbase shell its possible to scan data and retrieve all the information normally.

But with any rpc client region server don't retrieve data, all data come with null values.

Region Server log:
DEBUG [RpcServer.reader=2,bindAddress=HBASE,port=16020] ipc.RpcServer: RpcServer.listener,port=16020: DISCONNECTING client SERVER:37088 because read count=-1
DEBUG [RpcServer.reader=2,bindAddress=HBASE,port=16020] ipc.RpcServer: RpcServer.listener,port=16020: DISCONNECTING client SERVER2:36997 because read count=-1

Master log:
2016-03-31 18:16:27,998 DEBUG [ProcedureExecutorTimeout] procedure2.ProcedureExecutor$CompletedProcedureCleaner: No completed procedures to cleanup.
2016-03-31 18:16:57,998 DEBUG [ProcedureExecutorTimeout] procedure2.ProcedureExecutor$CompletedProcedureCleaner: No completed procedures to cleanup.
2016-03-31 18:17:27,998 DEBUG [ProcedureExecutorTimeout] procedure2.ProcedureExecutor$CompletedProcedureCleaner: No completed procedures to cleanup
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14903," I've been reading on Latest Reference Guide and try to translated into Chinese!
     I think this sentence ""When a table is in the process of splitting,"" should be ""When a Region is in the process of splitting,"" on chapter 銆?2.2. hbase:meta銆戙€?     By the way,is this document the latest?銆恏ttp://hbase.apache.org/book.html#arch.overview銆慖 will translate it锛?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,2015-12-03 19:23:27.39,,false,,,,,,,,,,,,,9223372036854775807,,,,,Sun Dec 06 02:38:23 UTC 2015,,,,,,0|i2p5cf:,9223372036854775807,,,,,,,,03/Dec/15 19:23;apurtell;bq. I think this sentence """"When a table is in the process of splitting",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14957,"for initializing nutch, after configuring nutch whent I am trying to kickoff start-hbase.sh I am getting the below error.

/cygdrive/c/users/gaurav.kandpal/desktop/test/hbase-0.94.9.tar/hbase-0.94.9/hbase-0.94.9/bin/../conf/hbase-env.sh: line 101: $'\r': command not found
/cygdrive/c/users/gaurav.kandpal/desktop/test/hbase-0.94.9.tar/hbase-0.94.9/hbase-0.94.9/bin/../conf/hbase-env.sh: line 104: $'\r': command not found
/cygdrive/c/users/gaurav.kandpal/desktop/test/hbase-0.94.9.tar/hbase-0.94.9/hbase-0.94.9/bin/../conf/hbase-env.sh: line 107: $'\r': command not found
/cygdrive/c/users/gaurav.kandpal/desktop/test/hbase-0.94.9.tar/hbase-0.94.9/hbase-0.94.9/bin/../conf/hbase-env.sh: line 110: $'\r': command not found
/cygdrive/c/users/gaurav.kandpal/desktop/test/hbase-0.94.9.tar/hbase-0.94.9/hbase-0.94.9/bin/../conf/hbase-env.sh: line 115: $'\r': command not found
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.
'nrecognized VM option 'UseConcMarkSweepGC
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.
'nrecognized VM option 'UseConcMarkSweepGC
starting master, logging to /cygdrive/c/users/gaurav.kandpal/desktop/test/hbase-0.94.9.tar/hbase-0.94.9/hbase-0.94.9/bin/../logs/hbase-Gaurav.Kandpal-master-gauravk.out
localhost: /cygdrive/c/users/gaurav.kandpal/desktop/test/hbase-0.94.9.tar/hbase-0.94.9/hbase-0.94.9/bin/regionservers.sh: line 64: ssh: command not found

reference URL is 

https://gist.github.com/xrstf/b48a970098a8e76943b9
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2761,"Never seen this prior to the new meta prefetch stuff. Saw it tonight on a YCSB run after about an hour.

Exception in thread ""Thread-9"" java.lang.OutOfMemoryError: GC overhead limit exceeded
        at java.util.Hashtable.rehash(Hashtable.java:356)
        at java.util.Hashtable.put(Hashtable.java:412)
        at java.util.Properties.setProperty(Properties.java:143)
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1337)
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1227)
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1156)
        at org.apache.hadoop.conf.Configuration.iterator(Configuration.java:1198)
        at org.apache.hadoop.hbase.HBaseConfiguration.hashCode(HBaseConfiguration.java:112)
        at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:121)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:130)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:99)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:102)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.prefetchRegionCache(HConnectionManager.java:733)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:784)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:678)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.processBatchOfPuts(HConnectionManager.java:1424)
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:660)
        at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:545)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2731,"We're getting zillions of these in HMaster when it starts assigning regions at startup and it doesn't seem to progress.

{code}
2010-06-15 06:30:00,287 WARN org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: 
<org.apache.hadoop.hbase.master.HMaster>Failed to create ZNode /hbase/UNASSIGNED/1766164500 in ZooKeeper^D
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /hbase/UNASSIGNED/1766164500^D
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:110)^D
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)^D
        at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:637)^D
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.createZNodeIfNotExists(ZooKeeperWrapper.java:974)^D
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.createUnassignedRegion(ZooKeeperWrapper.java:1053)^D
        at org.apache.hadoop.hbase.master.RegionManager.doRegionAssignment(RegionManager.java:355)^D
        at org.apache.hadoop.hbase.master.RegionManager.assignRegions(RegionManager.java:312)^D
        at org.apache.hadoop.hbase.master.RegionManager.assignRegionsToMultipleServers(RegionManager.java:292)^D
        at org.apache.hadoop.hbase.master.RegionManager.assignRegions(RegionManager.java:221)^D
        at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:500)^D
        at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:425)^D
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:335)^D
        at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:700)^D
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)^D
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)^D
        at java.lang.reflect.Method.invoke(Method.java:597)^D
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:576)^D
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:919)

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3122,"10/10/18 16:26:44 INFO catalog.CatalogTracker: acer,60020,1287443908850 carrying .META.; unsetting .META. location
10/10/18 16:26:44 INFO catalog.CatalogTracker: Current cached META location is not valid, resetting
10/10/18 16:26:44 INFO handler.ServerShutdownHandler: Splitting logs for acer,60020,1287443908850
10/10/18 16:26:44 INFO zookeeper.ZKUtil: hconnection-0x12bc1a2f0a60001 Set watcher on existing znode /hbase/root-region-server
10/10/18 16:26:44 INFO catalog.RootLocationEditor: Unsetting ROOT region location in ZooKeeper
10/10/18 16:26:44 DEBUG zookeeper.ZKAssign: master:60000-0x12bc1a2f0a60000 Creating (or updating) unassigned node for 70236052 with OFFLINE state
10/10/18 16:26:44 WARN master.LoadBalancer: Wanted to do random assignment but no servers to assign to
10/10/18 16:26:44 ERROR executor.EventHandler: Caught throwable while processing event M_SERVER_SHUTDOWN
java.lang.NullPointerException
	at org.apache.hadoop.hbase.master.LoadBalancer$RegionPlan.toString(LoadBalancer.java:595)
	at java.lang.String.valueOf(String.java:2826)
	at java.lang.StringBuilder.append(StringBuilder.java:115)
	at org.apache.hadoop.hbase.master.AssignmentManager.getRegionPlan(AssignmentManager.java:803)
	at org.apache.hadoop.hbase.master.AssignmentManager.getRegionPlan(AssignmentManager.java:777)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:720)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:640)
	at org.apache.hadoop.hbase.master.AssignmentManager.assignRoot(AssignmentManager.java:922)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:97)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:150)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13822,"Launching the shell from a build of {{branch-1.1}} gives me the following error

{noformat}
$ echo $HBASE_HOME
/Users/ndimiduk/repos/hbase
$ $HBASE_HOME/bin/hbase shell
NoMethodError: undefined method `getTerminal' for Java::Jline::Terminal:Module
  refresh_width at /Users/ndimiduk/repos/hbase/hbase-shell/src/main/ruby/shell/formatter.rb:33
     initialize at /Users/ndimiduk/repos/hbase/hbase-shell/src/main/ruby/shell/formatter.rb:46
         (root) at /Users/ndimiduk/repos/hbase/bin/hirb.rb:115
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/Users/ndimiduk/.m2/repository/org/slf4j/slf4j-log4j12/1.7.7/slf4j-log4j12-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13934,"HBase Client get's stuck when I try to execute a PUT operation.

{code}
Thread [BenchmarkThread-0] (Suspended)  
    owns: BufferedMutatorImpl  (id=43)  
    Unsafe.park(boolean, long) line: not available [native method]  
    LockSupport.park(Object) line: 186  
    AbstractQueuedSynchronizer$ConditionObject.await() line: 2043   
    ArrayBlockingQueue<E>.take() line: 374  
    BoundedCompletionService<V>.take() line: 75 
    ScannerCallableWithReplicas.call(int) line: 190 
    ScannerCallableWithReplicas.call(int) line: 56  
    RpcRetryingCaller<T>.callWithoutRetries(RetryingCallable<T>, int) line: 200 
    ClientSmallReversedScanner.loadCache() line: 211    
    ClientSmallReversedScanner.next() line: 185 
    ConnectionManager$HConnectionImplementation.locateRegionInMeta(TableName, byte[], boolean, boolean, int) line: 1200 
    ConnectionManager$HConnectionImplementation.locateRegion(TableName, byte[], boolean, boolean, int) line: 1109   
    AsyncProcess.submit(ExecutorService, TableName, List<Row>, boolean, Callback<CResult>, boolean) line: 369   
    AsyncProcess.submit(TableName, List<Row>, boolean, Callback<CResult>, boolean) line: 320    
    BufferedMutatorImpl.backgroundFlushCommits(boolean) line: 206   
    BufferedMutatorImpl.flush() line: 183   
    HTable.flushCommits() line: 1436    
    HTable.put(Put) line: 1032  
{code}

Source code:

Connect:
{code}
        this.config = HBaseConfiguration.create();
        config.set(""hbase.zookeeper.quorum"", zookeeperHost);

        Connection connection = ConnectionFactory.createConnection(config);
        this.table = connection.getTable(TableName.valueOf(tableName));
{code}

Put:
{code}
        final Put put = new Put(Bytes.toBytes(key));
        for (Map.Entry<String, String> pair : columnValues.entrySet()) {
            final String column = pair.getKey();
            final String value = pair.getValue();
            put.addColumn(columnFamily, Bytes.toBytes(column), Bytes.toBytes(value));
        }

        try {
            table.put(put);
        } catch (IOException e) {
            throw new ClientException(""put error"", e);
        }
{code}

Client log:

{code}
17:00:58,193  INFO ZooKeeper:438 - Initiating client connection, connectString=nosql-x64-node-1.local:2181 sessionTimeout=90000 watcher=hconnection-0x3018fc1a0x0, quorum=nosql-x64-node-1.local:2181, baseZNode=/hbase
17:00:58,325  INFO ClientCnxn:975 - Opening socket connection to server 192.168.56.201/192.168.56.201:2181. Will not attempt to authenticate using SASL (unknown error)
17:00:58,329  INFO ClientCnxn:852 - Socket connection established to 192.168.56.201/192.168.56.201:2181, initiating session
17:00:58,346  INFO ClientCnxn:1235 - Session establishment complete on server 192.168.56.201/192.168.56.201:2181, sessionid = 0x14e06dbd6450020, negotiated timeout = 40000
{code}

Server's log:
{code}
2015-06-18 17:12:28,183 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /192.168.56.1:35002 which had sessionid 0x14e06dbd6450020
2015-06-18 17:12:30,001 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x14e06dbd645001d, timeout of 40000ms exceeded
2015-06-18 17:12:30,002 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x14e06dbd645001d
2015-06-18 17:12:31,078 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /192.168.56.1:35130
2015-06-18 17:12:31,080 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /192.168.56.1:35130
2015-06-18 17:12:31,092 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x14e06dbd6450021 with negotiated timeout 40000 for client /192.168.56.1:35130
{code}

Happens both with HBASE running in standalone and distributed mode.

Any idea what causing this?

HBase version: 1.0.1 (client + server)


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13444,"IntegrationTestBigLinkedList compiled on branch-1 can't talk to an hbase cluster running branch-1.0. See attached stack trace for more details.

Repro steps:
1) start a cluster from branch-1.0
2) copy configs from that cluster into another repo on branch-1
3) run IntegrationTestBigLinkedlist as follows:
./bin/hbase org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList loop 1 1 100 /tmp/blah2 1 10 10 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13087,"{code}org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family table does not exist in region hbase:meta,,1.1588230740 in table 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'}
	at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:4513)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.doNonAtomicRegionMutation(HRegionServer.java:3687)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3576)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:30816)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2029)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)
: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:228)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$1700(AsyncProcess.java:208)
	at org.apache.hadoop.hbase.client.AsyncProcess.waitForAllPreviousOpsAndReset(AsyncProcess.java:1689)
	at org.apache.hadoop.hbase.client.BufferedMutatorImpl.backgroundFlushCommits(BufferedMutatorImpl.java:208)
	at org.apache.hadoop.hbase.client.BufferedMutatorImpl.flush(BufferedMutatorImpl.java:183)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1404)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:1017)
	at org.apache.hadoop.hbase.MetaTableAccessor.put(MetaTableAccessor.java:1123)
	at org.apache.hadoop.hbase.MetaTableAccessor.putToMetaTable(MetaTableAccessor.java:1113)
	at org.apache.hadoop.hbase.MetaTableAccessor.updateTableState(MetaTableAccessor.java:1436)
	at org.apache.hadoop.hbase.MetaTableAccessor.updateTableState(MetaTableAccessor.java:948)
	at org.apache.hadoop.hbase.master.TableStateManager.writeMetaState(TableStateManager.java:195)
	at org.apache.hadoop.hbase.master.TableStateManager.setTableState(TableStateManager.java:69)
	at org.apache.hadoop.hbase.master.AssignmentManager.setEnabledTable(AssignmentManager.java:3427)
	at org.apache.hadoop.hbase.master.HMaster.assignMeta(HMaster.java:903)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:698)
	at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:166)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1494)
	at java.lang.Thread.run(Thread.java:745)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5971,"Here is what happens when we try to register server bean:

{code}
javax.management.NotCompliantMBeanException: org.apache.hadoop.hbase.master.MXBean: Method org.apache.hadoop.hbase.master.MXBean.getRegionServers has parameter or return type that cannot be translated into an open type
	at com.sun.jmx.mbeanserver.Introspector.throwException(Introspector.java:412)
	at com.sun.jmx.mbeanserver.MBeanAnalyzer.<init>(MBeanAnalyzer.java:101)
	at com.sun.jmx.mbeanserver.MBeanAnalyzer.analyzer(MBeanAnalyzer.java:87)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.getAnalyzer(MXBeanIntrospector.java:53)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.getPerInterface(MBeanIntrospector.java:163)
	at com.sun.jmx.mbeanserver.MBeanSupport.<init>(MBeanSupport.java:147)
	at com.sun.jmx.mbeanserver.MXBeanSupport.<init>(MXBeanSupport.java:48)
	at com.sun.jmx.mbeanserver.Introspector.makeDynamicMBean(Introspector.java:184)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:915)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)
	at org.apache.hadoop.metrics.util.MBeanUtil.registerMBean(MBeanUtil.java:58)
	at org.apache.hadoop.hbase.master.HMaster.registerMBean(HMaster.java:1926)
	at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:617)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:367)
	at java.lang.Thread.run(Thread.java:680)
Caused by: java.lang.IllegalArgumentException: Method org.apache.hadoop.hbase.master.MXBean.getRegionServers has parameter or return type that cannot be translated into an open type
	at com.sun.jmx.mbeanserver.ConvertingMethod.from(ConvertingMethod.java:32)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.mFrom(MXBeanIntrospector.java:63)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.mFrom(MXBeanIntrospector.java:33)
	at com.sun.jmx.mbeanserver.MBeanAnalyzer.initMaps(MBeanAnalyzer.java:118)
	at com.sun.jmx.mbeanserver.MBeanAnalyzer.<init>(MBeanAnalyzer.java:99)
	... 14 more
Caused by: javax.management.openmbean.OpenDataException: Cannot convert type: java.util.Map<java.lang.String, org.apache.hadoop.hbase.ServerLoad>
	at com.sun.jmx.mbeanserver.OpenConverter.openDataException(OpenConverter.java:1411)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:264)
	at com.sun.jmx.mbeanserver.ConvertingMethod.<init>(ConvertingMethod.java:184)
	at com.sun.jmx.mbeanserver.ConvertingMethod.from(ConvertingMethod.java:27)
	... 18 more
Caused by: javax.management.openmbean.OpenDataException: Cannot convert type: class org.apache.hadoop.hbase.ServerLoad
	at com.sun.jmx.mbeanserver.OpenConverter.openDataException(OpenConverter.java:1411)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:264)
	at com.sun.jmx.mbeanserver.OpenConverter.makeTabularConverter(OpenConverter.java:360)
	at com.sun.jmx.mbeanserver.OpenConverter.makeParameterizedConverter(OpenConverter.java:402)
	at com.sun.jmx.mbeanserver.OpenConverter.makeConverter(OpenConverter.java:296)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:262)
	... 20 more
Caused by: javax.management.openmbean.OpenDataException: Cannot convert type: java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$Coprocessor>
	at com.sun.jmx.mbeanserver.OpenConverter.openDataException(OpenConverter.java:1411)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:264)
	at com.sun.jmx.mbeanserver.OpenConverter.makeCompositeConverter(OpenConverter.java:467)
	at com.sun.jmx.mbeanserver.OpenConverter.makeConverter(OpenConverter.java:293)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:262)
	... 24 more
Caused by: javax.management.openmbean.OpenDataException: Cannot convert type: class org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$Coprocessor
	at com.sun.jmx.mbeanserver.OpenConverter.openDataException(OpenConverter.java:1411)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:264)
	at com.sun.jmx.mbeanserver.OpenConverter.makeArrayOrCollectionConverter(OpenConverter.java:315)
	at com.sun.jmx.mbeanserver.OpenConverter.makeParameterizedConverter(OpenConverter.java:393)
	at com.sun.jmx.mbeanserver.OpenConverter.makeConverter(OpenConverter.java:296)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:262)
	... 27 more
Caused by: javax.management.openmbean.OpenDataException: Cannot convert type: java.util.Map<com.google.protobuf.Descriptors$FieldDescriptor, java.lang.Object>
	at com.sun.jmx.mbeanserver.OpenConverter.openDataException(OpenConverter.java:1411)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:264)
	at com.sun.jmx.mbeanserver.OpenConverter.makeCompositeConverter(OpenConverter.java:467)
	at com.sun.jmx.mbeanserver.OpenConverter.makeConverter(OpenConverter.java:293)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:262)
	... 31 more
Caused by: javax.management.openmbean.OpenDataException: Cannot convert type: class com.google.protobuf.Descriptors$FieldDescriptor
	at com.sun.jmx.mbeanserver.OpenConverter.openDataException(OpenConverter.java:1411)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:264)
	at com.sun.jmx.mbeanserver.OpenConverter.makeTabularConverter(OpenConverter.java:359)
	at com.sun.jmx.mbeanserver.OpenConverter.makeParameterizedConverter(OpenConverter.java:402)
	at com.sun.jmx.mbeanserver.OpenConverter.makeConverter(OpenConverter.java:296)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:262)
	... 34 more
Caused by: javax.management.openmbean.OpenDataException: Cannot convert type: class com.google.protobuf.Descriptors$Descriptor
	at com.sun.jmx.mbeanserver.OpenConverter.openDataException(OpenConverter.java:1411)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:264)
	at com.sun.jmx.mbeanserver.OpenConverter.makeCompositeConverter(OpenConverter.java:467)
	at com.sun.jmx.mbeanserver.OpenConverter.makeConverter(OpenConverter.java:293)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:262)
	... 38 more
Caused by: javax.management.openmbean.OpenDataException: Recursive data structure, including com.google.protobuf.Descriptors$Descriptor
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:250)
	at com.sun.jmx.mbeanserver.OpenConverter.makeCompositeConverter(OpenConverter.java:467)
	at com.sun.jmx.mbeanserver.OpenConverter.makeConverter(OpenConverter.java:293)
	at com.sun.jmx.mbeanserver.OpenConverter.toConverter(OpenConverter.java:262)
	... 41 more
{code}

On the 'Recursive data structure', jmx open mbean is really helpful suggesting that you just need to rewrite the recursive data structure.

I'll have a go at this later.... tracking something else at mo.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7092,"One instance of ""java.util.concurrent.ConcurrentHashMap"" loaded by ""<system class loader>"" occupies 3,972,154,848 (92.88%) bytes. The instance is referenced by org.apache.hadoop.hbase.regionserver.HRegionServer @ 0x7038d3798 , loaded by ""sun.misc.Launcher$AppClassLoader @ 0x703994668"". The memory is accumulated in one instance of ""java.util.concurrent.ConcurrentHashMap$Segment[]"" loaded by ""<system class loader>"".

Keywords
sun.misc.Launcher$AppClassLoader @ 0x703994668
java.util.concurrent.ConcurrentHashMap
java.util.concurrent.ConcurrentHashMap$Segment[]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6376,"I noticed that commands like ""bin/hbase shell"" doesn't work. The exception trace is:
{noformat}
bin/hbase shell
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/jruby/Main
Caused by: java.lang.ClassNotFoundException: org.jruby.Main
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
{noformat}
This is a trunk build (mvn package -DskipTests=true) and then I am trying to run the bin/hbase command from the root directory. (Am I missing something?)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6521,"This jira is to track a solution/patch to the mailing list thread titled ""Handling protocol versions"" - http://search-hadoop.com/m/6k7GUM028E/v=threaded.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7433,"when i use the client of kettler insert data into hbase table by put operator,it is no problem when the table only has one region,but the data is also too much,so i want to load balancing,so i created many region when i created the table,this time problem is producted,exception is follow:

 Problem inserting row into HBase: Failed 1 action: servers with issues: slave2.hadoop:60020, 
 at org.pentaho.di.trans.steps.hbaseoutput.HBaseOutput.processRow(HBaseOutput.java:316)
 at org.pentaho.di.trans.step.RunThread.run(RunThread.java:50)
 at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: servers with issues: slave2.hadoop:60020, 
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:1601)
org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1377)
at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:916)
at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:772)
at org.apache.hadoop.hbase.client.HTable.put(HTable.java:747)
at org.pentaho.hbase.shim.common.CommonHBaseConnection.executeTargetTablePut(CommonHBaseConnection.java:732)
at org.pentaho.di.trans.steps.hbaseoutput.HBaseOutput.processRow(HBaseOutput.java:307)

we know the client find the rowkey belong to the region of the table,but can't connection the regionserver.but the regionserver is ok,but not running gc
so i can't understand the problem,please help me ,thanks
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6310,"We're still working the on the root cause here, but after the leap second armageddon we had a hard time getting our 0.94 cluster back up. This is what we saw in the logs until the master died by itself:

{noformat}
2012-07-01 23:01:52,149 DEBUG
org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation:
locateRegionInMeta parentTable=-ROOT-,
metaLocation={region=-ROOT-,,0.70236052, hostname=sfor3s28,
port=10304}, attempt=16 of 100 failed; retrying after sleep of 32000
because: HRegionInfo was null or empty in -ROOT-,
row=keyvalues={.META.,,1259448304806/info:server/1341124914705/Put/vlen=14/ts=0,
.META.,,1259448304806/info:serverstartcode/1341124914705/Put/vlen=8/ts=0}
{noformat}

(it's strage that we retry this)

This was really misleading because I could see the regioninfo in a scan:

{noformat}
hbase(main):002:0> scan '-ROOT-'
ROW                                           COLUMN+CELL
 .META.,,1                                    column=info:regioninfo,
timestamp=1331755381142, value={NAME => '.META.,,1', STARTKEY => '',
ENDKEY => '', ENCODED => 1028785192,}
 .META.,,1                                    column=info:server,
timestamp=1341183448693, value=sfor3s40:10304
 .META.,,1
column=info:serverstartcode, timestamp=1341183448693,
value=1341183444689
 .META.,,1                                    column=info:v,
timestamp=1331755419291, value=\x00\x00
 .META.,,1259448304806                        column=info:server,
timestamp=1341124914705, value=sfor3s24:10304
 .META.,,1259448304806
column=info:serverstartcode, timestamp=1341124914705,
value=1341124455863
{noformat}

Except that the devil is in the details, "".META.,,1"" is not "".META.,,1259448304806"". Basically something writes to .META. by directly creating the row key without caring if the row is in the old format. I did a deleteall in the shell and it fixed the issue... until some time later it was stuck again because the edits reappeared (still not sure why). This time the PostOpenDeployTasksThread were stuck in the RS trying to update .META. but there was no logging (saw it with a jstack). I deleted the row again to make it work.

I'm marking this as a blocker against 0.94.2 since we're trying to get 0.94.1 out, but I wouldn't recommend upgrading to 0.94 if your cluster was created before 0.89",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5513,"Used Cloudera Manager 3.7.3 to install Cloudera CDH3U3 on a cluster of EC2 instances. After installation, HBase master cannot start. Both HDFS NN and DN have started successfully.

The HBase log shows 

PM 	INFO 	org.apache.hadoop.hbase.metrics 	

MetricsString added: url

Mar 2, 4:41:21 PM 	INFO 	org.apache.hadoop.hbase.metrics 	

MetricsString added: version

Mar 2, 4:41:21 PM 	INFO 	org.apache.hadoop.hbase.metrics 	

new MBeanInfo

Mar 2, 4:41:21 PM 	INFO 	org.apache.hadoop.hbase.metrics 	

new MBeanInfo

Mar 2, 4:41:21 PM 	INFO 	org.apache.hadoop.hbase.master.metrics.MasterMetrics 	

Initialized

Mar 2, 4:41:21 PM 	INFO 	org.apache.hadoop.hbase.master.ActiveMasterManager 	

Master=epoch-node-101:60000

Mar 2, 4:41:22 PM 	WARN 	org.apache.hadoop.hdfs.DFSClient 	

DataStreamer Exception: org.apache.hadoop.ipc.RemoteException: java.io.IOException: File /hbase/hbase.version could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1520)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:665)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1434)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1430)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1428)

	at org.apache.hadoop.ipc.Client.call(Client.java:1107)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:226)
	at $Proxy6.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy6.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.locateFollowingBlock(DFSClient.java:3553)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:3421)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2100(DFSClient.java:2627)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2822)

Mar 2, 4:41:22 PM 	WARN 	org.apache.hadoop.hdfs.DFSClient 	

Error Recovery for block null bad datanode[0] nodes == null

Mar 2, 4:41:22 PM 	WARN 	org.apache.hadoop.hdfs.DFSClient 	

Could not get block locations. Source file ""/hbase/hbase.version"" - Aborting...

Mar 2, 4:41:22 PM 	WARN 	org.apache.hadoop.hbase.util.FSUtils 	

Unable to create version file at hdfs://epoch-node-101:8020/hbase, retrying: java.io.IOException: File /hbase/hbase.version could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1520)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:665)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1434)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1430)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1428)

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3804,"After putting some significant load on the sever (load around of 8 for approximatively 50 minutes) the following starts showing in the logs and then hbase is completely stuck: won't recover without a restart (I copy a large chunk of the master logs before the problem in case it helps; the bottom part about ROOT and META repeats forever):

9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305484717
2011-04-20 06:19:51,228 INFO org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter: Using syncFs -- HDFS-200
2011-04-20 06:19:51,228 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Creating writer path=hdfs://hqsnosq
l01:9000/hbase/Property/69e1f895ca9d6824b409015a9f9c03a3/recovered.edits/0000000000000098012 region=69e1f895ca9d6824b409
015a9f9c03a3
2011-04-20 06:19:51,539 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Pushed=38 entries from hdfs://HQSNO
SQL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305484717
2011-04-20 06:19:51,540 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Splitting hlog 42 of 43: hdfs://HQS
NOSQL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305492251, length=67522024
2011-04-20 06:19:51,540 INFO org.apache.hadoop.hbase.util.FSUtils: Recovering file hdfs://HQSNOSQL01:9000/hbase/.logs/HQ
SNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305492251
2011-04-20 06:19:52,543 INFO org.apache.hadoop.hbase.util.FSUtils: Finished lease recover attempt for hdfs://HQSNOSQL01:
9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305492251
2011-04-20 06:19:53,336 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Pushed=40 entries from hdfs://HQSNO
SQL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305492251
2011-04-20 06:19:54,894 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Splitting hlog 43 of 43: hdfs://HQS
NOSQL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305500805, length=75765855
2011-04-20 06:19:54,906 INFO org.apache.hadoop.hbase.util.FSUtils: Recovering file hdfs://HQSNOSQL01:9000/hbase/.logs/HQ
SNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305500805
2011-04-20 06:19:55,108 INFO org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter: Using syncFs -- HDFS-200
2011-04-20 06:19:55,108 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Creating writer path=hdfs://hqsnosq
l01:9000/hbase/Property/a21bf162e9ff2915ff036f486919c9b5/recovered.edits/0000000000000098062 region=a21bf162e9ff2915ff03
6f486919c9b5
2011-04-20 06:19:55,908 INFO org.apache.hadoop.hbase.util.FSUtils: Finished lease recover attempt for hdfs://HQSNOSQL01:
9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305500805
2011-04-20 06:19:56,842 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Pushed=43 entries from hdfs://HQSNO
SQL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305500805
2011-04-20 06:19:56,859 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305143661 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305143661
2011-04-20 06:19:56,863 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305152287 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305152287
2011-04-20 06:19:56,867 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305160979 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305160979
2011-04-20 06:19:56,871 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305170430 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305170430
2011-04-20 06:19:56,875 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305178662 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305178662
2011-04-20 06:19:56,879 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305188551 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305188551
2011-04-20 06:19:56,883 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305196703 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305196703
2011-04-20 06:19:56,887 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305205039 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305205039
2011-04-20 06:19:56,891 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305213412 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305213412
2011-04-20 06:19:56,895 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305220665 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305220665
2011-04-20 06:19:56,899 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305231697 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305231697
2011-04-20 06:19:56,913 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305239174 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305239174
2011-04-20 06:19:56,917 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305248013 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305248013
2011-04-20 06:19:56,921 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305256411 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305256411
2011-04-20 06:19:56,925 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305265663 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305265663
2011-04-20 06:19:56,929 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305274667 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305274667
2011-04-20 06:19:56,933 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305283140 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305283140
2011-04-20 06:19:56,937 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305291307 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305291307
2011-04-20 06:19:56,941 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305300632 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305300632
2011-04-20 06:19:56,945 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305309439 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305309439
2011-04-20 06:19:56,949 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305316405 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305316405
2011-04-20 06:19:56,953 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305322730 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305322730
2011-04-20 06:19:56,957 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305330453 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305330453
2011-04-20 06:19:56,961 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305337020 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305337020
2011-04-20 06:19:56,965 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305345309 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305345309
2011-04-20 06:19:56,969 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305352766 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305352766
2011-04-20 06:19:56,972 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305362335 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305362335
2011-04-20 06:19:56,976 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305370474 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305370474
2011-04-20 06:19:56,980 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305379360 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305379360
2011-04-20 06:19:56,984 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305387434 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305387434
2011-04-20 06:19:56,988 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305396557 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305396557
2011-04-20 06:19:56,992 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305403848 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305403848
2011-04-20 06:19:56,996 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305412950 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305412950
2011-04-20 06:19:57,000 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305420349 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305420349
2011-04-20 06:19:57,004 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305429358 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305429358
2011-04-20 06:19:57,008 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305437383 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305437383
2011-04-20 06:19:57,012 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305446715 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305446715
2011-04-20 06:19:57,016 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305460169 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305460169
2011-04-20 06:19:57,678 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305467377 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305467377
2011-04-20 06:19:57,685 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305476873 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305476873
2011-04-20 06:19:57,689 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305484717 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305484717
2011-04-20 06:19:57,693 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305492251 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305492251
2011-04-20 06:19:57,697 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Archived processed log hdfs://HQSNOS
QL01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146/HQSNOSQL01%3A60020.1303305500805 to hdfs://hqsnosql01:9000/hbase/.o
ldlogs/HQSNOSQL01%3A60020.1303305500805
2011-04-20 06:19:57,701 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Waiting for split writer threads to
finish
2011-04-20 06:19:57,874 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Split writers finished
2011-04-20 06:19:57,881 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/36d89fc46915d8db56bad45c64a313a3/recovered.edits/0000000000000096979 (wrote 134 edits in 6107ms)
2011-04-20 06:19:57,885 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/4499b405bae1047884256f39b7559376/recovered.edits/0000000000000096571 (wrote 30 edits in 1338ms)
2011-04-20 06:19:57,889 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/465fb6b0a1f2d5306c7bb87145a32be2/recovered.edits/0000000000000096568 (wrote 22 edits in 909ms)
2011-04-20 06:19:57,893 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/4bc3c0bd3a824fb6c7fabbd332ef1009/recovered.edits/0000000000000097151 (wrote 85 edits in 3982ms)
2011-04-20 06:19:57,897 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/4bfff6ceb59cc4b6098eea42b49ee9ed/recovered.edits/0000000000000097336 (wrote 117 edits in 4810ms)
2011-04-20 06:19:57,901 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/52dee69cbe0890b54aee56bda54577c9/recovered.edits/0000000000000096567 (wrote 63 edits in 4445ms)
2011-04-20 06:19:57,905 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/539e4afe8064897395d4dc891605e702/recovered.edits/0000000000000097127 (wrote 53 edits in 3433ms)
2011-04-20 06:19:57,909 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/5728cb0bb67c7c3d8701fc0679db97b9/recovered.edits/0000000000000097473 (wrote 134 edits in 6623ms)
2011-04-20 06:19:57,913 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/5f92d0c1defc108140df27322257584d/recovered.edits/0000000000000096672 (wrote 77 edits in 7211ms)
2011-04-20 06:19:57,917 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/69e1f895ca9d6824b409015a9f9c03a3/recovered.edits/0000000000000098012 (wrote 10 edits in 306ms)
2011-04-20 06:19:57,921 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/70746a106ab152f290264d0b2b0f773c/recovered.edits/0000000000000096722 (wrote 117 edits in 7245ms)
2011-04-20 06:19:57,925 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/906e3283419ae67052c34e31cc40ff05/recovered.edits/0000000000000097951 (wrote 31 edits in 2389ms)
2011-04-20 06:19:57,929 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/94112f821b90271f9d693d5505d5eebf/recovered.edits/0000000000000097692 (wrote 71 edits in 4771ms)
2011-04-20 06:19:57,933 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/9f519dfd7370990d017e7f6d187968d3/recovered.edits/0000000000000096697 (wrote 77 edits in 5551ms)
2011-04-20 06:19:57,937 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/9f60e52d384d0fd9dfc2a2f3be42ac43/recovered.edits/0000000000000097877 (wrote 24 edits in 840ms)
2011-04-20 06:19:58,054 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/a21bf162e9ff2915ff036f486919c9b5/recovered.edits/0000000000000098062 (wrote 8 edits in 1860ms)
2011-04-20 06:19:58,061 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/abc26969d71b22de80c7e889cc9a6c12/recovered.edits/0000000000000096576 (wrote 5 edits in 281ms)
2011-04-20 06:19:58,065 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/b5d7c2bd8383ea8871890f40b9827dcf/recovered.edits/0000000000000097554 (wrote 125 edits in 5240ms)
2011-04-20 06:19:58,073 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/bf06b369cf84e5bccdd4e845636a2af6/recovered.edits/0000000000000096839 (wrote 1 edits in 17ms)
2011-04-20 06:19:58,077 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/cf46d330cdaa1120c8e1a5fcf1899b0f/recovered.edits/0000000000000097442 (wrote 1 edits in 850ms)
2011-04-20 06:19:58,081 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/d850f84bfdfa28c63934a0be5a41257e/recovered.edits/0000000000000096572 (wrote 53 edits in 2467ms)
2011-04-20 06:19:58,085 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/d9b94307130a7096032b44b3aa18d3ea/recovered.edits/0000000000000096795 (wrote 155 edits in 10534ms)
2011-04-20 06:19:58,088 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/da6540fdaae565a6d04cd78a145240dd/recovered.edits/0000000000000097580 (wrote 53 edits in 2992ms)
2011-04-20 06:19:58,092 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/df02c5d923c466c5b89337fecee920cf/recovered.edits/0000000000000096924 (wrote 1 edits in 25ms)
2011-04-20 06:19:58,096 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://hqsnosql01:9000/h
base/Property/e90c1c020e3148756a57d977133e31fc/recovered.edits/0000000000000096569 (wrote 96 edits in 3862ms)
2011-04-20 06:19:58,097 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: hlog file splitting completed in 866
02 ms for hdfs://hqsnosql01:9000/hbase/.logs/HQSNOSQL01,60020,1303302276146
2011-04-20 06:19:58,102 INFO org.apache.hadoop.hbase.catalog.RootLocationEditor: Unsetting ROOT region location in ZooKe
eper
2011-04-20 06:19:58,113 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12f72de7aee0000 Creating (or up
dating) unassigned node for 70236052 with OFFLINE state
2011-04-20 06:19:58,133 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12f72de7aee0000 Creating (or up
dating) unassigned node for 1028785192 with OFFLINE state
2011-04-20 06:19:58,139 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=M_ZK_REGION_OFFLINE,
 server=HQSNOSQL01:60000, region=1028785192/.META.
2011-04-20 06:20:36,363 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,
,1.1028785192 state=OFFLINE, ts=1303305598133
2011-04-20 06:20:36,364 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning .META.,,1.1028785192 to a random server
2011-04-20 06:20:36,364 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  -ROOT-,
,0.70236052 state=OFFLINE, ts=1303305598113
2011-04-20 06:20:36,364 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning -ROOT-,,0.70236052 to a random server
2011-04-20 06:20:36,364 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=.META.,,1.102878519
2 state=OFFLINE, ts=1303305598133
2011-04-20 06:20:36,364 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=-ROOT-,,0.70236052
state=OFFLINE, ts=1303305598113
2011-04-20 06:21:06,374 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,
,1.1028785192 state=OFFLINE, ts=1303305636364
2011-04-20 06:21:06,374 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning .META.,,1.1028785192 to a random server
2011-04-20 06:21:06,374 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  -ROOT-,
,0.70236052 state=OFFLINE, ts=1303305636364
2011-04-20 06:21:06,374 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning -ROOT-,,0.70236052 to a random server
2011-04-20 06:21:06,374 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=.META.,,1.102878519
2 state=OFFLINE, ts=1303305636364
2011-04-20 06:21:06,374 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=-ROOT-,,0.70236052
state=OFFLINE, ts=1303305636364
2011-04-20 06:21:36,385 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,
,1.1028785192 state=OFFLINE, ts=1303305666374
2011-04-20 06:21:36,385 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning .META.,,1.1028785192 to a random server
2011-04-20 06:21:36,385 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  -ROOT-, 
,0.70236052 state=OFFLINE, ts=1303305666374
2011-04-20 06:21:36,385 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning -ROOT-,,0.70236052 to a random server
2011-04-20 06:21:36,385 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=.META.,,1.102878519
2 state=OFFLINE, ts=1303305666374
2011-04-20 06:21:36,385 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=-ROOT-,,0.70236052
state=OFFLINE, ts=1303305666374
2011-04-20 06:22:06,393 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,
,1.1028785192 state=OFFLINE, ts=1303305696385
2011-04-20 06:22:06,393 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning .META.,,1.1028785192 to a random server
2011-04-20 06:22:06,393 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  -ROOT-,
,0.70236052 state=OFFLINE, ts=1303305696385
2011-04-20 06:22:06,393 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning -ROOT-,,0.70236052 to a random server
2011-04-20 06:22:06,393 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=.META.,,1.102878519
2 state=OFFLINE, ts=1303305696385
2011-04-20 06:22:06,393 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=-ROOT-,,0.70236052
state=OFFLINE, ts=1303305696385
2011-04-20 06:22:36,402 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,
,1.1028785192 state=OFFLINE, ts=1303305726393
2011-04-20 06:22:36,402 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning .META.,,1.1028785192 to a random server
2011-04-20 06:22:36,402 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  -ROOT-,
,0.70236052 state=OFFLINE, ts=1303305726394
2011-04-20 06:22:36,402 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning -ROOT-,,0.70236052 to a random server
2011-04-20 06:22:36,402 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=.META.,,1.102878519
2 state=OFFLINE, ts=1303305726393
2011-04-20 06:22:36,402 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=-ROOT-,,0.70236052
state=OFFLINE, ts=1303305726394
2011-04-20 06:23:06,411 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,
,1.1028785192 state=OFFLINE, ts=1303305756402
2011-04-20 06:23:06,411 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning .META.,,1.1028785192 to a random server
2011-04-20 06:23:06,411 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  -ROOT-,
,0.70236052 state=OFFLINE, ts=1303305756402
2011-04-20 06:23:06,411 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning -ROOT-,,0.70236052 to a random server
2011-04-20 06:23:06,412 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=.META.,,1.102878519
2 state=OFFLINE, ts=1303305756402
2011-04-20 06:23:06,412 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=-ROOT-,,0.70236052
state=OFFLINE, ts=1303305756402
2011-04-20 06:23:36,420 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,
,1.1028785192 state=OFFLINE, ts=1303305786412
2011-04-20 06:23:36,420 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning .META.,,1.1028785192 to a random server
2011-04-20 06:23:36,420 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  -ROOT-,
,0.70236052 state=OFFLINE, ts=1303305786412
2011-04-20 06:23:36,420 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning -ROOT-,,0.70236052 to a random server
2011-04-20 06:23:36,420 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=.META.,,1.102878519
2 state=OFFLINE, ts=1303305786412
2011-04-20 06:23:36,420 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=-ROOT-,,0.70236052
state=OFFLINE, ts=1303305786412
2011-04-20 06:24:06,429 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  .META.,
,1.1028785192 state=OFFLINE, ts=1303305816420
2011-04-20 06:24:06,430 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning .META.,,1.1028785192 to a random server
2011-04-20 06:24:06,430 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  -ROOT-,
,0.70236052 state=OFFLINE, ts=1303305816420
2011-04-20 06:24:06,430 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OFFLINE for too long, rea
ssigning -ROOT-,,0.70236052 to a random server
2011-04-20 06:24:06,430 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=.META.,,1.102878519",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1033,"If there is a row with more timestamps than versions (which can happen if only some cells are newer than others in other columns), get and getRow fail to find columns with newer timestamps.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1222,"The scripts in hbase/bin (e.g. start-hbase.sh) try to start Zookeeper. Why? There is no Zookeeper support in 0.19.x
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-922,"Currently it is possible to enable a bloom filter after a table is created and data has been stored in it by disabling the table and modifying the column.

While this correctly sets the attribute in the column descriptor, it does not create bloom filters for existing data so that on the first compaction, an NPE will be thrown because the HStore expects each HStoreFile to have a bloom filter.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-863,"Whenever I make any request to the rest server, my http call hangs forever.

In the stacktrace, it looks like hbase waits on a lock it holds:

""SocketListener0-1"" prio=10 tid=0x00007fc88c1e2000 nid=0x4860 in Object.wait() [0x0000000041bdd000..0x0000000041bdea00]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        - waiting on <0x00007fc8ef59d700> (a org.apache.hadoop.ipc.Client$Call)
        at org.apache.hadoop.ipc.Client.call(Client.java:552)
        - locked <0x00007fc8ef59d700> (a org.apache.hadoop.ipc.Client$Call)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Invoker.invoke(HbaseRPC.java:230)
        at $Proxy1.getProtocolVersion(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC.getProxy(HbaseRPC.java:340)
        at org.apache.hadoop.hbase.ipc.HbaseRPC.getProxy(HbaseRPC.java:327)
        at org.apache.hadoop.hbase.ipc.HbaseRPC.getProxy(HbaseRPC.java:364)
        at org.apache.hadoop.hbase.ipc.HbaseRPC.waitForProxy(HbaseRPC.java:302)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getHRegionConnection(HConnectionManager.java:771)
        - locked <0x00007fc8ef067618> (a java.util.concurrent.ConcurrentHashMap)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:518)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:478)
        - locked <0x00007fc8ef067600> (a java.lang.Integer)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:438)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:127)
        at org.apache.hadoop.hbase.rest.GenericHandler.getTable(GenericHandler.java:260)
        at org.apache.hadoop.hbase.rest.TableHandler.doGet(TableHandler.java:74)
        at org.apache.hadoop.hbase.rest.Dispatcher.doGet(Dispatcher.java:105)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
        at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
        at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
        at org.mortbay.http.HttpServer.service(HttpServer.java:954)
        at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
        at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
        at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
        at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
        at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-542,"As I was investigating HBASE-532, I became suspicious that scanners suffer from problems similar to those that getFull and getClosest suffered before. Namely, when there are multiple stores per columnfamily for a region (memcache and 1+ stofiles, empty memcache and 2+ storefiles), incorrect answers are produced. I will attach a test case that showcases this problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-560,"After HBASE-547 Master and region server will not start because they cannot find the jsp classes:
{code}
2008-04-03 18:38:49,051 ERROR [HMaster] hbase.HMaster(1216): Failed startup
java.io.IOException: Problem starting http server
        at org.apache.hadoop.hbase.util.InfoServer.start(InfoServer.java:227)
        at org.apache.hadoop.hbase.HMaster.startServiceThreads(HMaster.java:1201)
        at org.apache.hadoop.hbase.HMaster.run(HMaster.java:1063)
Caused by: org.mortbay.util.MultiException[java.lang.ClassNotFoundException: org
.apache.hadoop.hbase.generated.master.hql_jsp, java.lang.ClassNotFoundException:
 org.apache.hadoop.hbase.generated.master.master_jsp]
        at org.mortbay.http.HttpServer.doStart(HttpServer.java:731)
        at org.mortbay.util.Container.start(Container.java:72)
        at org.apache.hadoop.hbase.util.InfoServer.start(InfoServer.java:205)
        ... 2 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21234,"Getting following exception during ChoreService runs in HBase Master logs. As a result we are accumulating a lot of data in archive folder as archive is not getting reclaimed.聽
{code:java}
Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest.internalGetFieldAccessorTable(SnapshotProtos.java:1190
{code}
聽Complete stack-trace
{code:java}
2018-09-26 10:15:06,188 ERROR [master01,16000,1536315941769_ChoreService_3] snapshot.SnapshotHFileCleaner: Exception while checking if files were valid, keeping them just in case. java.io.IOException: ExecutionException at org.apache.hadoop.hbase.snapshot.SnapshotManifestV2.loadRegionManifests(SnapshotManifestV2.java:161) at org.apache.hadoop.hbase.snapshot.SnapshotManifest.load(SnapshotManifest.java:364) at org.apache.hadoop.hbase.snapshot.SnapshotManifest.open(SnapshotManifest.java:130) at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.visitTableStoreFiles(SnapshotReferenceUtil.java:128) at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.getHFileNames(SnapshotReferenceUtil.java:357) at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.getHFileNames(SnapshotReferenceUtil.java:340) at org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner$1.filesUnderSnapshot(SnapshotHFileCleaner.java:88) at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.getSnapshotsInProgress(SnapshotFileCache.java:303) at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.getUnreferencedFiles(SnapshotFileCache.java:194) at org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.getDeletableFiles(SnapshotHFileCleaner.java:63) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteFiles(CleanerChore.java:287) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:211) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:234) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:206) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:234) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:206) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:234) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:206) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:234) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:206) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:234) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:206) at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:130) at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest.internalGetFieldAccessorTable(SnapshotProtos.java:1190) at com.google.protobuf.GeneratedMessage.getDescriptorForType(GeneratedMessage.java:98) at com.google.protobuf.AbstractMessage$Builder.findMissingFields(AbstractMessage.java:789) at com.google.protobuf.AbstractMessage$Builder.findMissingFields(AbstractMessage.java:780) at com.google.protobuf.AbstractMessage$Builder.newUninitializedMessageException(AbstractMessage.java:770) at com.google.protobuf.AbstractMessage.newUninitializedMessageException(AbstractMessage.java:237) at com.google.protobuf.AbstractParser.newUninitializedMessageException(AbstractParser.java:57) at com.google.protobuf.AbstractParser.checkMessageInitialized(AbstractParser.java:71) at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:217)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18006,"I have been reading the code for the new async scan paths excessively, and noticed that there is a problem in the retrying layer for openScan RPCs. 

In AsyncClientScanner#callOpenScanner() we are doing a open scan RPC. The retrying logic comes from using the single rpc retrying caller in openScanner(). However, we have the logic for failing the scanner if any of the RPC calls here: 
{code}
      stub.scan(controller, request, resp -> {
        if (controller.failed()) {
          future.completeExceptionally(controller.getFailed());
          return;
        }
        future.complete(new OpenScannerResponse(loc, isRegionServerRemote, stub, controller, resp));
      });
{code}

So, if the open scan gets an UnknownScannerException or something, instead of retrying, it just fails the whole scan. 

[~Apache9] FYI. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20341,There are even metrics from HBASE-12220 that expose counts. Talk them up and hedged reads in refguide.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19312,See the discussion in HBASE-19266.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19443,"When the loader is loading data to HBase, without any forewarning that client gets stuck and prints the below message continuously:

[ERROR] AsyncProcess[hconnection-0x71f5455a-shared--pool20-t40846] Cannot get replica 0 location for {""totalColumns"":20,""families"":{""v"":[{""timestamp"":1512584999999,""tag"":[],""qualifier"":""0"",""vlen"":4},{""timestamp"":1512584999999,""tag"":[],""qualifier"":""uid"",""vlen"":8},{""timestamp"":1512584999999,""tag"":[],""qualifier"":""1"",""vlen"":8},{""timestamp"":1512584999999,""tag"":[],""qualifier"":""2"",""vlen"":11}]},""row"":""C\\x99L[5\\x80\\x00\\x00""}

At this time no other loaders are impacted. Restart of the loader seems to solve the issue until next occurence.


Upon doing jstack at this time on the loader, it is observed that process is stuck on a object monitor inside 'AsyncProcess.java' class.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20534,We need better user facing text to explain that they need to set hbase.localcluster.assign.random.ports to true. See HBASE-20224.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19706,Deleted cells are always hiding the other cells even if the scan ran with time range having no delete marker.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18246,"Before HBASE-18036, SSH would use round-robin to re-distribute regions during processing.  Round-robin assignment would loss data locality.  HBASE-18036 retains data locality if the dead region server has already restarted when the dead RS is processing.  

With Proc-V2 based AM, the change of HBASE-18036 in Apache HBASE 1.x releases is no longer possible.  We need to implement the same logic under Proc-V2 based AM.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19409,"YARN ATSv2 leverages HBase as its data store. When ATSv2 is enabled, 
YARN NM will act as HBase clients to write data into HBase cluster.

Because YARN NM jvms already register jvmMetrics in the metrics system and 
no duplicate is allowed, when HBase client tries to register jvmMetrics again, NM will crash with the following exception.
{code}
ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: Error starting NodeManager
org.apache.hadoop.service.ServiceStateException: java.io.IOException: java.lang.reflect.InvocationTargetException
        at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:105)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:173)
        at org.apache.hadoop.yarn.server.timelineservice.collector.TimelineCollectorManager.serviceInit(TimelineCollectorManager.java:62)
        at org.apache.hadoop.yarn.server.timelineservice.collector.NodeTimelineCollectorManager.serviceInit(NodeTimelineCollectorManager.java:112)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
        at org.apache.hadoop.yarn.server.timelineservice.collector.PerNodeTimelineCollectorsAuxService.serviceInit(PerNodeTimelineCollectorsAuxService.java:87)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:167)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:315)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:440)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:833)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:894)
Caused by: java.io.IOException: java.lang.reflect.InvocationTargetException
        at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:221)
        at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:114)
        at org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl.serviceInit(HBaseTimelineWriterImpl.java:123)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
        ... 15 more
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:219)
        ... 18 more
Caused by: java.lang.RuntimeException: Could not create  interface org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource Is the hadoop compatibility jar on the classpath?
        at org.apache.hadoop.hbase.CompatibilitySingletonFactory.getInstance(CompatibilitySingletonFactory.java:75)
        at org.apache.hadoop.hbase.zookeeper.MetricsZooKeeper.<init>(MetricsZooKeeper.java:38)
        at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.<init>(RecoverableZooKeeper.java:130)
        at org.apache.hadoop.hbase.zookeeper.ZKUtil.connect(ZKUtil.java:137)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:108)
        at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
        at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveZooKeeperWatcher(ConnectionImplementation.java:1231)
        at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:101)
        at org.apache.hadoop.hbase.client.ConnectionImplementation.retrieveClusterId(ConnectionImplementation.java:526)
        at org.apache.hadoop.hbase.client.ConnectionImplementation.<init>(ConnectionImplementation.java:288)
        ... 23 more
Caused by: java.util.ServiceConfigurationError: org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource: Provider org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl could not be instantiated
        at java.util.ServiceLoader.fail(ServiceLoader.java:232)
        at java.util.ServiceLoader.access$100(ServiceLoader.java:185)
        at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384)
        at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)
        at java.util.ServiceLoader$1.next(ServiceLoader.java:480)
        at org.apache.hadoop.hbase.CompatibilitySingletonFactory.getInstance(CompatibilitySingletonFactory.java:59)
        ... 33 more
Caused by: org.apache.hadoop.metrics2.MetricsException: Metrics source JvmMetrics already exists!
        at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152)
        at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125)
        at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229)
        at org.apache.hadoop.metrics2.source.JvmMetrics.create(JvmMetrics.java:111)
        at org.apache.hadoop.metrics2.source.JvmMetrics$Singleton.init(JvmMetrics.java:61)
        at org.apache.hadoop.metrics2.source.JvmMetrics.initSingleton(JvmMetrics.java:120)
        at org.apache.hadoop.hbase.metrics.BaseSourceImpl$DefaultMetricsSystemInitializer.init(BaseSourceImpl.java:52)
        at org.apache.hadoop.hbase.metrics.BaseSourceImpl.<init>(BaseSourceImpl.java:112)
        at org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl.<init>(MetricsZooKeeperSourceImpl.java:56)
        at org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl.<init>(MetricsZooKeeperSourceImpl.java:51)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at java.lang.Class.newInstance(Class.java:442)
        at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:380)
        ... 36 more
{code}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12757,"I excute mapreduce scan all table, sometimes map input value of rowkey is out of range on current Region (get from inputsplit ).
this mabey  lost data or get unused data.
ps. I want  to use ImportTSV translate table.....
eg. 
location=datanode11,start_row=D9CB114FD09A82A3_0000000000000000_m_43DAAA689D4AFC86 ,rowkey=D323E1D0A51E5185_0000000000000000_m_75686B8924108044 ,end_row=DB0C4FC44E6D80C1_0000000000000000_m_E956CC65322BA3E5",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11156,"# hbase shell
2014-05-13 14:51:41,582 INFO  [main] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
HBase Shell; enter 'help<RETURN>' for list of supported commands.
Type ""exit<RETURN>"" to leave the HBase Shell
Version 0.96.1.1-cdh5.0.0, rUnknown, Thu Mar 27 23:01:59 PDT 2014.

Not able to create table in Hbase. Please help
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18855,"We documented the workaround for folks using surefire needing to set a system property otherwise mini cluster won't start in HBASE-18849, but maybe we can do better.

Can we rewrite the SO? Or patch the java code to use the correct value instead of checking a system property for it? It should be ok to have a patch to hardcode this sine we're telling folks to use a static value anyway.

hbase-thirdparty already has mechanisms for patching the source libs (ref. protobuf) so the mechanics shouldn't be too complex.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17556,"We noticed in our application, that sometimes when we interact with a table an operation will fail with an exception, an all operations that happen on the same region will also fail until the application is restarted.

It seems that when a merge or split happens on a region that is already in the clients cache, and the client is configured to retry operations, then there is no way for the client to detect this. In RpcRetryingCaller#callWithRetries if a call fails with RegionNotServingException then the cache will be cleared only if the retry parameter is equal to 1. This means the call will fail but the following calls will succeed.

RpcRetryingCaller#callWithoutRetries contains the comment ""It would be nice to clear the location cache here"". Additionally, the stale cache will cause this call to fail, even though the data is available.

See also HBASE-12534",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11295,"Attached Files:

HRegionServer.java - instramented from 0.96.1.1-cdh5.0.0
HBaseLeaseTimeoutIT.java - reproducing JUnit 4 test
WaitFilter.java - Scan filter (extends FilterBase) that overrides filterRowKey() to sleep during invocation
SpliceFilter.proto - Protobuf defintiion for WaitFilter.java
OutOfOrderScann_InstramentedServer.log - instramented server log
Steps.txt - this note

Set up:

In HBaseLeaseTimeoutIT, create a scan, set the given filter (which sleeps in overridden filterRowKey() method) and set it on the scan, and scan the table.
This is done in test client_0x0_server_150000x10().

Here's what I'm seeing (see also attached log):

A new request comes into server (ID 1940798815214593802 - RpcServer.handler=96) and a RegionScanner is created for it, cached by ID, immediately looked up again and cached RegionScannerHolder's nextCallSeq incremeted (now at 1).
The RegionScan thread goes to sleep in WaitFilter#filterRowKey().

A short (variable) period later, another request comes into the server (ID 8946109289649235722 - RpcServer.handler=98) and the same series of events happen to this request.

At this point both RegionScanner threads are sleeping in WaitFilter.filterRowKey(). After another period, the client retries another scan request which thinks its next_call_seq is 0.  However, HRegionServer's cached RegionScannerHolder thinks the matching RegionScanner's nextCallSeq should be 1.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17842,"The directions in the following section are not correct.

https://archive.cloudera.com/cdh5/cdh/5/hbase-1.2.0-cdh5.8.0/book.html#_integration_testing_with_an_hbase_mini_cluster

It is pointing to HBase 0.98.3 and `HBaseTestingUtility` can not be resolved in 1.2.0",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17671,"We have a HBase Thrift2 server deployed on Windows, basically the physical view looks like:
QueryEngine <==> HBase Thrift2 <==> HBase cluster
Here QueryEngine is a C++ application, and HBase cluster is a about 50-nodes HBase cluster (CDH 5.3.3, namely Hbase version 0.98.6).

Our Thrift2 Java options looks like:
-server -Xms4096m -Xmx4096m -XX:MaxDirectMemorySize=8192m -XX:+HeapDumpOnOutOfMemoryError -XX:+UseG1GC -XX:+ParallelRefProcEnabled -XX:G1HeapRegionSize=4M -XX:InitiatingHeapOccupancyPercent=40 -XX:+PrintAdaptiveSizePolicy -XX:+PrintPromotionFailure -Dhbase.log.dir=d:\vhayu\thrift2\log -verbose:gc -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -XX:PrintFLSStatistics=1 -Xloggc:log_gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=200M -Dhbase.log.file=hbase-thrift2.log  -Dhbase.home.dir=D:\vhayu\thrift2\hbase0.98 -Dhbase.id.str=root -Dlog4j.info -Dhbase.root.logger=INFO,DRFA -cp ""d:\vhayu\thrift2\hbase0.98\*;d:\vhayu\thrift2\conf"" org.apache.hadoop.hbase.thrift2.ThriftServer -b 127.0.0.1 -f framed start

The phenomenon of  the issue is that after some time running, Thrift2 sometimes reports OOM and heap dump file (.hprof) file was generated. The consequence of this will always trigger high latency form HBase cluster.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15385,"When using Wsab file system, we found that a failed atomic folder rename operation can never recovery for the destination file deleted in Wasb filesystem. 
{quota}
ls: Attempting to complete rename of file hbase/azurtst-xiaomi/data/default/YCSBTest/.tabledesc during folder rename redo, and file was not found in source or destination.
{quote}

The reason is the the file is renamed to the destination file  before the crash, and the destination file is deleted by another process after crash. So the recovery is blocked during finishing the rename operation of this file when found the source and destination files all don't exist.

See: NativeAzureFileSystem.java #finishSingleFileRename

Another serious problem is that the recovery of atomic rename operation may delete new created file which is same name as the source file, because the file system don't check if there are rename operation need be redo.

Suggestions are welcomed~

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16395,"I had sended an email to user@hbase.apache.org,but received no help.

The cluster enabled shortCircuitLocalReads.
<property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
</property>

When enabled replication,we found a large number of error logs.
1.shortCircuitLocalReads(fail everytime).
2.Try reading via the datanode on targetAddr(success).
How to make shortCircuitLocalReads successfully when enabled replication?

2016-08-03 10:46:21,721 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Opening log for replication dn7%2C60020%2C1470136216957.1470192327030 at 16999670
2016-08-03 10:46:21,723 WARN org.apache.hadoop.hdfs.DFSClient: BlockReaderLocal requested with incorrect offset: Offset 0 and length 17073479 don't match block blk_4137524355009640437_53760530 ( blockLen 16999670 )
2016-08-03 10:46:21,723 WARN org.apache.hadoop.hdfs.DFSClient: BlockReaderLocal: Removing blk_4137524355009640437_53760530 from cache because local file /sdd/hdfs/dfs/data/blocksBeingWritten/blk_4137524355009640437 could not be opened.
2016-08-03 10:46:21,724 INFO org.apache.hadoop.hdfs.DFSClient: Failed to read block blk_4137524355009640437_53760530 on local machinejava.io.IOException: Offset 0 and length 17073479 don't match block blk_4137524355009640437_53760530 ( blockLen 16999670 )
at org.apache.hadoop.hdfs.BlockReaderLocal.<init>(BlockReaderLocal.java:287)
at org.apache.hadoop.hdfs.BlockReaderLocal.newBlockReader(BlockReaderLocal.java:171)
at org.apache.hadoop.hdfs.DFSClient.getLocalBlockReader(DFSClient.java:358)
at org.apache.hadoop.hdfs.DFSClient.access$800(DFSClient.java:74)
at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:2073)
at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2224)
at java.io.DataInputStream.read(DataInputStream.java:149)
at java.io.DataInputStream.readFully(DataInputStream.java:195)
at java.io.DataInputStream.readFully(DataInputStream.java:169)
at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1508)
at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1486)
at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1475)
at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1470)
at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader$WALReader.<init>(SequenceFileLogReader.java:55)
at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.init(SequenceFileLogReader.java:178)
at org.apache.hadoop.hbase.regionserver.wal.HLog.getReader(HLog.java:734)
at org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.openReader(ReplicationHLogReaderManager.java:69)
at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.openReader(ReplicationSource.java:574)
at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:364)
2016-08-03 10:46:21,724 INFO org.apache.hadoop.hdfs.DFSClient: Try reading via the datanode on /192.168.7.139:50010",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15818,"Unable to create a table with multiple families (as suggested by the Examples)
also the shell is exiting. (I only tested 1.2 and 2.0 and have the problem, 1.1 seems to be ok)
{noformat}
hbase(main):001:0> create 鈥榯1鈥? 鈥榝1鈥? 鈥榝2鈥? 鈥榝3鈥?
ERROR: wrong number of arguments (0 for 1)

Examples:
  hbase> create 't1', 'f1', 'f2', 'f3'
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15403,"hbase pe --nomapred --rows=100 --table='t4' randomWrite 10
# count on t4 gives 620 rows

hbase pe --nomapred --rows=200 --table='t5' randomWrite 10
# count on t5 gives 1257 rows

hbase pe --nomapred --table='t6' --rows=200 randomWrite 1
# count on t6 gives 126 rows

I was working with 1.2.0, but it's likely that it'll also be affecting master.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1920,"Testing in HBASE-1908 uncovered an issue where I had a client that had cached a region location.  I killed that regionserver, waited for recovery/reassignment, and then tried to scan the table again from the same client w/o restarting it.

A client normally gets a NotServingRegionException when a region is reassigned, but since this server is dead the client just got Connection Refused type exceptions.  These didn't seem to trigger the client to ask META for a new region location.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3266,"I was in the situation described by HBASE-3265, where I had a number of RS waiting on ROOT, but the master hadn't seen any RS checkins, so was waiting on checkins. To get past this, I restarted one of the region servers. The restarted server checked in, and the master began its startup.
At this point the master started scanning /hbase/.logs for things to split. It correctly identified that the RS on haus01 was running (this is the one I restarted):

2010-11-23 00:21:25,595 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://haus01.sf.cloudera.com:11020/hbase-normal/.logs/haus01.sf.cloudera.com,60020,1290500443143 belongs to an existing region server

but then incorrectly decided that the RS on haus02 was down:

2010-11-23 00:21:25,595 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://haus01.sf.cloudera.com:11020/hbase-normal/.logs/haus02.sf.cloudera.com,60020,1290498411450 doesn't belong to a known region server, splitting

However ZK shows that this RS is up:
[zk: haus01.sf.cloudera.com:2222(CONNECTED) 3] ls /hbase/rs
[haus04.sf.cloudera.com,60020,1290498411533, haus05.sf.cloudera.com,60020,1290498411520, haus03.sf.cloudera.com,60020,1290498411518, haus01.sf.cloudera.com,60020,1290500443143, haus02.sf.cloudera.com,60020,1290498411450]

splitLogsAfterStartup seems to check ServerManager.onlineServers, which best I can tell is derived from heartbeats and not from ZK (sorry if I got some of this wrong, still new to this new codebase)

Of course, the master went into an infinite splitting loop at this point since haus02 is up and renewing its DFS lease on its logs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3540,"I inserted 100G or so of data and got a region stuck in a CLOSED state. Different region servers kept trying to open it, but they failed to transition OFFLINE->OPENING because it was in a CLOSED state. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6266,"
Hi,
please find the below logs for same scenario:

java.lang.NullPointerException
	at com.onmobile.bmg.scheduler.mr.scheduler.SchedulerMR$SchedulerOutputCommitter.getStringData(SchedulerMR.java:1149)
	at com.onmobile.bmg.scheduler.mr.scheduler.SchedulerMR$SchedulerOutputCommitter.updateJobTable(SchedulerMR.java:945)
	at com.onmobile.bmg.scheduler.mr.scheduler.SchedulerMR$SchedulerOutputCommitter.commitTask(SchedulerMR.java:803)
	at org.apache.hadoop.mapred.Task.commit(Task.java:721)
	at org.apache.hadoop.mapred.Task.done(Task.java:644)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:460)
	at org.apache.hadoop.mapred.Child.main(Child.java:158)
java.lang.NullPointerException
	at com.onmobile.bmg.scheduler.mr.scheduler.SchedulerMR$SchedulerOutputCommitter.getStringData(SchedulerMR.java:1149)
	at com.onmobile.bmg.scheduler.mr.scheduler.SchedulerMR$SchedulerOutputCommitter.updateJobTableForReporting(SchedulerMR.java:1055)
	at com.onmobile.bmg.scheduler.mr.scheduler.SchedulerMR$SchedulerOutputCommitter.commitTask(SchedulerMR.java:804)
	at org.apache.hadoop.mapred.Task.commit(Task.java:721)
	at org.apache.hadoop.mapred.Task.done(Task.java:644)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:460)
	at org.apache.hadoop.mapred.Child.main(Child.java:158)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4548,"In HBASE-4377, Jon noticed that HConnectionManager.listTable now looks on HDFS for the table list. This seems incorrect, since the client may not have access to the hbase directory on HDFS (eg in a secure cluster). At the least, it should RPC to the master to find a table list, and have the master do the list on HDFS.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4073,"See this thread: http://search-hadoop.com/?q=Errors+after+major+compaction&fc_project=HBase

In it, Eran has snippets from a log that show us being asked open a region we already have opened.

We need to make sure that the root issue is addressed -- the races around assignment and its timeouts -- and then after that do something like a check if we already have region open before we queue an open (we can't return message to the master from down inside the regionserver event handlers).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14419,"[root@localhost local]# ll
lrwxrwxrwx.  1 root root   11 Sep 12 21:34 hbase -> hbase-1.1.2
drwxr-xr-x. 30 root root 4096 Sep 12 21:34 hbase-1.1.2

[root@localhost local]# ./hbase/bin/start-hbase.sh
Error: Could not find or load main class org.apache.hadoop.hbase.util.HBaseConfTool
Error: Could not find or load main class org.apache.hadoop.hbase.zookeeper.ZKServerTool
starting master, logging to /usr/local/hbase/logs/hbase-root-master-localhost.out
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0
Error: Could not find or load main class org.apache.hadoop.hbase.master.HMaster
starting regionserver, logging to /usr/local/hbase/logs/hbase-root-1-regionserver-localhost.out
Error: Could not find or load main class org.apache.hadoop.hbase.regionserver.HRegionServer

why show this error ?

It exist 銆?[root@localhost local]# find ./ -name HBaseConfTool.class
./hbase-1.1.2/hbase-server/target/classes/org/apache/hadoop/hbase/util/HBaseConfTool.class


/etc/profle:
export JAVA_HOME=/usr/local/jdk1.8.0_20
export HBASE_HOME=/usr/local/hbase
export PATH=$JAVA_HOME/bin:$HBASE_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$HBASE_HOME/hbase-server/target/classes

I add  $HBASE_HOME/hbase-server/target/classes, but it still not find class file銆倂ersion 0.98xx has no this problem锛寃hy the version 1.1.2  so eggache锛?I am just a newer锛実eting start follow official docs, but  can not run銆侷 am so sad銆傘€傘€俿os銆傘€傘€?

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12967,"Refer to this thread
http://osdir.com/ml/general/2015-02/msg03547.html

A user tries to alter a table with a new split policy.  Due to an invalid classname the table does not get enabled and the table becomes unusable.  I think Procedure V2 is a long term soln for this but I think we atleast need to provide a work around or a set of steps to come out of this.  Any fix before Procedure V2 comes into place would useful for the already released versions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13756,"I have observed below exception when running Phoenix integration tests with HBase-1.1.0. I think same can happen in real cluster when RS reporting to master.
{noformat}
ABORTING region server 100.73.163.39,53415,1432394107922: Unhandled: org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos$ServerLoad$Builder.setNumberOfRequests(J)Lorg/apache/hadoop/hbase/protobuf/generated/ClusterStatusProtos$ServerLoad$Builder;
Cause:
java.lang.NoSuchMethodError: org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos$ServerLoad$Builder.setNumberOfRequests(J)Lorg/apache/hadoop/hbase/protobuf/generated/ClusterStatusProtos$ServerLoad$Builder;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.buildServerLoad(HRegionServer.java:1165)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:1127)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:944)
        at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.runRegionServer(MiniHBaseCluster.java:156)
        at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.access$000(MiniHBaseCluster.java:108)
        at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer$1.run(MiniHBaseCluster.java:140)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:356)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1594)
        at org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:306)
        at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.run(MiniHBaseCluster.java:138)
        at java.lang.Thread.run(Thread.java:745)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5881,"This issue will occur only in hadoop 23.x & above/

In hadoop 0.20.x
{code}
public static void returnDecompressor(Decompressor decompressor) {
    if (decompressor == null) {
      return;
    }
    decompressor.reset();
    payback(decompressorPool, decompressor);
  }
{code}


In hadoop 0.23.x
{code}
  public static void returnDecompressor(Decompressor decompressor) {
    if (decompressor == null) {
      return;
    }
    // if the decompressor can't be reused, don't pool it.
    if (decompressor.getClass().isAnnotationPresent(DoNotPool.class)) {
      return;
    }
    decompressor.reset();
    payback(decompressorPool, decompressor);
  }
{code}

Here annotation has been added. By default this library will be loaded if there are no native library.
{code}
@DoNotPool
public class BuiltInGzipDecompressor
{code}

Due to this each time new compressor/decompressor will be loaded, this leads to native memory leak.
{noformat}
2012-04-25 22:11:48,093 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2012-04-25 22:11:48,093 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
2012-04-25 22:11:48,093 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5895,"Running a YCSB workload against trunk, the slow query log ends up logging the entire contents of ""mutate"" RPCs (in PB-encoded binary). This then makes the logging back up, which makes more slow queries, which makes the whole thing spin out of control. We should only summarize the RPC, rather than printing the whole contents.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5702,"This bug is so easy to reproduce I'm wondering why it hasn't been reported yet. Stop any number of region servers on a 0.94/6 cluster and you'll see in the master interface one task per stopped region server saying the following:

|Processing schema change exclusion for region server = sv4r27s44,62023,1333402175340|RUNNING (since 5sec ago)|No schema change in progress. Skipping exclusion for server = sv4r27s44,62023,1333402175340 (since 5sec ago)|

It's gonna stay there until the master cleans it:

bq. WARN org.apache.hadoop.hbase.monitoring.TaskMonitor: Status Processing schema change exclusion for region server = sv4r27s44,62023,1333402175340: status=No schema change in progress. Skipping exclusion for server = sv4r27s44,62023,1333402175340, state=RUNNING, startTime=1333404636419, completionTime=-1 appears to have been leaked

It's not clear to me why it's using a MonitoredTask in the first place. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11913,"hbck shows errors on a perfectly fine cluster, because of an incorrect check if there have been errors. fix didn't change the printout, just the error detection.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10647,"In MemStore.updateColumnValue, when removing old values, size is not decreased, but local variable addedSize is decreased, so size is greater than real value. This leads to the problem of negative value for HRegion.memstoreSize.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9527,Go over all old APIs that take a table name and ensure that it is not possible to pass in a byte array that is a namespace + tablename; instead throw an exception.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10271,"HBASE-9593 moved the creation of the ephemeral znode earlier in the region server startup process such that we don't have access to the ServerName from the Master's POV. HRS.getMyEphemeralNodePath() calls HRS.getServerName() which at that point will return this.isa.getHostName(). If you set hbase.regionserver.ipc.address to 0.0.0.0, you will create a znode with that address.

What happens next is that the RS will report for duty correctly but the master will do this:

{noformat}
2014-01-02 11:45:49,498 INFO  [master:172.21.3.117:60000] master.ServerManager: Registering server=0:0:0:0:0:0:0:0%0,60020,1388691892014
2014-01-02 11:45:49,498 INFO  [master:172.21.3.117:60000] master.HMaster: Registered server found up in zk but who has not yet reported in: 0:0:0:0:0:0:0:0%0,60020,1388691892014
{noformat}

The cluster is then unusable.

I think a better solution is to track the heartbeats for the region servers and expire those that haven't checked-in for some time. The 0.89-fb branch has this concept, and they also use it to detect rack failures: https://github.com/apache/hbase/blob/0.89-fb/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java#L1224. In this jira's scope I would just add the heartbeat tracking and add a unit test for the wildcard address.

What do you think [~rajesh23]?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2913,See this thread originated by Thomas Downing: http://www.mail-archive.com/user@hbase.apache.org/msg00992.html  In it he is finding that we leak sockets and filehandles and that they are never recovered during sustained high rate ingest.  Investigate.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12040,"While testing 0.99.0RC1 release performances, compared to 0.98.6, figured that:
- FilteredScanTest is 100 times slower;
- RandomReadTest is 1.5 times slower;
- RandomSeekScanTest is 3.2 times slower;
- RandomScanWithRange10Test is 1,2 times slower;
- RandomScanWithRange100Test is 1,3 times slower;
- RandomScanWithRange1000Test is 4 times slower;
- SequentialReadTest is 1,7 times slower;
- SequentialWriteTest is just a bit faster;
- RandomWriteTest	 is just a bit faster;
- GaussianRandomReadBenchmark is just a beat slower;
- SequentialReadBenchmark is 1,1 times slower;
- SequentialWriteBenchmark is 1,1 times slower;
- UniformRandomReadBenchmark crashed;
- UniformRandomSmallScan is 1,3 times slower.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12101,"log snippet.
 from one of the region server
2014-09-26 18:22:47,793 WARN  [RS_OPEN_REGION-b1-255-07:60020-0] regionserver.HStore: Failed flushing store file, retrying num=0
2014-09-26 18:24:58,554 WARN  [DataStreamer for file /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/b4cb1ad7892440b6a7c13a7c30053d3f] hdfs.DFSClient: DataStreamer Exception
2014-09-26 18:24:58,555 WARN  [RS_OPEN_REGION-b1-255-07:60020-0] regionserver.HStore: Failed flushing store file, retrying num=1
2014-09-26 18:48:09,077 WARN  [DataStreamer for file /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/a6f6f951de6047b0b691ea42ddd5e036] hdfs.DFSClient: DataStreamer Exception
2014-09-26 18:48:09,079 WARN  [RS_OPEN_REGION-b1-255-07:60020-0] regionserver.HStore: Failed flushing store file, retrying num=2
2014-09-26 18:48:53,363 WARN  [DataStreamer for file /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/7e99efe5981a46ee9ba7ce4b7e50dd26] hdfs.DFSClient: DataStreamer Exception


Hdfs dir for hbase
-rwxr-xr-x   3 hbase hbase   41047119 2014-09-23 02:40 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/t/fc0d247e689c40b598e2e4e1dfaa5f0f.

-rwxr-xr-x   3 hbase hbase 146163105792 2014-09-26 19:21 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/2ae6cce7b6ea446991405bc8c7382f03
-rwxr-xr-x   3 hbase hbase 146028888064 2014-09-26 19:21 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/4f8dc1f8e06844be8cc1a9d61a77624a
-rwxr-xr-x   3 hbase hbase 140794396672 2014-09-26 19:21 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/5bb43145bab1454d8fe1758cfaa91286
-rwxr-xr-x   3 hbase hbase 150994944000 2014-09-26 19:21 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/66f124990997420eb6001b86bd9cea30
-rwxr-xr-x   3 hbase hbase 141197049856 2014-09-26 19:21 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/88cede4cce514e97973b08ef5d0fc32c
-rwxr-xr-x   3 hbase hbase 144015622144 2014-09-26 19:21 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/aeb55b1f7e214da192c3d21f84a01ceb
-rwxr-xr-x   3 hbase hbase 152605556736 2014-09-26 19:21 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/c58c57e7aef74fe3b2a4332deec426a9
-rwxr-xr-x   3 hbase hbase 144552493056 2014-09-26 19:21 /hbase/data/default/tsdb/5b2e8261c6f88eb44c861fd24dbc2b42/.tmp/ed76cac79cc04adc866670fe261f5cc6 


Hbase master data
5b2e8261c6f88eb44c861fd24dbc2b42	tsdb,,1411066769435.5b2e8261c6f88eb44c861fd24dbc2b42. state=OPENING, ts=Fri Sep 26 19:21:02 IST 2014 (1311s ago), server=hostname.colo.xyz.com,60020,1411736155186	1311508",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12026,"hi,all!
My Hadoop works very well execpt the HBASE.
It displayed that Hbase Ave Load work heavily,but i cann't find out which 
area is hot ......


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6469,"In Enable/DisableTableHandler code, if something goes wrong in handling, the table state in zk is left as ENABLING / DISABLING. After that we cannot force any more action from the API or CLI, and the only recovery path is restarting the master. 

{code}
    if (done) {
      // Flip the table to enabled.
      this.assignmentManager.getZKTable().setEnabledTable(
        this.tableNameStr);
      LOG.info(""Table '"" + this.tableNameStr
      + ""' was successfully enabled. Status: done="" + done);
    } else {
      LOG.warn(""Table '"" + this.tableNameStr
      + ""' wasn't successfully enabled. Status: done="" + done);
    }
{code}

Here, if done is false, the table state is not changed. There is also no way to set skipTableStateCheck from cli / api. 

We have run into this issue a couple of times before. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11595,"Reported using HBase 0.98.3 and HDFS 2.4.1

All data before failure has not yet been flushed so only exists in the WAL files. During distributed splitting, the WAL has either not been written out and synced in the same way as an unencrypted WAL or is unreadable:
{noformat}
2014-07-26 19:29:16,160 ERROR [RS_LOG_REPLAY_OPS-host1:60020-0] codec.BaseDecoder: Partial cell read caused by EOF: java.io.IOException: Premature EOF from inputStream
{noformat}

This file is still moved to oldWALs even though splitting failed. 

Setting 'hbase.regionserver.wal.encryption' to false allows data recovery.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11584,"HBase file encryption some consistences observed and data loss happens after running the hbck tool,
the operation steps are as below.

Procedure:
1. Start the Hbase services (HMaster & region Server)
2. Enable HFile encryption and WAL file encryption as below, and perform 'table4-0' put operations (100 records added)
<property>
 <name>hbase.crypto.keyprovider</name>
 <value>org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider</value>
</property>
<property>
 <name>hbase.crypto.keyprovider.parameters</name>
 <value>jceks:///opt/shankar1/kdc_keytab/hbase.jks?password=Hadoop@234</value>
</property>
<property>
 <name>hbase.crypto.master.key.name</name>
 <value>hdfs</value>
</property>
<property>
 <name>hfile.format.version</name>
 <value>3</value>
</property>
<property>
 <name>hbase.regionserver.hlog.reader.impl</name>
 <value>org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader</value>
</property>
<property>
 <name>hbase.regionserver.hlog.writer.impl</name>
 <value>org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter</value>
</property>
<property>
 <name>hbase.regionserver.wal.encryption</name>
 <value>true</value>
</property>
 
3. Machine went down, so all process went down
4. We disabled the WAL file encryption for performance reason, and keep encryption only for Hfile, as below
<property>
 <name>hbase.crypto.keyprovider</name>
 <value>org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider</value>
</property>
<property>
 <name>hbase.crypto.keyprovider.parameters</name>
 <value>jceks:///opt/shankar1/kdc_keytab/hbase.jks?password=Hadoop@234</value>
</property>
<property>
 <name>hbase.crypto.master.key.name</name>
 <value>hdfs</value>
</property>
<property>
 <name>hfile.format.version</name>
 <value>3</value>
</property>

5. Start the Region Server and query the 'table4-0' data
hbase(main):003:0> count 'table4-0'
ERROR: org.apache.hadoop.hbase.NotServingRegionException: Region table4-0,,1406207815456.fc10620a3dcc14e004ab034420f7d332. is not online on XX-XX-XX-XX,60020,1406209023146
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2685)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:4119)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3066)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29497)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2084)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
        at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:168)
        at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:39)
        at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:111)
        at java.lang.Thread.run(Thread.java:662)

6. Not able to read the data, so we decided to revert back the configuration (as original)

7. Kill/Stop the Region Server, revert all the configurations as original, as below

<property>
 <name>hbase.crypto.keyprovider</name>
 <value>org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider</value>
</property>
<property>
 <name>hbase.crypto.keyprovider.parameters</name>
 <value>jceks:///opt/shankar1/kdc_keytab/hbase.jks?password=Hadoop@234</value>
</property>
<property>
 <name>hbase.crypto.master.key.name</name>
 <value>hdfs</value>
</property>
<property>
 <name>hfile.format.version</name>
 <value>3</value>
</property>
<property>
 <name>hbase.regionserver.hlog.reader.impl</name>
 <value>org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader</value>
</property>
<property>
 <name>hbase.regionserver.hlog.writer.impl</name>
 <value>org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter</value>
</property>
<property>
 <name>hbase.regionserver.wal.encryption</name>
 <value>true</value>
</property>

7. Start the Region Server, and perform the 'table4-0' query 
hbase(main):003:0> count 'table4-0'
ERROR: org.apache.hadoop.hbase.NotServingRegionException: Region table4-0,,1406207815456.fc10620a3dcc14e004ab034420f7d332. is not online on XX-XX-XX-XX,60020,1406209023146
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2685)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:4119)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3066)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29497)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2084)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
        at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:168)
        at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:39)
        at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:111)
        at java.lang.Thread.run(Thread.java:662)

8. Run the hbase hbck to repair, as below
./hbase hbck -details
.........................
Summary:
  table1-0 is okay.
    Number of regions: 0
    Deployed on:
  table2-0 is okay.
    Number of regions: 0
    Deployed on:
  table3-0 is okay.
    Number of regions: 0
    Deployed on:
  table4-0 is okay.
    Number of regions: 0
    Deployed on:
  table5-0 is okay.
    Number of regions: 0
    Deployed on:
  table6-0 is okay.
    Number of regions: 0
    Deployed on:
  table7-0 is okay.
    Number of regions: 0
    Deployed on:
  table8-0 is okay.
    Number of regions: 0
    Deployed on:
  table9-0 is okay.
    Number of regions: 0
    Deployed on:
  hbase:meta is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  hbase:acl is okay.
    Number of regions: 0
    Deployed on:
  hbase:namespace is okay.
    Number of regions: 0
    Deployed on:
22 inconsistencies detected.
Status: INCONSISTENT
2014-07-24 19:13:05,532 INFO  [main] client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
2014-07-24 19:13:05,533 INFO  [main] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x1475d1611611bcf
2014-07-24 19:13:05,533 DEBUG [main] zookeeper.ZooKeeper: Closing session: 0x1475d1611611bcf
2014-07-24 19:13:05,533 DEBUG [main] zookeeper.ClientCnxn: Closing client for session: 0x1475d1611611bcf
2014-07-24 19:13:05,546 DEBUG [main-SendThread(XX-XX-XX-XX:2181)] zookeeper.ClientCnxn: Reading reply sessionid:0x1475d1611611bcf, packet:: clientPath:null serverPath:null finished:false header:: 6,-11  replyHeader:: 6,4295102074,0  request:: null response:: null
2014-07-24 19:13:05,546 DEBUG [main] zookeeper.ClientCnxn: Disconnecting client for session: 0x1475d1611611bcf
2014-07-24 19:13:05,546 DEBUG [main-SendThread(XX-XX-XX-XX:2181)] zookeeper.ClientCnxn: An exception was thrown while closing send thread for session 0x1475d1611611bcf : Unable to read additional data from server sessionid 0x1475d1611611bcf, likely server has closed socket
2014-07-24 19:13:05,546 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-07-24 19:13:05,546 INFO  [main] zookeeper.ZooKeeper: Session: 0x1475d1611611bcf closed
shankar1@XX-XX-XX-XX:~/DataSight/hbase/bin>


9. Fix the assignments as below
./hbase hbck -fixAssignments
Summary:
  table1-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table2-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table3-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table4-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table5-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table6-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table7-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table8-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table9-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  hbase:meta is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  hbase:acl is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  hbase:namespace is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
0 inconsistencies detected.
Status: OK
2014-07-24 19:44:55,194 INFO  [main] client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
2014-07-24 19:44:55,194 INFO  [main] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x2475d15f7b31b73
2014-07-24 19:44:55,194 DEBUG [main] zookeeper.ZooKeeper: Closing session: 0x2475d15f7b31b73
2014-07-24 19:44:55,194 DEBUG [main] zookeeper.ClientCnxn: Closing client for session: 0x2475d15f7b31b73
2014-07-24 19:44:55,203 DEBUG [main-SendThread(XX-XX-XX-XX:2181)] zookeeper.ClientCnxn: Reading reply sessionid:0x2475d15f7b31b73, packet:: clientPath:null serverPath:null finished:false header:: 7,-11  replyHeader:: 7,4295102377,0  request:: null response:: null
2014-07-24 19:44:55,203 DEBUG [main] zookeeper.ClientCnxn: Disconnecting client for session: 0x2475d15f7b31b73
2014-07-24 19:44:55,204 DEBUG [main-SendThread(XX-XX-XX-XX:2181)] zookeeper.ClientCnxn: An exception was thrown while closing send thread for session 0x2475d15f7b31b73 : Unable to read additional data from server sessionid 0x2475d15f7b31b73, likely server has closed socket
2014-07-24 19:44:55,204 INFO  [main] zookeeper.ZooKeeper: Session: 0x2475d15f7b31b73 closed
2014-07-24 19:44:55,204 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down

10. Fix the assignments as below
./hbase hbck -fixAssignments -fixMeta
Summary:
  table1-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table2-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table3-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table4-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table5-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table6-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table7-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table8-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  table9-0 is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  hbase:meta is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  hbase:acl is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
  hbase:namespace is okay.
    Number of regions: 1
    Deployed on:  XX-XX-XX-XX,60020,1406209023146
0 inconsistencies detected.
Status: OK
2014-07-24 19:46:16,290 INFO  [main] client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
2014-07-24 19:46:16,290 INFO  [main] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x3475d1605321be9
2014-07-24 19:46:16,290 DEBUG [main] zookeeper.ZooKeeper: Closing session: 0x3475d1605321be9
2014-07-24 19:46:16,290 DEBUG [main] zookeeper.ClientCnxn: Closing client for session: 0x3475d1605321be9
2014-07-24 19:46:16,300 DEBUG [main-SendThread(XX-XX-XX-XX:2181)] zookeeper.ClientCnxn: Reading reply sessionid:0x3475d1605321be9, packet:: clientPath:null serverPath:null finished:false header:: 6,-11  replyHeader:: 6,4295102397,0  request:: null response:: null
2014-07-24 19:46:16,300 DEBUG [main] zookeeper.ClientCnxn: Disconnecting client for session: 0x3475d1605321be9
2014-07-24 19:46:16,300 DEBUG [main-SendThread(XX-XX-XX-XX:2181)] zookeeper.ClientCnxn: An exception was thrown while closing send thread for session 0x3475d1605321be9 : Unable to read additional data from server sessionid 0x3475d1605321be9, likely server has closed socket
2014-07-24 19:46:16,300 INFO  [main] zookeeper.ZooKeeper: Session: 0x3475d1605321be9 closed
2014-07-24 19:46:16,300 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down

hbase(main):006:0> count 'table4-0'
0 row(s) in 0.0200 seconds

=> 0
hbase(main):007:0> 

Complete data loss happened,

WALs, oldWALs & /hbase/data/default/table4-0/ does not have any data
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1736,"What I saw was master shutting itself down because it had lost zk lease.  Fine.   The RS though doesn't look like it can deal with this situation.    We'll see stuff like this:

{code}
...failed on connection exception: java.net.ConnectException: Connection refused
    at org.apache.hadoop.hbase.ipc.HBaseClient.wrapException(HBaseClient.java:744)
    at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:722)
    at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:328)
    at $Proxy0.regionServerReport(Unknown Source)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:470)
    at java.lang.Thread.run(Unknown Source)
Caused by: java.net.ConnectException: Connection refused
    at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
    at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
    at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
    at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:404)
    at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.setupIOstreams(HBaseClient.java:305)
    at org.apache.hadoop.hbase.ipc.HBaseClient.getConnection(HBaseClient.java:826)
    at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:707)
    ... 4 more
{code}

... all over the regionserver as it tries to send heartbeat to master on this broken connection.

On split, we close parent, add children to the catalog but then when we try to tell the master about the split, it fails.  Means the children never get deployed.  Meantime  the parent is offline.

This issue is about going through the regionserver and anytime it has a connection to master, make sure on fault that no damage is done the table and then that the regionserver puts a pause on splitting.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10826,"{code}
    KeyValue kv1 = new KeyValue(Bytes.toBytes(""aaa""), Bytes.toBytes(""fam1""), Bytes.toBytes(""q1""),
        Bytes.toBytes(""val""));
    writer.append(kv1);
    KeyValue kv2 = new KeyValue(Bytes.toBytes(""aab""), Bytes.toBytes(""fam1""), Bytes.toBytes(""q1""),
        Bytes.toBytes(""val""));
    writer.append(kv2);
    KeyValue kv4 = new KeyValue(Bytes.toBytes(""aac""), Bytes.toBytes(""fam1""), Bytes.toBytes(""q1""),
        Bytes.toBytes(""val""));
    writer.append(kv4);
    KeyValue kv5 = new KeyValue(Bytes.toBytes(""aac""), Bytes.toBytes(""fam12""), Bytes.toBytes(""q2""),
        Bytes.toBytes(""val""));
writer.append(kv5);
{code}
{code}
    KeyValue toSeek = new KeyValue(Bytes.toBytes(""aac""), Bytes.toBytes(""fam1""),
        Bytes.toBytes(""q2""), Bytes.toBytes(""val""));
    StoreFileScanner s = reader.getStoreFileScanner(false, false);
    s.reseek(toSeek);
{code}
Now calling s.next() should point to the last KV - kv5.
Before calling s.next() it would have done a moveToPrevious since there is no KV that exactly matches with the toSeek key.
Incase of NONE, PREFIX, DIFF, FAST_DIFF things work fine as expected.
But in case of Prefix Tree, calling reseek() points to a key that is same as the toSeek key which does not exist at all. 
Will attach a testcase that shows this problem. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10702,"One of our user contacted me about an issue with Deletes.

Some of the deletes they do are not totally processed. Therefore, after the Delete, if they do a Get, from time to time, the Get return the row when it should have been deleted and should have returned nothing. After multiple Deletes, the row is finally deleted. If we don't retry after the 1st attempt, the row stays there. Even after a flush, a major_compact, etc.

I have been able to reproduce the issue in 0.94.2 (CDH4.2.0 EC2), 0.94.15(CDH4.6.0 EC2) and 0.94.17 (Apache version bare metal)

Here is a simple output from my test app.

1736509 Doing a delete for 0000099676 failed. Start to count
puts=311 deletes=64 retries=2

2281712 Doing a delete for 0000027606 failed. Start to count
puts=3679 deletes=247 retries=2

2388305 Doing a delete for 0000018306 failed. Start to count
puts=4744 deletes=290 retries=2

2532943 Doing a delete for 0000030446 failed. Start to count
puts=5678 deletes=337 retries=2

2551421 Doing a delete for 0000046304 failed. Start to count
puts=5845 deletes=345 retries=2

2561099 Doing a delete for 0000019619 failed. Start to count
puts=5869 deletes=347 retries=3

First field is the time in ms since the test started.  So first error occurs after about 30 minutes. Below are the number of puts and deletes done, and the numbers of required retries to get the value deleted.

Key is random number between  0000000000 and 0000100000.

Very simple test. Just doing more puts than deletes.

Tests are running on 0.96.1.1 for almost 1h now so it seems to be fine, but it's not on the same cluster, so I will keep that running for hours/days first.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10557,"Flush triggered by hlog-replay(replayRecoveredEdits) and region-close(non-abort close) get processed directly by region without putting flush entry into flushQueue, hence not handled by MemStoreFlusher, So DroppedSnapshotException emitted from internalFlushcache is not handled properly",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2647,"Saw this failure on my Hudson:

org.apache.hadoop.hbase.client.NoServerForRegionException: Timed out trying to locate root region because: Failed setting up proxy to /192.168.42.22:44708 after attempts=1
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRootRegion(HConnectionManager.java:1023)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:630)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:606)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:676)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:635)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:606)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:132)
	at org.apache.hadoop.hbase.HBaseClusterTestCase.hBaseClusterSetup(HBaseClusterTestCase.java:110)
	at org.apache.hadoop.hbase.HBaseClusterTestCase.setUp(HBaseClusterTestCase.java:147)
	at org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.setUp(TestLogRolling.java:131)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3490,"I am trying to run the Map Reduce job to upload the text file into the Hbase-0.89 from the HDFS file system by using the Sample code in the Hbase-0.20.6 API document. But it seems, BatchUpdate has been completely removed. Does any one have the sample code to upload the Bulk of data into Hbase using Map reduce Program. 

Thanks in advance



 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9912,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8974,"I'm exercising the patch over on HBASE-8803 and I've noticed something in the logs: it looks like {{rolling-restart.sh}} is restarting all the region servers multiple times instead of just the current entry in the loop iteration.

The logic looks like this:

{noformat}
for each rs in active region server list:
  unload $rs // move all regions to other RS's
  restart all Region Servers // !?! bug?
  reload $rs // pile 'em back on
{noformat}

Shouldn't that step 2 be only {{restart $rs}}?

This is what I see in the logs. My cluster has 9 active RegionServers. Notice the bit in the middle where all 9 are stopped and started again after unloading the target RS.

{noformat}
$ time /usr/lib/hbase/bin/rolling-restart.sh --rs-only --graceful --maxthreads 30                                                                                                       
Gracefully restarting: hor18n39.gq1.ygridcore.net
Disabling balancer!
...
Unloading hor18n39.gq1.ygridcore.net region(s)
...
Valid region move targets: 
hor18n37.gq1.ygridcore.net,60020,1374094975268
hor17n37.gq1.ygridcore.net,60020,1374094975264
hor18n35.gq1.ygridcore.net,60020,1374094975327
hor17n39.gq1.ygridcore.net,60020,1374094975281
hor18n36.gq1.ygridcore.net,60020,1374094975254
hor17n36.gq1.ygridcore.net,60020,1374094975277
hor17n34.gq1.ygridcore.net,60020,1374094975291
hor18n38.gq1.ygridcore.net,60020,1374094975259
13/07/17 21:44:38 INFO region_mover: Moving 330 region(s) from hor18n39.gq1.ygridcore.net,60020,1374094975326 during this cycle
13/07/17 21:44:38 INFO region_mover: Moving region b59050cf97aabcef838e3c50e93e6d13 (1 of 330) to server=hor18n37.gq1.ygridcore.net,60020,1374094975268
...
13/07/17 21:54:20 INFO region_mover: Moving region d00026d7cc396bb3e6ea91106cc6ab55 (329 of 330) to server=hor18n37.gq1.ygridcore.net,60020,1374094975268
13/07/17 21:54:20 INFO region_mover: Moving region a722179b33e6ece8c9cee3fba3056acd (330 of 330) to server=hor17n37.gq1.ygridcore.net,60020,1374094975264
13/07/17 21:54:21 INFO region_mover: Wrote list of moved regions to /tmp/hor18n39.gq1.ygridcore.net
Unloaded hor18n39.gq1.ygridcore.net region(s)
hor18n35.gq1.ygridcore.net: stopping regionserver.
hor17n39.gq1.ygridcore.net: stopping regionserver.
hor18n36.gq1.ygridcore.net: stopping regionserver.
hor17n37.gq1.ygridcore.net: stopping regionserver.
hor17n34.gq1.ygridcore.net: stopping regionserver.
hor18n38.gq1.ygridcore.net: stopping regionserver.
hor18n37.gq1.ygridcore.net: stopping regionserver.
hor17n36.gq1.ygridcore.net: stopping regionserver.
hor18n39.gq1.ygridcore.net: stopping regionserver.
hor18n36.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor18n36.gq1.ygridcore.net.out
hor17n36.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor17n36.gq1.ygridcore.net.out
hor17n37.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor17n37.gq1.ygridcore.net.out
hor18n37.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor18n37.gq1.ygridcore.net.out
hor18n38.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor18n38.gq1.ygridcore.net.out
hor17n34.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor17n34.gq1.ygridcore.net.out
hor18n35.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor18n35.gq1.ygridcore.net.out
hor18n39.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor18n39.gq1.ygridcore.net.out
hor17n39.gq1.ygridcore.net: starting regionserver, logging to /grid/0/var/log/hbase/hbase-hbase-regionserver-hor17n39.gq1.ygridcore.net.out
Reloading hor18n39.gq1.ygridcore.net region(s)
...
13/07/17 21:54:27 INFO region_mover: Moving 330 regions to hor18n39.gq1.ygridcore.net,60020,1374098064602
13/07/17 21:56:47 INFO region_mover: Moving region 7d0a02f452c334a12026b45346a87d36 (1 of 330) to server=hor18n39.gq1.ygridcore.net,60020,1374098064602 in thread 0
13/07/17 21:56:54 INFO region_mover: Moving region af5448c90e78a8f0d935efb0b380502e (2 of 330) to server=hor18n39.gq1.ygridcore.net,60020,1374098064602 in thread 1
...
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7670,"We found ZK event not be watched by master for a  long time in our testing.
It seems one ZK-Event-Handle thread block it.
Attaching some logs on master
{code}
2013-01-16 22:18:55,667 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, 
2013-01-16 22:18:56,270 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, 
...
2013-01-16 23:55:33,259 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Retrying
org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=100, exceptions:
        at org.apache.hadoop.hbase.client.ServerCallable.withRetries(ServerCallable.java:183)
        at org.apache.hadoop.hbase.client.HTable.get(HTable.java:676)
        at org.apache.hadoop.hbase.catalog.MetaReader.get(MetaReader.java:247)
        at org.apache.hadoop.hbase.catalog.MetaReader.getRegion(MetaReader.java:349)
        at org.apache.hadoop.hbase.catalog.MetaReader.readRegionLocation(MetaReader.java:289)
        at org.apache.hadoop.hbase.catalog.MetaReader.getMetaRegionLocation(MetaReader.java:276)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.getMetaServerConnection(CatalogTracker.java:424)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:489)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:451)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:289)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:169)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
2013-01-16 23:55:33,261 WARN org.apache.hadoop.hbase.master.AssignmentManager: Attempted to handle region transition for server but server is not online
{code}

Between 2013-01-16 22:18:56 and 2013-01-16 23:55:33, there is no any logs about handling ZK Event.


{code}
this.metaNodeTracker = new MetaNodeTracker(zookeeper, throwableAborter) {
      public void nodeDeleted(String path) {
        if (!path.equals(node)) return;
        ct.resetMetaLocation();
      }
    }
public void resetMetaLocation() {
    LOG.debug(""Current cached META location, "" + metaLocation +
      "", is not valid, resetting"");
    synchronized(this.metaAvailable) {
      this.metaAvailable.set(false);
      this.metaAvailable.notifyAll();
    }
  }

private AdminProtocol getMetaServerConnection(){
synchronized (metaAvailable){
...
ServerName newLocation = MetaReader.getMetaRegionLocation(this);
...
}
}
{code}

From the above code, we would found that nodeDeleted() would wait synchronized (metaAvailable) until MetaReader.getMetaRegionLocation(this) done,
however, getMetaRegionLocation() could be retrying for a long time",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6670,"Currently HbaseObjectWritable uses ProtobufUtil to perform serialization of Scan objects, ProtobufUtil.toParameter() calls HbaseObjectWritable.writeObject().

We should untangle such mixture and ultimately remove HbaseObjectWritable",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4575,I've found some misnaming of certain ZK config options.  Make them consistent.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2549,"Once we move to all Scans, the trackers could use a refresh.  There are often times where we return, for example, a MatchCode.SKIP (which just goes to the next KV not including the current one) where we could be sending a more optimal return code like MatchCode.SEEK_NEXT_ROW.

This is a jira to review all of this code after 2248 goes in.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5154,"1. Call put to insert some value in column 'fm:a' like:
Put.add('fm', 'a', 1000, 'abc'), here timestamp = 1000.
2. Delete the column 'fm:a'
3. Try to do #1 again.(it doesn't work, but can insert put which use timestamp > 1000)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3809,"This is a duplicate of another issue but at the moment I cannot find the original.

If you had a 700 node cluster and then you ran something on the cluster which killed 100 nodes, and .META. had been running on one of those downed nodes, well, you'll have all of your master executors processing ServerShutdowns and more than likely non of the currently processing executors will be servicing the shutdown of the server that was carrying .META.

Well, for server shutdown to complete at the moment, an online .META. is required.  So, in the above case, we'll be stuck. The current executors will not be able to clear to make space for the processing of the server carrying .META. because they need .META. to complete.

We can make the master handlers have no bound so it will expand to accomodate all crashed servers -- so it'll have the one .META. in its queue -- or we can change it so shutdown handling doesn't require .META. to be on-line (its used to figure the regions the server was carrying); we could use the master's in-memory picture of the cluster (But IIRC, there may be holes ....TBD)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7364,"RCFile is not thread-safe, even if each reader is only used by one thread as intended, because it is possible to return decompressors to the pool multiple times by calling close on the reader multiple times. Then, different threads can pick up the same decompressor twice from the pool, resulting in decompression failures.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7227,"without this, we're looking for deadlocks.

I'm looking at the code currently, I may add stuff to this jira ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6464,"reportTableInFlux() gets all tables not in flux. However, when no table is found in getTable(numSkipped) function, it will return null. Then, errorReporter attempts to print the table number, which causes a NPE here.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6498,"Hi Dear:

I met problem with starting Hbase:

I have 5 machines (Ubuntu)

109.123.121.23 rsmm-master.example.com
109.123.121.24 rsmm-slave-1.example.com
109.123.121.25 rsmm-slave-2.example.com
109.123.121.26 rsmm-slave-3.example.com
109.123.121.27 rsmm-slave-4.example.com

Hadoop 0.20.205.0
Zookeeper: zookeeper-3.3.5.jar
Hbase: hbase-0.94.0

The configuration file:
1. /etc/hosts seting is fine
#127.0.0.1      localhost
109.123.121.23 rsmm-master.example.com
109.123.121.24 rsmm-slave-1.example.com
109.123.121.25 rsmm-slave-2.example.com
109.123.121.26 rsmm-slave-3.example.com
109.123.121.27 rsmm-slave-4.example.com
# The following lines are desirable for IPv6 capable hosts
::1     ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

2. /home/hduser/hadoop-0.20.205.0/conf/core-site.xml:
<property>
  <name>hadoop.tmp.dir</name>
  <value>/home/hduser/hadoop-0.20.205.0/data</value>
</property>
<property>
  <name>fs.default.name</name>
  <value>hdfs://rsmm-master.example.com:9000</value>
</property>


3. I use individual zookeeper. /home/hduser/zookeeper/conf/zoo.cfg 
tickTime=2000
dataDir=/home/hduser/zookeeper/conf
dataLogDir=/home/hduser/zookeeper/logs
clientPort=2181
initLimit=10
syncLimit=5
minSessionTimeout=10000
maxSessionTimeout=20000
server.1=rsmm-master.example.com:2888:3888
server.2=rsmm-slave-1.example.com:2888:3888
server.3=rsmm-slave-2.example.com:2888:3888
server.4=rsmm-slave-3.example.com:2888:3888
server.5=rsmm-slave-4.example.com:2888:3888

4. /home/hduser/hbase/conf/hbase-site.xml

  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>rsmm-master.example.com,rsmm-slave-1.example.com,rsmm-slave-2.example.com,rsmm-slave-3.example.com,rsmm-slave-4.example.com</value>
  </property>
  <property>
    <name>hbase.master</name>
    <value>rsmm-master.example.com:60000</value>
  </property>
  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/home/hduser/zookeeper/conf</value>
  </property>
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://rsmm-master.example.com:9000/hbase</value>
  </property>
   <property>
    <name>dfs.support.append</name>
    <value>true</value>
   </property>
   <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property> 
<property>
<name>hbase.master.maxclockskew</name>
<value>180000</value>
</property>
<property> 
<name>hbase.master.distributed.log.splitting</name> 
<value>false</value> 
</property>
<property>
<name>hbase.master.info.port</name>
<value>60010</value>
</property>
<property>
<name>hbase.master.port</name>
<value>60000</value></property>
<property>
<name>hbase.defaults.for.version.skip</name>
<value>true</value>
</property>

5.  /home/hduser/hbase/conf/hbase-env.sh
export JAVA_HOME=/usr/java/jre1.6.0_33
export HADOOP_HOME=/home/hduser/hadoop-0.20.205.0
export HBASE_HOME=/home/hduser/hbase
export PATH=$PATH:/home/hduser/hbase/bin
export HBASE_CLASSPATH=/home/hduser/hadoop-0.20.205.0/conf
export HBASE_HEAPSIZE=2048
export HBASE_OPTS=""-XX:+UseConcMarkSweepGC""
export HBASE_MANAGES_ZK=false

I have checked the configuration file, I believe it is set OK

=============================================================================

Then I start hadoop, it is OK
because I could visit:
http://109.123.121.23:50030/jobtracker.jsp
http://109.123.121.23:50070/dfshealth.jsp
http://109.123.121.24:50060/tasktracker.jsp
http://109.123.121.25:50060/tasktracker.jsp
http://109.123.121.26:50060/tasktracker.jsp
http://109.123.121.26:50060/tasktracker.jsp

I start zookeeper in all the clusters, 
runnig  /home/hduser/zookeeper/bin/zkServer.sh status
JMX enabled by default
Using config: /home/hduser/zookeeper/bin/../conf/zoo.cfg
Mode: follower

Then I log in zookeeper command line:
I could view, create ,etc..


Then  I start HBASE, then jps

2778 NameNode
19996 HMaster
3209 JobTracker
30732 Jps
3126 SecondaryNameNode
3382 QuorumPeerMain

in hbase shell: status
4 servers, 0 dead, 0.5000 average load

it looks good but the log shows: 

Tue Dec 12 15:04:21 CST 2028 Starting master on rsmm-master.example.com
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 26056
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 26056
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2028-12-12 15:04:21,916 INFO org.apache.hadoop.hbase.util.VersionInfo: HBase 0.94.0
2028-12-12 15:04:21,917 INFO org.apache.hadoop.hbase.util.VersionInfo: Subversion https://svn.apache.org/repos/asf/hbase/branches/0.94 -r 1332822
2028-12-12 15:04:21,917 INFO org.apache.hadoop.hbase.util.VersionInfo: Compiled by jenkins on Tue May  1 21:43:54 UTC 2012
2028-12-12 15:04:22,219 DEBUG org.apache.hadoop.hbase.master.HMaster: Set serverside HConnection retries=100
2028-12-12 15:04:23,181 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,181 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,182 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,182 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,183 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,184 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,184 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,185 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,185 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,186 INFO org.apache.hadoop.ipc.HBaseServer: Starting Thread-1
2028-12-12 15:04:23,204 INFO org.apache.hadoop.hbase.ipc.HBaseRpcMetrics: Initializing RPC Metrics with hostName=HMaster, port=60000
2028-12-12 15:04:23,468 INFO org.apache.zookeeper.ZooKeeper: Client environment:zookeeper.version=3.3.5-1301095, built on 03/15/2012 19:48 GMT
2028-12-12 15:04:23,468 INFO org.apache.zookeeper.ZooKeeper: Client environment:host.name=rsmm-master.example.com
2028-12-12 15:04:23,468 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.version=1.6.0_33
2028-12-12 15:04:23,468 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2028-12-12 15:04:23,468 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.home=/usr/java/jre1.6.0_33
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.class.path=/home/hduser/hbase/conf:/usr/java/jre1.6.0_33/lib/tools.jar:/home/hduser/hbase:/home/hduser/hbase/hbase-0.94.0.jar:/home/hduser/hbase/hbase-0.94.0-tests.jar:/home/hduser/hbase/lib/activation-1.1.jar:/home/hduser/hbase/lib/asm-3.1.jar:/home/hduser/hbase/lib/avro-1.5.3.jar:/home/hduser/hbase/lib/avro-ipc-1.5.3.jar:/home/hduser/hbase/lib/commons-beanutils-1.7.0.jar:/home/hduser/hbase/lib/commons-beanutils-core-1.8.0.jar:/home/hduser/hbase/lib/commons-cli-1.2.jar:/home/hduser/hbase/lib/commons-codec-1.4.jar:/home/hduser/hbase/lib/commons-collections-3.2.1.jar:/home/hduser/hbase/lib/commons-configuration-1.6.jar:/home/hduser/hbase/lib/commons-digester-1.8.jar:/home/hduser/hbase/lib/commons-el-1.0.jar:/home/hduser/hbase/lib/commons-httpclient-3.1.jar:/home/hduser/hbase/lib/commons-io-2.1.jar:/home/hduser/hbase/lib/commons-lang-2.5.jar:/home/hduser/hbase/lib/commons-logging-1.1.1.jar:/home/hduser/hbase/lib/commons-math-2.1.jar:/home/hduser/hbase/lib/commons-net-1.4.1.jar:/home/hduser/hbase/lib/core-3.1.1.jar:/home/hduser/hbase/lib/guava-r09.jar:/home/hduser/hbase/lib/hadoop-core-0.20.205.0.jar:/home/hduser/hbase/lib/high-scale-lib-1.1.1.jar:/home/hduser/hbase/lib/httpclient-4.1.2.jar:/home/hduser/hbase/lib/httpcore-4.1.3.jar:/home/hduser/hbase/lib/jackson-core-asl-1.5.5.jar:/home/hduser/hbase/lib/jackson-jaxrs-1.5.5.jar:/home/hduser/hbase/lib/jackson-mapper-asl-1.5.5.jar:/home/hduser/hbase/lib/jackson-xc-1.5.5.jar:/home/hduser/hbase/lib/jamon-runtime-2.3.1.jar:/home/hduser/hbase/lib/jasper-compiler-5.5.23.jar:/home/hduser/hbase/lib/jasper-runtime-5.5.23.jar:/home/hduser/hbase/lib/jaxb-api-2.1.jar:/home/hduser/hbase/lib/jaxb-impl-2.1.12.jar:/home/hduser/hbase/lib/jersey-core-1.4.jar:/home/hduser/hbase/lib/jersey-json-1.4.jar:/home/hduser/hbase/lib/jersey-server-1.4.jar:/home/hduser/hbase/lib/jettison-1.1.jar:/home/hduser/hbase/lib/jetty-6.1.26.jar:/home/hduser/hbase/lib/jetty-util-6.1.26.jar:/home/hduser/hbase/lib/jruby-complete-1.6.5.jar:/home/hduser/hbase/lib/jsp-2.1-6.1.14.jar:/home/hduser/hbase/lib/jsp-api-2.1-6.1.14.jar:/home/hduser/hbase/lib/libthrift-0.8.0.jar:/home/hduser/hbase/lib/log4j-1.2.16.jar:/home/hduser/hbase/lib/netty-3.2.4.Final.jar:/home/hduser/hbase/lib/protobuf-java-2.4.0a.jar:/home/hduser/hbase/lib/servlet-api-2.5-6.1.14.jar:/home/hduser/hbase/lib/slf4j-api-1.5.8.jar:/home/hduser/hbase/lib/slf4j-log4j12-1.5.8.jar:/home/hduser/hbase/lib/snappy-java-1.0.3.2.jar:/home/hduser/hbase/lib/stax-api-1.0.1.jar:/home/hduser/hbase/lib/velocity-1.7.jar:/home/hduser/hbase/lib/xmlenc-0.52.jar:/home/hduser/hbase/lib/zookeeper-3.3.5.jar:/home/hduser/hadoop-0.20.205.0/conf:/home/hduser/hadoop-0.20.205.0/libexec/../conf:/usr/java/jre1.6.0_33/lib/tools.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/hadoop-core-0.20.205.0.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/asm-3.2.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/aspectjrt-1.6.5.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/aspectjtools-1.6.5.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-beanutils-1.7.0.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-beanutils-core-1.8.0.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-cli-1.2.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-codec-1.4.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-collections-3.2.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-configuration-1.6.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-daemon-1.0.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-digester-1.8.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-el-1.0.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-httpclient-3.0.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-lang-2.4.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-logging-1.1.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-logging-api-1.0.4.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-math-2.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/commons-net-1.4.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/core-3.1.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/hadoop-capacity-scheduler-0.20.205.0.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/hadoop-fairscheduler-0.20.205.0.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/hadoop-thriftfs-0.20.205.0.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/hsqldb-1.8.0.10.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jackson-core-asl-1.0.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jackson-mapper-asl-1.0.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jasper-compiler-5.5.12.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jasper-runtime-5.5.12.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jdeb-0.8.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jersey-core-1.8.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jersey-json-1.8.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jersey-server-1.8.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jets3t-0.6.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jetty-6.1.26.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jetty-util-6.1.26.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jsch-0.1.42.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/junit-4.5.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/kfs-0.2.2.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/log4j-1.2.15.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/mockito-all-1.8.5.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/oro-2.0.8.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/servlet-api-2.5-20081211.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/slf4j-api-1.5.8.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/slf4j-log4j12-1.4.3.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/slf4j-log4j12-1.5.8.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/xmlenc-0.52.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jsp-2.1/jsp-2.1.jar:/home/hduser/hadoop-0.20.205.0/libexec/../share/hadoop/lib/jsp-2.1/jsp-api-2.1.jar:/home/hduser/hbase/hbase-0.94.0.jar:/home/hduser/zookeeper/zookeeper-3.3.5.jar
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.library.path=/home/hduser/hadoop-0.20.205.0/libexec/../lib:/home/hduser/hbase/lib/native/Linux-i386-32
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:os.name=Linux
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:os.arch=i386
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:os.version=3.0.0-24-generic
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:user.name=hduser
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:user.home=/home/hduser
2028-12-12 15:04:23,469 INFO org.apache.zookeeper.ZooKeeper: Client environment:user.dir=/home/hduser/hbase/bin
2028-12-12 15:04:23,470 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=rsmm-slave-3.example.com:2181,rsmm-slave-2.example.com:2181,rsmm-slave-1.example.com:2181,rsmm-master.example.com:2181,rsmm-slave-4.example.com:2181 sessionTimeout=180000 watcher=master:60000
2028-12-12 15:04:23,489 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server rsmm-slave-4.example.com/109.123.121.27:2181
2028-12-12 15:04:23,496 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to rsmm-slave-4.example.com/109.123.121.27:2181, initiating session
2028-12-12 15:04:23,496 INFO org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper: The identifier of this process is 10155@rsmm-master.example.com
2028-12-12 15:04:23,520 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server rsmm-slave-4.example.com/109.123.121.27:2181, sessionid = 0xffb11d36a60b0004, negotiated timeout = 20000
2028-12-12 15:04:23,598 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server Responder: starting
2028-12-12 15:04:23,602 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server listener on 60000: starting
2028-12-12 15:04:23,625 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 0 on 60000: starting
2028-12-12 15:04:23,626 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 1 on 60000: starting
2028-12-12 15:04:23,626 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 2 on 60000: starting
2028-12-12 15:04:23,626 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 3 on 60000: starting
2028-12-12 15:04:23,627 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 4 on 60000: starting
2028-12-12 15:04:23,627 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 5 on 60000: starting
2028-12-12 15:04:23,627 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 6 on 60000: starting
2028-12-12 15:04:23,627 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 7 on 60000: starting
2028-12-12 15:04:23,627 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 8 on 60000: starting
2028-12-12 15:04:23,628 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 9 on 60000: starting
2028-12-12 15:04:23,632 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=Master, sessionId=rsmm-master.example.com,60000,1860217463298
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: revision
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: hdfsUser
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: hdfsDate
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: hdfsUrl
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: date
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: hdfsRevision
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: user
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: hdfsVersion
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: url
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: MetricsString added: version
2028-12-12 15:04:23,640 INFO org.apache.hadoop.hbase.metrics: new MBeanInfo
2028-12-12 15:04:23,641 INFO org.apache.hadoop.hbase.metrics: new MBeanInfo
2028-12-12 15:04:23,642 INFO org.apache.hadoop.hbase.master.metrics.MasterMetrics: Initialized
2028-12-12 15:04:23,658 INFO org.apache.hadoop.hbase.master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/rsmm-master.example.com,60000,1860217463298 from backup master directory
2028-12-12 15:04:23,674 WARN org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper: Node /hbase/backup-masters/rsmm-master.example.com,60000,1860217463298 already deleted, and this is not a retry
2028-12-12 15:04:23,675 INFO org.apache.hadoop.hbase.master.ActiveMasterManager: Master=rsmm-master.example.com,60000,1860217463298
2028-12-12 15:04:24,081 DEBUG org.apache.hadoop.hbase.catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@1c3e9ba
2028-12-12 15:04:24,142 INFO org.apache.hadoop.hbase.master.HMaster: Server active/primary master; rsmm-master.example.com,60000,1860217463298, sessionid=0xffb11d36a60b0004, cluster-up flag was=false
2028-12-12 15:04:24,184 DEBUG org.apache.hadoop.hbase.executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-rsmm-master.example.com,60000,1860217463298, corePoolSize=5, maxPoolSize=5
2028-12-12 15:04:24,184 DEBUG org.apache.hadoop.hbase.executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-rsmm-master.example.com,60000,1860217463298, corePoolSize=5, maxPoolSize=5
2028-12-12 15:04:24,184 DEBUG org.apache.hadoop.hbase.executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-rsmm-master.example.com,60000,1860217463298, corePoolSize=3, maxPoolSize=3
2028-12-12 15:04:24,185 DEBUG org.apache.hadoop.hbase.executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-rsmm-master.example.com,60000,1860217463298, corePoolSize=5, maxPoolSize=5
2028-12-12 15:04:24,185 DEBUG org.apache.hadoop.hbase.executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-rsmm-master.example.com,60000,1860217463298, corePoolSize=1, maxPoolSize=1
2028-12-12 15:04:24,187 DEBUG org.apache.hadoop.hbase.master.LogCleaner: Add log cleaner in chain: org.apache.hadoop.hbase.master.TimeToLiveLogCleaner
2028-12-12 15:04:24,259 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2028-12-12 15:04:24,348 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2028-12-12 15:04:24,358 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60010
2028-12-12 15:04:24,359 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 60010 webServer.getConnectors()[0].getLocalPort() returned 60010
2028-12-12 15:04:24,359 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 60010
2028-12-12 15:04:24,359 INFO org.mortbay.log: jetty-6.1.26
2028-12-12 15:04:24,865 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:60010
2028-12-12 15:04:24,865 DEBUG org.apache.hadoop.hbase.master.HMaster: Started service threads
2028-12-12 15:04:24,865 INFO org.apache.hadoop.hbase.master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2028-12-12 15:04:25,338 WARN org.apache.hadoop.hbase.master.ServerManager: Reported time for server rsmm-slave-3.example.com,60020,1860217439763 is out of sync with master by 25058ms. (Warning threshold is 10000ms; error threshold is 180000ms)
2028-12-12 15:04:25,339 INFO org.apache.hadoop.hbase.master.ServerManager: Registering server=rsmm-slave-3.example.com,60020,1860217439763
2028-12-12 15:04:25,366 INFO org.apache.hadoop.hbase.master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 501 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2028-12-12 15:04:25,580 INFO org.apache.hadoop.hbase.master.ServerManager: Registering server=rsmm-slave-1.example.com,60020,1860217460976
2028-12-12 15:04:25,603 WARN org.apache.hadoop.hbase.master.ServerManager: Reported time for server rsmm-slave-4.example.com,60020,1860217451403 is out of sync with master by 13667ms. (Warning threshold is 10000ms; error threshold is 180000ms)
2028-12-12 15:04:25,603 INFO org.apache.hadoop.hbase.master.ServerManager: Registering server=rsmm-slave-4.example.com,60020,1860217451403
2028-12-12 15:04:25,617 INFO org.apache.hadoop.hbase.master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 752 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2028-12-12 15:04:25,649 WARN org.apache.hadoop.hbase.master.ServerManager: Reported time for server rsmm-slave-2.example.com,60020,1860217448183 is out of sync with master by 16960ms. (Warning threshold is 10000ms; error threshold is 180000ms)
2028-12-12 15:04:25,650 INFO org.apache.hadoop.hbase.master.ServerManager: Registering server=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:25,668 INFO org.apache.hadoop.hbase.master.ServerManager: Waiting for region servers count to settle; currently checked in 4, slept for 803 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2028-12-12 15:04:27,170 INFO org.apache.hadoop.hbase.master.ServerManager: Finished waiting for region servers count to settle; checked in 4, slept for 2305 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2028-12-12 15:04:27,176 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://rsmm-master.example.com:9000/hbase/.logs/rsmm-slave-1.example.com,60020,1860217460976 belongs to an existing region server
2028-12-12 15:04:27,176 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://rsmm-master.example.com:9000/hbase/.logs/rsmm-slave-2.example.com,60020,1860217448183 belongs to an existing region server
2028-12-12 15:04:27,176 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://rsmm-master.example.com:9000/hbase/.logs/rsmm-slave-3.example.com,60020,1860217439763 belongs to an existing region server
2028-12-12 15:04:27,177 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://rsmm-master.example.com:9000/hbase/.logs/rsmm-slave-4.example.com,60020,1860217451403 belongs to an existing region server
2028-12-12 15:04:27,177 INFO org.apache.hadoop.hbase.master.MasterFileSystem: No logs to split
2028-12-12 15:04:28,185 INFO org.apache.hadoop.hbase.catalog.RootLocationEditor: Unsetting ROOT region location in ZooKeeper
2028-12-12 15:04:28,193 WARN org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper: Node /hbase/root-region-server already deleted, and this is not a retry
2028-12-12 15:04:28,196 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0xffb11d36a60b0004 Creating (or updating) unassigned node for 70236052 with OFFLINE state
2028-12-12 15:04:28,223 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for -ROOT-,,0.70236052 so generated a random one; hri=-ROOT-,,0.70236052, src=, dest=rsmm-slave-2.example.com,60020,1860217448183; 4 (online=4, available=4) available servers
2028-12-12 15:04:28,223 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region -ROOT-,,0.70236052 to rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,224 DEBUG org.apache.hadoop.hbase.master.ServerManager: New connection to rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,225 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=rsmm-slave-3.example.com:2181,rsmm-slave-2.example.com:2181,rsmm-slave-1.example.com:2181,rsmm-master.example.com:2181,rsmm-slave-4.example.com:2181 sessionTimeout=180000 watcher=hconnection
2028-12-12 15:04:28,227 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server rsmm-slave-4.example.com/109.123.121.27:2181
2028-12-12 15:04:28,228 INFO org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper: The identifier of this process is 10155@rsmm-master.example.com
2028-12-12 15:04:28,230 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to rsmm-slave-4.example.com/109.123.121.27:2181, initiating session
2028-12-12 15:04:28,239 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server rsmm-slave-4.example.com/109.123.121.27:2181, sessionid = 0xffb11d36a60b0006, negotiated timeout = 20000
2028-12-12 15:04:28,440 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=rsmm-slave-2.example.com,60020,1860217448183, region=70236052/-ROOT-, which is more than 15 seconds late
2028-12-12 15:04:28,728 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=rsmm-slave-2.example.com,60020,1860217448183, region=70236052/-ROOT-, which is more than 15 seconds late
2028-12-12 15:04:28,754 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=rsmm-slave-2.example.com,60020,1860217448183, region=70236052/-ROOT-, which is more than 15 seconds late
2028-12-12 15:04:28,758 INFO org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for -ROOT-,,0.70236052 from rsmm-slave-2.example.com,60020,1860217448183; deleting unassigned node
2028-12-12 15:04:28,759 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0xffb11d36a60b0004 Deleting existing unassigned node for 70236052 that is in expected state RS_ZK_REGION_OPENED
2028-12-12 15:04:28,769 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: The znode of region -ROOT-,,0.70236052 has been deleted.
2028-12-12 15:04:28,769 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0xffb11d36a60b0004 Successfully deleted unassigned node for region 70236052 in expected state RS_ZK_REGION_OPENED
2028-12-12 15:04:28,771 INFO org.apache.hadoop.hbase.master.AssignmentManager: The master has opened the region -ROOT-,,0.70236052 that was online on rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,776 INFO org.apache.hadoop.hbase.master.HMaster: -ROOT- assigned=1, rit=false, location=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,791 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,794 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,884 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Failed verification of .META.,,1 at address=rsmm-slave-4.example.com,60020,1860211448024; org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: .META.,,1
2028-12-12 15:04:28,936 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,937 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,943 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Failed verification of .META.,,1 at address=rsmm-slave-4.example.com,60020,1860211448024; org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: .META.,,1
2028-12-12 15:04:28,994 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:28,995 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:29,000 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Failed verification of .META.,,1 at address=rsmm-slave-4.example.com,60020,1860211448024; org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: .META.,,1
2028-12-12 15:04:29,051 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:29,052 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:29,057 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Failed verification of .META.,,1 at address=rsmm-slave-4.example.com,60020,1860211448024; org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: .META.,,1
2028-12-12 15:04:29,109 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:29,110 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@76f2e8; serverName=rsmm-slave-2.example.com,60020,1860217448183
2028-12-12 15:04:29,115 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Fa",,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6174,"I see this:

{code}

Tests in error: 
  testCalls(org.apache.hadoop.hbase.ipc.TestPBOnWritableRpc): java.lang.NoSuchMethodError: org.apache.hadoop.net.NetUtils.getInputStream(Ljava/net/Socket;)Ljava/io/InputStream;

{code}

when I do this:

{code}
$ ~/bin/mvn/bin/mvn -PlocalTests test -Dtest=TestPBOnWritableRpc -Dhadoop.profile=2.0
{code}

... is this ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4767,"when i want to upgrade my dev box from hbase dompiled on wto, 25-10-2011 to current branch master got exeption:
java.io.IOException: HTD not found in input buffer
        at org.apache.hadoop.hbase.HRegionInfo.readFields(HRegionInfo.java:738)

trying to rebuild META by OfflineMetaRepair i had the same exception too",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1163,"Mapreduce tasks based on TIF won't start. Clients trying to find regions by start key block indefinitely (Heritrix hbase writer eventually times out archiver). 

Master seems hung in root scan. I've dumped thread stacks 10 times in 10 minutes and the same HBaseClient$Call  object appears in the trace. See below:

Thread 21 (RegionManager.rootScanner):
  State: WAITING
  Blocked count: 500
  Waited count: 621
  Waiting on org.apache.hadoop.hbase.ipc.HBaseClient$Call@55a2896d
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:695)
    org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:321)
    $Proxy2.next(Unknown Source)
    org.apache.hadoop.hbase.master.BaseScanner.scanRegion(BaseScanner.java:161)
    org.apache.hadoop.hbase.master.RootScanner.scanRoot(RootScanner.java:55)
    org.apache.hadoop.hbase.master.RootScanner.maintenanceScan(RootScanner.java:80)
    org.apache.hadoop.hbase.master.BaseScanner.chore(BaseScanner.java:137)
    org.apache.hadoop.hbase.Chore.run(Chore.java:65)

I only see messages from the MetaScanner scanner in the master log, nothing from RootScanner.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2536,"The hbase.hstore.blockingStoreFiles threshold is currently across the entire region, which means that if the number of column families multiplied by hbase.hstore.compactionThreshold is greater than the threshold, writes will freeze up, since we neither flush nor compact.

We should set this threshold per store, not per region, probably.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1497,"Web UI seems to work when running in pseudo-distributed mode.  However, when running on our dev cluster the master UI does not work.

Navigating (any browser, tried many) to:  http://master:60010/master.jsp

{noformat}
HTTP ERROR: 404
/master.jsp
RequestURI=/master.jsp
Powered by Jetty://
{noformat}

http://master:60010/  gives a directory listing, showing webapps/

Eventually leading to http://dn0:60010/webapps/master/master.jsp which gives a 404 as above.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1675,During cluster idle and rebalance both META and ROOT tables become unavailable leading to cascading NotServingRegion exceptions and cluster unavailability.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-774,"Looking at our 70-node cluster, whose current state is mostly read-only but for a service that is trickling in pages at about 5/600 an hour, network traffic goes through the roof every 30 minutes.  This is 0.1.3.  Regionserver logs are silent but for the optional flush that runs every 30 minutes.  The optional flush will put a few small files out on the filesystem tripping compactions of small files.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-151,"Here are the log lines for the region.  Was undergoing heavy load at the time.

{code}
...
2008-01-28 17:37:22,070 INFO org.apache.hadoop.hbase.HRegion: Unblocking updates for region test_table,000000000844535,1201569706879 'IPC Server handler 7 on 60020'
2008-01-28 17:37:22,116 INFO org.apache.hadoop.hbase.HRegion: Unblocking updates for region test_table,000000000844535,1201569706879 'IPC Server handler 8 on 60020'
2008-01-28 17:37:22,117 INFO org.apache.hadoop.hbase.HRegion: Unblocking updates for region test_table,000000000844535,1201569706879 'IPC Server handler 0 on 60020'
2008-01-28 17:37:56,713 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region test_table,000000000844535,1201569706879. Took 9mins, 34sec
2008-01-28 17:37:56,713 INFO org.apache.hadoop.hbase.HRegion: starting compaction on region test_table,000000000697863,1201569706879
2008-01-28 17:37:56,905 INFO org.apache.hadoop.hbase.HRegion: Splitting test_table,000000000844535,1201569706879 because largest aggregate size is 1.3g and desired size is 256.0m
2008-01-28 17:37:56,960 DEBUG org.apache.hadoop.hbase.HRegion: waiting for cache flush to complete for region test_table,000000000844535,1201569706879
2008-01-28 17:38:26,498 DEBUG org.apache.hadoop.hbase.HRegion: Finished memcache flush for region test_table,000000000844535,1201569706879 in 68738ms, sequenceid=559406
2008-01-28 17:38:26,498 DEBUG org.apache.hadoop.hbase.HRegion: Started memcache flush for region test_table,000000000697863,1201569706879. Size 128.0m
2008-01-28 17:38:26,499 DEBUG org.apache.hadoop.hbase.HRegion: compactions and cache flushes disabled for region test_table,000000000844535,1201569706879
2008-01-28 17:38:26,500 DEBUG org.apache.hadoop.hbase.HRegion: new updates and scanners for region test_table,000000000844535,1201569706879 disabled
2008-01-28 17:38:26,500 DEBUG org.apache.hadoop.hbase.HRegion: no more active scanners for region test_table,000000000844535,1201569706879 
2008-01-28 17:38:26,500 DEBUG org.apache.hadoop.hbase.HRegion: no more row locks outstanding on region test_table,000000000844535,1201569706879
2008-01-28 17:38:26,647 DEBUG org.apache.hadoop.hbase.HRegionServer: test_table,000000000844535,1201569706879 closing (Adding to retiringRegions)
2008-01-28 17:38:26,647 DEBUG org.apache.hadoop.hbase.HRegion: Started memcache flush for region test_table,000000000844535,1201569706879. Size 77.7m
2008-01-28 17:38:36,316 INFO org.apache.hadoop.hbase.HRegion: Unblocking updates for region test_table,000000000697863,1201569706879 'IPC Server handler 9 on 60020'
2008-01-28 17:38:36,317 INFO org.apache.hadoop.hbase.HRegion: Unblocking updates for region test_table,000000000697863,1201569706879 'IPC Server handler 2 on 60020'
2008-01-28 17:38:36,321 INFO org.apache.hadoop.hbase.HRegion: Unblocking updates for region test_table,000000000697863,1201569706879 'IPC Server handler 4 on 60020'
2008-01-28 17:39:21,023 DEBUG org.apache.hadoop.hbase.HRegion: Finished memcache flush for region test_table,000000000697863,1201569706879 in 54525ms, sequenceid=572619
2008-01-28 17:39:21,077 DEBUG org.apache.hadoop.hbase.HRegion: Started memcache flush for region test_table,000000000697863,1201569706879. Size 12.4m
2008-01-28 17:39:51,129 DEBUG org.apache.hadoop.hbase.HRegion: Finished memcache flush for region test_table,000000000844535,1201569706879 in 84482ms, sequenceid=573888
2008-01-28 17:39:51,130 DEBUG org.apache.hadoop.hbase.HRegionServer: test_table,000000000844535,1201569706879 closed
2008-01-28 17:39:51,130 INFO org.apache.hadoop.hbase.HRegion: closed test_table,000000000844535,1201569706879 
2008-01-28 17:39:51,130 DEBUG org.apache.hadoop.hbase.HRegionServer: test_table,000000000844535,1201569706879 closed
2008-01-28 17:39:55,664 DEBUG org.apache.hadoop.hbase.HRegion: Finished memcache flush for region test_table,000000000697863,1201569706879 in 34587ms, sequenceid=5738892008-01-28 17:40:06,756 INFO org.apache.hadoop.hbase.HRegionServer: region split, META updated, and report to master all successful. Old region=test_table,000000000844535,1201569706879, new regions: test_table,000000000844535,1201570676957, test_table,000000000920444,1201570676959. Split took 1mins, 40sec
2008-01-28 17:44:16,033 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region test_table,000000000697863,1201569706879. Took 6mins, 19sec
2008-01-28 17:44:16,262 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000844535,1201569706879 does not need compaction
2008-01-28 17:44:16,262 INFO org.apache.hadoop.hbase.HRegion: starting compaction on region test_table,000000000697863,1201569706879
2008-01-28 17:44:16,285 INFO org.apache.hadoop.hbase.HRegion: Splitting test_table,000000000697863,1201569706879 because largest aggregate size is 1.4g and desired size is 256.0m
2008-01-28 17:44:16,288 DEBUG org.apache.hadoop.hbase.HRegion: waiting for compaction to complete for region test_table,000000000697863,1201569706879
2008-01-28 17:49:33,196 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region test_table,000000000697863,1201569706879. Took 5mins, 16sec
2008-01-28 17:49:33,196 DEBUG org.apache.hadoop.hbase.HRegion: compactions and cache flushes disabled for region test_table,000000000697863,1201569706879
2008-01-28 17:49:33,196 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000697863,1201569706879 does not need compaction
2008-01-28 17:49:33,196 DEBUG org.apache.hadoop.hbase.HRegion: new updates and scanners for region test_table,000000000697863,1201569706879 disabled
2008-01-28 17:49:33,196 DEBUG org.apache.hadoop.hbase.HRegion: no more active scanners for region test_table,000000000697863,1201569706879
2008-01-28 17:49:33,196 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000697863,1201569706879 does not need compaction
2008-01-28 17:49:33,196 DEBUG org.apache.hadoop.hbase.HRegion: no more row locks outstanding on region test_table,000000000697863,1201569706879
2008-01-28 17:49:33,196 DEBUG org.apache.hadoop.hbase.HRegionServer: test_table,000000000697863,1201569706879 closing (Adding to retiringRegions)
2008-01-28 17:49:33,196 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000844535,1201569706879 does not need compaction
2008-01-28 17:49:33,197 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000844535,1201569706879 does not need compaction
2008-01-28 17:49:33,197 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000844535,1201569706879 does not need compaction
2008-01-28 17:49:33,197 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000697863,1201569706879 does not need compaction
2008-01-28 17:49:33,197 DEBUG org.apache.hadoop.hbase.HRegionServer: test_table,000000000697863,1201569706879 closed
2008-01-28 17:49:33,197 INFO org.apache.hadoop.hbase.HRegion: closed test_table,000000000697863,1201569706879
2008-01-28 17:49:33,197 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000697863,1201569706879 does not need compaction
2008-01-28 17:49:33,197 DEBUG org.apache.hadoop.hbase.HRegionServer: test_table,000000000697863,1201569706879 closed
2008-01-28 17:49:33,198 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000844535,1201569706879 does not need compaction
2008-01-28 17:49:33,198 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000697863,1201569706879 does not need compaction
2008-01-28 17:49:33,198 DEBUG org.apache.hadoop.hbase.HRegion: region test_table,000000000697863,1201569706879 does not need compaction
2008-01-28 17:49:34,773 INFO org.apache.hadoop.hbase.HRegionServer: region split, META updated, and report to master all successful. Old region=test_table,000000000697863,1201569706879, new regions: test_table,000000000697863,1201571056287, test_table,000000000771750,1201571056288. Split took 1sec
2008-01-28 19:09:32,812 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020, call batchUpdate(test_table,000000000844535,1201569706879, 9223372036854775807, org.apache.hadoop.hbase.io.BatchUpdate@53533c55) from XX.XX.XX.58:59891: error: org.apache.hadoop.hbase.NotServingRegionException: test_table,000000000844535,1201569706879
org.apache.hadoop.hbase.NotServingRegionException: test_table,000000000844535,1201569706879
2008-01-28 19:09:32,813 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate(test_table,000000000844535,1201569706879, 9223372036854775807, org.apache.hadoop.hbase.io.BatchUpdate@170aeb17) from XX.XX.XX.58:59891: error: org.apache.hadoop.hbase.NotServingRegionException: test_table,000000000844535,1201569706879
org.apache.hadoop.hbase.NotServingRegionException: test_table,000000000844535,1201569706879
2008-01-28 19:09:39,574 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020, call batchUpdate(test_table,000000000844535,1201569706879, 9223372036854775807, org.apache.hadoop.hbase.io.BatchUpdate@57ee026e) from XX.XX.XX.32:50384: error: org.apache.hadoop.hbase.NotServingRegionException: test_table,000000000844535,1201569706879
org.apache.hadoop.hbase.NotServingRegionException: test_table,000000000844535,1201569706879
2008-01-28 19:09:39,583 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate(test_table,000000000844535,1201569706879, 9223372036854775807, org.apache.hadoop.hbase.io.BatchUpdate@4ae1b0db) from XX.XX.XX.32:50384: error: org.apache.hadoop.hbase.NotServingRegionException: test_table,000000000844535,1201569706879
org.apache.hadoop.hbase.NotServingRegionException: test_table,000000000844535,1201569706879
...
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21576,"Master has killed an RS that was hosting meta due to some HDFS issue (most likely; I've lost the RS logs due to HBASE-21575).
RS took a very long time to die (again, might be a separate bug, I'll file if I see repro), and a long time to restart; meanwhile master never tried to reassign meta, and eventually killed itself not being able to update it.
It seems like a RS on a bad machine would be especially prone to slow abort/startup, as well as to issues causing master to kill it, so it would make sense for master to immediately relocate meta once meta-hosting RS is dead after a kill; or even when killing the RS. In the former case (if the RS needs to die for meta to be reassigned safely), perhaps the RS hosting meta in particular should try to die fast in such circumstances, and not do any cleanup.
{noformat}
2018-12-08 04:52:55,144 WARN  [RpcServer.default.FPBQ.Fifo.handler=39,queue=4,port=17000] master.MasterRpcServices: <server1>,17020,1544264858183 reported a fatal error:
***** ABORTING region server <server1>,17020,1544264858183: Replay of WAL required. Forcing server shutdown *****
.... [aborting for ~7 minutes]
2018-12-08 04:53:44,190 INFO  [PEWorker-7] client.RpcRetryingCallerImpl: Call exception, tries=6, retries=61, started=41190 ms ago, cancelled=false, msg=org.apache.hadoop.hbase.regionserver.RegionServerAbortedException: Server <server1>,17020,1544264858183 aborting, details=row '...' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=<server1>,17020,1544264858183, seqNum=-1
... [starting for ~5]
2018-12-08 04:59:58,574 INFO  [RpcServer.default.FPBQ.Fifo.handler=45,queue=0,port=17000] client.RpcRetryingCallerImpl: Call exception, tries=10, retries=61, started=392702 ms ago, cancelled=false, msg=Call to <server1> failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: <server1>, details=row '...' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=<server1>,17020,1544264858183, seqNum=-1
... [re-initializing for at least ~7]
2018-12-08 05:04:17,271 INFO  [hconnection-0x4d58bcd4-shared-pool3-t1877] client.RpcRetryingCallerImpl: Call exception, tries=6, retries=61, started=41137 ms ago, cancelled=false, msg=org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server <server1>,17020,1544274145387 is not running yet
...
2018-12-08 05:11:18,470 ERROR [RpcServer.default.FPBQ.Fifo.handler=38,queue=3,port=17000] master.HMaster: ***** ABORTING master ...,17000,1544230401860: FAILED persisting region=... state=OPEN *****^M
{noformat}

There are no signs of meta assignment activity at all in master logs",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13535,"hbase-1.1 will be the first release with DLR on by default. I've been running  ITBLLs on a cluster trying to find issues with DLR. My first few runs ran nicely... but the current run failed complaining regions are not online and indeed recovery is stuck making no progress.

Upon examination, it looks to be an assignment rather than DLR issue. A server carring meta has its meta log replayed first but we are seemingly failing to assign regions after meta is back online.

Meantime, my regionserver logs are filling with spewing complaint that regions are not online (we should dampen our logging of region not being online... ) and then the split log workers are stuck:

{code}
Thread 13206 (RS_LOG_REPLAY_OPS-c2021:16020-1-Writer-2):
  State: TIMED_WAITING
  Blocked count: 45
  Waited count: 59
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.waitUntilRegionOnline(WALSplitter.java:1959)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.locateRegionAndRefreshLastFlushedSequenceId(WALSplitter.java:1857)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.groupEditsByServer(WALSplitter.java:1761)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.append(WALSplitter.java:1674)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.writeBuffer(WALSplitter.java:1104)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.doRun(WALSplitter.java:1096)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.run(WALSplitter.java:1066)
Thread 13205 (RS_LOG_REPLAY_OPS-c2021:16020-1-Writer-1):
  State: TIMED_WAITING
  Blocked count: 45
  Waited count: 59
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.waitUntilRegionOnline(WALSplitter.java:1959)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.locateRegionAndRefreshLastFlushedSequenceId(WALSplitter.java:1857)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.groupEditsByServer(WALSplitter.java:1761)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.append(WALSplitter.java:1674)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.writeBuffer(WALSplitter.java:1104)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.doRun(WALSplitter.java:1096)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.run(WALSplitter.java:1066)
Thread 13204 (RS_LOG_REPLAY_OPS-c2021:16020-1-Writer-0):
  State: TIMED_WAITING
  Blocked count: 50
  Waited count: 63
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.waitUntilRegionOnline(WALSplitter.java:1959)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.locateRegionAndRefreshLastFlushedSequenceId(WALSplitter.java:1857)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.groupEditsByServer(WALSplitter.java:1761)
    org.apache.hadoop.hbase.wal.WALSplitter$LogReplayOutputSink.append(WALSplitter.java:1674)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.writeBuffer(WALSplitter.java:1104)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.doRun(WALSplitter.java:1096)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.run(WALSplitter.java:1066)
{code}


...complaining that:

2015-04-22 21:28:02,746 DEBUG [RS_LOG_REPLAY_OPS-c2021:16020-1] wal.WALSplitter: Used 134248328 bytes of buffered edits, waiting for IO threads...

The accounting seems off around here in SSH where it is moving regions that were on dead server to OFFLINE but is reporting no regions to assign:

{code}
143320 2015-04-21 17:05:07,571 INFO  [MASTER_SERVER_OPERATIONS-c2020:16000-0] handler.ServerShutdownHandler: Mark regions in recovery for crashed server c2024.halxg.cloudera.com,16020,1429660802192 before assignment; regions=[]
143321 2015-04-21 17:05:07,572 DEBUG [MASTER_SERVER_OPERATIONS-c2020:16000-0] master.RegionStates: Adding to processed servers c2024.halxg.cloudera.com,16020,1429660802192
143322 2015-04-21 17:05:07,575 INFO  [MASTER_SERVER_OPERATIONS-c2020:16000-0] master.RegionStates: Transition {8d63312bc39a39727afea627bb20fee4 state=OPEN, ts=1429660996054, server=c2024.halxg.cloudera.com,16020,1429660802192} to {8d63312bc39a39727afea627bb20fee4 state=OFFLINE, ts=1429661107575, server=c2024.halxg.cloudera.com,16020,1429660802192}
143323 2015-04-21 17:05:07,575 INFO  [MASTER_SERVER_OPERATIONS-c2020:16000-0] master.RegionStates: Transition {64c97bf39441e09977332c02e628a8c2 state=OPEN, ts=1429660996045, server=c2024.halxg.cloudera.com,16020,1429660802192} to {64c97bf39441e09977332c02e628a8c2 state=OFFLINE, ts=1429661107575, server=c2024.halxg.cloudera.com,16020,1429660802192}
143324 2015-04-21 17:05:07,575 INFO  [MASTER_SERVER_OPERATIONS-c2020:16000-0] master.RegionStates: Transition {3f4ea5ea14653cee6006f13c7d06d10b state=OPEN, ts=1429660996066, server=c2024.halxg.cloudera.com,16020,1429660802192} to {3f4ea5ea14653cee6006f13c7d06d10b state=OFFLINE, ts=1429661107575, server=c2024.halxg.cloudera.com,16020,1429660802192}
143325 2015-04-21 17:05:07,575 INFO  [MASTER_SERVER_OPERATIONS-c2020:16000-0] master.RegionStates: Transition {6eaf51e55c9c23356a697f286f473db8 state=OPEN, ts=1429660996051, server=c2024.halxg.cloudera.com,16020,1429660802192} to {6eaf51e55c9c23356a697f286f473db8 state=OFFLINE, ts=1429661107575, server=c2024.halxg.cloudera.com,16020,1429660802192}
143326 2015-04-21 17:05:07,575 INFO  [MASTER_SERVER_OPERATIONS-c2020:16000-0] master.RegionStates: Transition {1cbe63cd29c7709209adbf4305ebc746 state=OPEN, ts=1429660996062, server=c2024.halxg.cloudera.com,16020,1429660802192} to {1cbe63cd29c7709209adbf4305ebc746 state=OFFLINE, ts=1429661107575, server=c2024.halxg.cloudera.com,16020,1429660802192}
143327 2015-04-21 17:05:07,575 INFO  [MASTER_SERVER_OPERATIONS-c2020:16000-0] master.RegionStates: Transition {3a49d17e189b2a26eb73e1d43cf2d0ac state=OPEN, ts=1429660996053, server=c2024.halxg.cloudera.com,16020,1429660802192} to {3a49d17e189b2a26eb73e1d43cf2d0ac state=OFFLINE, ts=1429661107575, server=c2024.halxg.cloudera.com,16020,1429660802192}
143328 2015-04-21 17:05:07,576 INFO  [MASTER_SERVER_OPERATIONS-c2020:16000-0] handler.ServerShutdownHandler: Reassigning 0 region(s) that c2024.halxg.cloudera.com,16020,1429660802192 was carrying (and 0 regions(s) that were opening on this server)

{code}

... and indeed these regions are never assigned.  I see DLR on occasion timing out like this....

2015-04-22 21:27:31,327 ERROR [RS_LOG_REPLAY_OPS-c2021:16020-1-Writer-0] wal.WALSplitter: Exiting thread

....

Caused by:


Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.NotServingRegionException): org.apache.hadoop.hbase.NotServingRegionException: Region IntegrationTestBigLinkedList,\xB3333333(,1429660019160.8d63312bc39a39727afea627bb20fee4. is not online on c2024.halxg.cloudera.com,16020,1429661908290

... which is one of the regions in the set of OFFLINE but not assigned.

Digging....",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21343,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21324,"When there a few regions, the balancer seems to do a poorish job. My cluster is all out of whack and while the balancer runs, it doesn't do anything. So, I need to configure the balancer to run against large number of regions. There is no doc in reguide to help and there is no logging coming out of the balancer to help either. Let me fix.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21337,"Cluster A-HDP 3.0.0(hadoop3.0, hbase2.0); cluster B-native hadoop2.7, hbase1.2.6. 
I want to replicate a table named T(only one CF named 'f') on cluster A and B with each other, that is, the table T data of A changes will be synchronized to B, and the table T data of B changes will be synchronized to A. I configured repplication both on Cluster A and B for table T using 'add_peer' and 'enable_table_replication' by Hbase shell(firstly A to B,2ndly B to A).Then锛孖 did test in Hbase shell as below,
1.Put a record by typing ""put 'T','r1','f:a','1'"" on A,then Scan table T,it's no problem,the record can be found on both A and B;
2.Put a record by typing ""put 'T','r2','f:a','1'"" on B,no problem,both found on A and B;
3.Put a record by typing ""put 'T','r1','f:a','2'"" to update the value to '2' on A,no problem, updated successfully on both A and B;
4.Put a record by typing ""put 'T','r1','f:a','3'"" to update the value to '3' on B,no problem, updated successfully on both A and B;
5.Put a record by typing ""put 'T','r1','f:a','4'"" to update the value to '4' on A,the problem was coming, there is no update both A and B, that means this 'Put'is not effected,the value is still '3' on A and B although the Hbase shell does not give an error when I 'put'.
6.after about 1 minute, I typing the 'Put' again to update the value to '4' on A, now, it's successful, the value is updated to '4' both on A and B.

May I ask what's the reason? Anything I missed to configure?Thx.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14320,"Our normal Jenkins setup up on builds.apache.org (e.g. [this one|https://builds.apache.org/job/HBase-TRUNK/lastCompletedBuild/testReport/]) makes it easy to get test reports on the latest builds, as well as providing some [pretty history views|https://builds.apache.org/job/HBase-TRUNK/lastCompletedBuild/testReport/history/]. This functionality seems to have been inadvertently broken when we turned the [1.2|https://builds.apache.org/job/HBase-1.2/] and [1.3|https://builds.apache.org/job/HBase-1.3/] jobs into matrix jobs in order to test jdk7 and jdk8 in parallel. Should be an easy fix on the Jenkins side to sort this out...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14198,"After running 

mvn eclipse:eclipse I tried to import projects into Eclipse (Luna) and got multiple build errors, similar to:
{code}
Cannot nest output folder 'hbase-thrift/target/test-classes/META-INF' inside output folder 'hbase-thrift/target/test-classes'	hbase-thrift		
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9725,"to me, seems lost brackets for createMethodTimeMetrics",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-880,"The current API does not scale very well. For each new feature, we have to add many methods to take care of all the overloads. Also, the need to batch row operations (gets, inserts, deletes) implies that we have to manage some ""entities"" like we are able to do with BatchUpdate but not with the other operations. The RowLock should be an attribute of such an entity.

The scope of this jira is only to replace current API with another feature-compatible one, other methods will be added in other issues.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14760,"Over in https://issues.apache.org/jira/browse/HBASE-14758?focusedCommentId=14989134&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14989134 , [~carp84] found that since HBASE-14725, the likes of TestAsyncProcess no longer runs as part of general build.

It seems like any test that gets a category-based timer in that patch no longer runs as part of the build.

The test runs fine if I invoke on cmd-line.

Other category-based timeout tests seem to show in the general build.

Looking....",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21053,"Steps to reproduce are as follows:

1. Create a table with region replication
{code}
create ""test"", ""cf"", \{REGION_REPLICATION => 2}
{code}

2. Load data to the table
{code}
(0...2000).each\{|i| put ""test"", ""row#{i}"", ""cf:col"", ""val""}
{code}

3. Split the table
{code}
split ""test""
{code}

After that, the state of the replica region of the split parent region (info:state_0001) is CLOSING, but the correct state is CLOSED.
{code}
hbase> scan 'hbase:meta', \{FILTER => ""PrefixFilter('test')""}
ROW COLUMN+CELL
 test column=table:state, timestamp=1534271346311, value=\x08\x00
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:regioninfo, timestamp=1534271348477, value={ENCODED => cc6bd353efe820b6a5ede1abfa2b05ec, NAME => 'test,,1534271345843.cc6bd353efe820b6a5ede
 c. 1abfa2b05ec.', STARTKEY => '', ENDKEY => '', OFFLINE => true, SPLIT => true}
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:seqnumDuringOpen, timestamp=1534271346308, value=\x00\x00\x00\x00\x00\x00\x00\x02
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:seqnumDuringOpen_0001, timestamp=1534271346309, value=\x00\x00\x00\x00\x00\x00\x00\x02
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:server, timestamp=1534271346308, value=10.0.1.6:16020
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:server_0001, timestamp=1534271346309, value=10.0.1.6:16020
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:serverstartcode, timestamp=1534271346308, value=1534267943127
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:serverstartcode_0001, timestamp=1534271346309, value=\x00\x00\x01e9~\xE8\xD7
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:sn, timestamp=1534271348271, value=10.0.1.6,16020,1534267943127
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:sn_0001, timestamp=1534271348271, value=10.0.1.6,16020,1534267943127
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:splitA, timestamp=1534271348477, value={ENCODED => fe68bd328e37ab8a9cfa5616d7a5bb14, NAME => 'test,,1534271348168.fe68bd328e37ab8a9cfa5616d
 c. 7a5bb14.', STARTKEY => '', ENDKEY => 'row78'}
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:splitB, timestamp=1534271348477, value={ENCODED => b77c219092dbbe4376d72868099f1386, NAME => 'test,row78,1534271348168.b77c219092dbbe4376d7
 c. 2868099f1386.', STARTKEY => 'row78', ENDKEY => ''}
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:state, timestamp=1534271348436, value=CLOSED
 c.
 test,,1534271345843.cc6bd353efe820b6a5ede1abfa2b05e column=info:state_0001, timestamp=1534271348271, value=CLOSING聽 <-----聽 Wrong state!
 c.
...
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21079,"Go to any table from table.jsp and try compact/split a table region.

Even when the hbase is secure any user can split/compact the table.

The same behavior is not聽 from the hbase shell and work as expected.

聽

聽",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20972,"Call queue size is the currently queued and running Calls bytes size. It gets incremented after we parse a call and before we add it to the queue of calls for the scheduler to use. It get decremented after we have 'run' the Call. 

When setting up a call, total size of it is added. So when a new call can not be dispatched by BlockingQueue full, the call queue size should be decremented. We shouldn't add size of rejected calls to the call queue size.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19329,"
2017-11-16 02:50:33,474 WARN  [blackstone064030,16020,1510632966258_ChoreService_1] quotas.QuotaCache: Unable to read user from quota table
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 3 actions: Table 'hbase:quota' was not found, got: hbase:namespace.: 3 times, servers with issues: null
,
	at org.apache.hadoop.hbase.quotas.QuotaTableUtil.doGet(QuotaTableUtil.java:330)
	at org.apache.hadoop.hbase.quotas.QuotaUtil.fetchUserQuotas(QuotaUtil.java:155)
	at org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore$3.fetchEntries(QuotaCache.java:256)
	at org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore.fetch(QuotaCache.java:290)
	at org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore.fetchUserQuotaState(QuotaCache.java:248)
	at org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore.chore(QuotaCache.java:213)
2017-11-16 02:55:33,453 WARN  [blackstone064030,16020,1510632966258_ChoreService_1] quotas.QuotaCache: Unable to read namespace from quota table
org.apache.hadoop.hbase.TableNotFoundException: Table 'hbase:quota' was not found, got: hbase:namespace.
	at org.apache.hadoop.hbase.quotas.QuotaTableUtil.doGet(QuotaTableUtil.java:330)
	at org.apache.hadoop.hbase.quotas.QuotaUtil.fetchGlobalQuotas(QuotaUtil.java:220)
	at org.apache.hadoop.hbase.quotas.QuotaUtil.fetchNamespaceQuotas(QuotaUtil.java:207)
	at org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore$1.fetchEntries(QuotaCache.java:226)
	at org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore.fetch(QuotaCache.java:290)
	at org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore.fetchNamespaceQuotaState(QuotaCache.java:218)
	at org.apache.hadoop.hbase.quotas.QuotaCache$QuotaRefresherChore.chore(QuotaCache.java:211)
2017-11-16 02:55:33,488 WARN  [blackstone064030,16020,1510632966258_ChoreService_1] quotas.QuotaCache: Unable to read table from quota table
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 47 actions: Table 'hbase:quota' was not found, got: hbase:namespace.: 47 times, servers with issues: nu
ll,",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19025,"MasterProcWALs getting pile up and getting below error in Hmaster log
2017-10-17 03:34:42,141 INFO  [ip-176-0-0-44:16000.activeMasterManager] hdfs.DFSClient: Successfully connected to /176.0.0.29:50010 for BP-1665161556-176.0.
0.44-1498805562805:blk_1073773522_32746
2017-10-17 03:34:42,182 INFO  [ip-176-0-0-44:16000.activeMasterManager] util.FSHDFSUtils: Recover lease on dfs file hdfs://192.168.168.1:9000/hbase2/MasterProcWALs/state-00000000000000005592.log
2017-10-17 03:34:42,182 INFO  [ip-176-0-0-44:16000.activeMasterManager] util.FSHDFSUtils: Recovered lease, attempt=0 on file=hdfs://ec2-34-195-113-113.compu
te-1.amazonaws.com:9000/hbase2/MasterProcWALs/state-00000000000000005592.log after 0ms
2017-10-17 03:34:42,184 WARN  [ip-176-0-0-44:16000.activeMasterManager] hdfs.BlockReaderFactory: I/O error constructing remote block reader.
java.io.IOException: Got error, status message opReadBlock BP-1665161556-176.0.0.44-1498805562805:blk_1073773523_32747 received exception java.io.FileNotFou
ndException: /data/datanode/data/current/BP-1665161556-176.0.0.44-1498805562805/current/finalized/subdir0/subdir123/blk_1073773523_32747.meta (Too many open
 files), for OP_READ_BLOCK, self=/176.0.0.44:59340, remote=/176.0.0.44:50010, for file /hbase2/MasterProcWALs/state-00000000000000005592.log, for pool BP-16
65161556-176.0.0.44-1498805562805 block 1073773523_32747
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20675,"we use [withStopRow|https://hbase.apache.org/2.0/apidocs/org/apache/hadoop/hbase/client/Scan.html#withStopRow-byte:A-boolean-] API to scan a rowkey range [startrow, stoprow], both inclusive, but the server can't return the last row including stoprow, however there is no exception.

For example, the there are the following rows in hbase:

||rowkey||CF+qualifier+value||
|1|{value1}|
|2|{value2}
|3|{value3}|


{code:java}
// Do scan like this
Scan scan = new Scan();
scan.withStartRow(bytes(1), true);
scan.withStopRow(bytes(3), true);
{code}
The result returned only contains the first two rows: 鈥?鈥?and 鈥?鈥? no 鈥?鈥?

Thanks.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20762,"When a precommit run fails due to license issues, we get pointed to a file in our maven logs:

{noformat}
/testptch/hbase/hbase-assembly/target/maven-shared-archive-resources/META-INF/LICENSE
{noformat}

But we don't have that file saved, so we don't know what the actual failure was. So we should save that in our build artifacts. Or maybe we can print a snippet from that file directly into the maven log. Both would be acceptable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18586,"I have 2 HBase tables - one with a single column family, and other has 4 column families. Both tables are keyed by same rowkey, and the column families all have a single column qualifier each, with a json string as value (each json payload is about 10-20K in size). All column families use fast-diff encoding and gzip compression.

After loading about 60MM rows to each table, a scan test on (any) single column family in the 2nd table takes 4x the time to scan the single column family from the 1st table. In both cases, the scanner is bounded by a start and stop key to scan 1MM rows. Performance did not change much even after running a major compaction on both tables.

Though HBase doc and other tech forums recommend not using more than 1 column family per table, nothing I have read so far suggests scan performance will linearly degrade based on number of column families. Has anyone else experienced this, and is there a simple explanation for this?

To note, the reason second table has 4 column families is even though I only scan one column family at a time now, there are requirements to scan multiple column families from that table given a set of rowkeys.

Thanks for any insight into the performance question.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19037,"I'm testing the speed. At the time of the request, I know part of the key.
```
scan 'id_bank', {STARTROW=>""24168557""+""\137"",STOPROW=>""24168557""+""\177"",COLUMNS => ['high', 'low'], BLOCKCACHE => 'true'}
```
When I run the scan, the response returns a short time, and if I make a second request, the answer is already returned quickly, why?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17948,"I have installed HBase (1.2.4) Hadoop(2.7.3) on Master slave multi cluster combination.

Master

/etc/hosts/
127.0.0.1 developer4
192.168.1.149  master 
192.168.1.161  slave

Slave

127.0.0.1  cilm063-ThinkCentre-A58
192.168.1.149   master
192.168.1.161   slave

I have properly installed Hbase and working fine.

When I run the below command then getting following error.



hbase hbck details

ERROR: RegionServer: cilm063-thinkcentre-a58,16020,1492865892520 Unable to fetch region information. java.net.UnknownHostException: cilm063-thinkcentre-a58


Please help me  where I am doing wrong.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19600,Placeholder for myself. Running ITBLL on cluster w/ no chaos fails to complete. We are missing connections. Digging. Cluster is 7 node running 8 tasks of 25M each.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19874,"hbase聽 configure聽 聽 bucketcache锛屄燩roduction environment聽 聽exist聽is not deleted銆?

deleted file聽 number聽reached more than a few hundred锛?and聽Growing銆偮犅燤emory is growing.

$ ll|grep delete
lr-x------ 1 data data 64 Jan 28 14:28 1048 -> /block4/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir247/subdir216/blk_3036141819 (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1050 -> /block4/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir247/subdir216/blk_3036141819_1962457009.meta (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1078 -> /block5/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir247/subdir62/blk_3036102314 (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1079 -> /block7/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir247/subdir95/blk_3036110832 (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1091 -> /block3/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir245/subdir53/blk_3035968976_1962284166.meta (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1092 -> /block9/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir247/subdir97/blk_3036111332 (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1093 -> /block9/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir247/subdir97/blk_3036111332_1962426522.meta (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1096 -> /block5/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir247/subdir62/blk_3036102314_1962417504.meta (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1100 -> /block7/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir247/subdir95/blk_3036110832_1962426022.meta (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1101 -> /block10/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir245/subdir13/blk_3035958550 (deleted)
lr-x------ 1 data data 64 Jan 28 14:28 1102 -> /block10/hadoop/dfs/data/current/BP-1101579887-10.50.64.23-1497104043858/current/finalized/subdir245/subdir13/blk_3035958550_1962273740.meta (deleted)

聽",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19669,"Online HBase services, large requests锛?  hbase version:  1.3.1    hadoop version:  2.7.4   os  linux version: centos6.5

hdfs-site.xml  conf:   
<property>
<name>dfs.client.read.shortcircuit</name>
<value>true</value>
<source>hdfs-site.xml</source>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>/var/run/hadoop-hdfs/dn_socket</value>
<source>hdfs-site.xml</source>
</property>
 
os   linux  command :    netstat -an  

unix  2      [ ACC ]     STREAM     LISTENING     10576083 /var/run/hadoop-hdfs/dn_socket  

*{color:#d04437}problem :    /var/run/hadoop-hdfs/dn_socket   only   one   LISTENING锛? but  no  CONNECTED {color}*",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19800,"while using list command in hbase shell, most of all works well except which one contains 'd' char, as well as hbase program api prefix regex.

eg.聽 list 'd.\*' wont work, but '^d\[\da-f\]\{31\}' works well. and 'd.\*' performs just listing all of the tables.

!image-2018-01-16-12-13-25-723.png!

聽",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19727,"I have started a cluster with 5 RSes, but after only two RSes were online. I've checked one of the logs, it keeps trying to report to the backup HMaster.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18969,"{code}RowFilter(=, 'regexstring:(?s)^.{4}\\Q\xc4\x98\\E.{1}(?:.{6})*\\Q\x00\x00\x0a\x00\x00\x05\\E(?:.{6})*$'){code}

can  match 

{code}\x00\x00\x03Y\xC4\x98\xD0\x00\x00\x0A\x00\x00\x05 column=t:[\xC0\x8C1, timestamp=1507530755374, value={\x00\xE1\x00 {code}

but
{code}RowFilter(=, 'regexstring:(?s)^.{4}\\Q\xc4\\E.{2}(?:.{6})*\\Q\x00\x00\x0a\x00\x00\x05\\E(?:.{6})*$'){code}
can not match",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18947,"Take backup of test1,test2,test3,test11,test12,test13 

and then take backup of only test2

{code}./hbase backup -d create incremental hdfs://localhost:8020/test/ -t test2{code}

It should only backup test2 but it backup all tables once backed up. This can be seen in hdfs as backed up tables and logs show the same : 

Logs show :
2017-09-25 19:29:39,170 DEBUG [main] impl.IncrementalTableBackupClient: For incremental backup, current table set is [test1,test2,test3,test11, test12,test13]

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18074,"HBASE-12751 did this:

{code}
...
         // If we haven't got any rows in our batch, we should block to
         // get the next one.
-        boolean shouldBlock = numReadyToWrite == 0;
         RowLock rowLock = null;
         try {
-          rowLock = getRowLockInternal(mutation.getRow(), shouldBlock);
+          rowLock = getRowLock(mutation.getRow(), true);
         } catch (IOException ioe) {
           LOG.warn(""Failed getting lock in batch put, row=""
             + Bytes.toStringBinary(mutation.getRow()), ioe);
         }
         if (rowLock == null) {
           // We failed to grab another lock
..
{code}

In old codebase, getRowLock with a true meant do not wait on row lock. In the HBASE-12751 codebase, the flag is read/write. So, we get a read lock on every mutation in the batch. If ten mutations in a batch on average, then we'll 10x the amount of locks.

I'm in here because interesting case where increments and batch going into same row seem to backup and stall trying to get locks. Looks like this where all handlers are one of either of the below:

{code}
""RpcServer.FifoWFPBQ.default.handler=190,queue=10,port=60020"" #243 daemon prio=5 os_prio=0 tid=0x00007fbb58691800 nid=0x2d2527 waiting on condition [0x00007fbb4ca49000]
   java.lang.Thread.State: TIMED_WAITING (parking)
  at sun.misc.Unsafe.park(Native Method)
  - parking to wait for  <0x00000007c6001b38> (a java.util.concurrent.locks.ReentrantReadWriteLock$FairSync)
  at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireNanos(AbstractQueuedSynchronizer.java:934)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireNanos(AbstractQueuedSynchronizer.java:1247)
  at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.tryLock(ReentrantReadWriteLock.java:1115)
  at org.apache.hadoop.hbase.regionserver.HRegion.getRowLockInternal(HRegion.java:5171)
  at org.apache.hadoop.hbase.regionserver.HRegion.doIncrement(HRegion.java:7453)
...
{code}

{code}
""RpcServer.FifoWFPBQ.default.handler=180,queue=0,port=60020"" #233 daemon prio=5 os_prio=0 tid=0x00007fbb586ed800 nid=0x2d251d waiting on condition [0x00007fbb4d453000]
   java.lang.Thread.State: TIMED_WAITING (parking)
  at sun.misc.Unsafe.park(Native Method)
  - parking to wait for  <0x0000000354976c00> (a java.util.concurrent.locks.ReentrantReadWriteLock$FairSync)
  at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
  at java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.tryLock(ReentrantReadWriteLock.java:871)
  at org.apache.hadoop.hbase.regionserver.HRegion.getRowLockInternal(HRegion.java:5171)
  at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:3017)
...
{code}

It gets so bad it looks like deadlock but if you give it a while, we move on (I put it down to safe point giving a misleading view on what is happening).

Let me put back the optimization.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20629,"{code:java}
bin/oozied.sh start{code}
聽
{code:java}
Setting up oozie DB

Validate DB Connection
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/util/ReflectionUtils
at org.apache.oozie.service.Services.setServiceInternal(Services.java:377)
at org.apache.oozie.service.Services.<init>(Services.java:111)
at org.apache.oozie.tools.OozieDBCLI.getJdbcConf(OozieDBCLI.java:169)
at org.apache.oozie.tools.OozieDBCLI.createConnection(OozieDBCLI.java:918)
at org.apache.oozie.tools.OozieDBCLI.validateConnection(OozieDBCLI.java:926)
at org.apache.oozie.tools.OozieDBCLI.createDB(OozieDBCLI.java:188)
at org.apache.oozie.tools.OozieDBCLI.run(OozieDBCLI.java:131)
at org.apache.oozie.tools.OozieDBCLI.main(OozieDBCLI.java:79)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.util.ReflectionUtils
at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
... 8 more{code}
{code:java}
/opt/oozie/oozie-5.1.0-SNAPSHOT/bin/oozie-setup.sh sharelib create -fs hdfs://hadoop.example.com:8020 -locallib ~/share/{code}
{code:java}
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/fs/Path
at org.apache.oozie.tools.OozieSharelibCLI.run(OozieSharelibCLI.java:153)
at org.apache.oozie.tools.OozieSharelibCLI.main(OozieSharelibCLI.java:67)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.Path
at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
... 2 more{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19668,"Online HBase services, large requests锛?  hbase version:  1.3.1    hadoop version:  2.7.4   os  linux version: centos6.5

hdfs-site.xml  conf:   
<property>
<name>dfs.client.read.shortcircuit</name>
<value>true</value>
<source>hdfs-site.xml</source>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>/var/run/hadoop-hdfs/dn_socket</value>
<source>hdfs-site.xml</source>
</property>
 
os   linux  command :    netstat -an  

unix  2      [ ACC ]     STREAM     LISTENING     10576083 /var/run/hadoop-hdfs/dn_socket  

*{color:#d04437}problem :    /var/run/hadoop-hdfs/dn_socket   only   one   LISTENING锛? but  no  CONNECTED {color}*",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20696,"{code}
hbase(main):020:0> list_peers
 PEER_ID CLUSTER_KEY ENDPOINT_CLASSNAME REMOTE_ROOT_DIR SYNC_REPLICATION_STATE STATE REPLICATE_ALL NAMESPACES TABLE_CFS BANDWIDTH SERIAL
 1 lg-hadoop-tst-st01.bj:10010,lg-hadoop-tst-st02.bj:10010,lg-hadoop-tst-st03.bj:10010:/hbase/test-hbase-slave nil hdfs://lg-hadoop-tst-st01.bj:20100/hbase/test-hbase-slave/remoteWALs ACTIVE ENABLED false  default.ycsb-test 0 false
1 row(s)
Took 0.0446 seconds                                                                                                    
=> #<Java::JavaUtil::ArrayList:0x43ab9ae9>    ----> It's useless .. 
{code}

Interested contributors are welcome to fix this bug...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20351,"{code}
stack@ve0524:~$ ./hbase/bin/hbase --config conf_hbase shell
2018-04-04 19:58:02,187 DEBUG [main] logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2018-04-04 19:58:02,191 DEBUG [main] util.ResourceLeakDetector: -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
2018-04-04 19:58:02,192 DEBUG [main] util.ResourceLeakDetector: -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
2018-04-04 19:58:02,214 DEBUG [main] internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2018-04-04 19:58:02,215 DEBUG [main] internal.PlatformDependent0: Java version: 8
2018-04-04 19:58:02,216 DEBUG [main] internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2018-04-04 19:58:02,216 DEBUG [main] internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2018-04-04 19:58:02,217 DEBUG [main] internal.PlatformDependent0: java.nio.Buffer.address: available
2018-04-04 19:58:02,217 DEBUG [main] internal.PlatformDependent0: direct buffer constructor: available
2018-04-04 19:58:02,218 DEBUG [main] internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2018-04-04 19:58:02,218 DEBUG [main] internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2018-04-04 19:58:02,218 DEBUG [main] internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2018-04-04 19:58:02,218 DEBUG [main] internal.PlatformDependent: sun.misc.Unsafe: available
2018-04-04 19:58:02,218 DEBUG [main] internal.PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
2018-04-04 19:58:02,218 DEBUG [main] internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2018-04-04 19:58:02,219 DEBUG [main] internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2018-04-04 19:58:02,219 DEBUG [main] internal.PlatformDependent: -Dio.netty.maxDirectMemory: 1073741824 bytes
2018-04-04 19:58:02,219 DEBUG [main] internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2018-04-04 19:58:02,220 DEBUG [main] internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2018-04-04 19:58:02,220 DEBUG [main] util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@7dbae40
2018-04-04 19:58:02,229 DEBUG [main] internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2018-04-04 19:58:02,260 DEBUG [main] channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 96
2018-04-04 19:58:02,282 DEBUG [main] nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2018-04-04 19:58:02,282 DEBUG [main] nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
HBase Shell
Use ""help"" to get list of supported commands.
Use ""exit"" to quit this interactive shell.
Version 2.0.0, r0db342d312784a6663b406fdb0f7b3b3c1fa928d, Mon Apr  2 22:54:56 PDT 2018
Took 0.0028 seconds
hbase(main):001:0>
{code}


Does it each time I run a command



{code}
hbase(main):001:0> describe 'ycsb'
2018-04-04 19:59:00,084 DEBUG [main] buffer.AbstractByteBuf: -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
2018-04-04 19:59:00,084 DEBUG [main] util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@66ab924
2018-04-04 19:59:00,121 DEBUG [main] channel.DefaultChannelId: -Dio.netty.processId: 697 (auto-detected)
2018-04-04 19:59:00,123 DEBUG [main] util.NetUtil: -Djava.net.preferIPv4Stack: true
2018-04-04 19:59:00,123 DEBUG [main] util.NetUtil: -Djava.net.preferIPv6Addresses: false
2018-04-04 19:59:00,124 DEBUG [main] util.NetUtil: Loopback interface: lo (lo, 127.0.0.1)
2018-04-04 19:59:00,125 DEBUG [main] util.NetUtil: /proc/sys/net/core/somaxconn: 128
2018-04-04 19:59:00,125 DEBUG [main] channel.DefaultChannelId: -Dio.netty.machineId: 00:1e:67:ff:fe:c5:54:b4 (auto-detected)
2018-04-04 19:59:00,130 DEBUG [main] internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2018-04-04 19:59:00,131 DEBUG [main] internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2018-04-04 19:59:00,151 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 82
2018-04-04 19:59:00,151 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 10
2018-04-04 19:59:00,151 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2018-04-04 19:59:00,151 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2018-04-04 19:59:00,151 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2018-04-04 19:59:00,152 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.tinyCacheSize: 512
2018-04-04 19:59:00,152 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2018-04-04 19:59:00,152 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2018-04-04 19:59:00,152 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2018-04-04 19:59:00,152 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2018-04-04 19:59:00,152 DEBUG [main] buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2018-04-04 19:59:00,161 DEBUG [main] buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2018-04-04 19:59:00,161 DEBUG [main] buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 65536
2018-04-04 19:59:00,161 DEBUG [main] buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2018-04-04 19:59:00,189 DEBUG [Default-IPC-NioEventLoopGroup-1-1] util.Recycler: -Dio.netty.recycler.maxCapacityPerThread: 32768
2018-04-04 19:59:00,190 DEBUG [Default-IPC-NioEventLoopGroup-1-1] util.Recycler: -Dio.netty.recycler.maxSharedCapacityFactor: 2
2018-04-04 19:59:00,190 DEBUG [Default-IPC-NioEventLoopGroup-1-1] util.Recycler: -Dio.netty.recycler.linkCapacity: 16
2018-04-04 19:59:00,190 DEBUG [Default-IPC-NioEventLoopGroup-1-1] util.Recycler: -Dio.netty.recycler.ratio: 8
Table ycsb is ENABLED
ycsb
COLUMN FAMILIES DESCRIPTION
{NAME => 'family', VERSIONS => '1', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE => 'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'ROW', CACHE_INDEX_ON_WRITE =>
'false', IN_MEMORY => 'false', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE => '65536', METADATA => {'IN_MEMORY_COMPACTION' => 'NONE'}}
1 row(s)
Took 0.6422 seconds
hbase(main):002:0>
{code}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19690,"I use the following command in master branch :
{code}
mvn clean verify install javadoc:aggregate package assembly:single -DskipTests=true -Dmaven.javadoc.skip=true -Dhadoop.profile=3.0
{code}
It fails with the following error:
{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:2.17:check (checkstyle) on project hbase-error-prone: Failed during checkstyle execution: Unable to process suppressions file location: hbase/checkstyle-suppressions.xml: Cannot create file-based resource:invalid distance too far back -> [Help 1]
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19405,"Looks like between branches this is very different.  
In master the client extends the correct exception but it is not called from the StoreScanner.
Looking quickly at 1.4 it does not look to extend the correct exception and it is not called from anywhere. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19331,"when a region split happens on a key with trailing byte equals zero, the end key of the first resulting region and and start key of the second resulting region in meta table gets corrupted.

Here is the link to code to reproduce this issue
https://bitbucket.org/flytxt/hbase-meta-corruption-test
 


*+Test Result+*

[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.flytxt.HbaseRegionMetaTest
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
18:23:54.346 [main] INFO com.flytxt.HbaseRegionMetaTest - Dropping table SAMPLE_TBL_1
18:23:56.094 [main] INFO com.flytxt.HbaseRegionMetaTest - Dropping table SAMPLE_TBL_2
18:23:58.107 [main] INFO com.flytxt.HbaseRegionMetaTest - Creating new table SAMPLE_TBL_1
18:23:58.658 [main] INFO com.flytxt.HbaseRegionMetaTest - Creating new table SAMPLE_TBL_1
18:23:59.212 [main] INFO com.flytxt.HbaseRegionMetaTest - Starting puts to table SAMPLE_TBL_1
18:24:00.046 [main] INFO com.flytxt.HbaseRegionMetaTest - Puts complete .. lets split SAMPLE_TBL_1
18:24:00.500 [main] INFO com.flytxt.HbaseRegionMetaTest - Starting puts to table SAMPLE_TBL_2
18:24:02.073 [main] INFO com.flytxt.HbaseRegionMetaTest - Puts complete .. lets split SAMPLE_TBL_2
18:24:02.753 [main] INFO com.flytxt.HbaseRegionMetaTest - region split complete .. Lets verify region infos for table SAMPLE_TBL_1 
18:24:02.754 [main] INFO com.flytxt.HbaseRegionMetaTest - ===========================================================
18:24:02.754 [main] INFO com.flytxt.HbaseRegionMetaTest - Region Name : SAMPLE_TBL_1,,1511355240515.56c8fd8e42228c3c1ec71f9a4da65f5f.
18:24:02.755 [main] INFO com.flytxt.HbaseRegionMetaTest - Region Id :1511355240515
18:24:02.755 [main] INFO com.flytxt.HbaseRegionMetaTest - Region start key :[]  , Key length :0
18:24:02.755 [main] INFO com.flytxt.HbaseRegionMetaTest - Region end key : [0, 0, 0, 0, 0, 19, -76]  , Key length :7
18:24:02.755 [main] INFO com.flytxt.HbaseRegionMetaTest - -----------------------------------------------------------
18:24:02.762 [main] INFO com.flytxt.HbaseRegionMetaTest - ===========================================================
18:24:02.762 [main] INFO com.flytxt.HbaseRegionMetaTest - Region Name : SAMPLE_TBL_1,\x00\x00\x00\x00\x00\x13\xB4,1511355240515.c06afed17b2a5c4fb54bacf704dd8a9e.
18:24:02.762 [main] INFO com.flytxt.HbaseRegionMetaTest - Region Id :1511355240515
18:24:02.762 [main] INFO com.flytxt.HbaseRegionMetaTest - Region start key :[0, 0, 0, 0, 0, 19, -76]  , Key length :7
18:24:02.763 [main] INFO com.flytxt.HbaseRegionMetaTest - Region end key : []  , Key length :0
18:24:02.763 [main] INFO com.flytxt.HbaseRegionMetaTest - -----------------------------------------------------------
18:24:03.005 [main] INFO com.flytxt.HbaseRegionMetaTest - region split complete .. Lets verify region infos for table SAMPLE_TBL_2 
18:24:03.006 [main] INFO com.flytxt.HbaseRegionMetaTest - ===========================================================
18:24:03.006 [main] INFO com.flytxt.HbaseRegionMetaTest - Region Name : SAMPLE_TBL_2,,1511355242363.0679851100e16aad005c743af618452e.
18:24:03.006 [main] INFO com.flytxt.HbaseRegionMetaTest - Region Id :1511355242363
18:24:03.007 [main] INFO com.flytxt.HbaseRegionMetaTest - Region start key :[]  , Key length :0
18:24:03.008 [main] INFO com.flytxt.HbaseRegionMetaTest - Region end key : [0, 0, 0, 0, 0, 0, 19, -57]  , Key length :8
18:24:03.008 [main] INFO com.flytxt.HbaseRegionMetaTest - -----------------------------------------------------------
18:24:03.008 [main] INFO com.flytxt.HbaseRegionMetaTest - ===========================================================
18:24:03.008 [main] INFO com.flytxt.HbaseRegionMetaTest - Region Name : SAMPLE_TBL_2,\x00\x00\x00\x00\x00\x00\x13\xC7,1511355242363.326b5175036efdeae89f9493b436e114.
18:24:03.008 [main] INFO com.flytxt.HbaseRegionMetaTest - Region Id :1511355242363
18:24:03.008 [main] INFO com.flytxt.HbaseRegionMetaTest - Region start key :[0, 0, 0, 0, 0, 0, 19, -57]  , Key length :8
18:24:03.008 [main] INFO com.flytxt.HbaseRegionMetaTest - Region end key : []  , Key length :0
18:24:03.009 [main] INFO com.flytxt.HbaseRegionMetaTest - -----------------------------------------------------------
[ERROR] Tests run: 3, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 10.777 s <<< FAILURE! - in com.flytxt.HbaseRegionMetaTest
[ERROR] testTableRegionStartAndEndKey[0](com.flytxt.HbaseRegionMetaTest)  Time elapsed: 0.228 s  <<< FAILURE!
java.lang.AssertionError: 
Region end key error for SAMPLE_TBL_1,,1511355240515.56c8fd8e42228c3c1ec71f9a4da65f5f.
Expected: is <8>
     but: was <7>
	at com.flytxt.HbaseRegionMetaTest.testTableRegionStartAndEndKey(HbaseRegionMetaTest.java:170)

[ERROR] testTableRegionStartAndEndKey[0](com.flytxt.HbaseRegionMetaTest)  Time elapsed: 0.23 s  <<< FAILURE!
java.lang.AssertionError: 
Region start key error for SAMPLE_TBL_1,\x00\x00\x00\x00\x00\x13\xB4,1511355240515.c06afed17b2a5c4fb54bacf704dd8a9e.
Expected: is <8>
     but: was <7>
	at com.flytxt.HbaseRegionMetaTest.testTableRegionStartAndEndKey(HbaseRegionMetaTest.java:167)

[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Failures: 
[ERROR] com.flytxt.HbaseRegionMetaTest.testTableRegionStartAndEndKey[0](com.flytxt.HbaseRegionMetaTest)
[ERROR]   Run 1: HbaseRegionMetaTest.testTableRegionStartAndEndKey:170 Region end key error for SAMPLE_TBL_1,,1511355240515.56c8fd8e42228c3c1ec71f9a4da65f5f.
Expected: is <8>
     but: was <7>
[ERROR]   Run 2: HbaseRegionMetaTest.testTableRegionStartAndEndKey:167 Region start key error for SAMPLE_TBL_1,\x00\x00\x00\x00\x00\x13\xB4,1511355240515.c06afed17b2a5c4fb54bacf704dd8a9e.
Expected: is <8>
     but: was <7>
[INFO] 
[INFO] 
[ERROR] Tests run: 2, Failures: 1, Errors: 0, Skipped: 0




  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17901,"Once per several days region server fails to flush a memstore and stops.

April, 8:
{code}
2017-04-08 00:10:57,737 WARN  [MemStoreFlusher.1] regionserver.HStore: Failed flushing store file, retrying num=9
java.io.IOException: ScanWildcardColumnTracker.checkColumn ran into a column actually smaller than the previous column: 
	at org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.checkVersions(ScanWildcardColumnTracker.java:117)
	at org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.match(ScanQueryMatcher.java:464)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:529)
	at org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:119)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:74)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:915)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2271)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2375)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2105)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2067)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1958)
	at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1884)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushOneForGlobalPressure(MemStoreFlusher.java:215)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$600(MemStoreFlusher.java:75)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:244)
	at java.lang.Thread.run(Thread.java:745)
2017-04-08 00:10:57,737 FATAL [MemStoreFlusher.1] regionserver.HRegionServer: ABORTING region server datanode13.webmeup.com,16020,1491573320653: Replay of WAL required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: di_ordinal_tmp,gov.ok.data/browse?page=2&category=Natural%20Resources&limitTo=datasets&tags=ed,1489764397211.9d7ca11018672c4aace7f30c8f4253f3.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2428)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2105)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2067)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1958)
	at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1884)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushOneForGlobalPressure(MemStoreFlusher.java:215)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$600(MemStoreFlusher.java:75)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:244)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: ScanWildcardColumnTracker.checkColumn ran into a column actually smaller than the previous column: 
	at org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.checkVersions(ScanWildcardColumnTracker.java:117)
	at org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.match(ScanQueryMatcher.java:464)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:529)
	at org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:119)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:74)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:915)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2271)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2375)
	... 9 more
{code}

After region server restart it functioned properly for a couple of days.

April, 10:
{code}
2017-04-10 22:36:32,147 WARN  [MemStoreFlusher.0] regionserver.HStore: Failed flushing store file, retrying num=9
java.io.IOException: Non-increasing Bloom keys: de.tina-eicke.blog/category/garten/\x09h after de.uina-eicke.blog/category/fruehling/\x09h
	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.appendGeneralBloomfilter(StoreFile.java:936)
	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.append(StoreFile.java:969)
	at org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:125)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:74)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:915)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2271)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2375)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2105)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2067)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1958)
	at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1884)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$900(MemStoreFlusher.java:75)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 22:36:32,147 FATAL [MemStoreFlusher.0] regionserver.HRegionServer: ABORTING region server datanode13.webmeup.com,16020,1491828707088: Replay of WAL required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: di_ordinal_tmp,de.thschroeer/lmo/lmo.php?action=results&file=archiv/BLW2-2013.l98&endtab=8&st=8&tabtype=2\x09hw,1489764397211.b07eaba657affc2ba29f84b59c672836.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2428)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2105)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2067)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1958)
	at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1884)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$900(MemStoreFlusher.java:75)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Non-increasing Bloom keys: de.tina-eicke.blog/category/garten/\x09h after de.uina-eicke.blog/category/fruehling/\x09h
	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.appendGeneralBloomfilter(StoreFile.java:936)
	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.append(StoreFile.java:969)
	at org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:125)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:74)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:915)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2271)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2375)
	... 9 more 
{code}

April, 13
{code}
2017-04-13 14:06:30,189 WARN  [MemStoreFlusher.1] regionserver.HStore: Failed flushing store file, retrying num=9
java.io.IOException: ScanWildcardColumnTracker.checkColumn ran into a column actually smaller than the previous column: p
        at org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.checkVersions(ScanWildcardColumnTracker.java:117)
        at org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.match(ScanQueryMatcher.java:464)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:529)
        at org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:119)
        at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:74)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:915)
        at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2271)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2375)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2105)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2067)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1958)
        at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1884)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$900(MemStoreFlusher.java:75)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
        at java.lang.Thread.run(Thread.java:745)
2017-04-13 14:06:30,190 INFO  [regionserver/datanode13.webmeup.com/88.99.58.169:16020-longCompactions-1491986731568] compress.CodecPool: Got brand-new decompressor [.gz]
2017-04-13 14:06:30,190 INFO  [regionserver/datanode13.webmeup.com/88.99.58.169:16020-shortCompactions-1491986746336] compress.CodecPool: Got brand-new decompressor [.gz]
2017-04-13 14:06:30,190 FATAL [MemStoreFlusher.1] regionserver.HRegionServer: ABORTING region server datanode13.webmeup.com,16020,1491986730362: Replay of WAL required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: di_ordinal_tmp,net.teleklik.lepavina/citati_izreke/index.php?page=2\x09h,1491054654848.ddb53de0e924251818ac2cb0c07b072f.
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2428)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2105)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2067)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1958)
        at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1884)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$900(MemStoreFlusher.java:75)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: ScanWildcardColumnTracker.checkColumn ran into a column actually smaller than the previous column: p
        at org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.checkVersions(ScanWildcardColumnTracker.java:117)
        at org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.match(ScanQueryMatcher.java:464)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:529)
        at org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:119)
        at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:74)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:915)
        at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2271)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2375)
        ... 9 more
2017-04-13 14:06:30,190 FATAL [MemStoreFlusher.1] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: []
{code}

Table description:
{code}
'di_ordinal_tmp', {TABLE_ATTRIBUTES => {DURABILITY => 'ASYNC_WAL', MAX_FILESIZE => '8589934592'}, {NAME => 'di', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'FAST_DIFF', TTL => '10368000 SECONDS (120 DAYS)', COMPRESSION => 'GZ', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0', METADATA => {'COMPRESSION_COMPACT' => 'GZ'}}
{code}

The table is being populated only using put operations. There has never been any bulk loading into this table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20025,HBASE-20013 addressed flakeyness in branch-2. This issue is about backport for branch-1. The patch on HBASE-20013 and perhaps some portion of HBASE-20020 would help?,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20596,"杩愯鐜(environment)锛歬ubernetes+docker(centos6.9)

杩愯鏈嶅姟锛坰ervices锛夛細

hadoop锛?.7锛?zk(3.4.6)+hbase(1.1.2)

閰嶇疆淇℃伅(conf):

1銆佷笉鍩轰簬hosts鏂囦欢鍋氫富鏈哄悕瑙ｆ瀽锛坣o /etc/hosts锛夛紝浣跨敤kube-dns瑙ｆ瀽涓绘満鍚?

2銆乭base-site.xml 濡備笅

!image-2018-05-17-10-11-30-540.png!

3銆乺egionservers鏂囦欢濡備笅

!image-2018-05-17-10-13-38-856.png!

4銆乺egionserver 鍚姩log 鎵撳嵃ERROR锛屼絾鏄惎鍔ㄦ垚鍔?

!image-2018-05-17-10-14-08-046.png!

4銆乄ebUI鏄剧ず寮傚父锛堝浜嗕竴鍊嶇殑regionserver锛?

!image-2018-05-17-10-14-40-134.png!

聽

聽

5銆乭base shell 寮傚父

!image-2018-05-17-10-15-12-225.png!

6銆侀噸鍚痳egionserver鍚庯紝log涓?涓婅堪寮傚父渚濈劧瀛樺湪锛屼絾鏄痺ebUI姝ｅ父锛宻hell client姝ｅ父

!image-2018-05-17-10-15-52-051.png!

聽

聽

!image-2018-05-17-10-16-01-313.png!

聽

聽",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20339,"Our program analyzer has detected a potential security issue as follows聽
{code:java}
PrintWriter out = ServletUtil.initHTML(response, ""Log Level"");
String logName = ServletUtil.getParameter(request, ""log"");
String level = ServletUtil.getParameter(request, ""level"");

if (logName != null) {
   out.println(""<br /><hr /><h3>Results</h3>"");
   out.println(MARKER
        + ""Submitted Log Name: <b>"" + logName + ""</b><br />"");
  ...
}{code}
Above is the code piece. Seems that the log name is directly collected from the web request, and only whether the data is null is checked. So an attacker may provide a ""logName"" with a piece of injected code, leading to cross-site attacks. And besides, the variable ""level"" may also have such vulnerability.

聽

(org.apache.hadoop.hbase.http.log.LogLevel.java Line 111/118)

Linkage to the code is here:

[https://github.com/apache/hbase/blob/9e9b347d667e1fc6165c9f8ae5ae7052147e8895/hbase-http/src/main/java/org/apache/hadoop/hbase/http/log/LogLevel.java#L111]

聽

SourceBrella inc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17889,"We run into one case with read-replica, when the server hosting the primary region is shutdown, we see Get did not go to replica region and it paused for about 50 seconds before Get was resumed. 

More debugging finds out that when the server is down, one of the threads was stuck at the write, it holds lock at 
https://github.com/apache/hbase/blob/branch-1.3/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClientImpl.java#L916.
The later write threads were waiting on this lock until all threads in the connection's thread pool were stuck on this lock. At that moment, no work will be done. After socket write times out, it frees up all threads and it continues.

When QueueingFuture#cancel() is called, it does not interrupt the working thread and return the thread to the pool.

Attaching the jstack trace.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20436,"Saw the following compilation error in hbase-spark-it module:
{code}
[ERROR] COMPILATION ERROR :
[INFO] -------------------------------------------------------------
[ERROR] /hbase/hbase-spark-it/src/test/java/org/apache/hadoop/hbase/spark/IntegrationTestSparkBulkLoad.java:[638,10] abstract method processOptions(org.apache.hbase.thirdparty.org.apache.commons.cli.CommandLine) in org.apache.hadoop.hbase.util.AbstractHBaseTool cannot be accessed directly
{code}
The processOptions method of AbstractHBaseTool is abstract.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17891,"As it stayed in the API document, the the result in the postScannerNext() to return to the client, can be modified. How can I do this in the java code? Thanks a lot.

Best regards,
land Li",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20028,"{noformat}
2018-02-20 16:36:41,794 ERROR [Thread-85] assignment.AssignmentManager: java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.hadoop.hbase.util.VersionInfo.compareVersion(VersionInfo.java:122)
	at org.apache.hadoop.hbase.master.assignment.AssignmentManager.lambda$getExcludedServersForSystemTable$5(AssignmentManager.java:1860)
	at java.util.Collections.max(Collections.java:712)
	at org.apache.hadoop.hbase.master.assignment.AssignmentManager.getExcludedServersForSystemTable(AssignmentManager.java:1859)
	at org.apache.hadoop.hbase.master.assignment.AssignmentManager.lambda$checkIfShouldMoveSystemRegionAsync$0(AssignmentManager.java:464){noformat}
Looks like a race condition around an RS losing its ZK lock. If AM tries to see if it should move a Region to a server who we've seen that the lock was lost but the RS hasn't yet been processed as ""dead"", we can get into a situation where {{HMaster.getRegionServerVersion()}} returns null and causes this to fail.

Looks like a simple filter on the servers to preclude null versions would fix the problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19305,"when i alter hbase ttl, i found the alter cannot success for more than one day, the table size is not large  enough.
The the table size is : 303.6 G  /hbase/data/default/SqlMetaData_Ver2
The alter begin time is :
2017-11-17 15:14:22,128
but util 2017-11-20 18:00, the alter action has not been completed,so I do not know what went wrong ?
Someone can help me? Thank you very much!",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18366,"It worked for a few days after enabling it with HBASE-18278. But started failing after commits:

6786b2b
68436c9
75d2eca
50bb045
df93c13

It works with one commit before: c5abb6c. Need to see what changed with those commits.

Currently it fails with TableNotFoundException.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19872,"hbase 1.3.1聽 regionserver聽 crash ,聽 configure bucketcache.

error log :

聽FATAL [RpcServer.FifoWFPBQ.default.handler=42,queue=2,port=16020] regionserver.RSRpcServices: Run out of memory; RSRpcServices will abort itself immediately

聽

聽hbase-env.sh:

export HBASE_REGIONSERVER_OPTS=""-XX:+UseG1GC -XX:+UnlockExperimentalVMOptions -Xmx24g -Xms24g -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=512M -XX:MaxGCPauseMillis=100 -XX:G1NewSizePercent=5 -XX:ConcGCThreads=4 -XX:ParallelGCThreads=16 -XX:-ResizePLAB -XX:+ParallelRefProcEnabled -XX:InitiatingHeapOccupancyPercent=65 -XX:G1HeapRegionSize=32M -XX:G1MixedGCCountTarget=64 -XX:G1OldCSetRegionThresholdPercent=5 -XX:MaxTenuringThreshold=1 -XX:MaxDirectMemorySize=28g -XX:ReservedCodeCacheSize=512M -XX:+DisableExplicitGC -Xloggc:${HBASE_LOG_DIR}/regionserver.gc.log""

聽

hbase-site.xml:

聽

<property>
 聽聽聽聽聽 <name>hbase.bucketcache.combinedcache.enabled</name>
 聽聽聽聽聽 <value>true</value>
 聽聽聽 </property>
 聽聽 聽<property>
 聽聽聽 聽聽 <name>hbase.bucketcache.ioengine</name>
 聽 聽聽聽聽 <value>offheap</value>
 聽聽聽 </property>
 <property>
 聽聽聽聽 聽 <name>hbase.bucketcache.size</name>
 聽 聽聽聽聽 <value>25600</value>
 聽聽聽 </property>
 聽聽 聽<property>
 聽聽 聽聽 聽<name>hbase.bucketcache.writer.queuelength</name>
 聽聽聽聽聽 <value>64</value>
 聽聽 聽</property>
 聽聽聽 <property>
 聽聽聽聽聽 <name>hbase.bucketcache.writer.threads</name>
 聽聽聽聽聽 <value>3</value>
 聽聽聽 </property>
 <property>
 <name>hfile.block.cache.size</name>
 <value>0.3</value>
 </property>

聽",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18198,"If null ACLs are passed then zk node creation fails with NPE
{code}
java.lang.NullPointerException
	at org.apache.zookeeper.server.PrepRequestProcessor.removeDuplicates(PrepRequestProcessor.java:1301)
	at org.apache.zookeeper.server.PrepRequestProcessor.fixupACL(PrepRequestProcessor.java:1341)
	at org.apache.zookeeper.server.PrepRequestProcessor.pRequest2Txn(PrepRequestProcessor.java:519)
	at org.apache.zookeeper.server.PrepRequestProcessor.pRequest(PrepRequestProcessor.java:1126)
	at org.apache.zookeeper.server.PrepRequestProcessor.run(PrepRequestProcessor.java:178)
{code}

Below APIs have problem.
{code}
public void create(final String path, byte data[], List<ACL> acl,
            CreateMode createMode, StringCallback cb, Object ctx)

public void create(final String path, byte data[], List<ACL> acl,
            CreateMode createMode, Create2Callback cb, Object ctx)
{code}

Solution:  Need to handle NULL acl in removeDuplicates method in server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19585,"Testing, RS crashes soon after startup with below cryptic mess. This is the branch-2 started over a 0.98 data. [~Apache9] You have a clue sir?

{code}
595126 2017-12-21 13:09:38,058 INFO  [regionserver/ve0528.halxg.cloudera.com/10.17.240.22:16020] wal.AbstractFSWAL: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, prefi       x=ve0528.halxg.cloudera.com%2C16020%2C1513890565537, suffix=, logDir=hdfs://ve0524.halxg.cloudera.com:8020/hbase/WALs/ve0528.halxg.cloudera.com,16020,1513890565537, archiv       eDir=hdfs://ve0524.halxg.cloudera.com:8020/hbase/oldWALs
595127 2017-12-21 13:09:38,107 ERROR [regionserver/ve0528.halxg.cloudera.com/10.17.240.22:16020] regionserver.HRegionServer: ***** ABORTING region server ve0528.halxg.cloudera.co       m,16020,1513890565537: Unhandled: Bad type on operand stack
595128 Exception Details:
595129   Location:
595130     org/apache/hadoop/hdfs/protocolPB/PBHelperClient.convert(Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$ContentSummaryProto;)Lorg/apache/hadoop/fs/ContentSummary; @       98: invokestatic
595131   Reason:
595132     Type 'org/apache/hadoop/fs/ContentSummary$Builder' (current frame, stack[1]) is not assignable to 'org/apache/hadoop/fs/QuotaUsage$Builder'
595133   Current Frame:
595134     bci: @98
595135     flags: { }
595136     locals: { 'org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$ContentSummaryProto', 'org/apache/hadoop/fs/ContentSummary$Builder' }
595137     stack: { 'org/apache/hadoop/hdfs/protocol/proto/HdfsProtos$StorageTypeQuotaInfosProto', 'org/apache/hadoop/fs/ContentSummary$Builder' }
595138   Bytecode:
595139     0x0000000: 2ac7 0005 01b0 bb03 3159 b703 324c 2b2a
595140     0x0000010: b603 33b6 0334 2ab6 0335 b603 362a b603
595141     0x0000020: 37b6 0338 2ab6 0339 b603 3a2a b603 3bb6
595142     0x0000030: 033c 2ab6 033d b603 3e2a b603 3fb6 0340
595143     0x0000040: 2ab6 0341 b603 422a b603 43b6 0344 2ab6
595144     0x0000050: 0345 b603 4657 2ab6 0347 9900 0b2a b603
595145     0x0000060: 482b b803 492b b603 4ab0
595146   Stackmap Table:
595147     same_frame(@6)
595148     append_frame(@101,Object[#2126])
595149  *****
{code}

2.8.2 hadoop.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19294,"when create table failed in execute phase master is getting aborted.

DEBUG [RpcServer.FifoWFPBQ.default.handler=8,queue=3,port=16000] ipc.RpcServer: RpcServer.FifoWFPBQ.default.handler=8,queue=3,port=16000: callId: 443 service: MasterService methodName: ListTableDescriptorsByNamespace size: 51 connection: 
java.io.InterruptedIOException: Retry interrupted

java.lang.RuntimeException: HMaster Aborted
        at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:239)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:137)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:3207)


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16298,"For policy/compliance reasons, we removed the tests jars from lib/ directory on HBase Master. Everything was working fine from 1.0 to 1.1.3.

When I upgraded from 1.1.3 to 1.1.5, the /master-status page started to return an error 500: {{java.lang.IllegalArgumentException: Failed to load ESAPI.properties as a classloader resource.}}

After some search, I found out that ESAPI has been added following HBASE-15122 which also added the ESAPI.properties files into src/main/resources.

However, it seems an exclusion has been put on packaging: the file is absent from hbase-server-1.1.5.jar, but present in hbase-server-1.1.5-tests.jar, which is in the lib/ directory in the tar.gz distribution.

Our workaround is to deploy back hbase-server-1.1.5-tests.jar in lib/. However, it does not seem right to require tests jar to have HBase master propertly work.

Even if it is the current HBase policy to keep those jars, I think the hbase-server.jar should contain ESAPI.properties.

The same thing applies for 1.2 branch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16170,"Hello HBase Team,

I am facing hanging problem while building ""Phoenix4.4-HBase1.1"" on RHEL 7.2 ppc64le which is dependent on HBase.

I am having IOP setup done with environment setup as open jdk 1.8 and maven 3.3.9, Hbase 1.1.1 installed and IOP hadoop services with ambari running on it.

When I build ""Phoenix4.4-HBase 1.1"" than there occurs hang at below point without any error logs, hanging occurs each time at different points.
For 1st build, below are the lines where hang up occurs for infinite time:
i.e. Running org.apache.hadoop.hbase.regionserver.PhoenixRpcSchedulerFactoryTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.017 sec - in org.apache.hadoop.hbase.regionserver.PhoenixRpcSchedulerFactoryTest

2nd time when I build,hang up occurs at different point. It is suspected to be HBase issue.

Team: Can you please help us in this and let us know the reason for hanging. Thank You.

Thanks & Regards,
Sonali Shrivastava

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16439,"Some rows is missing when put them into a table using mutateRow method and each row has thousands of columns. The code excerpt:
{code}
try (HConnection hc = HConnectionManager.createConnection(conf)) {
	try (HTableInterface table = hc.getTable(tableName)) {
		final LocalDate startDate = LocalDate.of(1980, 01, 01); 
		for (int i = 0; i < 15000; i++) {
			byte[] row = Bytes.toBytes(Integer.toString(i));

			long ts = System.currentTimeMillis();
			Put put = new Put(row, ts + 1);
			LocalDate date = startDate; 
			for (int j = 0; j < 5000; j++) {
				put.add(
					family,
					Bytes.toBytes(DateTimeFormatter.BASIC_ISO_DATE.format(date)),
					Bytes.toBytes(Integer.toString(j))
				);
				date = date.plusDays(1);
			}
			
			RowMutations rm = new RowMutations(row);

			rm.add(put);
			
			table.mutateRow(rm);
		}
	}
}
{code}
Resulting number of rows varies - sometimes it 200, sometimes it 8000. But never expected 15000.
The full code of test application is attached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13566,"As hbase run MetaLogRoller thread for writting meta hlog, I got below error

ERROR [RS_OPEN_META-xxx:60020-0-MetaLogRoller] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: Failing write. Tried pipeline recovery 5 times without success.
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:918)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)
2015-04-25 19:52:05,463 ERROR [RS_OPEN_META-host152:60020-0-MetaLogRoller] wal.FSHLog: Failed close of HLog writer
java.io.IOException: Failing write. Tried pipeline recovery 5 times without success.
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:918)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)
2015-04-25 19:52:05,463 FATAL [RS_OPEN_META-host152:60020-0-MetaLogRoller] regionserver.HRegionServer: ABORTING region server host152,60020,1429927886571: Failed log close in log roller
org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException: #1429959124806
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.cleanupCurrentWriter(FSHLog.java:777)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:565)
        at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:97)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failing write. Tried pipeline recovery 5 times without success.
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:918)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)

note:
I hava checked namenode log, there is no error,just close the write socket
and hadoop and hbase file is all fine",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14019,"hbase-0.98.9-hadoop2/bin/hbase org.apache.hadoop.hbase.mapreduce.Import item_restore /data/item_backup 
Fails with numerous RetriesExhaustedException

The export process eg "" hbase-0.98.9-hadoop2/bin/hbase org.apache.hadoop.hbase.mapreduce.Export item /data/item_backup ""
works flawlessly and the file item_backup is created import of the same file to a table of a different name, fails.

Please see attached job log",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14018,"+ Pseudo-distributed Hadoop (2.6.0), ZK_HBASE_MANAGE = true (1 master, 1 regionserver).
+ Put data to OpenTSDB, 1000 records / s, for 2000 seconds.
+ RegionServer is aborted.

=== RegionServer logs ===
2015-07-03 16:37:37,332 INFO  [LruBlockCacheStatsExec",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14180,"HBase keeps throwing a timeout exception I have tryed every configuration I could think about to increase it.

Partial stacktrace:
{quote}
Caused by: java.io.IOException: Call to hdp-w-1.c.dks-hadoop.internal/10.240.2.235:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=43, waitTime=60001, operationTimeout=60000 expired.
        at org.apache.hadoop.hbase.ipc.RpcClientImpl.wrapException(RpcClientImpl.java:1242)
        at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1210)
        at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
        at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:32651)
        at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:213)
        at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:62)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:369)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:343)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:126)
        ... 4 more
Caused by: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=43, waitTime=60001, operationTimeout=60000 expired.
        at org.apache.hadoop.hbase.ipc.Call.checkAndSetTimeout(Call.java:70)
        at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1184)
        ... 13 more
{quote}

I've tryed editing config files and also setting config in Ambari with the next keys to increase the timeout with no success:
- hbase.rpc.timeout
- dfs.socket.timeout
- dfs.client.socket-timeout
- zookeeper.session.timeout

Also the Phoenix properties, but I think it's mostly an HBase issue:
- phoenix.query.timeoutMs
- phoenix.query.keepAliveMs

Full stack trace: 
{quote}
Error: Encountered exception in sub plan [0] execution. (state=,code=0)
java.sql.SQLException: Encountered exception in sub plan [0] execution.
        at org.apache.phoenix.execute.HashJoinPlan.iterator(HashJoinPlan.java:157)
        at org.apache.phoenix.jdbc.PhoenixStatement$1.call(PhoenixStatement.java:251)
        at org.apache.phoenix.jdbc.PhoenixStatement$1.call(PhoenixStatement.java:241)
        at org.apache.phoenix.call.CallRunner.run(CallRunner.java:53)
        at org.apache.phoenix.jdbc.PhoenixStatement.executeQuery(PhoenixStatement.java:240)
        at org.apache.phoenix.jdbc.PhoenixStatement.execute(PhoenixStatement.java:1250)
        at sqlline.Commands.execute(Commands.java:822)
        at sqlline.Commands.sql(Commands.java:732)
        at sqlline.SqlLine.dispatch(SqlLine.java:808)
        at sqlline.SqlLine.begin(SqlLine.java:681)
        at sqlline.SqlLine.start(SqlLine.java:398)
        at sqlline.SqlLine.main(SqlLine.java:292)
Caused by: org.apache.phoenix.exception.PhoenixIOException: org.apache.phoenix.exception.PhoenixIOException: Failed after attempts=36, exceptions:
Mon Aug 03 16:47:06 UTC 2015, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=60303: row '' on table 'hive_post_topics' at region=hive_post_topics,,1438084107396.cdbdc246ff0b7dfed31d481e0bccd2b5., hostname=hdp-w-1.c.dks-hadoop.internal,16020,1438619912282, seqNum=45322

        at org.apache.phoenix.util.ServerUtil.parseServerException(ServerUtil.java:108)
        at org.apache.phoenix.iterate.BaseResultIterators.getIterators(BaseResultIterators.java:542)
        at org.apache.phoenix.iterate.RoundRobinResultIterator.getIterators(RoundRobinResultIterator.java:176)
        at org.apache.phoenix.iterate.RoundRobinResultIterator.next(RoundRobinResultIterator.java:91)
        at org.apache.phoenix.join.HashCacheClient.serialize(HashCacheClient.java:106)
        at org.apache.phoenix.join.HashCacheClient.addHashCache(HashCacheClient.java:82)
        at org.apache.phoenix.execute.HashJoinPlan$HashSubPlan.execute(HashJoinPlan.java:339)
        at org.apache.phoenix.execute.HashJoinPlan$1.call(HashJoinPlan.java:136)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at org.apache.phoenix.job.JobManager$InstrumentedJobFutureTask.run(JobManager.java:172)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.concurrent.ExecutionException: org.apache.phoenix.exception.PhoenixIOException: Failed after attempts=36, exceptions:
Mon Aug 03 16:47:06 UTC 2015, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=60303: row '' on table 'hive_post_topics' at region=hive_post_topics,,1438084107396.cdbdc246ff0b7dfed31d481e0bccd2b5., hostname=hdp-w-1.c.dks-hadoop.internal,16020,1438619912282, seqNum=45322

        at java.util.concurrent.FutureTask.report(FutureTask.java:122)
        at java.util.concurrent.FutureTask.get(FutureTask.java:202)
        at org.apache.phoenix.iterate.BaseResultIterators.getIterators(BaseResultIterators.java:538)
        ... 11 more
Caused by: org.apache.phoenix.exception.PhoenixIOException: Failed after attempts=36, exceptions:
Mon Aug 03 16:47:06 UTC 2015, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=60303: row '' on table 'hive_post_topics' at region=hive_post_topics,,1438084107396.cdbdc246ff0b7dfed31d481e0bccd2b5., hostname=hdp-w-1.c.dks-hadoop.internal,16020,1438619912282, seqNum=45322

        at org.apache.phoenix.util.ServerUtil.parseServerException(ServerUtil.java:108)
        at org.apache.phoenix.iterate.ScanningResultIterator.next(ScanningResultIterator.java:56)
        at org.apache.phoenix.iterate.TableResultIterator.next(TableResultIterator.java:104)
        at org.apache.phoenix.iterate.LookAheadResultIterator$1.advance(LookAheadResultIterator.java:47)
        at org.apache.phoenix.iterate.LookAheadResultIterator.init(LookAheadResultIterator.java:59)
        at org.apache.phoenix.iterate.LookAheadResultIterator.peek(LookAheadResultIterator.java:73)
        at org.apache.phoenix.iterate.ParallelIterators$1.call(ParallelIterators.java:97)
        at org.apache.phoenix.iterate.ParallelIterators$1.call(ParallelIterators.java:85)
        ... 5 more
Caused by: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:
Mon Aug 03 16:47:06 UTC 2015, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=60303: row '' on table 'hive_post_topics' at region=hive_post_topics,,1438084107396.cdbdc246ff0b7dfed31d481e0bccd2b5., hostname=hdp-w-1.c.dks-hadoop.internal,16020,1438619912282, seqNum=45322

        at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.throwEnrichedException(RpcRetryingCallerWithReadReplicas.java:271)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:223)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:61)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
        at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)
        at org.apache.hadoop.hbase.client.ClientScanner.loadCache(ClientScanner.java:403)
        at org.apache.hadoop.hbase.client.ClientScanner.next(ClientScanner.java:364)
        at org.apache.phoenix.iterate.ScanningResultIterator.next(ScanningResultIterator.java:50)
        ... 11 more
Caused by: java.net.SocketTimeoutException: callTimeout=60000, callDuration=60303: row '' on table 'hive_post_topics' at region=hive_post_topics,,1438084107396.cdbdc246ff0b7dfed31d481e0bccd2b5., hostname=hdp-w-1.c.dks-hadoop.internal,16020,1438619912282, seqNum=45322
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:159)
        at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:64)
        ... 3 more
Caused by: java.io.IOException: Call to hdp-w-1.c.dks-hadoop.internal/10.240.2.235:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=43, waitTime=60001, operationTimeout=60000 expired.
        at org.apache.hadoop.hbase.ipc.RpcClientImpl.wrapException(RpcClientImpl.java:1242)
        at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1210)
        at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
        at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:32651)
        at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:213)
        at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:62)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:369)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:343)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:126)
        ... 4 more
Caused by: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=43, waitTime=60001, operationTimeout=60000 expired.
        at org.apache.hadoop.hbase.ipc.Call.checkAndSetTimeout(Call.java:70)
        at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1184)
        ... 13 more
{quote}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15966,"In a YARN job, I am creating HFiles with code that has been cribbed from the TableOutputFormat class and bulkloading them with LoadIncrementalHFiles.doBulkLoad.

On other clusters, where fs.defaultFS is set to an hdfs: URI, and my HFiles are placed in an hdfs: URI, the bulkload works as intended.

On this particular cluster, where fs.defaultFS is set to a wasb: URI and my HFiles are placed in a wasb: URI, the bulkload also works as intended.

However, on this same cluster, whenever I place the HFiles in an hdfs: URI, I get the following logs in my application from the HBase client logging repeatedly:

[02 Jun 23:23:26.002](20259/140062246807296) Info2:org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://[my cluster]/[my path] first=\x00\x00\x11\x06 last=;\x8B\x85\x18
[02 Jun 23:23:26.002](20259/140062245754624) Info3:org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles: Going to connect to server region=[my namespace]:[my table],,1464909723920.00eafdb73989312bd8864f0913255f50., hostname=10.0.1.6,16020,1464698786237, seqNum=2 for row  with hfile group [{[B@4d0409e7,hdfs://[my cluster]/[my path]}]
[02 Jun 23:23:26.012](20259/140062245754624) Info1:org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles: Attempt to bulk load region containing  into table [my namespace]:[my table] with files [family:[my family] path:hdfs://[my cluster]/[my path]] failed.  This is recoverable and they will be retried.
[02 Jun 23:23:26.019](20259/140061634982912) Info2:org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles: Split occured while grouping HFiles, retry attempt 2 with 1 files remaining to group or split

And when I look at the appropriate region server's log, I find the following exception repeatedly:

2016-06-02 20:22:50,771 ERROR [B.DefaultRpcServer.handler=22,queue=2,port=16020] access.SecureBulkLoadEndpoint: Failed to complete bulk load
java.io.FileNotFoundException: File doesn't exist: hdfs://[my cluster]/[my path]      at org.apache.hadoop.fs.azure.NativeAzureFileSystem.setPermission(NativeAzureFileSystem.java:2192)
       at org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$1.run(SecureBulkLoadEndpoint.java:280)
       at org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$1.run(SecureBulkLoadEndpoint.java:270)
       at java.security.AccessController.doPrivileged(Native Method)
       at javax.security.auth.Subject.doAs(Subject.java:356)
       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1651)
       at org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.secureBulkLoadHFiles(SecureBulkLoadEndpoint.java:270)
       at org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos$SecureBulkLoadService.callMethod(SecureBulkLoadProtos.java:4631)
       at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:6986)
       at org.apache.hadoop.hbase.regionserver.HRegionServer.execServiceOnRegion(HRegionServer.java:3456)
       at org.apache.hadoop.hbase.regionserver.HRegionServer.execService(HRegionServer.java:3438)
       at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29998)
       at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2080)
       at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
       at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
       at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
       at java.lang.Thread.run(Thread.java:745)

Looking at the appropriate code in SecureBulkLoadEndpoint.java, I'm finding the following:

        public Boolean run() {
          FileSystem fs = null;
         try {
            Configuration conf = env.getConfiguration();
            fs = FileSystem.get(conf);
            for(Pair<byte[], String> el: familyPaths) {
              Path p = new Path(el.getSecond());
              Path stageFamily = new Path(bulkToken, Bytes.toString(el.getFirst()));
              if(!fs.exists(stageFamily)) {
                fs.mkdirs(stageFamily);
                fs.setPermission(stageFamily, PERM_ALL_ACCESS);
              }
            }


The call to FileSystem.get is obviously the culprit, since it gets the FileSystem object based on fs.defaultFS, which is suboptimal in this case and other cases where the HFiles are located on a different type of filesystem than the defaultFS.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15681,"Unable to read remote HBase tables from a local java Client due to a timeOut error. Seeing the following error:

java.io.IOException: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:
Wed Apr 20 10:32:43 WEST 2016, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=75181: row 'pentaho_mappings,,' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=localhost,16020,1461071963695, seqNum=0


	at com.pentaho.big.data.bundles.impl.shim.hbase.table.HBaseTableImpl.exists(HBaseTableImpl.java:71)

	at org.pentaho.big.data.kettle.plugins.hbase.mapping.MappingAdmin.getMappedTables(MappingAdmin.java:502)

	at org.pentaho.big.data.kettle.plugins.hbase.output.HBaseOutputDialog.setupMappedTableNames(HBaseOutputDialog.java:818)

	at org.pentaho.big.data.kettle.plugins.hbase.output.HBaseOutputDialog.access$900(HBaseOutputDialog.java:88)

	at org.pentaho.big.data.kettle.plugins.hbase.output.HBaseOutputDialog$7.widgetSelected(HBaseOutputDialog.java:398)

	at org.eclipse.swt.widgets.TypedListener.handleEvent(Unknown Source)

	at org.eclipse.swt.widgets.EventTable.sendEvent(Unknown Source)

	at org.eclipse.swt.widgets.Widget.sendEvent(Unknown Source)

	at org.eclipse.swt.widgets.Display.runDeferredEvents(Unknown Source)

	at org.eclipse.swt.widgets.Display.readAndDispatch(Unknown Source)

	at org.pentaho.big.data.kettle.plugins.hbase.output.HBaseOutputDialog.open(HBaseOutputDialog.java:603)

	at org.pentaho.di.ui.spoon.delegates.SpoonStepsDelegate.editStep(SpoonStepsDelegate.java:125)

	at org.pentaho.di.ui.spoon.Spoon.editStep(Spoon.java:8783)

	at org.pentaho.di.ui.spoon.trans.TransGraph.editStep(TransGraph.java:3072)

	at org.pentaho.di.ui.spoon.trans.TransGraph.mouseDoubleClick(TransGraph.java:755)

	at org.eclipse.swt.widgets.TypedListener.handleEvent(Unknown Source)

	at org.eclipse.swt.widgets.EventTable.sendEvent(Unknown Source)

	at org.eclipse.swt.widgets.Widget.sendEvent(Unknown Source)

	at org.eclipse.swt.widgets.Display.runDeferredEvents(Unknown Source)

	at org.eclipse.swt.widgets.Display.readAndDispatch(Unknown Source)

	at org.pentaho.di.ui.spoon.Spoon.readAndDispatch(Spoon.java:1347)

	at org.pentaho.di.ui.spoon.Spoon.waitForDispose(Spoon.java:7989)

	at org.pentaho.di.ui.spoon.Spoon.start(Spoon.java:9269)

	at org.pentaho.di.ui.spoon.Spoon.main(Spoon.java:662)

	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)

	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)

	at java.lang.reflect.Method.invoke(Unknown Source)

	at org.pentaho.commons.launcher.Launcher.main(Launcher.java:92)

Caused by: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:
Wed Apr 20 10:32:43 WEST 2016, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=75181: row 'pentaho_mappings,,' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=localhost,16020,1461071963695, seqNum=0


	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.throwEnrichedException(RpcRetryingCallerWithReadReplicas.java:270)

	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:225)

	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:63)

	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)

	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)

	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)

	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:161)

	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:156)

	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:888)

	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:601)

	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:365)

	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:310)

	at org.pentaho.hadoop.hbase.factory.HBase10Admin.tableExists(HBase10Admin.java:41)

	at org.pentaho.hbase.shim.common.CommonHBaseConnection.tableExists(CommonHBaseConnection.java:206)

	at org.pentaho.hbase.shim.common.HBaseConnectionImpl.access$801(HBaseConnectionImpl.java:35)

	at org.pentaho.hbase.shim.common.HBaseConnectionImpl$9.call(HBaseConnectionImpl.java:185)

	at org.pentaho.hbase.shim.common.HBaseConnectionImpl$9.call(HBaseConnectionImpl.java:181)

	at org.pentaho.hbase.shim.common.HBaseConnectionImpl.doWithContextClassLoader(HBaseConnectionImpl.java:76)

	at org.pentaho.hbase.shim.common.HBaseConnectionImpl.tableExists(HBaseConnectionImpl.java:181)

	at com.pentaho.big.data.bundles.impl.shim.hbase.HBaseConnectionWrapper.tableExists(HBaseConnectionWrapper.java:72)

	at com.pentaho.big.data.bundles.impl.shim.hbase.table.HBaseTableImpl.exists(HBaseTableImpl.java:69)

	... 28 more

Caused by: java.net.SocketTimeoutException: callTimeout=60000, callDuration=75181: row 'pentaho_mappings,,' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=localhost,16020,1461071963695, seqNum=0

	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:159)

	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:64)

	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)

	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)

	at java.lang.Thread.run(Unknown Source)

Caused by: java.net.ConnectException: Connection refused: no further information

	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)

	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)

	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)

	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)

	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)

	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:404)

	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:710)

	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:890)

	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:859)

	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1193)

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:216)

	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:300)

	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:32651)

	at org.apache.hadoop.hbase.client.ScannerCallable.openScanner(ScannerCallable.java:372)

	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:199)

	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:62)

	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)

	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:371)

	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:345)

	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:126)

	... 4 more



hbase-site.xml :

<?xml version=""1.0""?>
<?xml-stylesheet type=""text/xsl"" href=""configuration.xsl""?>
<!--
/**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration>
<property>
   <name>hbase.cluster.distributed</name>
   <value>true</value>
</property>
<property>
   <name>hbase.rootdir</name>
   <value>hdfs://master-sigma:54310/hbase</value>
</property>
<property>
    <name>hbase.zookeeper.quorum</name>
    <value>master-sigma</value>
</property>
<property>
  <name>hbase.master.ipc.address</name>
  <value>0.0.0.0</value>
</property>
<property>
  <name>hbase.regionserver.ipc.address</name>
  <value>0.0.0.0</value>
</property>
<property>
  <name>hbase.master</name>
  <value>master-sigma:16000</value>
</property>

</configuration>

Your help please
thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17687,"First , I created a table on phoenix, as this:
---------------------------------------------------------------------------
DROP TABLE IF EXISTS bidwd_test01 CASCADE;
CREATE TABLE IF NOT EXISTS bidwd_test01(
   rk VARCHAR,
   c1 integer,
   c2 VARCHAR,
   c3 VARCHAR,
   c4 VARCHAR
   constraint bidwd_test01_pk primary key(rk)
)
COMPRESSION='SNAPPY'
;
---------------------------------------------------------------------------
And then , I upserted two rows into the table:
---------------------------------------------------------------------------
upsert into bidwd_test01 values('001',1,'zhangsan','20170217','2017-02-17 12:34:22');
upsert into bidwd_test01 values('002',2,'lisi','20170216','2017-02-16 12:34:22');
---------------------------------------------------------------------------
At last , I scaned the table like this:
---------------------------------------------------------------------------
select * from bidwd_test01;
---------------------------------------------------------------------------

It's OK by now, but, I want to create a hive on hbase table ,that mapping to the phoenix table , the script likes this:
---------------------------------------------------------------------------
USE BIDWD;
DROP TABLE test01;
CREATE EXTERNAL TABLE test01
(
 rk string,
 id int,
 name string,
 datekey string,
 time_stamp string
)
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'  
WITH SERDEPROPERTIES (""hbase.columns.mapping"" = "":key,0:C1,0:C2,0:C3,0:C4"")  
TBLPROPERTIES (""hbase.table.name"" = ""BIDWD_TEST01"");
---------------------------------------------------------------------------

So,I also try to insert some data into the table,and scan this table:
---------------------------------------------------------------------------
set hive.execution.engine=mr;
insert into test01 values('003',3,'lisi2','20170215','2017-02-15 12:34:22');
select * from test01;
---------------------------------------------------------------------------

But,there are some problems like this:
+------------+------------+--------------+-----------------+----------------------+--+
| test01.rk  | test01.id  | test01.name  | test01.datekey  |  test01.time_stamp   |
+------------+------------+--------------+-----------------+----------------------+--+
| 001        | NULL       | zhangsan     | 20170217        | 2017-02-17 12:34:22  |
| 002        | NULL       | lisi         | 20170216        | 2017-02-16 12:34:22  |
| 003        | 3          | lisi2        | 20170215        | 2017-02-15 12:34:22  |
+------------+------------+--------------+-----------------+----------------------+--+

the column ""id"" 's value was null,only the last row is ok.
but,when I scan data in the phoenix ,there are some errors like this:
Error: ERROR 201 (22000): Illegal data. Expected length of at least 115 bytes, but had 31 (state=22000,code=201)
java.sql.SQLException: ERROR 201 (22000): Illegal data. Expected length of at least 115 bytes, but had 31
	at org.apache.phoenix.exception.SQLExceptionCode$Factory$1.newException(SQLExceptionCode.java:389)
	at org.apache.phoenix.exception.SQLExceptionInfo.buildException(SQLExceptionInfo.java:145)
	at org.apache.phoenix.schema.KeyValueSchema.next(KeyValueSchema.java:211)
	at org.apache.phoenix.expression.ProjectedColumnExpression.evaluate(ProjectedColumnExpression.java:113)
	at org.apache.phoenix.compile.ExpressionProjector.getValue(ExpressionProjector.java:69)
	at org.apache.phoenix.jdbc.PhoenixResultSet.getString(PhoenixResultSet.java:591)
	at sqlline.Rows$Row.<init>(Rows.java:183)
	at sqlline.BufferedRows.<init>(BufferedRows.java:38)
	at sqlline.SqlLine.print(SqlLine.java:1546)
	at sqlline.Commands.execute(Commands.java:833)
	at sqlline.Commands.sql(Commands.java:732)
	at sqlline.SqlLine.dispatch(SqlLine.java:702)
	at sqlline.SqlLine.begin(SqlLine.java:575)
	at sqlline.SqlLine.start(SqlLine.java:292)
	at sqlline.SqlLine.main(SqlLine.java:194)

So,I don't know why? How can I solve this problem?

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5742,"In 0.90 the LoadIncrementalHFiles constructor did not throw an exception, now it throws Exception.  The constructor should ether not throw an exception or throw ZooKeeperConnectionException, and MasterNotRunningException since those come from the HBaseAdmin call.

https://github.com/apache/hbase/blob/trunk/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java#L105",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11790,While debugging HBASE-11591 it was found that we in case of bulk load either thro TSV and by using LoadIncrementalHFiles we should be able to use the HFileOutputFormat2 so that the the metadata BULKLOAD_TIME_KEY is added to the HFile.  If not this file will not be considered as part of bulk load and we end up in not reading from these files.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14236,"This is an error on online documation.  (http://hbase.apache.org/book.html#_get_started_with_hbase ).

To locate the error you can go to 
2.2. Get Started with HBase
Example 2. Example hbase-site.xml for Standalone HBase

The config example here do not specify a port for the region server. So When you go to the 2.4 Advanced - Fully Distributed (http://hbase.apache.org/book.html#quickstart_fully_distributed). You will hit error.
Because the region server will conflict with backup master or master. As they use the same port.

People who read this section are always newbee, this will confuse them.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11850,"we don't stop until the map in 'connections' is empty.
the new connection is put in this map at creation, but if this connection is not used it will never be removed.

No totally sure of the fix yet. Probability is low (but not zero. I saw it happening).

The code is different in 0.98. It's 0.99+ issue only.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11894,"As part of HBASE-9249 & HBASE-9489, added new hooks in split and merge which take meta entries from coprocessor hooks if any. These meta entries helps to ensure atomicity of split(merge) of regions by server and split(merge) of the regions handled in coprocessors(This is required in secondary indexing case).

After HBASE-11611 the meta entries are not getting added to meta both in split and merge.
{code}
    @MetaMutationAnnotation
    List<Mutation> metaEntries = new ArrayList<Mutation>();
    if (rsCoprocessorHost != null) {
      if (rsCoprocessorHost.preMergeCommit(this.region_a, this.region_b, metaEntries)) {
        throw new IOException(""Coprocessor bypassing regions "" + this.region_a + "" ""
            + this.region_b + "" merge."");
      }
      try {
        for (Mutation p : metaEntries) {
          HRegionInfo.parseRegionName(p.getRow());
        }
      } catch (IOException e) {
        LOG.error(""Row key of mutation from coprocessor is not parsable as region name.""
            + ""Mutations from coprocessor should only be for hbase:meta table."", e);
        throw e;
      }
    }

    // This is the point of no return. Similar with SplitTransaction.
    // IF we reach the PONR then subsequent failures need to crash out this
    // regionserver
    this.journal.add(JournalEntry.PONR);

    // Add merged region and delete region_a and region_b
    // as an atomic update. See HBASE-7721. This update to hbase:meta makes the region
    // will determine whether the region is merged or not in case of failures.
    // If it is successful, master will roll-forward, if not, master will
    // rollback
    if (services != null && !services.reportRegionStateTransition(TransitionCode.MERGE_PONR,
        mergedRegionInfo, region_a.getRegionInfo(), region_b.getRegionInfo())) {
      // Passed PONR, let SSH clean it up
      throw new IOException(""Failed to notify master that merge passed PONR: ""
        + region_a.getRegionInfo().getRegionNameAsString() + "" and ""
        + region_b.getRegionInfo().getRegionNameAsString());
    }
{code}

I think while reporting region state transition to master we need to pass meta entries also so that we can add them to meta along with split or merge updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8997,hbase-8996 disabled the test because it is flakey.  See hbase-8996 for the thread dump when test was hung.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17339,"The current implementation of a get operation (to retrieve values for a specific key) scans through all relevant stores of the region; for each store both memory components (memstores segments) and disk components (hfiles) are scanned in parallel.
We suggest to apply an optimization that speculatively scans memory-only components first and only if the result is incomplete scans both memory and disk.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13293,"https://builds.apache.org/job/HBase-TRUNK-jacoco/15/testReport/junit/org.apache.hadoop.hbase.trace/TestHTraceHooks/testTraceCreateTable/

{noformat}
java.util.ConcurrentModificationException: null
	at java.util.HashMap$HashIterator.nextEntry(HashMap.java:926)
	at java.util.HashMap$KeyIterator.next(HashMap.java:960)
	at org.apache.htrace.TraceTree$SpansByProcessId.<init>(TraceTree.java:111)
	at org.apache.htrace.TraceTree.<init>(TraceTree.java:151)
	at org.apache.hadoop.hbase.trace.TestHTraceHooks.testTraceCreateTable(TestHTraceHooks.java:120)
{noformat}

This should be a benefit of running unit test slow...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12225,Went zombie in HBase-TRUNK #5644  Add timeout so fails faster.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16909,See linked jira for comments. Change name as seems appropriate.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5617,"With coprocessors hooks while put happens we have the provision to create new puts to other tables or regions.  These puts can be done with writeToWal as false.
In 0.94 and above the puts are first written to memstore and then to WAL.  If any failure in the WAL append or sync the memstore is rollbacked.  
Now the problem is that if the put that happens in the main flow fails there is no way to rollback the 
puts that happened in the prePut.

We can add coprocessor hooks to like pre/postRoolBackMemStore.  Is any one hook enough here?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12941,CompactionRequestor is a 'interface audience private' class with no users in the HBase code base.  Unused things should be deleted.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12705,"Among the comments in HBASE-12294 was reference to the fact that you can't just build HBase by running {{mvn package}} from the top-level directory because of dependencies of certain goals on the hbase-annotations and hbase-checkstyle modules. I'd like to take a stab at reorganizing the project layout so that it's no longer necessary to do a {{mvn install}} on these modules before your local build will succeed.

Down the rabbit hole I go, unless someone objects. :)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15110,"right now the ref guide lists Hadoop 1.0 as ""X"" for hbase 0.94. the 0.94 version of the book listed it as ""S"".

It's also the default version used in the 0.94 pom, so we should update the ref guide to show it as a minimum of NT.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6322,"From a mailing list question:

While generating some load against a library that makes extensive use of HTablePool in 0.92, I noticed that the largest heap consumer was java.lang.ref.Finalizer.  Digging in, I discovered that HTablePool's internal PooledHTable extends HTable, which instantiates a ThreadPoolExecutor and supporting objects every time a pooled HTable is retrieved.  Since ThreadPoolExecutor has a finalizer, it and its dependencies can't get garbage collected until the finalizer runs.  The result is by using HTablePool, we're creating a ton of objects to be finalized that are stuck on the heap longer than they should be, creating our largest source of pressure on the garbage collector.  It looks like this will also be a problem in 0.94 and trunk.

The easy fix is just to have PooledHTable implement HTableInterface (rather than subclass HTable), but this does break a unit test that explicitly checks that PooledHTable implements HTable -- I can only assume this test is there for some historical passivity reason.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15749,"HBase codebase uses Guava library extensively.

There have been JIRAs such as HBASE-14963 which tried to make compatibility story around Guava better.

Long term fix, as suggested over in HBASE-14963, is to shade Guava dependency.
Future use of Guava in HBase would be more secure once shading is done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18128,"The sequence for a compaction are as follows:
1. Compaction writes new files under region/.tmp directory (compaction output)
2. Compaction atomically moves the temporary file under region directory
3. Compaction appends a WAL edit containing the compaction input and output files. Forces sync on WAL.
4. Compaction deletes the input files from the region directory.

But if a flush happened between 3 and 4, then the regionserver crushed. The compaction marker will be skipped when splitting log because the sequence id of compaction marker is smaller than lastFlushedSequenceId.
{code}
        if (lastFlushedSequenceId >= entry.getKey().getLogSeqNum()) {
          editsSkipped++;
          continue;
        }
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17742,"As titled, reverse scan with empty start row should return empty result but doesn't in latest master code base.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17811,"Module Thrift fails with this output:
Results :

Failed tests:
  TestThriftHttpServer.testRunThriftServerWithHeaderBufferLength
Expected: (an instance of org.apache.thrift.transport.TTransportException and exception with message a string containing ""HTTP Response code: 413"")
     but: exception with message a string containing ""HTTP Response code: 413"" message was ""java.net.ConnectException: Connection refused (Connection refused)""
Stacktrace was: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused (Connection refused)
        at org.apache.thrift.transport.THttpClient.flush(THttpClient.java:356)
        at org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:73)
        at org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:62)
        at org.apache.hadoop.hbase.thrift.generated.Hbase$Client.send_getTableNames(Hbase.java:901)
        at org.apache.hadoop.hbase.thrift.generated.Hbase$Client.getTableNames(Hbase.java:894)
        at org.apache.hadoop.hbase.thrift.TestThriftServer.checkTableList(TestThriftServer.java:248)
        at org.apache.hadoop.hbase.thrift.TestThriftHttpServer.talkToThriftServer(TestThriftHttpServer.java:187)
        at org.apache.hadoop.hbase.thrift.TestThriftHttpServer.runThriftServer(TestThriftHttpServer.java:147)
        at org.apache.hadoop.hbase.thrift.TestThriftHttpServer.testRunThriftServerWithHeaderBufferLength(TestThriftHttpServer.java:121)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
        at java.net.PlainSocketImpl.socketConnect(Native Method)
        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
        at java.net.Socket.connect(Socket.java:589)
        at java.net.Socket.connect(Socket.java:538)
        at sun.net.NetworkClient.doConnect(NetworkClient.java:180)
        at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
        at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
        at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
        at sun.net.www.http.HttpClient.New(HttpClient.java:308)
        at sun.net.www.http.HttpClient.New(HttpClient.java:326)
        at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202)
        at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138)
        at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032)
        at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966)
        at org.apache.thrift.transport.THttpClient.flush(THttpClient.java:344)
        ... 20 more


Tests run: 88, Failures: 1, Errors: 0, Skipped: 0
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17781,"Command:
mvn clean install -X

Previous History:
After applying patch HBASE-17723, the test ""TestSimpleRpcScheduler"" passes but, the below test fails.

Final Output:

Tests in error:
  TestAcidGuarantees.testGetAtomicity:418->runTestAtomicity:315->runTestAtomicity:324->runTestAtomicity:388 禄 Runtime
  TestAcidGuarantees.testMobGetAtomicity:435->runTestAtomicity:388 禄 Runtime Def...

Tests run: 1774, Failures: 0, Errors: 2, Skipped: 6
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17789,", if we try to a hbase using ""HBaseAdmin"" by reading a value of """"hbase.zookeeper.quorum"" from list peers with value as ""a:2181,b:2181c:2181:/hbase"". org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersStringFromHbaseConfig returns a incorrect queryString which causes following exception Because last host would see  :/hbase also in the string. This method was existing earlier but never being called before above change",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17767,"cms gc pause serious program:

2017-03-10T10:15:29.524+0800: 4555920.160: [GC2017-03-10T10:15:29.524+0800: 4555920.160: [ParNew: 3067133K->340736K(3067136K), 2.0586980 secs] 80328431K->78058138K(100322560K), 2.0590280 secs] [Times: user=3.94 sys=0.34, real=2.05 secs]
2017-03-10T10:15:32.911+0800: 4555923.547: [CMS-concurrent-sweep: 1441.773/1618.869 secs] [Times: user=2518.60 sys=59.25, real=1618.62 secs]
2017-03-10T10:15:32.911+0800: 4555923.547: [CMS-concurrent-reset-start]
2017-03-10T10:15:33.126+0800: 4555923.762: [CMS-concurrent-reset: 0.215/0.215 secs] [Times: user=1.23 sys=0.08, real=0.22 secs]
2017-03-10T10:15:33.236+0800: 4555923.873: [GC2017-03-10T10:15:33.237+0800: 4555923.873: [ParNew: 3067011K->340736K(3067136K), 2.4140270 secs] 80615855K->78315999K(100322560K), 2.4144230 secs] [Times: user=4.63 sys=0.36, real=2.41 secs]
2017-03-10T10:15:35.655+0800: 4555926.292: [GC [1 CMS-initial-mark: 77975263K(97255424K)] 78316286K(100322560K), 0.0149650 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]
2017-03-10T10:15:35.671+0800: 4555926.307: [CMS-concurrent-mark-start]
2017-03-10T10:15:36.098+0800: 4555926.734: [CMS-concurrent-mark: 0.427/0.427 secs] [Times: user=5.72 sys=0.05, real=0.43 secs]
2017-03-10T10:15:36.098+0800: 4555926.734: [CMS-concurrent-preclean-start]
2017-03-10T10:15:36.291+0800: 4555926.928: [CMS-concurrent-preclean: 0.192/0.193 secs] [Times: user=0.80 sys=0.03, real=0.19 secs]
2017-03-10T10:15:36.291+0800: 4555926.928: [CMS-concurrent-abortable-preclean-start]
2017-03-10T10:15:37.378+0800: 4555928.014: [GC2017-03-10T10:15:37.378+0800: 4555928.014: [ParNew: 3067083K->340736K(3067136K), 2.6221190 secs] 81042347K->78771078K(100322560K), 2.6224970 secs] [Times: user=4.79 sys=0.48, real=2.62 secs]
2017-03-10T10:15:41.012+0800: 4555931.648: [CMS-concurrent-abortable-preclean: 2.083/4.721 secs] [Times: user=13.51 sys=0.87, real=4.72 secs]
2017-03-10T10:15:41.015+0800: 4555931.652: [GC[YG occupancy: 2011637 K (3067136 K)]2017-03-10T10:15:41.016+0800: 4555931.652: [GC2017-03-10T10:15:41.016+0800: 4555931.652: [ParNew: 2011637K->340736K(3067136K), 2.0773980 secs] 80441979K->79117650K(100322560K), 2.0777380 secs] [Times: user=4.09 sys=0.38, real=2.07 secs]






regionserver  JVM config:

export HBASE_REGIONSERVER_OPTS=""$HBASE_REGIONSERVER_OPTS -XX:PermSize=256m -XX:MaxPermSize=256m -Xms96G -Xmx96G""
export HBASE_OPTS=""$HBASE_OPTS -Djava.net.preferIPv4Stack=true
-XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=60 -XX:+CMSParallelRemarkEnabled -XX:+CMSConcurrentMTEnabled
-XX:ParallelGCThreads=40 -XX:+DisableExplicitGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -verbose:gc
-XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=1 -XX:+CMSScavengeBeforeRemark -XX:+HeapDumpOnOutOfMemoryError

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15431,"I ran HBase with ""-XX:+PrintCompilation -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining"" and then looked for ""hot method too big"" log lines.

I'll attach a log of those messages.
I tried to increase -XX:FreqInlineSize to 1010 to inline all these methods (as long as they're hot, but actually didn't see any improvement).

In all cases I primed the JVM to make sure the JVM gets a chance to profile the methods and decide whether they're hot or not.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17643,Looking at https://builds.apache.org/job/HBase-1.3-JDK8/ there's bunch of failing / flaky builds. Prior to releasing 1.3.1 we need to address those.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17693,"testFailover is failing with Timeout Error.
{code}
Error Message

test timed out after 30000 milliseconds
Stacktrace

org.junit.runners.model.TestTimedOutException: test timed out after 30000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hbase.util.Threads.sleep(Threads.java:146)
	at org.apache.hadoop.hbase.master.TestMasterNoCluster.testFailover(TestMasterNoCluster.java:246)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17695,"testMultiRegionTable UT fails as below.

{code}
Error Message

Failed after attempts=35, exceptions:
Thu Feb 23 21:07:26 UTC 2017, RpcRetryingCaller{globalStartTime=1487884046035, pause=100, retries=35}, org.apache.hadoop.hbase.MasterNotRunningException: java.io.IOException: Can't get master address from ZooKeeper; znode data == null
Thu Feb 23 21:07:26 UTC 2017, RpcRetryingCaller{globalStartTime=1487884046035, pause=100, retries=35}, org.apache.hadoop.hbase.MasterNotRunningException: java.io.IOException: Can't get master address from ZooKeeper; znode data == null
Thu Feb 23 21:07:26 UTC 2017, RpcRetryingCaller{globalStartTime=1487884046035, pause=100, retries=35}, org.apache.hadoop.hbase.MasterNotRunningException: java.io.IOException: Can't get master address from ZooKeeper; znode data == null
Thu Feb 23 21:07:27 UTC 2017, RpcRetryingCaller{globalStartTime=1487884046035, pause=100, retries=35}, org.apache.hadoop.hbase.MasterNotRunningException: java.io.IOException: Can't get master address from ZooKeeper; znode data == null{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17692,"testSameVersionUpdatesRecoveryWithCompaction test fails with NPE as below.
{code:title=cmd}mvn -B -nsu test -Dtest=TestOpenedRegionHandler,TestMasterFileSystemWithWALDir,TestDistributedLogSplitting,TestRegionPlacement,TestGetLastFlushedSequenceId,TestZKLessAMOnCluster,TestMasterRestartAfterDisablingTable,TestSplitLogManager,TestSimpleRegionNormalizerOnCluster,TestHFileLinkCleaner,TestSnapshotFromMaster,TestLogsCleaner,TestModifyColumnFamilyProcedure,TestCreateTableProcedure2,TestTruncateTableProcedure,TestWALProcedureStoreOnHDFS,TestProcedureAdmin,TestAddColumnFamilyProcedure,TestDisableTableProcedure,TestCreateTableProcedure,TestDeleteTableProcedure,TestEnableTableProcedure,TestMasterProcedureQueue,TestDeleteColumnFamilyProcedure,TestModifyTableProcedure,TestMasterFailoverWithProcedures,TestSnapshotFileCache,TestTableDeleteFamilyHandler,TestCreateTableHandler,TestTableDescriptorModification,TestEnableTableHandler,TestStochasticLoadBalancer,TestFavoredNodeAssignmentHelper,TestStochasticLoadBalancer2,TestConstraint,TestFilterList,TestParseFilter,TestSingleColumnValueFilter,TestMultipleColumnPrefixFilter,TestColumnPrefixFilter,TestColumnPaginationFilter,TestPrefixFilter,TestScanRowPrefix,TestNullComparator,TestRegexComparator,TestPageFilter,TestDependentColumnFilter,TestFuzzyRowAndColumnRangeFilter,TestFuzzyRowFilterEndToEnd,TestFilterSerialization,TestFilterWrapper,TestComparatorSerialization,TestRandomRowFilter,TestSingleColumnValueExcludeFilter,TestColumnRangeFilter,TestFilter,TestFuzzyRowFilter,TestFirstKeyValueMatchingQualifiersFilter,TestMultiRowRangeFilter,TestPutDeleteEtcCellIteration,TestResultSizeEstimation,TestTimestampsFilter,TestUpdateConfiguration,TestClientTimeouts,TestResult,TestClientPushback,TestConnectionUtils --projects :hbase-server{code}

{code}
Running org.apache.hadoop.hbase.filter.TestFirstKeyValueMatchingQualifiersFilter
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.4 sec - in org.apache.hadoop.hbase.filter.TestFirstKeyValueMatchingQualifiersFilter
Running org.apache.hadoop.hbase.filter.TestDependentColumnFilter
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.487 sec - in org.apache.hadoop.hbase.filter.TestDependentColumnFilter

Results :


Tests in error: 
  TestDistributedLogSplitting.testSameVersionUpdatesRecoveryWithCompaction:1377 禄 NullPointer


Tests run: 384, Failures: 0, Errors: 1, Skipped: 3

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 59:21 min
[INFO] Finished at: 2017-02-23T21:57:52+00:00
[INFO] Final Memory: 51M/898M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.18:test (default-test) on project hbase-server: There are test failures.
[ERROR] 
[ERROR] Please refer to /grid/0/nobody/workspace/build-support/SOURCES/hbase/hbase-server/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException{code}

{code}
Stacktrace

java.lang.NullPointerException: null
	at org.apache.hadoop.hbase.util.Bytes.toLong(Bytes.java:604)
	at org.apache.hadoop.hbase.util.Bytes.toLong(Bytes.java:578)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.testSameVersionUpdatesRecoveryWithCompaction(TestDistributedLogSplitting.java:1377){code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17150,"This part of application is a legacy code from a first version. 
If backup destination is local cluster, then during restore we copy HFiles into local temp dir first. For remote cluster we do not do this. Seems should be other way around.
{quote}
What does this mean?
253 2016-11-17 14:13:39,782 DEBUG [main] util.RestoreServerUtil: File hdfs://ve0524.halxg.cloudera.com:8020/user/stack/backup/backup_1479419995738/default/x_1/archive/data/default/x_1 on local cluster, back it up before restore
Is this a full copy of the backup to elsewhere?
296 2016-11-17 14:13:47,907 DEBUG [main] util.RestoreServerUtil: Copied to temporary path on local cluster: /user/stack/hbase-staging/restore
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13942,"Performing any operataion using a single hconnection with client threads > hbase.hconnection.threads.max causing the client to stall indefinetly during first region split. All the hconnection threads in client side are waiting with the following stack. 

hconnection-0x648a83fd-shared--pool1-t8"" daemon prio=10 tid=0x00007f447c003800 nid=0x62ff waiting on condition [0x00007f44c72f0000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000007d768bdf0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:374)
        at org.apache.hadoop.hbase.util.BoundedCompletionService.take(BoundedCompletionService.java:74)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:174)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:56)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
        at org.apache.hadoop.hbase.client.ClientSmallReversedScanner.next(ClientSmallReversedScanner.java:145)
        at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegionInMeta(ConnectionManager.java:1200)
        at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1109)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.findAllLocationsOrFail(AsyncProcess.java:916)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.groupAndSendMultiAction(AsyncProcess.java:833)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.resubmit(AsyncProcess.java:1156)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.receiveMultiAction(AsyncProcess.java:1296)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.access$1200(AsyncProcess.java:574)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl$SingleServerRequestRunnable.run(AsyncProcess.java:716)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17461,"On HBase shell, *major_compact* command simply passes the received *table_or_region_name* parameter straight to java *HBaseAdmin.majorCompact* method.

On some corner cases, HBase tables row keys may have special characters. Then, if a region is split in such a way that row keys with special characters are now part of the region name, calling *major_compact* on this regions will fail, if the special character ASCII code is higher than 127. This happens because Java byte type is signed, while ruby byte type isn't, causing the region name to be converted to a wrong string at Java side.

For example, considering a region named as below:

{noformat}
test,\xF8\xB9B2!$\x9C\x0A\xFEG\xC0\xE3\x8B\x1B\xFF\x15,1481745228583.b4bc69356d89018bfad3ee106b717285.
{noformat} 

Calling major_compat on it fails as follows:

{noformat}
hbase(main):008:0* major_compact ""test,\xF8\xB9B2!$\x9C\x0A\xFEG\xC0\xE3\x8B\x1B\xFF\x15,1484177359169.8128fa75ae0cd4eba38da2667ac8ec98.""

ERROR: Illegal character code:44, <,> at 4. User-space table qualifiers can only contain 'alphanumeric characters': i.e. [a-zA-Z_0-9-.]: test,锟紹2!$锟?锟紾锟斤拷锟?484177359169.8128fa75ae0cd4eba38da2667ac8ec98.
{noformat}

An easy solution is to convert *table_or_region_name* parameter properly, prior to calling *HBaseAdmin.majorCompact* in the same way as it's already done on some other shell commands, such as *get*:

{noformat}
admin.major_compact(table_or_region_name.to_s.to_java_bytes, family)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17378,"launch all mxosrvrs of a downed node, which will take a long time, about 4 mintues 45 seconds.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17196,"In the following case, the deleted mob cell can come back.

{code}
1) hbase(main):001:0> create 't1', {NAME => 'f1', IS_MOB => true, MOB_THRESHOLD => 10}

2) hbase(main):002:0> put 't1', 'r1', 'f1:q1', 'aaaaaaaaaaaaaaaaaaaa'

3) hbase(main):003:0> flush 't1'

4) hbase(main):004:0> deleteall 't1', 'r1'

5) hbase(main):005:0> scan 't1'
ROW                                                 COLUMN+CELL                                                                                                                                           
0 row(s)

6) hbase(main):006:0> flush 't1'

7) hbase(main):007:0> major_compact 't1'

After that, go to mobdir, remove the _del file, this is to simulate the case that  mob minor compaction does not the _del file. Right now, the cell in normal region is gone after the major compaction.

8) hbase(main):008:0> put 't1', 'r2', 'f1:q1', 'bbbbbbbbbbbbbbbbbbbbbbbb'
                                                                                                                                                      
9) hbase(main):009:0> flush 't1'

10) hbase(main):010:0> scan 't1'
ROW                                                 COLUMN+CELL                                                                                                                                           
 r2                                                 column=f1:q1, timestamp=1480451201393, value=bbbbbbbbbbbbbbbbbbbbbbbb                                                                                 
1 row(s)

11) hbase(main):011:0> compact 't1', 'f1', 'MOB'

12) hbase(main):012:0> scan 't1'
ROW                                                 COLUMN+CELL                                                                                                                                           
 r1                                                 column=f1:q1, timestamp=1480450987725, value=aaaaaaaaaaaaaaaaaaaa                                                                                     
 r2                                                 column=f1:q1, timestamp=1480451201393, value=bbbbbbbbbbbbbbbbbbbbbbbb                                                                                 
2 row(s)

The deleted ""r1"" comes back. The reason is that mob minor compaction does not include _del files so it generates references for the deleted cell.
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6338,"Every call in rpc handler a Method will be created, if we cache the method will improve a little.
I test with 0.90, Average Class.getMethod(String name, Class... parameterTypes) cost 4780 ns , if we cache it cost 2620 ns.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6968,"Here are 2 hbase write performance improvements recently:

1) Avoid creating HBaseConfiguraiton object for each HLog. Every time when creating a HBaseConfiguraiton object, it would parse the xml configuration files from disk, which is not cheap operation.
In HLog.java:
orig:
{code:title=HLog.java}
  newWriter = createWriter(fs, newPath, HBaseConfiguration.create(conf));
{code}
new:
{code}
  newWriter = createWriter(fs, newPath, conf);
{code}


2) Change 2 hotspot synchronized functions into double locking pattern. So it shall remove the synchronization overhead in the normal case.
orig:
{code:title=HBaseRpcMetrics.java}
  public synchronized void inc(String name, int amt) {	
    MetricsTimeVaryingRate m = get(name);	
    if (m == null) {	
      m = create(name);	
    }	
    m.inc(amt);	
  }
{code}

new:
{code}
  public void inc(String name, int amt) {	
    MetricsTimeVaryingRate m = get(name);	
    if (m == null) {	
      synchronized (this) {	
        if ((m = get(name)) == null) {	
          m = create(name);	
        }	
      }	
    }	
    m.inc(amt);	
  }
{code}
=====================
orig:
{code:title=MemStoreFlusher.java}
  public synchronized void reclaimMemStoreMemory() {	
    if (this.server.getGlobalMemstoreSize().get() >= globalMemStoreLimit) {	
      flushSomeRegions();	
    }
  }	
{code}
new:
{code}
  public void reclaimMemStoreMemory() {	
    if (this.server.getGlobalMemstoreSize().get() >= globalMemStoreLimit) {	
      flushSomeRegions();	
    }
  }	
  private synchronized void flushSomeRegions() {	
    if (this.server.getGlobalMemstoreSize().get() < globalMemStoreLimit) {	
      return; // double check the global memstore size inside of the synchronized block.	
    }	
 ...   
 }
{code}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6956,"Sometimes we see a lot of Exception about closed connections:
{code}
 org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@553fd068 closed
org.apache.hadoop.hbase.client.ClosedConnectionException: org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@553fd068 closed
{code}

After investigation we assumed that it occurs because closed connection returns back into HTablePool. 

For our opinion best solution is  check whether the table is closed in method HTablePool.putTable and if true don't add it into the queue and release such HTableInterface.

But unfortunatly right now there are no access to HTable#closed field through HTableInterface",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6773,"Today, it's an application level configuration. So all the HFiles are replicated 3 times per default.

There are some reasons to make it per table:
- some tables are critical while some others are not. For example, meta would benefit from an higher level of replication, to ensure we continue working even when we lose 20% of the cluster.
- some tables are backuped somewhere else, used by non essential process, so the user may accept a lower level of replication for these ones.
- it should be a dynamic parameter. For example, during a bulk load we set a replication of 1 or 2, then we increase it. It's in the same space as disabling the WAL for some writes.


The case that seems important to me is meta. We can also handle this one by a specific parameter in the usual hbase-site.xml if we don't want a generic solution.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6391,"The Scenario can be reproduce below.
Enabling an table, some region is online on regionserver,some are still being processed.
And restart the master.

when master failover:
        // Region is being served and on an active server
        // add only if region not in disabled and enabling table
        if (false == checkIfRegionBelongsToDisabled(regionInfo)
            && false == checkIfRegionsBelongsToEnabling(regionInfo)) {
          regions.put(regionInfo, regionLocation);
          addToServers(regionLocation, regionInfo);
        }

the opened region will not add to the Regions in master.
and in the following recoverTableInEnablingState,the region will be assigned again.
that will lead to the cluster inconsistent
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5686,Changes similar to HBASE-5209/HBASE-5596 need to be added for Avro.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5148,"In case you do not override compaction parameter on the table/cf level, the values returned by the table descriptor will not reflect the value configured in the cluster.

For example - let assume you disabled major compaction by setting ""hbase.hregion.majorcompaction"" in the config to ""0"", prior starting the cluster. Let also assume that you have a table that in which you didn't set at all this parameter.
Then invoking 
HTableDescriptor hTableDescriptor = conn.getHTableDescriptor(Bytes.toBytes(""my table""));
hTableDescriptor.getValue(""hbase.hregion.majorcompaction"")
should return the cluster property (currently returns the default, ignoring the cluster prop.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4134,"1. I found the problem(some regions were multiply assigned) while running hbck to check the cluster's health. Here's the result:
{noformat}
ERROR: Region test1,230778,1311216270050.fff783529fcd983043610eaa1cc5c2fe. is listed in META on region server 158-1-91-101:20020 but is multiply assigned to region servers 158-1-91-101:20020, 158-1-91-105:20020 
ERROR: Region test1,252103,1311216293671.fff9ed2cb69bdce535451a07686c0db5. is listed in META on region server 158-1-91-101:20020 but is multiply assigned to region servers 158-1-91-101:20020, 158-1-91-105:20020 
ERROR: Region test1,282187,1311216322104.ffff52782c0241a598b3e37ca8729da0. is listed in META on region server 158-1-91-103:20020 but is multiply assigned to region servers 158-1-91-103:20020, 158-1-91-105:20020 
Summary: 
  -ROOT- is okay. 
    Number of regions: 1 
    Deployed on: 158-1-91-105:20020 
  .META. is okay. 
    Number of regions: 1 
    Deployed on: 158-1-91-103:20020 
  test1 is okay. 
    Number of regions: 25297 
    Deployed on: 158-1-91-101:20020 158-1-91-103:20020 158-1-91-105:20020 
14829 inconsistencies detected. 
Status: INCONSISTENT 
{noformat}

2. Then I tried to use ""hbck -fix"" to fix the problem. Everything seemed ok. But I found that the total number of regions reported by load balancer (35029) was more than the actual region count(25299) after the fixing.
Here's the related logs snippet:
{noformat}
2011-07-22 02:19:02,866 INFO org.apache.hadoop.hbase.master.LoadBalancer: Skipping load balancing.  servers=3 regions=25299 average=8433.0 mostloaded=8433 
2011-07-22 03:06:11,832 INFO org.apache.hadoop.hbase.master.LoadBalancer: Skipping load balancing.  servers=3 regions=35029 average=11676.333 mostloaded=11677 leastloaded=11676
{noformat}

3. I tracked one region's behavior during the time. Taking the region of ""test1,282187,1311216322104.ffff52782c0241a598b3e37ca8729da0."" as example:
(1) It was assigned to ""158-1-91-101"" at first. 
(2) HBCK sent closing request to RegionServer. And RegionServer closed it silently without notice to HMaster.
(3) The region was still carried by RS ""158-1-91-103"" which was known to HMaster.
(4) HBCK will trigger a new assignment.

The fact is, the region was assigned again, but the old assignment information still remained in AM#regions,AM#servers.

That's why the problem of ""region count was larger than the actual number"" occurred.  

{noformat}
Line 178967: 2011-07-22 02:47:51,247 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling new unassigned node: /hbase/unassigned/ffff52782c0241a598b3e37ca8729da0 (region=test1,282187,1311216322104.ffff52782c0241a598b3e37ca8729da0., server=HBCKServerName, state=M_ZK_REGION_OFFLINE)
Line 178968: 2011-07-22 02:47:51,247 INFO org.apache.hadoop.hbase.master.AssignmentManager: Handling HBCK triggered transition=M_ZK_REGION_OFFLINE, server=HBCKServerName, region=ffff52782c0241a598b3e37ca8729da0
Line 178969: 2011-07-22 02:47:51,248 INFO org.apache.hadoop.hbase.master.AssignmentManager: HBCK repair is triggering assignment of region=test1,282187,1311216322104.ffff52782c0241a598b3e37ca8729da0.
Line 178970: 2011-07-22 02:47:51,248 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for test1,282187,1311216322104.ffff52782c0241a598b3e37ca8729da0. so generated a random one; hri=test1,282187,1311216322104.ffff52782c0241a598b3e37ca8729da0., src=, dest=158-1-91-101,20020,1311231878544; 3 (online=3, exclude=null) available servers
Line 178971: 2011-07-22 02:47:51,248 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region test1,282187,1311216322104.ffff52782c0241a598b3e37ca8729da0. to 158-1-91-101,20020,1311231878544
Line 178983: 2011-07-22 02:47:51,285 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=158-1-91-101,20020,1311231878544, region=ffff52782c0241a598b3e37ca8729da0
Line 179001: 2011-07-22 02:47:51,318 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=158-1-91-101,20020,1311231878544, region=ffff52782c0241a598b3e37ca8729da0
Line 179002: 2011-07-22 02:47:51,319 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for ffff52782c0241a598b3e37ca8729da0; deleting unassigned node
Line 179003: 2011-07-22 02:47:51,319 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:20000-0x1314ac5addb0042-0x1314ac5addb0042 Deleting existing unassigned node for ffff52782c0241a598b3e37ca8729da0 that is in expected state RS_ZK_REGION_OPENED
Line 179007: 2011-07-22 02:47:51,326 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:20000-0x1314ac5addb0042-0x1314ac5addb0042 Successfully deleted unassigned node for region ffff52782c0241a598b3e37ca8729da0 in expected state RS_ZK_REGION_OPENED
Line 179011: 2011-07-22 02:47:51,335 WARN org.apache.hadoop.hbase.master.AssignmentManager: Overwriting ffff52782c0241a598b3e37ca8729da0 on serverName=158-1-91-103,20020,1311232056655, load=(requests=0, regions=0, usedHeap=0, maxHeap=0)
Line 179012: 2011-07-22 02:47:51,335 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Opened region test1,282187,1311216322104.ffff52782c0241a598b3e37ca8729da0. on 158-1-91-101,20020,1311231878544
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5583,"Create table using splitkeys
-> MAster goes down before all regions are added to meta
-> On master restart the table is again enabled but with less number of regions than specified in splitkeys

Anyway client will get an exception if i had called sync ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17011,"As discussed in HBASE-16972, holding commits for now until 1.3.0 comes out.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16685,"During code review of backup / restore, Matteo raised comment on the following code:
{code}
        res = snapshotCp.run(options);
{code}
I think this will be a first time where HBase server has a direct dependency on a MR job.

also we need to revisit this code to avoid having one handler blocked for N hours while we are doing a copy.

This issue is to address the above comment.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16715,"I am trying to import the signing keys to verify downloaded hbase releases, but it appears to fail:

{code}
$ wget -O /tmp/KEYS https://www-us.apache.org/dist/hbase/KEYS
Connecting to www-us.apache.org (140.211.11.105:443)
KEYS                 100% |*******************************| 50537   0:00:00 ETA
$ gpg --import /tmp/KEYS
gpg: directory '/root/.gnupg' created
gpg: new configuration file '/root/.gnupg/dirmngr.conf' created
gpg: new configuration file '/root/.gnupg/gpg.conf' created
gpg: keybox '/root/.gnupg/pubring.kbx' created
gpg: /root/.gnupg/trustdb.gpg: trustdb created
gpg: key 945D66AF: public key ""Jean-Daniel Cryans (ASF key) <jdcryans@apache.org>"" imported
gpg: key D34B98D6: public key ""Michael Stack <stack@apache.org>"" imported
gpg: key 30CD0996: public key ""Michael Stack <stack@duboce.net>"" imported
gpg: key AEC77EAF: public key ""Todd Lipcon <tlipcon@mercea.net>"" imported
gpg: key F48B08A4: public key ""Ted Yu (Apache Public Key) <yuzhihong@gmail.com>"" imported
gpg: key 867B57B8: public key ""Ramkrishna S Vasudevan (for code checkin) <ram_krish_86@hotmail.com>"" imported
gpg: key 7CA45750: public key ""Lars Hofhansl (CODE SIGNING KEY) <larsh@apache.org>"" imported
gpg: key A1AC25A9: public key ""Lars Hofhansl (CODE SIGNING KEY) <larsh@apache.org>"" imported
gpg: key C7CFE328: public key ""Lars Hofhansl (CODE SIGNING KEY) <larsh@apache.org>"" imported
gpg: key E964B5FF: public key ""Enis Soztutar (CODE SIGNING KEY) <enis@apache.org>"" imported
gpg: key 0D80DB7C: public key ""Sean Busbey (CODE SIGNING KEY) <busbey@apache.org>"" imported
gpg: key 8644EEB6: public key ""Nick Dimiduk <ndimiduk@apache.org>"" imported
gpg: invalid radix64 character 3A skipped
gpg: CRC error; E1B6C3 - DFECFB
gpg: [don't know]: invalid packet (ctb=55)
gpg: read_block: read error: Invalid packet
gpg: import from '/tmp/KEYS' failed: Invalid keyring
gpg: Total number processed: 12
gpg:               imported: 12
gpg: no ultimately trusted keys found
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16546,test,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16539,"A ITBLL 1B row run fails when table schema is changed to specify lz4 compression but then servers cannot deploy it. 1.1.6rc2 passed, 1.2.3rc0 does not. Same testing environment. Something has changed between 1.1 and 1.2. 

We end up in this state and jobs cannot progress:
{noformat}
Number of regions in transition: 7
  IntegrationTestBigLinkedList,\xA0\x00\x00\x00\x00\x00\x00\x00,1472681289247.d947338bc0a76a9bba5af4c515019bc1. state=FAILED_OPEN, ts=Wed Aug 31 22:58:47 UTC 2016 (419s ago), server=null
  IntegrationTestBigLinkedList,\x8F\xFD@wn\x90\x9F\x12\x0Cej\x1F$\xE1&{,1472684144278.57f4bf5d3c6d7dbd60aa54d7080d43b6. state=FAILED_OPEN, ts=Wed Aug 31 23:01:09 UTC 2016 (276s ago), server=null
  IntegrationTestBigLinkedList,\xE0\x00\x00\x00\x00\x00\x00\x00,1472681289247.d5d8ec90585f29cd729ea3f4bf0b791a. state=FAILED_OPEN, ts=Wed Aug 31 23:01:09 UTC 2016 (276s ago), server=null
  IntegrationTestBigLinkedList,,1472683517911.19f79f1865001d4ae1a261c77726fbd4. state=FAILED_OPEN, ts=Wed Aug 31 22:58:46 UTC 2016 (419s ago), server=null
  IntegrationTestBigLinkedList,\xC0\x00\x00\x00\x00\x00\x00\x00,1472681289247.9706c191970f442489033e8baa210bfb. state=FAILED_OPEN, ts=Wed Aug 31 22:55:59 UTC 2016 (586s ago), server=null
  IntegrationTestBigLinkedList,\x80\x00\x00\x00\x00\x00\x00\x00,1472684144278.c38d5068d2e52324ad398062fc2064a6. state=FAILED_OPEN, ts=Wed Aug 31 22:56:16 UTC 2016 (569s ago), server=null
  IntegrationTestBigLinkedList,`\x00\x00\x00\x00\x00\x00\x00,1472681289247.b04b1836a8c0efd5481ccd6f50817ddf. state=FAILED_OPEN, ts=Wed Aug 31 22:53:43 UTC 2016 (722s ago), server=null
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16514,"The regionserver process was shutdown by some reason.
I looked into regionserver's log , it looks like detected jvm pause about 9122ms (zk session timout is 40s), and after 10 seconds it start another process to delete  regionserver's ephemeral node in zk, and regionserver process was gone, here is the detail log:

{quote}
2016-08-14 22:16:53,139 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9022ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=9122ms
2016-08-14 22:17:03,121 WARN  [main] util.HeapMemorySizeUtil: hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-08-14 22:17:03,177 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-08-14 22:17:03,177 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=olap3.data.lq
2016-08-14 22:17:03,177 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_09-icedtea
2016-08-14 22:17:03,177 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-08-14 22:17:03,177 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.9.x86_64/jre
2016-08-14 22:17:03,177 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/data/sysdir/hbase-1.1.2/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/data/sysdir/hbase-1.1.2:/data/sysdir/hbase-1.1.2/lib/activation-1.1.jar:/data/sysdir/hbase-1.1.2/lib/aopalliance-1.0.jar:/data/sysdir/hbase-1.1.2/lib/apacheds-i18n-2.0.0-M15.jar:/data/sysdir/hbase-1.1.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/data/sysdir/hbase-1.1.2/lib/api-asn1-api-1.0.0-M20.jar:/data/sysdir/hbase-1.1.2/lib/api-util-1.0.0-M20.jar:/data/sysdir/hbase-1.1.2/lib/asm-3.1.jar:/data/sysdir/hbase-1.1.2/lib/avro-1.7.4.jar:/data/sysdir/hbase-1.1.2/lib/commons-beanutils-1.7.0.jar:/data/sysdir/hbase-1.1.2/lib/commons-beanutils-core-1.8.0.jar:/data/sysdir/hbase-1.1.2/lib/commons-cli-1.2.jar:/data/sysdir/hbase-1.1.2/lib/commons-codec-1.9.jar:/data/sysdir/hbase-1.1.2/lib/commons-collections-3.2.1.jar:/data/sysdir/hbase-1.1.2/lib/commons-compress-1.4.1.jar:/data/sysdir/hbase-1.1.2/lib/commons-configuration-1.6.jar:/data/sysdir/hbase-1.1.2/lib/commons-daemon-1.0.13.jar:/data/sysdir/hbase-1.1.2/lib/commons-digester-1.8.jar:/data/sysdir/hbase-1.1.2/lib/commons-el-1.0.jar:/data/sysdir/hbase-1.1.2/lib/commons-httpclient-3.1.jar:/data/sysdir/hbase-1.1.2/lib/commons-io-2.4.jar:/data/sysdir/hbase-1.1.2/lib/commons-lang-2.6.jar:/data/sysdir/hbase-1.1.2/lib/commons-logging-1.2.jar:/data/sysdir/hbase-1.1.2/lib/commons-math-2.2.jar:/data/sysdir/hbase-1.1.2/lib/commons-math3-3.1.1.jar:/data/sysdir/hbase-1.1.2/lib/commons-net-3.1.jar:/data/sysdir/hbase-1.1.2/lib/disruptor-3.3.0.jar:/data/sysdir/hbase-1.1.2/lib/findbugs-annotations-1.3.9-1.jar:/data/sysdir/hbase-1.1.2/lib/guava-12.0.1.jar:/data/sysdir/hbase-1.1.2/lib/guice-3.0.jar:/data/sysdir/hbase-1.1.2/lib/guice-servlet-3.0.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-annotations-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-auth-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-client-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-common-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-hdfs-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-yarn-api-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-yarn-client-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-yarn-common-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hadoop-yarn-server-common-2.5.1.jar:/data/sysdir/hbase-1.1.2/lib/hbase-annotations-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-annotations-1.1.2-tests.jar:/data/sysdir/hbase-1.1.2/lib/hbase-client-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-common-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-common-1.1.2-tests.jar:/data/sysdir/hbase-1.1.2/lib/hbase-examples-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-hadoop2-compat-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-hadoop-compat-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-it-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-it-1.1.2-tests.jar:/data/sysdir/hbase-1.1.2/lib/hbase-prefix-tree-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-procedure-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-protocol-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-resource-bundle-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-rest-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-server-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-server-1.1.2-tests.jar:/data/sysdir/hbase-1.1.2/lib/hbase-shell-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/hbase-thrift-1.1.2.jar:/data/sysdir/hbase-1.1.2/lib/htrace-core-3.1.0-incubating.jar:/data/sysdir/hbase-1.1.2/lib/httpclient-4.2.5.jar:/data/sysdir/hbase-1.1.2/lib/httpcore-4.1.3.jar:/data/sysdir/hbase-1.1.2/lib/jackson-core-asl-1.9.13.jar:/data/sysdir/hbase-1.1.2/lib/jackson-jaxrs-1.9.13.jar:/data/sysdir/hbase-1.1.2/lib/jackson-mapper-asl-1.9.13.jar:/data/sysdir/hbase-1.1.2/lib/jackson-xc-1.9.13.jar:/data/sysdir/hbase-1.1.2/lib/jamon-runtime-2.3.1.jar:/data/sysdir/hbase-1.1.2/lib/jasper-compiler-5.5.23.jar:/data/sysdir/hbase-1.1.2/lib/jasper-runtime-5.5.23.jar:/data/sysdir/hbase-1.1.2/lib/javax.inject-1.jar:/data/sysdir/hbase-1.1.2/lib/java-xmlbuilder-0.4.jar:/data/sysdir/hbase-1.1.2/lib/jaxb-api-2.2.2.jar:/data/sysdir/hbase-1.1.2/lib/jaxb-impl-2.2.3-1.jar:/data/sysdir/hbase-1.1.2/lib/jcodings-1.0.8.jar:/data/sysdir/hbase-1.1.2/lib/jersey-client-1.9.jar:/data/sysdir/hbase-1.1.2/lib/jersey-core-1.9.jar:/data/sysdir/hbase-1.1.2/lib/jersey-guice-1.9.jar:/data/sysdir/hbase-1.1.2/lib/jersey-json-1.9.jar:/data/sysdir/hbase-1.1.2/lib/jersey-server-1.9.jar:/data/sysdir/hbase-1.1.2/lib/jets3t-0.9.0.jar:/data/sysdir/hbase-1.1.2/lib/jettison-1.3.3.jar:/data/sysdir/hbase-1.1.2/lib/jetty-6.1.26.jar:/data/sysdir/hbase-1.1.2/lib/jetty-sslengine-6.1.26.jar:/data/sysdir/hbase-1.1.2/lib/jetty-util-6.1.26.jar:/data/sysdir/hbase-1.1.2/lib/joni-2.1.2.jar:/data/sysdir/hbase-1.1.2/lib/jruby-complete-1.6.8.jar:/data/sysdir/hbase-1.1.2/lib/jsch-0.1.42.jar:/data/sysdir/hbase-1.1.2/lib/jsp-2.1-6.1.14.jar:/data/sysdir/hbase-1.1.2/lib/jsp-api-2.1-6.1.14.jar:/data/sysdir/hbase-1.1.2/lib/jsr305-1.3.9.jar:/data/sysdir/hbase-1.1.2/lib/junit-4.11.jar:/data/sysdir/hbase-1.1.2/lib/leveldbjni-all-1.8.jar:/data/sysdir/hbase-1.1.2/lib/libthrift-0.9.0.jar:/data/sysdir/hbase-1.1.2/lib/log4j-1.2.17.jar:/data/sysdir/hbase-1.1.2/lib/metrics-core-2.2.0.jar:/data/sysdir/hbase-1.1.2/lib/netty-3.2.4.Final.jar:/data/sysdir/hbase-1.1.2/lib/netty-all-4.0.23.Final.jar:/data/sysdir/hbase-1.1.2/lib/paranamer-2.3.jar:/data/sysdir/hbase-1.1.2/lib/protobuf-java-2.5.0.jar:/data/sysdir/hbase-1.1.2/lib/servlet-api-2.5-6.1.14.jar:/data/sysdir/hbase-1.1.2/lib/servlet-api-2.5.jar:/data/sysdir/hbase-1.1.2/lib/slf4j-api-1.7.7.jar:/data/sysdir/hbase-1.1.2/lib/slf4j-log4j12-1.7.5.jar:/data/sysdir/hbase-1.1.2/lib/snappy-java-1.0.4.1.jar:/data/sysdir/hbase-1.1.2/lib/spymemcached-2.11.6.jar:/data/sysdir/hbase-1.1.2/lib/xmlenc-0.52.jar:/data/sysdir/hbase-1.1.2/lib/xz-1.0.jar:/data/sysdir/hbase-1.1.2/lib/zookeeper-3.4.6.jar:/data/sysdir/hadoop-2.4.1-hbase/etc/hadoop:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-net-3.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jets3t-0.9.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-io-2.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/httpclient-4.2.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-compress-1.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/asm-3.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-collections-3.2.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jettison-1.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-logging-1.1.3.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-codec-1.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-digester-1.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jsr305-1.3.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/activation-1.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/xmlenc-0.52.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jetty-6.1.26.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/log4j-1.2.17.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/netty-3.6.2.Final.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/stax-api-1.0-2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/hadoop-auth-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/hadoop-annotations-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jersey-core-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/avro-1.7.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-cli-1.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jetty-util-6.1.26.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jersey-server-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/httpcore-4.2.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/paranamer-2.3.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jsch-0.1.42.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/guava-11.0.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-configuration-1.6.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/mockito-all-1.8.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jersey-json-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-el-1.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jsp-api-2.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/servlet-api-2.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-httpclient-3.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/zookeeper-3.4.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-math3-3.1.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-lang-2.6.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/junit-4.8.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/xz-1.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/hadoop-common-2.4.1-tests.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/hadoop-common-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/hadoop-common-2.4.1-path-1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/hadoop-lzo-0.4.20-SNAPSHOT.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/common/hadoop-nfs-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/commons-io-2.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/asm-3.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/guava-11.0.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/commons-el-1.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/hadoop-hdfs-2.4.1-patch-1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/hadoop-hdfs-2.4.1-tests.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/hdfs/hadoop-hdfs-nfs-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/commons-io-2.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/javax.inject-1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/asm-3.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jline-0.9.94.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jettison-1.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/commons-codec-1.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/activation-1.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jetty-6.1.26.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/log4j-1.2.17.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jersey-core-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/commons-cli-1.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jersey-server-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/aopalliance-1.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jackson-jaxrs-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/guava-11.0.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jersey-json-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jackson-xc-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/servlet-api-2.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/zookeeper-3.4.5.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/commons-lang-2.6.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/guice-3.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/xz-1.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/lib/jersey-client-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-common-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-server-tests-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-client-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-server-common-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/yarn/hadoop-yarn-api-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/hadoop-snappy-0.0.1-SNAPSHOT.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/javax.inject-1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/asm-3.2.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/hadoop-annotations-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/junit-4.10.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/guice-3.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/lib/xz-1.0.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.4.1.jar:/data/sysdir/hadoop-2.4.1-hbase/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.1-tests.jar:/data/sysdir/hadoop-2.4.1-hbase/contrib/capacity-scheduler/*.jar
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/data/sysdir/hadoop-2.4.1-hbase/lib/native
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.13.6
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/data/home/hbase
2016-08-14 22:17:03,178 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/data/sysdir/hbase-1.1.2/conf
2016-08-14 22:17:03,180 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.201.52:2181,192.168.201.53:2181,192.168.201.63:2181,192.168.201.64:2181,192.168.201.65:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@38987d26
2016-08-14 22:17:03,206 INFO  [main-SendThread(192.168.201.65:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.201.65/192.168.201.65:2181. Will not attempt to authenticate using SASL (unknown error)
2016-08-14 22:17:03,228 INFO  [main-SendThread(192.168.201.65:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.201.65/192.168.201.65:2181, initiating session
2016-08-14 22:17:03,234 INFO  [main-SendThread(192.168.201.65:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.201.65/192.168.201.65:2181, sessionid = 0x556683846220a79, negotiated timeout = 30000

{quote}

Then i looked into zk's log, i found these :
{quote}
8/14/16 10:17:03 PM CST session 0x556683846220a79 cxid 0x0 zxid 0xf73ca5859 createSession 30000
8/14/16 10:17:03 PM CST session 0x556683846220a79 cxid 0x1 zxid 0xf73ca585a delete '/olapHbase/rs/olap3.data.lq%2C16020%2C1470799848293
{quote}
And i looked master logs as below : 
{quote}
2016-08-14 22:16:43,942 INFO  [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table KYLIN_F5O605Z3QZ state from null to ENABLING
2016-08-14 22:16:43,952 INFO  [ProcedureExecutorThread-0] master.AssignmentManager: Bulk assigning 1 region(s) across 4 server(s), round-robin=true
2016-08-14 22:16:43,953 INFO  [olap1.data.lq,16000,1469605579716-GeneralBulkAssigner-2] master.AssignmentManager: Assigning 1 region(s) to olap3.data.lq,16020,1470799848293
2016-08-14 22:16:43,958 INFO  [olap1.data.lq,16000,1469605579716-GeneralBulkAssigner-2] master.RegionStates: Transition {6e207f0307d4213d6c0e195115df1b8d state=OFFLINE, ts=1471184203953, server=null} to {6e207f0307d4213d6c0e195115df1b8d state=PENDING_OPEN, ts=1471184203958, server=olap3.data.lq,16020,1470799848293}
2016-08-14 22:16:43,985 INFO  [AM.ZK.Worker-pool2-t4001] master.RegionStates: Transition {6e207f0307d4213d6c0e195115df1b8d state=PENDING_OPEN, ts=1471184203958, server=olap3.data.lq,16020,1470799848293} to {6e207f0307d4213d6c0e195115df1b8d state=OPENING, ts=1471184203985, server=olap3.data.lq,16020,1470799848293}
2016-08-14 22:17:03,238 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [olap3.data.lq,16020,1470799848293]
2016-08-14 22:17:03,240 WARN  [MASTER_SERVER_OPERATIONS-olap1:16000-2] hbase.HBaseConfiguration: Config option ""hbase.regionserver.lease.period"" is deprecated. Instead, use ""hbase.client.scanner.timeout.period""
2016-08-14 22:17:04,008 INFO  [ProcedureExecutorThread-0] master.AssignmentManager: Bulk assigning done
2016-08-14 22:17:04,011 INFO  [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table KYLIN_F5O605Z3QZ state from ENABLING to ENABLED
2016-08-14 22:17:04,251 INFO  [MASTER_SERVER_OPERATIONS-olap1:16000-2] handler.ServerShutdownHandler: Splitting logs for olap3.data.lq,16020,1470799848293 before assignment; region count=2033
2016-08-14 22:17:04,261 INFO  [MASTER_SERVER_OPERATIONS-olap1:16000-2] master.SplitLogManager: dead splitlog workers [olap3.data.lq,16020,1470799848293]
2016-08-14 22:17:04,263 INFO  [MASTER_SERVER_OPERATIONS-olap1:16000-2] master.SplitLogManager: started splitting 2 logs in [hdfs://olapHbaseCluster:8020/hbase/WALs/olap3.data.lq,16020,1470799848293-splitting] for [olap3.data.lq,16020,1470799848293]
2016-08-14 22:17:04,268 INFO  [main-EventThread] coordination.SplitLogManagerCoordination: task /olapHbase/splitWAL/WALs%2Folap3.data.lq%2C16020%2C1470799848293-splitting%2Folap3.data.lq%252C16020%252C1470799848293.default.1471182516751 acquired by olap1.data.lq,16020,1470799983323
2016-08-14 22:17:04,277 INFO  [main-EventThread] coordination.SplitLogManagerCoordination: task /olapHbase/splitWAL/WALs%2Folap3.data.lq%2C16020%2C1470799848293-splitting%2Folap3.data.lq%252C16020%252C1470799848293.default.1471180125256 acquired by olap2.data.lq,16020,1470800075996
2016-08-14 22:17:04,288 WARN  [olap1.data.lq,16000,1469605579716_ChoreService_1] hbase.HBaseConfiguration: Config option ""hbase.regionserver.lease.period"" is deprecated. Instead, use ""hbase.client.scanner.timeout.period""
 ....

{quote}

I'm not falimliar with hbase , may be it's not a bug , but i can not figure out why this happend. I will be grateful if somebody can help me.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16470,Two background activities which changes table regions can interfere with HBase hbck repair activity (potentially).,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16468,"Little nit, but no reason to create the extra objects.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16472,"When I created a table in HBase and then tried running create statement in phoenix. Phoenix returned me the following error. 

procedure.ModifyTableProcedure: Error trying to modify table=t21sample state=MODIFY_TABLE_PREPARE
org.apache.hadoop.hbase.TableNotDisabledException: t21sample
        at org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.prepareModify(ModifyTableProcedure.java:298)
        at org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.executeFromState(ModifyTableProcedure.java:98)
        at org.apache.hadoop.hbase.master.procedure.ModifyTableProcedure.executeFromState(ModifyTableProcedure.java:54)
        at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:107)
        at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:400)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:869)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:673)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:626)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$200(ProcedureExecutor.java:70)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$1.run(ProcedureExecutor.java:413)

The same error occurred in the case of altering an existing table. 
I some how managed to create a table in Phoenix by the same sequence if I disable the table after creating it. The phoenix returned me table disabled error. But after enabling the table in hbase, the table was created in phoenix, same worked for alter statement as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16457,"when i start the hbase cluster, the master node can't start with the error as follow:
2016-08-19 19:06:53,361 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_SERVER_SHUTDOWN
java.io.IOException: Server is stopped
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:193)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-08-19 19:06:53,364 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_SERVER_SHUTDOWN
java.io.IOException: Server is stopped
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:193)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-08-19 19:06:53,362 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_SERVER_SHUTDOWN
java.io.IOException: failed log splitting for vm-syscloud-s5,60020,1471599889568, will retry
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.resubmit(ServerShutdownHandler.java:346)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:219)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: error or interrupted while splitting logs in [hdfs://nameservice1/hbase/WALs/vm-syscloud-s5,60020,1471599889568-splitting] Task = installed = 31 done = 0 error = 0
	at org.apache.hadoop.hbase.master.SplitLogManager.splitLogDistributed(SplitLogManager.java:291)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:391)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:364)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:286)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:212)
	... 4 more
2016-08-19 19:06:53,361 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_SERVER_SHUTDOWN
java.io.IOException: failed log splitting for vm-syscloud-s3,60020,1471599886484, will retry
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.resubmit(ServerShutdownHandler.java:346)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:219)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: error or interrupted while splitting logs in [hdfs://nameservice1/hbase/WALs/vm-syscloud-s3,60020,1471599886484-splitting] Task = installed = 3 done = 0 error = 0
	at org.apache.hadoop.hbase.master.SplitLogManager.splitLogDistributed(SplitLogManager.java:291)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:391)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:364)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:286)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:212)
	... 4 more
2016-08-19 19:06:53,361 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_SERVER_SHUTDOWN
java.io.IOException: failed log splitting for vm-syscloud-s2,60020,1471599886831, will retry
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.resubmit(ServerShutdownHandler.java:346)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:219)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: error or interrupted while splitting logs in [hdfs://nameservice1/hbase/WALs/vm-syscloud-s2,60020,1471599886831-splitting] Task = installed = 30 done = 0 error = 0
	at org.apache.hadoop.hbase.master.SplitLogManager.splitLogDistributed(SplitLogManager.java:291)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:391)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:364)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:286)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:212)
	... 4 more
2016-08-19 19:06:53,367 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_SERVER_SHUTDOWN
java.io.IOException: Server is stopped
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:193)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-08-19 19:06:53,579 INFO org.apache.hadoop.hbase.master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped

i try to delete the log files in the HDFS,but i don't have permission because
the files owner user is hbase. i don't know how to solve this problem. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16424,"cygpath: can't convert empty path
cygpath: can't convert empty path
2016-08-16 13:25:30,999 ERROR [main] util.Shell: Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
        at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
        at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
        at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
        at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
        at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1699)
        at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKPropsFromHbaseConfig(ZKConfig.java:151)
        at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:67)
        at org.apache.hadoop.hbase.zookeeper.ZKServerTool.readZKNodes(ZKServerTool.java:47)
        at org.apache.hadoop.hbase.zookeeper.ZKServerTool.main(ZKServerTool.java:70)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16136,Check components are alive when closing RegionServer .,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16104,Support ColumnFamily when use PerformanceEvaluation to testing reading and writing performance with a table existed . ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5222,"After running ""stop_replication"" in the hbase shell on our slave cluster we saw replication continue for weeks. Turns out that the replication sink is missing a check to get the replication state and therefore continued to write.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16406,"The code i wrote belows:
	public static void addRow(String tableName, String row,String columnFamily, String column, String value) throws Exception {
            HTable table = new HTable(conf,tableName);
            Put put = new Put(Bytes.toBytes(row));
            put.add(Bytes.toBytes(columnFamily), Bytes.toBytes(column),Bytes.toBytes(value));
            table.put(put);
            table.close();
    }
 public static void main(String[] args){
    	String tableName = ""test1"";
    	String[] columnFamilys = { ""info"", ""course"" };
    	//createTable(tableName,columnFamilys);
    	try {
			addRow(tableName, ""tht"", ""info"", ""age"", ""20"");
//			addRow(tableName, ""tht"", ""info"", ""sex"", ""boy"");
	        addRow(tableName, ""tht"", ""course"", ""china"", ""97"");
//	        addRow(tableName, ""tht"", ""course"", ""math"", ""128"");
//	        addRow(tableName, ""tht"", ""course"", ""english"", ""85"");
		} catch (Exception e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
And The error:
org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: test1: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:228)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$1700(AsyncProcess.java:208)
	at org.apache.hadoop.hbase.client.AsyncProcess.waitForAllPreviousOpsAndReset(AsyncProcess.java:1700)
	at org.apache.hadoop.hbase.client.BufferedMutatorImpl.backgroundFlushCommits(BufferedMutatorImpl.java:208)
	at org.apache.hadoop.hbase.client.BufferedMutatorImpl.flush(BufferedMutatorImpl.java:183)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1449)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:1040)
	at hbase2.testCreate.addRow(testCreate.java:45)
	at hbase2.testCreate.main(testCreate.java:53)
How can i solve it?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16394,"My cluster dead one regionserver  because of ""Compaction is trying to add a bad range""
Here the log:
[2016-08-09T18:30:19.094+08:00] [INFO] regionserver.ReplicationSource : Log hdfs://athene/hbase/oldWALs/MJQ-HBASE-ATHENE-11139%2C16020%2C1470729882622.default.1470736608897 was moved to hdfs://athene/hbase/oldWA     Ls/MJQ-HBASE-ATHENE%2C16020%2C1470729882622.default.1470736608897
[2016-08-09T18:30:30.225+08:00] [INFO] regionserver.MemStoreFlusher : Waited 90070ms on a compaction to clean up 'TOO MANY STORE FILES'; waited long enough... proceeding with flush of tjs4:popt_info,160608008474430,147073716071     1.7900baab5204e4f36fa49379c30cd584.
[2016-08-09T18:30:30.226+08:00] [INFO] regionserver.HRegion : Started memstore flush for tjs4:popt_info,160608008474430,1470737160711.7900baab5204e4f36fa49379c30cd584., current region memstore size 769.41 MB, and 1/1 column fam     ilies' memstores are being flushed.
[2016-08-09T18:30:30.549+08:00] [INFO] regionserver.StripeStoreFileManager : 3 conflicting files (likely created by a flush)  of size 156153021 are moved to L0 due to concurrent stripe change
[2016-08-09T18:30:31.199+08:00] [INFO] regionserver.HStore : Completed compaction of 203 file(s) in c of tjs4:popt_info,160608008474430,1470737160711.7900baab5204e4f36fa49379c30cd584. into 20347d203d09442cac30c42b424adda6(size=     3.0 G), ded362eab9cf4a819675cd35992d4974(size=3.0 G), 281b1039ed2643679e5b0a3820f5059d(size=2.4 G), total size for store is 8.6 G. This selection was in queue for 0sec, and took 10mins, 16sec to execute.
[2016-08-09T18:30:31.200+08:00] [INFO] regionserver.CompactSplitThread : Completed compaction: Request = regionName=tjs4:popt_info,160608008474430,1470737160711.7900baab5204e4f36fa49379c30cd584., storeName=c, fileCount=203, fil     eSize=7.2 G, priority=-3, time=5388162916126535; duration=10mins, 16sec
[2016-08-09T18:30:31.201+08:00] [INFO] regionserver.HRegion : Starting compaction on ci in region ad_union:union_click,3487f383ad484bcbb5cef727b69cec2a,1466484980245.c5772fc60c54f64cc977ba9cc01d74ad.
[2016-08-09T18:30:31.201+08:00] [INFO] regionserver.HStore : Starting compaction of 14 file(s) in ci of ad_union:union_click,3487f383ad484bcbb5cef727b69cec2a,1466484980245.c5772fc60c54f64cc977ba9cc01d74ad. into tmpdir=hdfs://at     hene/hbase/data/ad_union/union_click/c5772fc60c54f64cc977ba9cc01d74ad/.tmp, totalSize=75.0 M
[2016-08-09T18:30:31.206+08:00] [INFO] hfile.CacheConfig : blockCache=org.apache.hadoop.hbase.io.hfile.CombinedBlockCache@52659482, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=fal     se, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
[2016-08-09T18:30:32.893+08:00] [INFO] regionserver.ReplicationSource : Log hdfs://athene/hbase/oldWALs/MJQ-HBASE-ATHENE-11139l%2C16020%2C1470729882622.default.1470736612825 was moved to hdfs://athene/hbase/oldWA     Ls/MJQ-HBASE-ATHENE-11139.%2C16020%2C1470729882622.default.1470736612825
[2016-08-09T18:30:34.373+08:00] [INFO] regionserver.HStore : Added hdfs://athene/hbase/data/tjs4/popt_info/7900baab5204e4f36fa49379c30cd584/c/775e8956cd2a48aaae70b9eded4457e9, entries=4336457, sequenceid=582528, filesize=48.7 M
[2016-08-09T18:30:34.373+08:00] [FATAL] regionserver.HRegionServer : ABORTING region server MJQ-HBASE-ATHENE-11139.,16020,1470729882622: Replay of WAL required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: tjs4:popt_info,160608008474430,1470737160711.7900baab5204e4f36fa49379c30cd584.
at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2354)
at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2057)
at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2019)
at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1911)
at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1837)
at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$800(MemStoreFlusher.java:75)
at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
at java.lang.Thread.run(Thread.java:745)
  Caused by: java.io.IOException: Compaction is trying to add a bad range.
at org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$CompactionOrFlushMergeCopy.processNewCandidateStripes(StripeStoreFileManager.java:837)
at org.apache.hadoop.hbase.regionserver.StripeStoreFileManager$CompactionOrFlushMergeCopy.mergeResults(StripeStoreFileManager.java:672)
at org.apache.hadoop.hbase.regionserver.StripeStoreFileManager.insertNewFiles(StripeStoreFileManager.java:144)
at org.apache.hadoop.hbase.regionserver.HStore.updateStorefiles(HStore.java:1052)
at org.apache.hadoop.hbase.regionserver.HStore.access$500(HStore.java:128)
at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.commit(HStore.java:2231)
at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2315)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16343,"When enabled replication,we found a large number of error logs.Is the cluster configuration incorrect?


2016-08-03 10:46:21,721 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Opening log for replication dn7%2C60020%2C1470136216957.1470192327030 at 16999670
2016-08-03 10:46:21,723 WARN org.apache.hadoop.hdfs.DFSClient: BlockReaderLocal requested with incorrect offset:  Offset 0 and length 17073479 don't match block blk_4137524355009640437_53760530 ( blockLen 16999670 )
2016-08-03 10:46:21,723 WARN org.apache.hadoop.hdfs.DFSClient: BlockReaderLocal: Removing blk_4137524355009640437_53760530 from cache because local file /sdd/hdfs/dfs/data/blocksBeingWritten/blk_4137524355009640437 could not be opened.
2016-08-03 10:46:21,724 INFO org.apache.hadoop.hdfs.DFSClient: Failed to read block blk_4137524355009640437_53760530 on local machinejava.io.IOException:  Offset 0 and length 17073479 don't match block blk_4137524355009640437_53760530 ( blockLen 16999670 )
        at org.apache.hadoop.hdfs.BlockReaderLocal.<init>(BlockReaderLocal.java:287)
        at org.apache.hadoop.hdfs.BlockReaderLocal.newBlockReader(BlockReaderLocal.java:171)
        at org.apache.hadoop.hdfs.DFSClient.getLocalBlockReader(DFSClient.java:358)
        at org.apache.hadoop.hdfs.DFSClient.access$800(DFSClient.java:74)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:2073)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2224)
        at java.io.DataInputStream.read(DataInputStream.java:149)
        at java.io.DataInputStream.readFully(DataInputStream.java:195)
        at java.io.DataInputStream.readFully(DataInputStream.java:169)
        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1508)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1486)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1475)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1470)
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader$WALReader.<init>(SequenceFileLogReader.java:55)
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.init(SequenceFileLogReader.java:178)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.getReader(HLog.java:734)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.openReader(ReplicationHLogReaderManager.java:69)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.openReader(ReplicationSource.java:574)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:364)

2016-08-03 10:46:21,724 INFO org.apache.hadoop.hdfs.DFSClient: Try reading via the datanode on /192.168.7.139:50010",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16203,"in hbase with kerbose and authorization on, I enter hbase shell with a hbase super user, and do the following steps:
{quote}
1. grant  ""newUser/slave2@HADOOP.COM""
""newUser/slave2@HADOOP.COM"" is one of the kerbose principles

2. exit hbase shell

3. enter hbase shell again with principle ""newUser/slave2@HADOOP.COM""

4. scan 't1'
t1 is one of the table in hbase
{quote}

the result is: AccessDeniedException 

after debug regionServer code, I find the problem is:
{quote}
1. when we grant the global admin to ""newUser/slave2@HADOOP.COM"", TableAuthManager store this info with the whole name, newUser/slave2@HADOOP.COM

2. when we enter hbase shell with principle ""newUser/slave2@HADOOP.COM"" and scan table, regionServer will do do authorization check, such as check if the user is superUser
when do this check, use the short name(newUser), not the whole name(newUser/slave2@HADOOP.COM)

{quote}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16202,"HBASE-15353 added a separate metric for tracking the number of CallQueueTooBigExceptions, but only went in to 1.4+.  Since CQTBE is already in 1.2+, it would be nice to at least get this in the upcoming 1.3.0 release.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16151,"here is the code and logs below:
HTable table = new HTable(tempConf,tableName);
LoadIncrementalHFiles loader = new LoadIncrementalHFiles(conf);
loader.doBulkLoad(dir, table);
13:49:15,806 DEBUG ProtobufRpcEngine:253 - Call: getBlockLocations took 0ms
13:49:15,821 DEBUG DFSClient:273 - newInfo = LocatedBlocks{
  fileLength=1051
  underConstruction=false
  blocks=[LocatedBlock{BP-644339120-172.30.115.58-1458531863647:blk_1075272092_1543930; getBlockSize()=1051; corrupt=false; offset=0; locs=[172.30.115.59:50010, 172.30.115.58:50010, 172.30.115.60:50010]; storageIDs=[DS-d09ae035-279c-408c-8272-d84eb29f3e3b, DS-30754a89-526a-40ca-b0e0-f4400b0527bb, DS-856412f0-e865-43c0-bd60-4650b7ff275d]; storageTypes=[DISK, DISK, DISK]}]
  lastLocatedBlock=LocatedBlock{BP-644339120-172.30.115.58-1458531863647:blk_1075272092_1543930; getBlockSize()=1051; corrupt=false; offset=0; locs=[172.30.115.59:50010, 172.30.115.58:50010, 172.30.115.60:50010]; storageIDs=[DS-d09ae035-279c-408c-8272-d84eb29f3e3b, DS-30754a89-526a-40ca-b0e0-f4400b0527bb, DS-856412f0-e865-43c0-bd60-4650b7ff275d]; storageTypes=[DISK, DISK, DISK]}
  isLastBlockComplete=true}
13:49:15,821 DEBUG Client:1025 - IPC Client (1094238221) connection to /172.30.115.58:8020 from uatxj990267 sending #4
13:49:15,821 DEBUG Client:1082 - IPC Client (1094238221) connection to /172.30.115.58:8020 from uatxj990267 got value #4
13:49:15,821 DEBUG ProtobufRpcEngine:253 - Call: getFileInfo took 0ms
13:49:15,821 DEBUG DFSClient:961 - Connecting to datanode 172.30.115.59:50010
13:49:15,821 DEBUG Client:1025 - IPC Client (1094238221) connection to /172.30.115.58:8020 from uatxj990267 sending #5
13:49:15,821 DEBUG Client:1082 - IPC Client (1094238221) connection to /172.30.115.58:8020 from uatxj990267 got value #5
13:49:15,821 DEBUG ProtobufRpcEngine:253 - Call: getServerDefaults took 0ms
13:49:15,837 DEBUG SaslDataTransferClient:244 - SASL client skipping handshake in unsecured configuration for addr = /172.30.115.59, datanodeId = 172.30.115.59:50010
13:49:15,899 DEBUG DFSClient:961 - Connecting to datanode 172.30.115.59:50010
13:49:15,915  INFO LoadIncrementalHFiles:517 - Trying to load hfile=hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68 first=14672656058391 last=14672656058393
13:49:15,946 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:49:16,258 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,163216552663,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:49:16,258 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:49:16,773 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,163216552663,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:49:16,773 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:49:17,788 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 9,4  replyHeader:: 9,163216552666,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:49:17,788 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:49:19,801 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 10,4  replyHeader:: 10,163216552668,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:49:19,801 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:49:23,811 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 11,4  replyHeader:: 11,163216552675,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:49:23,811 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:49:25,824 DEBUG Client:1185 - IPC Client (1094238221) connection to /172.30.115.58:8020 from uatxj990267: closed
13:49:25,824 DEBUG Client:980 - IPC Client (1094238221) connection to /172.30.115.58:8020 from uatxj990267: stopped, remaining connections 0
13:49:33,874 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 12,4  replyHeader:: 12,163216552690,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:49:33,874 DEBUG ClientCnxn:717 - Got ping response for sessionid: 0x254ba19dd2d97eb after 1ms
13:49:33,874 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:49:43,935 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 13,4  replyHeader:: 13,163216552705,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:49:43,935 DEBUG ClientCnxn:717 - Got ping response for sessionid: 0x254ba19dd2d97eb after 1ms
13:49:43,935 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:49:53,949 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 14,4  replyHeader:: 14,163216552723,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:49:53,949 DEBUG ClientCnxn:717 - Got ping response for sessionid: 0x254ba19dd2d97eb after 1ms
13:49:53,951 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:50:03,994 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 15,4  replyHeader:: 15,163216552738,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:50:03,996 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:50:04,193 DEBUG ClientCnxn:717 - Got ping response for sessionid: 0x254ba19dd2d97eb after 200ms
13:50:17,326 DEBUG ClientCnxn:717 - Got ping response for sessionid: 0x254ba19dd2d97eb after 0ms
13:50:24,172 DEBUG ClientCnxn:818 - Reading reply sessionid:0x254ba19dd2d97eb, packet:: clientPath:null serverPath:null finished:false header:: 16,4  replyHeader:: 16,163216552771,0  request:: '/hbase-unsecure/table/emp,F  response:: #ffffffff000146d61737465723a363030303017ffffff951415ffffff9f372d375042554680,s{163215998528,163216219499,1467010385319,1467103321910,8,0,0,0,31,0,163215998528} 
13:50:24,175 DEBUG LoadIncrementalHFiles:618 - Going to connect to server region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335 for row  with hfile group [{[B@281d9e15,hdfs://172.30.115.58:8020/apps/hbase/data/info/info/32d34121d62b4327a8303ee55bb98b68}]
13:50:24,182  INFO RpcRetryingCaller:129 - Call exception, tries=10, retries=35, started=68251 ms ago, cancelled=false, msg=row '' on table 'emp' at region=emp,,1467010385314.eb65b8443faee7c72ee1f003f1b8e7ba., hostname=hadoop002.icccuat.com,60020,1467195299232, seqNum=335
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14189,"The original description is ambiguous. I think i will rewrite it.
Let's see {{BlockCache}} constructor firstly
{code}
  public CacheConfig(Configuration conf, HColumnDescriptor family) {
    this(CacheConfig.instantiateBlockCache(conf),
        family.isBlockCacheEnabled(),
        family.isInMemory(),
        // For the following flags we enable them regardless of per-schema settings
        // if they are enabled in the global configuration.
        conf.getBoolean(CACHE_BLOCKS_ON_WRITE_KEY,
            DEFAULT_CACHE_DATA_ON_WRITE) || family.isCacheDataOnWrite(),
        conf.getBoolean(CACHE_INDEX_BLOCKS_ON_WRITE_KEY,
            DEFAULT_CACHE_INDEXES_ON_WRITE) || family.isCacheIndexesOnWrite(),
        conf.getBoolean(CACHE_BLOOM_BLOCKS_ON_WRITE_KEY,
            DEFAULT_CACHE_BLOOMS_ON_WRITE) || family.isCacheBloomsOnWrite(),
        conf.getBoolean(EVICT_BLOCKS_ON_CLOSE_KEY,
            DEFAULT_EVICT_ON_CLOSE) || family.isEvictBlocksOnClose(),
        conf.getBoolean(CACHE_DATA_BLOCKS_COMPRESSED_KEY, DEFAULT_CACHE_DATA_COMPRESSED),
        conf.getBoolean(PREFETCH_BLOCKS_ON_OPEN_KEY,
            DEFAULT_PREFETCH_ON_OPEN) || family.isPrefetchBlocksOnOpen(),
        conf.getBoolean(HColumnDescriptor.CACHE_DATA_IN_L1,
            HColumnDescriptor.DEFAULT_CACHE_DATA_IN_L1) || family.isCacheDataInL1(),
        conf.getBoolean(DROP_BEHIND_CACHE_COMPACTION_KEY,DROP_BEHIND_CACHE_COMPACTION_DEFAULT)
     );
  }
{code}

If we dig in it,  we will see {{CacheConfig.cacheDataOnRead}} is used to accept {{family.isBlockCacheEnabled()}}.  
I think it is confused as comments about {{cacheDataOnRead}}
{code}
  /**
   * Whether blocks should be cached on read (default is on if there is a
   * cache but this can be turned off on a per-family or per-request basis).
   * If off we will STILL cache meta blocks; i.e. INDEX and BLOOM types.
   * This cannot be disabled.
   */
  private boolean cacheDataOnRead;
{code}

So i think we should use another variable to represent for {{family.isBlockCacheEnabled()}}.

The secondary point is we use 'or' to decide {{cacheDataOnWrite}} is on/off when both CF and global has this setting.
{code}
conf.getBoolean(CACHE_BLOCKS_ON_WRITE_KEY,
            DEFAULT_CACHE_DATA_ON_WRITE) || family.isCacheDataOnWrite()
{code}

IMO we should use CF Level setting to override global setting. 


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15973,"In a production cluster, we have noticed a case where flushes were happening for 200-400KB in sizes. Turns out the periodic memstore flusher is force flushing because cells with older timestamps (in this case days old) were being inserted. 

We have periodic memstore flusher with 1 hour defaulted, so in a case where replication is lagging, or phoenix secondary index rebuild or the user doing back-in-time inserts with cell timestamps older than 1 hour, we will flush extremely frequently. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6103,"Currently HBaseServer is running with a single listener thread, which is responsible for accepting the connection, reading the data from network channel, deserializing the data into writable objects and handover to the IPC handler threads. 

When there are multiple hbase clients connecting to the region server (HBaseServer) and reading/writing a large set of data, the listener and the respond thread will be performance bottleneck. 

So the solution is to deserialize the data for each ipc connection in parallel for HBaseServer

BTW, it is also one of the reasons that the parallel scanning from multiple clients is far slower than single client case.







",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15874,"regionserver can't restart anyway,
anytime I start regionserver,it crushes. the hbase version is 1.0.0,revision=6c98bff7b719efdb16f71606f3b7d8229445eb8
regionserver's log is :
ava.lang.NullPointerException
        at org.apache.hadoop.hbase.protobuf.generated.WALProtos$FamilyScope$Builder.setScopeType(WALProtos.java:3939)
        at org.apache.hadoop.hbase.wal.WALKey.getBuilder(WALKey.java:503)
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.append(ProtobufLogWriter.java:118)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1962)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1843)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1796)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
2016-05-22 19:24:57,435 FATAL [regionserver/polaris-2/10.0.52.25:16020.logRoller] regionserver.HRegionServer: ABORTING region server polaris-2,16020,1463916286917: IOE in log roller
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.ensureIOException(FSHLog.java:2002)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.blockOnSync(FSHLog.java:1437)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.replaceWriter(FSHLog.java:956)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:711)
        at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:137)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hbase.protobuf.generated.WALProtos$FamilyScope$Builder.setScopeType(WALProtos.java:3939)
        at org.apache.hadoop.hbase.wal.WALKey.getBuilder(WALKey.java:503)
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.append(ProtobufLogWriter.java:118)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1962)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1843)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1796)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        ... 1 more
2016-05-22 19:24:57,436 FATAL [regionserver/polaris-2/10.0.52.25:16020.logRoller] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: [org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint]
2016-05-22 19:24:57,452 INFO  [regionserver/polaris-2/10.0.52.25:16020.logRoller] regionserver.HRegionServer: Dump of metrics as JSON on abort: {",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14363,"Currently HBCK just prints a vague ""Empty REGIONINFO_QUALIFIER found"" warning, and does not print the row it found that on. While fixing this is easy thanks to HBCK, some more detail (say the row/region ID) would be good to print, to avoid people manually scanning meta to obtain the very same info.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15692,"we encounter this problem on our production cluster.   
This is exception in HMaster.log
{code}
2016-04-22 11:05:06,390 ERROR [f04,16000,1459941011479_ChoreService_3] snapshot.SnapshotHFileCleaner: Exception while checking if files were valid, keeping them just in case.
org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException: Couldn't read snapshot info from:hdfs://f04/hbase/.hbase-snapshot/.tmp/frog_stastic_2016-04-07/.snapshotinfo
        at org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.readSnapshotInfo(SnapshotDescriptionUtils.java:295)
        at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.getHFileNames(SnapshotReferenceUtil.java:328)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner$1.filesUnderSnapshot(SnapshotHFileCleaner.java:85)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.getSnapshotsInProgress(SnapshotFileCache.java:303)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.getUnreferencedFiles(SnapshotFileCache.java:194)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.getDeletableFiles(SnapshotHFileCleaner.java:62)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteFiles(CleanerChore.java:233)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:157)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:124)
        at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: File does not exist: /hbase/.hbase-snapshot/.tmp/frog_stastic_2016-04-07/.snapshotinfo
        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:64)
        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:54)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1795)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1738)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1718)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1690)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:519)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:337)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

        at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
        at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
        at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
        at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1167)
        at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1155)
        at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1145)
        at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:268)
        at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:235)
        at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:228)
        at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1318)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:293)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:289)
{code}

I notice the code
{code: title=SnapshotDescriptionUtils#writeSnapshotInfo}
      // if we get an exception, try to remove the snapshot info
      if (!fs.delete(snapshotInfo, false)) {
        String msg = ""Couldn't delete snapshot info file: "" + snapshotInfo;
        LOG.error(msg);
        throw new IOException(msg);
      }
{code}

IMO we should delete the entire relates snapshot dir when we write failed. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15642,"This happened after we upgrade our cluster from 0.98.6 to 0.98.17. 
The number should be reduced,   but it always increases from original 20+ to 49 now. (yesterday it was 48)
Need to dig.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15404,"On running hbase pe --nomapred increment/append 10,  i see the following output where it seems like threads are executing operations serially. In the UI too, only one RS is getting requests at a time.
{noformat}
6/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-1
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-2
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-8
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-0
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-4
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-6
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-7
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-5
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-9
16/03/05 22:26:15 INFO hbase.PerformanceEvaluation: Timed test starting in thread TestClient-3
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.48, min=390.00, max=163444.00, stdDev=892.64, 95th=1361.00, 99th=1605.00
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.53, min=366.00, max=163400.00, stdDev=885.49, 95th=1361.00, 99th=1605.00
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.41, min=402.00, max=163436.00, stdDev=891.54, 95th=1359.00, 99th=1602.41
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.51, min=399.00, max=163610.00, stdDev=892.40, 95th=1360.00, 99th=1600.00
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.59, min=393.00, max=162932.00, stdDev=887.65, 95th=1361.00, 99th=1604.00
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.26, min=385.00, max=163482.00, stdDev=891.71, 95th=1358.00, 99th=1599.00
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.51, min=383.00, max=163246.00, stdDev=888.07, 95th=1360.00, 99th=1605.00
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.45, min=385.00, max=163405.00, stdDev=886.65, 95th=1359.00, 99th=1604.00
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.38, min=400.00, max=163580.00, stdDev=887.28, 95th=1359.00, 99th=1602.00
16/03/05 22:27:54 INFO hbase.PerformanceEvaluation: 0/104857/1048576, latency mean=942.29, min=407.00, max=163403.00, stdDev=889.77, 95th=1357.00, 99th=1597.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.75, min=366.00, max=163400.00, stdDev=817.84, 95th=1363.00, 99th=1605.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.75, min=383.00, max=163246.00, stdDev=821.95, 95th=1363.00, 99th=1604.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.75, min=389.00, max=163444.00, stdDev=824.03, 95th=1364.00, 99th=1603.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.56, min=382.00, max=163403.00, stdDev=822.44, 95th=1363.00, 99th=1603.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.79, min=393.00, max=162932.00, stdDev=818.75, 95th=1365.00, 99th=1601.84
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.70, min=388.00, max=163436.00, stdDev=823.52, 95th=1364.00, 99th=1606.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.72, min=376.00, max=163405.00, stdDev=820.65, 95th=1364.00, 99th=1605.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.56, min=382.00, max=163482.00, stdDev=823.43, 95th=1363.00, 99th=1599.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.67, min=376.00, max=163580.00, stdDev=821.59, 95th=1364.00, 99th=1602.00
16/03/05 22:29:35 INFO hbase.PerformanceEvaluation: 0/209714/1048576, latency mean=950.77, min=390.00, max=163610.00, stdDev=823.88, 95th=1363.00, 99th=1600.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.21, min=369.00, max=162932.00, stdDev=787.36, 95th=1361.00, 99th=1595.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.18, min=374.00, max=163610.00, stdDev=791.11, 95th=1359.00, 99th=1594.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.30, min=367.00, max=163444.00, stdDev=802.21, 95th=1362.00, 99th=1597.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.38, min=366.00, max=163400.00, stdDev=799.61, 95th=1360.00, 99th=1596.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.31, min=375.00, max=163580.00, stdDev=802.77, 95th=1359.00, 99th=1596.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.12, min=388.00, max=163436.00, stdDev=791.34, 95th=1361.00, 99th=1598.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.13, min=368.00, max=163405.00, stdDev=788.29, 95th=1360.00, 99th=1598.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.35, min=383.00, max=163246.00, stdDev=801.26, 95th=1362.00, 99th=1599.00
16/03/05 22:31:16 INFO hbase.PerformanceEvaluation: 0/314571/1048576, latency mean=952.21, min=382.00, max=163403.00, stdDev=801.88, 95th=1359.00, 99th=1598.00
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15564,"I'm using org.apache.hadoop.hbase.mapreduce.HashTable to create hashes for use in SyncTable.  Occasionally, the job page in jobhistory will say the job succeeded, but in my filesystem, I see ""manifest.tmp"" instead of the expected ""manifest"".  According to the code[1], the job must have failed, but I don't see failure anywhere.  

[1]https://github.com/apache/hbase/blob/ad3feaa44800f10d102255a240c38ccf23a82d49/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HashTable.java#L739-L741",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13245,"Counts of deletes and puts ( called mutations in metrics ) are totally off.

The time for delete or mutate is really the time that a batch of mutations containing a put or delete. The same is true for count.

We should have:
* number of puts
* number of deletes
* time for batch mutations
* number of batch mutations
* histogram of number of mutations in each batch

That way it's less reading tea leaves and more explicit that things are batched and we don't have more fine grained info.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15546,Improvements needed to consistency logic.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15452,"In looking why we spent so much time in StoreScanner.next when doing a simple Phoenix count\(*) query I came across checkScanOrder. Not only is this a function dispatch (that the JIT would eventually inline), it also requires setting the prevKV member for every Cell encountered.

Removing that logic a yields measurable end-to-end improvement of 5-20% (in 0.98).
I will repeat this test on my work machine tomorrow.

I think we're stable enough to remove that check anyway.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15372,"Currently, we keep WAL file per table in backup site, this creates significant data duplication in case of many tables in a backup set. We have to keep all WAL files in a single place and keep track of WAL files involved per table/backup id as links (references) 

This is not only the data duplication issue, but a performance issue as well (we copy the same file over and over again for every table in a backup set). ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11352,"We are exporting a very large table.  The export snapshot job takes 7+ days to complete.  During that time we had to bounce HMaster.  When HMaster initializes, it initializes the SnapshotManager which subsequently deletes the .tmp directory.

If this happens while the ExportSnapshot job is running the reference files get removed and the job fails.

Maybe we could put some sort of token such that when this job is running HMaster wont reset the tmp directory.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15303,"After [HBASE-8521|https://issues.apache.org/jira/browse/HBASE-8521], the LoadIncrementalHFiles could ask server to assign sequence id for bulk load hfiles by invoking SecureBulkLoadClient#bulkLoadHFiles:
{code}
  public boolean bulkLoadHFiles(List<Pair<byte[], String>> familyPaths, Token<?> userToken,
      String bulkToken, boolean assignSeqNum) throws IOException {
    try {
      return (Boolean) Methods.call(protocolClazz, proxy, ""bulkLoadHFiles"", new Class[] {
          List.class, Token.class, String.class, Boolean.class },
        new Object[] { familyPaths, userToken, bulkToken, assignSeqNum });
    } catch (Exception e) {
      throw new IOException(""Failed to bulkLoadHFiles"", e);
    }
  }
{code}
However, SecureBulkLoadProtocol does not define such interface(with assignSeqNum as last parameter), so that the client will encounter NoSuchMethodException when using secure. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15268,"<Pre-condition>

1. Enable Ranger for HBASE

2. Ranger has account: tester锛孯ole: admin

3. Disable Kerberos

<Reproduce steps>

1. use admin account to login Ranger Web

2. go to HBase repository

3. Create HBase policy

Policy Name: 111

HBase Table: * (exclude)

HBase Column-family: * (include)

HBase Column: * (include)

Audit Logging: Yes

Select Group: qateam

Select User: tester

Permissions: Read

Delegate Admin: Yes

Policy Name: 222

HBase Table: demoACL (include)

HBase Column-family: * (include)

HBase Column: * (include)

Audit Logging: Yes

Select Group: No

Group Select User: tester

Permissions: Read

Delegate Admin: No

4. logout admin

5. login tester

6. see HBase repository

<Actual Result>

tester can not see any policy (why I can not see 111 Policy?)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15237,"Just ran into this while testing with a custom build with made up version {{1.1.1-dal}} 
{code}
2016-02-08 20:10:38,494 ERROR [B.defaultRpcServer.handler=1,queue=1,port=52622] ipc.RpcServer: Unexpected throwable object路
java.lang.NumberFormatException: For input string: ""1-dal""
  at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
  at java.lang.Integer.parseInt(Integer.java:492)
  at java.lang.Integer.parseInt(Integer.java:527)
  at org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.currentClientHasMinimumVersion(ProcedurePrepareLatch.java:61)
  at org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.hasProcedureSupport(ProcedurePrepareLatch.java:47)
  at org.apache.hadoop.hbase.master.procedure.ProcedurePrepareLatch.createLatch(ProcedurePrepareLatch.java:43)
  at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1530)
  at org.apache.hadoop.hbase.master.MasterRpcServices.createTable(MasterRpcServices.java:449)
  at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:51097)
  at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
  at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
  at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
  at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
  at java.lang.Thread.run(Thread.java:745)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15193,"master has ByteBuffInputStream while branch-1 has ByteBufferInputStream.

cc. [~ram_krish], [~anoopsharma]. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14916,"Given test-patch.sh is always run from master, and that it now uses checkstyle_report.py, we should pull back the script to other branches too.
Otherwise we see error like: /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/jenkins.build/dev-support/test-patch.sh: line 662: /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase/dev-support/checkstyle_report.py: No such file or directory

[reference|https://builds.apache.org/job/PreCommit-HBASE-Build/16734//consoleFull]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15049,"I set {{hive.server2.authentication}} to be {{NONE}}

After HS2 start, i see exception in log below:
{code}
2015-12-29 16:58:42,339 ERROR [HiveServer2-Handler-Pool: Thread-31]: server.TThreadPoolServer (TThreadPoolServer.java:run(296)) - Error occurred during processing of message.
java.lang.RuntimeException: org.apache.thrift.transport.TSaslTransportException: No data or no sasl data in the stream
        at org.apache.thrift.transport.TSaslServerTransport$Factory.getTransport(TSaslServerTransport.java:219)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:268)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.thrift.transport.TSaslTransportException: No data or no sasl data in the stream
        at org.apache.thrift.transport.TSaslTransport.open(TSaslTransport.java:328)
        at org.apache.thrift.transport.TSaslServerTransport.open(TSaslServerTransport.java:41)
        at org.apache.thrift.transport.TSaslServerTransport$Factory.getTransport(TSaslServerTransport.java:216)
        ... 4 more
{code}

IMO the problem is we use Sasl transport when authType is NONE, 
{code:title=HiveAuthFactory.java}
  public TTransportFactory getAuthTransFactory() throws LoginException {
    TTransportFactory transportFactory;
    if (authTypeStr.equalsIgnoreCase(AuthTypes.KERBEROS.getAuthName())) {
      try {
        transportFactory = saslServer.createTransportFactory(getSaslProperties());
      } catch (TTransportException e) {
        throw new LoginException(e.getMessage());
      }
    } else if (authTypeStr.equalsIgnoreCase(AuthTypes.NONE.getAuthName())) {
      transportFactory = PlainSaslHelper.getPlainTransportFactory(authTypeStr);
    } else if (authTypeStr.equalsIgnoreCase(AuthTypes.LDAP.getAuthName())) {
      transportFactory = PlainSaslHelper.getPlainTransportFactory(authTypeStr);
    } else if (authTypeStr.equalsIgnoreCase(AuthTypes.PAM.getAuthName())) {
      transportFactory = PlainSaslHelper.getPlainTransportFactory(authTypeStr);
    } else if (authTypeStr.equalsIgnoreCase(AuthTypes.NOSASL.getAuthName())) {
      transportFactory = new TTransportFactory();
    } else if (authTypeStr.equalsIgnoreCase(AuthTypes.CUSTOM.getAuthName())) {
      transportFactory = PlainSaslHelper.getPlainTransportFactory(authTypeStr);
    } else {
      throw new LoginException(""Unsupported authentication type "" + authTypeStr);
    }
    return transportFactory;
  }
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4845,"When we bulkLoadHFile, we should check the hfile num and compact it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14956,"To perform the zkcli operations using hbase, 
jline is disabled,

{code}
[ERROR] Terminal initialization failed; falling back to unsupported
java.lang.IncompatibleClassChangeError: Found class jline.Terminal, but interface was expected
        at jline.TerminalFactory.create(TerminalFactory.java:101)
        at jline.TerminalFactory.get(TerminalFactory.java:158)
        at jline.console.ConsoleReader.<init>(ConsoleReader.java:229)
        at jline.console.ConsoleReader.<init>(ConsoleReader.java:221)
        at jline.console.ConsoleReader.<init>(ConsoleReader.java:209)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
        at org.apache.zookeeper.ZooKeeperMain.run(ZooKeeperMain.java:335)
        at org.apache.zookeeper.ZooKeeperMain.main(ZooKeeperMain.java:303)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServer.main(ZooKeeperMainServer.java:108)

JLine support is disabled
{code}

To enable this jline-<version>.jar is needed in hbase libraries.
eg: jline-2.11.jar should be exist in hbase/lib directory.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14195,"There is the issue with ConnectionCache (used to cache connections in Thrift and REST servers) chore implementation when closed connection is not removed from a cache.

Thrift server is affected most because it has local thread cache of Table instances and it does not check if Table instance is invalid (due to closed underlying connection) and it can't do it - no API.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13161,"Making a note of my recent experience with ITBLL; here is stuff that needs fixing.

+ I was able to run generate for about 24 hours with monkey going and loaded 10B rows. When I ran the verify (a few times), it got stuck at about 90odd percent and never made progress beyond that (this was about 20 hours in IIRC). I spent no time trying to figure why (ran out of cluster and time).
+ Verify at least takes too long. Need to make it run faster.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14981,"TestShell seems to be replaced by an AbstractTestShell class. Thus it does not seem that any of the shell unit tests are running? If so, is the intent to create a TestShell which subclasses the abstract class? 

On a related note I've written shell unit tests for HBASE-6721 and it requires a different Shell subclass as I need to have a different balancer and coprocessor installed. I'm hoping we can address that use case in this jira as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14820,"After the region server rolls back a timed out attempt of  region split, the region becomes unavailable. 

Symptoms:
The RS displays the region open in the web UI.
The meta table still points to the RS
Requests for the regions receive a NotServingRegionException. 
hbck reports 0 inconsistencies. 
Moving the region fails. 

Restarting the region server fixes the problem.

We have see multiple occurrences which require operation intervention.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1782,"When a region has too many store files and that that region server holds .META., it is easy to get a 90s deadlock. I will paste the stack traces in a moment.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1785,"the zk_dump command depends on zoo.cfg existing, which means it doesnt work when there is no zoo.cfg (a valid cluster config) and the quorum is in hbase-site.xml",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1171,"We decided to have the force split, compact, or major compact actions on tables or regions go through the master, in part because then it is easy to have pushbuttons in the master UI for table actions. Requests are relayed by the master via the instruction stream returned when HRS call in. As Zookeeper integration progresses, and the master shrinks accordingly, the code in HBaseAdmin for requesting force splits etc. should move away from the HMasterInterface.modifyTable and instead talk directly to the regionserver(s) as desired. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1419,"Assigner needs to take into account current region balance.  I'm seeing on recovery from a crash on a big cluster that we'll give near ten regions to first regionserver that reports in.  If that regionserver successfully opens the assigned ten, then that'll put it over the balancer slop differential and it'll then be asked to close its regions by the balancer.  This adds to the regionserver crash churn.  Dumb.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1983,"I was wondering why I was only flushing every 1k edits though I'd set hbase.regionserver.flushlogentries to 100.  Couldn't figure why.  J-D set me straight.  Flush is done up in HRS now at end of a put.  If the put is a big batch put, then 1k edits will go in before I sync.  In our descriptions in hbase-default.xml, need to bring this out.  I'm sure this file could do with a good clean up by now too... Let this issue cover that too.  For 0.21.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1976,"I was browsing though the HBase 0.20.1 code in order to learn about the way HBase deals with Configuration and I noticed that HBaseConfiguration overrides hashCode() without implementing equals(). This can cause some tricky, hard to debug problems whenever instances of this class are added to Maps or HashSets.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1729,"We log this every minute in RS logs:

{code}
2009-07-30 16:24:54,479 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: Cache Stats: Sizes: Total=414.8218MB (434972192), Free=252.50949MB (264775392), Max=667.3313MB (699747584), Counts: Blocks=1106, Access=273562, Hit=271671, Miss=1891, Evictions=0, Evicted=0, Ratios: Hit Ratio=99.30874705314636%, Miss Ratio=0.691250991076231%, Evicted/Run=NaN
{code}

Thats a metric.  Should be over in metrics.  Metrics does some of above but not all.  Extend it so just as comprehensive.  Then we can see it ganglia, jmx, etc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1753,"There is a deadlock somewhere in HTable or HConnectionManager when using the deprecated API in a multi-threaded application.

I haven't had a chance to look at the thread dump in detail yet, but will attach it to this issue",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1817,Add to package documentation the need of zk to be in classpath as of 0.20.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2162,"15:54 < dj_ryan> - next:
15:54 < dj_ryan> do next on Tree in memstore get rowid
15:55 < dj_ryan> acquire read lock on rowid (wait if necessary)
15:55 < dj_ryan> snapshot the entire row worth of data from memstore into scanner
15:55 < dj_ryan> release read lock on rowid
15:56 < dj_ryan> so if we get an insert on a row after the 'do next' which would call 'next' on the 
                 previous last value grabbed from the tree
15:56 < dj_ryan> we'd skip that one
15:56 < dj_ryan> which is fine
15:57 < dj_ryan> i guess the issue comes in when you have to next a bunch to get to the next row
15:57 < dj_ryan> but that is doable with a simple little while loop
15:57 < dj_ryan> this only applies to memstore
15:57 < dj_ryan> snapshot = hfile 
15:57 < dj_ryan> since its immutable",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2552,Assigning Lars F to check we don't have this issue in the rehashed thrift code (thanks Lars).,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2289,"I tried a few things but don't seem to be able to make it build.   Maybe someone has an idea?  (I'm trying to add in the site/javadoc to hudson build):

{code}
pynchon-2:trunk stack$ MAVEN_OPTS=-Xmx1024m
pynchon-2:trunk stack$ mvn site
[INFO] Scanning for projects...
[INFO] Reactor build order: 
[INFO]   HBase
[INFO]   HBase Core
[INFO]   HBase Contrib
[INFO]   HBase Contrib - Multi Datacenter Replication
[INFO]   HBase Contrib - Stargate
[INFO]   HBase Contrib - Transactional
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase
[INFO]    task-segment: [site]
[INFO] ------------------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[ERROR] FATAL ERROR
[INFO] ------------------------------------------------------------------------
[INFO] Java heap space
[INFO] ------------------------------------------------------------------------
[INFO] Trace
java.lang.OutOfMemoryError: Java heap space
        at java.util.HashMap.<init>(HashMap.java:209)
        at org.codehaus.plexus.util.xml.Xpp3Dom.<init>(Xpp3Dom.java:81)
        at hidden.org.codehaus.plexus.util.xml.Xpp3DomBuilder.build(Xpp3DomBuilder.java:104)
        at hidden.org.codehaus.plexus.util.xml.Xpp3DomBuilder.build(Xpp3DomBuilder.java:75)
        at hidden.org.codehaus.plexus.util.xml.Xpp3DomBuilder.build(Xpp3DomBuilder.java:40)
        at org.apache.maven.plugin.descriptor.PluginDescriptorBuilder.buildConfiguration(PluginDescriptorBuilder.java:330)
        at org.apache.maven.plugin.descriptor.PluginDescriptorBuilder.build(PluginDescriptorBuilder.java:50)
        at org.apache.maven.plugin.MavenPluginDiscoverer.createComponentDescriptors(MavenPluginDiscoverer.java:52)
        at org.codehaus.plexus.component.discovery.AbstractComponentDiscoverer.findComponents(AbstractComponentDiscoverer.java:78)
        at org.codehaus.plexus.DefaultPlexusContainer.discoverComponents(DefaultPlexusContainer.java:717)
        at org.codehaus.plexus.DefaultPlexusContainer.addJarResource(DefaultPlexusContainer.java:1396)
        at org.apache.maven.plugin.DefaultPluginManager.ensurePluginContainerIsComplete(DefaultPluginManager.java:853)
        at org.apache.maven.plugin.DefaultPluginManager.getConfiguredMojo(DefaultPluginManager.java:647)
        at org.apache.maven.plugin.DefaultPluginManager.getReport(DefaultPluginManager.java:583)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.getReports(DefaultLifecycleExecutor.java:982)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:650)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:556)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:535)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:387)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:348)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:180)
        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:328)
        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:138)
        at org.apache.maven.cli.MavenCli.main(MavenCli.java:362)
        at org.apache.maven.cli.compat.CompatibleMain.main(CompatibleMain.java:60)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315)
        at org.codehaus.classworlds.Launcher.launch(Launcher.java:255)
        at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2860,"Here is current help:

{code}
hbase(main):008:0> help 'drop'

COMMAND: drop
          Drop the named table. Table must first be disabled. If table has
          more than one region, run a major compaction on .META.:

          hbase> major_compact "".META.""
{code}

Here is the exception it throws:

{code}
ERROR: java.io.IOException: java.io.IOException: java.lang.NoSuchMethodError: org.apache.hadoop.hbase.master.HMaster.access$1(Lorg/apache/hadoop/hbase/master/HMaster;Lorg/apache/hadoop/hbase/client/Result;)Lorg/apache/hadoop/hbase/util/Pair;
        at org.apache.hadoop.hbase.master.HMaster$1.processRow(HMaster.java:890)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:156)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:68)
        at org.apache.hadoop.hbase.master.HMaster.getTableRegions(HMaster.java:901)
        at org.apache.hadoop.hbase.master.HMaster.modifyTable(HMaster.java:1036)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:576)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:919)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3049,"Recently I've been seeing some strange behavior around HLogs, HBASE-3038 is an example. Looking in my oldlogs folder, I see:

{noformat}
-rw-r--r--   3 hadoop supergroup  716716459 2010-09-29 01:08 /hbase/.oldlogs/10.20.20.176%3A60020.1285722528252
-rw-r--r--   3 hadoop supergroup   64841781 2010-09-29 01:10 /hbase/.oldlogs/10.20.20.176%3A60020.1285722620286
bunch of normally sized HLogs... then
-rw-r--r--   3 hadoop supergroup  769729956 2010-09-29 01:13 /hbase/.oldlogs/10.20.20.176%3A60020.1285722785347
{noformat}

680MB is way off the 64MB limit. My feeling is that the optimizations I did in the scope of HBASE-2922 that remove some blocking behavior have the side effect of getting a lot more data in a lot faster in some edge cases. Need to investigate more.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2872,"This is related to HBASE-2866 Regions going permanently offline. The fix prevented multiple duplicate updates from going to ZK. But the master still tries to update these regions.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2329,"In current trunk, mvn install is broke.  Test compilation fails:

{code}
[INFO] [resources:testResources {execution: default-testResources}]
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] [compiler:testCompile {execution: default-testCompile}]
[INFO] Compiling 101 source files to /Users/Stack/checkouts/trunk/core/target/test-classes
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR :
[INFO] -------------------------------------------------------------
[ERROR] /Users/Stack/checkouts/trunk/core/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java:[26,30] [deprecation] org.apache.hadoop.hbase.HBaseTestCase in org.apache.hadoop.hbase has been deprecated

[ERROR] /Users/Stack/checkouts/trunk/core/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java:[27,35] cannot find symbol
symbol  : class Bytes
location: package org.apache.hadoop.hbase.util

[ERROR] /Users/Stack/checkouts/trunk/core/src/test/java/org/apache/hadoop/hbase/HBaseTestCase.java:[36,37] cannot find symbol
symbol  : class Delete
location: package org.apache.hadoop.hbase.client
...
{code}

It does not seem to be able to find hbase classes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2384,"Currently, HTable#flushCommits()  ( i.e. HTableInterface) returns void , but the failure of the flush is not obvious to the user (although, taken care internally by appending to writeBuffer ). 

Changing return type to boolean , to help handle on the client side ( logging / retry etc. ) . 


Propagate the change to put(Put), put(List<Put) . 

Add a warning to close() as well. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2791,"I think this is part of the Master/ZooKeeper refactoring project but I'm putting it up here to be sure we cover it. Currently in ZKW (and other places around the code base) we do ZK operations and we don't really handle the exceptions, for example in ZKW.setClusterState:

{code}
    } catch (InterruptedException e) {
      LOG.warn(""<"" + instanceName + "">"" + ""Failed to set state node in ZooKeeper"", e);
    } catch (KeeperException e) {
      if(e.code() == KeeperException.Code.NODEEXISTS) {
        LOG.debug(""<"" + instanceName + "">"" + ""State node exists."");
      } else {
        LOG.warn(""<"" + instanceName + "">"" + ""Failed to set state node in ZooKeeper"", e);
      }
{code}

This has been always like that since we started using ZK.

What if the session was expired? What if it was only the connection that had a blip? Do we handle it correctly? We need to have this discussion.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3193,"From Charles Thayer up on the list:

{code}
I haven't seen any replies, which is probably because the master seems to
be changing rapidly at the moment.  However, if anyone needs this for
hbase 0.89.20100726, here's a patch to work around the issue temporarily
until 0.90.0 (which will probably fix the problem).

/charles thayer

--- src/main/java/org/apache/hadoop/hbase/master/HMaster.java   2010-07-30 21:09:11.000000000 +0000
+++ src/main/java/org/apache/hadoop/hbase/master/HMaster.java   2010-10-11 20:51:30.821519000 +0000
@@ -1297,11 +1297,18 @@

              runtime.getVmVendor() + "", vmVersion="" + runtime.getVmVersion());
            LOG.info(""vmInputArguments="" + runtime.getInputArguments());
          }
+
+         boolean hbase_manages_zk = true;
+         if (System.getenv(""HBASE_MANAGES_ZK"") != null
+             && System.getenv(""HBASE_MANAGES_ZK"").equals(""false""))
+           hbase_manages_zk = false;

+
          // If 'local', defer to LocalHBaseCluster instance.  Starts master
          // and regionserver both in the one JVM.
          if (LocalHBaseCluster.isLocal(conf)) {
            final MiniZooKeeperCluster zooKeeperCluster =
              new MiniZooKeeperCluster();
+           if (hbase_manages_zk) {  // thayer

            File zkDataPath = new File(conf.get(""hbase.zookeeper.property.dataDir""));
            int zkClientPort = conf.getInt(""hbase.zookeeper.property.clientPort"", 0);
            if (zkClientPort == 0) {
@@ -1319,11 +1326,15 @@

            }
            conf.set(""hbase.zookeeper.property.clientPort"",
              Integer.toString(clientPort));
+           } // thayer

+
            // Need to have the zk cluster shutdown when master is shutdown.
            // Run a subclass that does the zk cluster shutdown on its way out.
            LocalHBaseCluster cluster = new LocalHBaseCluster(conf, 1,
              LocalHMaster.class, HRegionServer.class);
+           if (hbase_manages_zk) {

            ((LocalHMaster)cluster.getMaster()).setZKCluster(zooKeeperCluster);
+           }
            cluster.startup();
          } else {
            HMaster master = constructMaster(masterClass, conf);
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2235,"Here is the short story:

Scenario is a cluster of 3 servers.  Server 1. crashed.  It was carrying the .META.   We split the logs.  .META. is put on the head of the assignment queue.  Server 2. happens to be in a state where it wants to report a split.  The master fails the report because there is no .META. (It fails it ugly with a NPE).  Server 3. checks in and falls into the assignment code (RegionManager#regionsAwaitingAssignment).  In here we have this bit of code around line #412:

{code}
    if (reassigningMetas && isMetaOrRoot && !isSingleServer) {
      return regionsToAssign; // dont assign anything to this server.
    }
{code}

Because we think this not a single server cluster -- we think there are two 'live' nodes -- we won't assign meta.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2409,"Ryan apparently said this 6 months ago, that on split, the regions are assigned back to the parent hosting regionserver almost always.  Then, to keep up some kinda balance, the load balancer kicks and closes the just opened daughters -- which have just been opened a moment ago -- to deploy them elsewhere in the name of keeping good balance.

This issue is to confirm the above behavior indeed happens and then to take action to make it so at least one of the daughters is held up so it doesn't go back to the current heartbeating host, the parent hosting server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3187,"Saw this testing.... All opener handlers stuck waiting on meta... doesn't recover... This RS had also been given a bunch of regions to open.

{code}
""RS_OPEN_REGION-sv2borg188,60020,1288644070661-2"" daemon prio=10 tid=0x0000000042c65000 nid=0x4e61 in Object.wait() [0x00007f9709e5b000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00007f972268ad00> (a java.util.concurrent.atomic.AtomicBoolean)
    at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:327)
    - locked <0x00007f972268ad00> (a java.util.concurrent.atomic.AtomicBoolean)
    at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMetaServerConnectionDefault(CatalogTracker.java:362)
    at org.apache.hadoop.hbase.catalog.MetaEditor.updateRegionLocation(MetaEditor.java:146)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1280)
    at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:156)
    at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)
    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:662)

""RS_OPEN_REGION-sv2borg188,60020,1288644070661-1"" daemon prio=10 tid=0x0000000042ce7800 nid=0x4e5c in Object.wait() [0x00007f9709f5c000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00007f972268ad00> (a java.util.concurrent.atomic.AtomicBoolean)
    at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:327)
    - locked <0x00007f972268ad00> (a java.util.concurrent.atomic.AtomicBoolean)
    at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMetaServerConnectionDefault(CatalogTracker.java:362)
    at org.apache.hadoop.hbase.catalog.MetaEditor.updateRegionLocation(MetaEditor.java:146)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1280)
    at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:156)
    at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)
    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:662)
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3245,"In getMap() method the comparator passed to versionMap does:

      public int compare(Long l1, Long l2) {
            return l2.compareTo(l1);
       }

which inverts the result of the comparison. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10453,"Right now we will encode tags always with prefix tree encoding. With other encoders it checks HCD#shouldCompressTags().  Suggest we can do the same fro PrefixTree also.

I can see some places PrefixTree impl passes booleans like isIncludeMvcc isIncludeTags etc.  We have encapsulated all such info into a HFileContext and the code path uses that now.  We can do the same with PrefixTree code path also.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4130,"Using a HTable instance with auto commit disabled in multiple thread may raise IndexOutOfBoundsException , as the processBatchOfPuts remove the commited results by their index which may be wrong as the list size shortened by other thread.

the following is the stack trace.

java.lang.IndexOutOfBoundsException: Index: 3781, Size: 2222
	at java.util.ArrayList.RangeCheck(ArrayList.java:547)
	at java.util.ArrayList.remove(ArrayList.java:387)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchOfPuts(HConnectionManager.java:1252)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:826)
	at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:682)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:667)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4182,"1. Start 2 RS.  Create some regions so that is is balanced.
2. Stop RS2.  Now all the Regions from RS2 are assigned to RS1.
3. Again start RS2.
4. Load Balancing is calculated and few regions from RS1 are assigned to RS2.
As part of this step Master tries to unassign the regions from RS1.
{noformat}
          RegionTransitionData data = ZKAssign.getDataNoWatch(zkw, ZKAssign
              .getNodeName(zkw, region.getEncodedName()), null);
          if (data.equals(EventType.RS_ZK_REGION_CLOSING)) {
            ZKAssign.createNodeClosing(zkw, region, master.getServerName());
          }
{noformat}

Now there is no data present in the unassigned node.  We are directly comparing the data.
Here data is null. Hence nullpointer exception is thrown.
Hence load balancing fails.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10261,I can start hbase in my hadoop-2.2.0 cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9245,"This is an umbrella issue that will cover the removal or refactoring of dangling dead code and cruft.  Some can make it into 0.96, some may have to wait for an 0.98.  The ""great culling"" of code will be grouped patches that are logically related.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10937,"There is known issue to run MR job for hbase0.96+ version. Details at section 鈥淣otice to Mapreduce users of HBase 0.96.1 and above鈥?https://hbase.apache.org/book.html

Basically we need to put hbase-protocol*.jar before hadoop loads protobuf-java jar.  I updated our documentation on http://phoenix.incubator.apache.org/bulk_dataload.html on how to use CsvBulkLoadTool for Phoenix 4.0 as following:

{noformat}
HADOOP_CLASSPATH=$(hbase mapredcp)::/path/to/hbase/conf hadoop jar phoenix-4.0.0-incubating-client.jar org.apache.phoenix.mapreduce.CsvBulkLoadTool --table EXAMPLE --input /data/example.csv
{noformat}
OR
{noformat}
HADOOP_CLASSPATH=/path/to/hbase-protocol.jar:/path/to/hbase/conf hadoop jar phoenix-4.0.0-incubating-client.jar org.apache.phoenix.mapreduce.CsvBulkLoadTool --table EXAMPLE --input /data/example.csv
{noformat} 

Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14744,"Hi Anoop/Ted,
I need to delete bulk records in Hbase table based on certain criteria.
I copied one piece of code from similar thread and it throws ""can not find  symbol"" error for most of the code.

Can you please provide me right code which would be used to delete bulk records

Here are the errors
DeleteRowsTest.java:75: error: cannot find symbol
   HTable tableName = new HTable(conf, ""salestoolsdata:account"");
                                 ^
  symbol:   variable conf
  location: class DeleteRowsTest
DeleteRowsTest.java:79: error: no suitable constructor found for SingleColumnValueFilter(char,String,CompareOp,byte[])
    SingleColumnValueFilter scvf = new SingleColumnValueFilter('d',""ISDELETED"",CompareOp.EQUAL, Bytes.toBytes(""true""));
                                   ^
    constructor SingleColumnValueFilter.SingleColumnValueFilter(byte[],byte[],CompareOp,byte[]) is not applicable
      (argument mismatch; char cannot be converted to byte[])
    constructor SingleColumnValueFilter.SingleColumnValueFilter(byte[],byte[],CompareOp,ByteArrayComparable) is not applicable
      (argument mismatch; char cannot be converted to byte[])
DeleteRowsTest.java:85: error: cannot find symbol
    long noOfRowsDeleted = invokeBulkDeleteProtocol(tableName, scan, 500, DeleteType.ROW, null);
                                                                          ^
  symbol:   variable DeleteType
  location: class DeleteRowsTest
DeleteRowsTest.java:89: error: cannot find symbol
    for (Result result : ht.getScanner(new Scan())) {
                         ^
  symbol:   variable ht
  location: class DeleteRowsTest
DeleteRowsTest.java:98: error: cannot find symbol
    HTable ht = new HTable(conf, tableName);
                           ^
  symbol:   variable conf
  location: class DeleteRowsTest
DeleteRowsTest.java:100: error: cannot find symbol
    Batch.Call<BulkDeleteProtocol, BulkDeleteResponse> callable = 
               ^
  symbol:   class BulkDeleteProtocol
  location: class DeleteRowsTest
DeleteRowsTest.java:100: error: cannot find symbol
    Batch.Call<BulkDeleteProtocol, BulkDeleteResponse> callable = 
                                   ^
  symbol:   class BulkDeleteResponse
  location: class DeleteRowsTest
DeleteRowsTest.java:101: error: cannot find symbol
        new Batch.Call<BulkDeleteProtocol, BulkDeleteResponse>() {
                       ^
  symbol:   class BulkDeleteProtocol
  location: class DeleteRowsTest
DeleteRowsTest.java:101: error: cannot find symbol
        new Batch.Call<BulkDeleteProtocol, BulkDeleteResponse>() {
                                           ^
  symbol:   class BulkDeleteResponse
  location: class DeleteRowsTest
DeleteRowsTest.java:102: error: cannot find symbol
      public BulkDeleteResponse call(BulkDeleteProtocol instance) throws IOException {
                                     ^
  symbol: class BulkDeleteProtocol
DeleteRowsTest.java:102: error: cannot find symbol
      public BulkDeleteResponse call(BulkDeleteProtocol instance) throws IOException {
             ^
  symbol: class BulkDeleteResponse
DeleteRowsTest.java:106: error: cannot find symbol
    Map<byte[], BulkDeleteResponse> result = ht.coprocessorExec(BulkDeleteProtocol.class,
                ^
  symbol:   class BulkDeleteResponse
  location: class DeleteRowsTest
DeleteRowsTest.java:106: error: cannot find symbol
    Map<byte[], BulkDeleteResponse> result = ht.coprocessorExec(BulkDeleteProtocol.class,
                                                                ^
  symbol:   class BulkDeleteProtocol
  location: class DeleteRowsTest
DeleteRowsTest.java:108: error: cannot find symbol
    for (BulkDeleteResponse response : result.values()) {
         ^
  symbol:   class BulkDeleteResponse
  location: class DeleteRowsTest
Note: Some messages have been simplified; recompile with -Xdiags:verbose to get full output
18 errors



Thanks
Marimuthu

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14265,"Now, there is no limit for users who can create table under 'hbase' NameSpace. I think it has some risk.

Because we use {{TableName.systemTable}} to decide whether this table is System or not.

But as code,  {{TableName.systemTable}} will be true, if NS equals ""hbase'
{code}
 if (Bytes.equals(NamespaceDescriptor.SYSTEM_NAMESPACE_NAME, namespace)) {
        this.namespace = NamespaceDescriptor.SYSTEM_NAMESPACE_NAME;
        this.namespaceAsString = NamespaceDescriptor.SYSTEM_NAMESPACE_NAME_STR;
        this.systemTable = true;
      } 
{code}
 
And we treat system table and normal table differently. 
For example,  https://issues.apache.org/jira/browse/HBASE-14257 will flush fast if table belong to system table.



",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14410,"Replication hangs until target cluster is restarted. 
IPC queue was at max bytes on a single region server on target cluster. Master appeared OK. Region server serving hbase:meta appeared OK. Have seen this several times since upgrade from .98.6 to 1.0.0.

Observed this in the stack trace in single region server on target cluster:
""hconnection-0x59e10d51-shared--pool8-t97669"" daemon prio=10 tid=0x0000000001235000 nid=0xa47 in Object.wait() [0x00007ff5186fb000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1189)
        - locked <0x00000004147a0000> (a org.apache.hadoop.hbase.ipc.Call)
        at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:216)
        at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:300)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.get(ClientProtos.java:31865)
        at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRowOrBefore(ProtobufUtil.java:1580)
        at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegionInMeta(ConnectionManager.java:1294)
        at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1126)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.findAllLocationsOrFail(AsyncProcess.java:916)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.groupAndSendMultiAction(AsyncProcess.java:833)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.resubmit(AsyncProcess.java:1156)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.receiveGlobalFailure(AsyncProcess.java:1123)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.access$1100(AsyncProcess.java:574)
        at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl$SingleServerRequestRunnable.run(AsyncProcess.java:705)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8810,"After the defaults were changed in the xml some constants were left the same.

DEFAULT_HBASE_CLIENT_PAUSE for example.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14396,"Currently the hbase audit log only records the user and scope,we can't know which table the user is operating on unless the scope is table.

It would be better to know what's going on if we record the exact table and column family we are operating on besides the scope.

  String logMessage =
        ""Access "" + (result.isAllowed() ? ""allowed"" : ""denied"") + "" for user ""
            + (result.getUser() != null ? result.getUser().getShortName() : ""UNKNOWN"")
            + ""; reason: "" + result.getReason() + ""; remote address: ""
            + (remoteAddr != null ? remoteAddr : """") + ""; request: "" + result.getRequest()
            + ""; context: "" + result.toContextString();",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14390,"mvn clean package -DskipTests

{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.2:compile (default-compile) on project hbase-rest: Compilation failure: Compilation failure:
[ERROR] /Users/chenheng/apache/hbase/hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RootResource.java:[108,10] 鎵句笉鍒扮鍙?[ERROR] 绗﹀彿:   绫?NamespacesResource
[ERROR] 浣嶇疆: 绫?org.apache.hadoop.hbase.rest.RootResource
[ERROR] /Users/chenheng/apache/hbase/hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/provider/JAXBContextResolver.java:[34,42] 鎵句笉鍒扮鍙?[ERROR] 绗﹀彿:   绫?NamespacesInstanceModel
[ERROR] 浣嶇疆: 绋嬪簭鍖?org.apache.hadoop.hbase.rest.model
[ERROR] /Users/chenheng/apache/hbase/hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/provider/JAXBContextResolver.java:[35,42] 鎵句笉鍒扮鍙?[ERROR] 绗﹀彿:   绫?NamespacesModel
[ERROR] 浣嶇疆: 绋嬪簭鍖?org.apache.hadoop.hbase.rest.model
[ERROR] /Users/chenheng/apache/hbase/hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RootResource.java:[109,16] 鎵句笉鍒扮鍙?[ERROR] 绗﹀彿:   绫?NamespacesResource
[ERROR] 浣嶇疆: 绫?org.apache.hadoop.hbase.rest.RootResource
[ERROR] /Users/chenheng/apache/hbase/hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/provider/JAXBContextResolver.java:[68,5] 鎵句笉鍒扮鍙?[ERROR] 绗﹀彿:   绫?NamespacesModel
[ERROR] 浣嶇疆: 绫?org.apache.hadoop.hbase.rest.provider.JAXBContextResolver
[ERROR] /Users/chenheng/apache/hbase/hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/provider/JAXBContextResolver.java:[69,5] 鎵句笉鍒扮鍙?[ERROR] 绗﹀彿:   绫?NamespacesInstanceModel
[ERROR] 浣嶇疆: 绫?org.apache.hadoop.hbase.rest.provider.JAXBContextResolver
[ERROR] -> [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hbase-rest
{code}

[~stack]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5789,"The HConnectionManager offers a few methods to manage deletion of connections. The public deleteConnection method does not allow the caller to specify that the connection is stale. The deleteStaleConnection takes an HConnection instance. In order to get the HConnection instance a caller need to call getConnection with the connection's Configuration instance to retrieve the connection. But, getConnection will attempt to connect if the connection has already been deleted, which sort of defeat the purpose of deleting the connection. It also complicates caller as they need to handle ZooKeeperConnectionException. 

To simplify clients it would be nice to be able to specify ""staleConnection"" on the deleteConnection method or offer a deleteStaleConnection method that takes a Configuration parameter. Or something completely different? ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5362,"I have an application like a scheduler that starts periodically some MR jobs that reads from one HBase table and write in more tables, changing the row key and the columns list. 
I have encounted a problem with this: after each MR job, I have +1 connections open to ZK and after a period of time, I have received IOException. I saw that I am not the first that had had this problem, but I didn't see any fix. No in HBase 0.90.4, nor in HBase 0.92.
To fix this issue I wrote a custom TableInputFormat that forces to close the connection to ZK after each getSplits call. 
Also, the initTableMapperJob was overwritten.
I found an open JIRA issue here: https://issues.apache.org/jira/browse/HBASE-3792

Regards,
Ionut I. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4762,"Patch in HBASE-3914 fixed root assigned in two regionservers. But it seemed like root region will never be assigned if verifyRootRegionLocation throws IOE.
Like following master logs:
{noformat}
2011-10-19 19:13:34,873 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_META_SERVER_S
HUTDOWN
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.ipc.ServerNotRunningException: Server is not running yet
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1090)

        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:771)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:256)
        at $Proxy7.getRegionInfo(Unknown Source)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyRegionLocation(CatalogTracker.java:424)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyRootRegionLocation(CatalogTracker.java:471)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.verifyAndAssignRoot(ServerShutdownHandler.java:90)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:126)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
{noformat}
After this, -ROOT-'s region won't be assigned, like this:
{noformat}
2011-10-19 19:18:40,000 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: locateRegionInMeta parent
Table=-ROOT-, metaLocation=address: dw79.kgb.sqa.cm4:60020, regioninfo: -ROOT-,,0.70236052, attempt=0 of 10 failed; retrying after s
leep of 1000 because: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: -ROOT-,,0
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2771)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1802)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:569)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1091)
{noformat}
So we should rewrite the verifyRootRegionLocation method.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6198,"We synchronize on region state doing single assign of a region but then over in the handleRegion zk callback, we don't synchronize on the regionstate instance.  Makes no sense.  Either get rid of all synchronization or put synchronization everywhere (we should probably do the latter since it makes things easier to reason about, and these states are already complicated.  There could be a performance issue though).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14263,"It seems that logic around selection of store file candidates is broken:
{code}
        // Compute the total size of files that will
        // have to be read if this set of files is compacted.
        long size = getTotalStoreSize(potentialMatchFiles);
        // Store the smallest set of files.  This stored set of files will be used
        // if it looks like the algorithm is stuck.
        if (mightBeStuck && size < smallestSize) {
          smallest = potentialMatchFiles;
          smallestSize = size;
        }
        if (size > comConf.getMaxCompactSize()) {
          continue;
        }

        ++opts;
        if (size >= comConf.getMinCompactSize()
            && !filesInRatio(potentialMatchFiles, currentRatio)) {
          continue;
        }
{code}
This is from applyCompactionPolicy method. As you can see, both min compaction size and max compaction size are applied to a *selection* of files and not to individual files. It mostly works as expected only because nobody seems using non-default hbase.hstore.compaction.max.size, which is  Long.MAX_VALUE  and  it  is not  that  easy  to  figure out  what  is  going  on  on an opposite side (why small files do not get included?)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14316,"On truncate table command, the hbase doesn't maintain the pre-defined splits. It simply drops and re creates table. It should have some mechanism to maintain the predefined splits.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14281,"Follow-on issue for HBASE-13329: CellComparator#getMinimumMidpointArray seems to have had a necessary change omitted and the patch only covered one of the two places diffIdx could overflow the short.

For some background, we ran into the HBASE-13329 issue where a flush would cause a regionserver abort. After abort, the region in question would almost indefinitely sit in the FAILED_OPEN state. Applying the patch from HBASE-13329 didn't solve the issue, but I noticed a comment in that issue which applied the same change in CellComparator#getMinimumMidpointArray, but the change was omitted from the attached patch.

RS abort for reference:

slave3.xxx.xxx.xxx,60020,1440131603772: Replay of WAL required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: deduplication,P\xDFt\x10\x053e73ceff5a2717d2ba76887ea21a2a8e353d1372\xFE,1438362391124.2bb6a602be6b1bfcea0508af4ba42235.
at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2243)
at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1972)
at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1935)
at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1833)
at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:452)
at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:413)
at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$800(MemStoreFlusher.java:70)
at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:229)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NegativeArraySizeException
at org.apache.hadoop.hbase.CellComparator.getMinimumMidpointArray(CellComparator.java:494)
at org.apache.hadoop.hbase.CellComparator.getMidpoint(CellComparator.java:448)
at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.finishBlock(HFileWriterV2.java:165)
at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.checkBlockBoundary(HFileWriterV2.java:146)
at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.append(HFileWriterV2.java:263)
at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.append(StoreFile.java:949)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14299,for modularization purpose code refactor should be applied to storage module,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14284,"TestDistributedLogReplay puts up regionservers with *40* priority handlers each. This makes for TDLR running with many hundreds of threads. Trying to figure why 40, I see the test can hang if less with all client use stuck never timing out:

{code}
""RS:2;localhost:58498"" prio=5 tid=0x00007fd284d4e800 nid=0x416af in Object.wait() [0x000000012952e000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:461)
	at io.netty.util.concurrent.DefaultPromise.await0(DefaultPromise.java:355)
	- locked <0x00000007dff93ea0> (a org.apache.hadoop.hbase.ipc.AsyncCall)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:266)
	at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:42)
	at org.apache.hadoop.hbase.ipc.AsyncRpcClient.call(AsyncRpcClient.java:231)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:214)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:288)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.regionServerReport(RegionServerStatusProtos.java:8994)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:1148)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:957)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.runRegionServer(MiniHBaseCluster.java:156)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.access$000(MiniHBaseCluster.java:108)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer$1.run(MiniHBaseCluster.java:140)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:356)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1594)
	at org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:279)
	at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.run(MiniHBaseCluster.java:138)
	at java.lang.Thread.run(Thread.java:744)

{code}

We  never recover.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13391,"TestRegionObserverInterface is frequently failing on branch-1 .

Example:

{noformat}
java.lang.AssertionError: Result of org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver$Legacy.getCtPreWALRestore is expected to be 1, while we get 0
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.verifyMethodResult(TestRegionObserverInterface.java:751)
	at org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.testLegacyRecovery(TestRegionObserverInterface.java:685)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14204,"After upgrade hbase-0.98.3-hadoop2 to hbase-1.0.11, everything works fine, HMaster and RegionServers all started OK, hbase shell works OK, table scan works OK. Except pig script failed to store data to Hbase using org.apache.pig.backend.hadoop.hbase.HBaseStorage.


Detailed exception from pig.
{quote}
Pig Stack Trace
---------------
ERROR 1200: Pig script failed to parse:
<line 13, column 0> pig script failed to validate: java.lang.RuntimeException: could not instantiate 'org.apache.pig.backend.hadoop.hbase.HBaseStorage' with arguments '[cf:*]'

Failed to parse: Pig script failed to parse:
<line 13, column 0> pig script failed to validate: java.lang.RuntimeException: could not instantiate 'org.apache.pig.backend.hadoop.hbase.HBaseStorage' with arguments '[cf:*]'
        at org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:199)
        at org.apache.pig.PigServer$Graph.validateQuery(PigServer.java:1707)
        at org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1680)
        at org.apache.pig.PigServer.registerQuery(PigServer.java:623)
        at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:1082)
        at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:505)
        at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)
        at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)
        at org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)
        at org.apache.pig.Main.run(Main.java:565)
        at org.apache.pig.Main.main(Main.java:177)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by:
<line 13, column 0> pig script failed to validate: java.lang.RuntimeException: could not instantiate 'org.apache.pig.backend.hadoop.hbase.HBaseStorage' with arguments '[cf:*]'
        at org.apache.pig.parser.LogicalPlanBuilder.buildStoreOp(LogicalPlanBuilder.java:1009)
        at org.apache.pig.parser.LogicalPlanGenerator.store_clause(LogicalPlanGenerator.java:7806)
        at org.apache.pig.parser.LogicalPlanGenerator.op_clause(LogicalPlanGenerator.java:1669)
        at org.apache.pig.parser.LogicalPlanGenerator.general_statement(LogicalPlanGenerator.java:1102)
        at org.apache.pig.parser.LogicalPlanGenerator.statement(LogicalPlanGenerator.java:560)
        at org.apache.pig.parser.LogicalPlanGenerator.query(LogicalPlanGenerator.java:421)
        at org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:191)
        ... 15 more
Caused by: java.lang.RuntimeException: could not instantiate 'org.apache.pig.backend.hadoop.hbase.HBaseStorage' with arguments '[cf:*]'
        at org.apache.pig.impl.PigContext.instantiateFuncFromSpec(PigContext.java:772)
        at org.apache.pig.parser.LogicalPlanBuilder.buildStoreOp(LogicalPlanBuilder.java:988)
        ... 21 more
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:525)
        at org.apache.pig.impl.PigContext.instantiateFuncFromSpec(PigContext.java:740)
        ... 22 more
Caused by: java.lang.NoSuchMethodError: org.apache.hadoop.hbase.client.Scan.setCacheBlocks(Z)V
        at org.apache.pig.backend.hadoop.hbase.HBaseStorage.initScan(HBaseStorage.java:427)
        at org.apache.pig.backend.hadoop.hbase.HBaseStorage.<init>(HBaseStorage.java:368)
        at org.apache.pig.backend.hadoop.hbase.HBaseStorage.<init>(HBaseStorage.java:239)
        ... 27 more
================================================================================

{quote}


Here is the classpath for running pig, as you can see, I am using the hbase-client.1.0.1.1 version. 
{quote}
[hadoop@hadoop-master-1 ~]$ pig -useHCatalog
ls: cannot access /opt/apache-hive-0.14.0-bin/lib/slf4j-api-*.jar: No such file or directory
ls: cannot access /opt/apache-hive-0.14.0-bin/hcatalog/lib/*hbase-storage-handler-*.jar: No such file or directory
Find hadoop at /opt/hadoop-2.4.1/bin/hadoop
dry run:
HADOOP_CLASSPATH: /opt/hbase-1.0.1.1/conf:/opt/pig-0.15.0/conf:/usr/java/latest/lib/tools.jar:/opt/apache-hive-0.14.0-bin/lib/hive-metastore-0.14.0.jar:/opt/apache-hive-0.14.0-bin/lib/libthrift-0.9.0.jar:/opt/apache-hive-0.14.0-bin/lib/hive-exec-0.14.0.jar:/opt/apache-hive-0.14.0-bin/lib/libfb303-0.9.0.jar:/opt/apache-hive-0.14.0-bin/lib/jdo-api-3.0.1.jar::/opt/apache-hive-0.14.0-bin/lib/hive-hbase-handler-0.14.0.jar:/opt/apache-hive-0.14.0-bin/hcatalog/share/hcatalog/hive-hcatalog-core-0.14.0.jar::/opt/apache-hive-0.14.0-bin/hcatalog/share/hcatalog/hive-hcatalog-pig-adapter-0.14.0.jar:/opt/apache-hive-0.14.0-bin/conf:/opt/hadoop-2.4.1/etc/hadoop/:/opt/pig-0.15.0/lib/accumulo-core-1.5.0.jar:/opt/pig-0.15.0/lib/accumulo-fate-1.5.0.jar:/opt/pig-0.15.0/lib/accumulo-server-1.5.0.jar:/opt/pig-0.15.0/lib/accumulo-start-1.5.0.jar:/opt/pig-0.15.0/lib/accumulo-trace-1.5.0.jar:/opt/pig-0.15.0/lib/antlr-runtime-3.4.jar:/opt/pig-0.15.0/lib/asm-3.3.1.jar:/opt/pig-0.15.0/lib/automaton-1.11-8.jar:/opt/pig-0.15.0/lib/avro-1.7.5.jar:/opt/pig-0.15.0/lib/avro-tools-1.7.5-nodeps.jar:/opt/pig-0.15.0/lib/groovy-all-1.8.6.jar:/opt/pig-0.15.0/lib/guava-11.0.jar:/opt/pig-0.15.0/lib/hive-common-0.14.0.jar:/opt/pig-0.15.0/lib/hive-exec-0.14.0-core.jar:/opt/pig-0.15.0/lib/hive-serde-0.14.0.jar:/opt/pig-0.15.0/lib/hive-shims-common-0.14.0.jar:/opt/pig-0.15.0/lib/hive-shims-common-secure-0.14.0.jar:/opt/pig-0.15.0/lib/jackson-core-asl-1.8.8.jar:/opt/pig-0.15.0/lib/jackson-mapper-asl-1.8.8.jar:/opt/pig-0.15.0/lib/jansi-1.9.jar:/opt/pig-0.15.0/lib/jline-1.0.jar:/opt/pig-0.15.0/lib/joda-time-2.5.jar:/opt/pig-0.15.0/lib/jruby-complete-1.6.7.jar:/opt/pig-0.15.0/lib/js-1.7R2.jar:/opt/pig-0.15.0/lib/json-simple-1.1.jar:/opt/pig-0.15.0/lib/jython-standalone-2.5.3.jar:/opt/pig-0.15.0/lib/kryo-2.22.jar:/opt/pig-0.15.0/lib/piggybank.jar:/opt/pig-0.15.0/lib/protobuf-java-2.5.0.jar:/opt/pig-0.15.0/lib/snappy-java-1.1.0.1.jar:/opt/pig-0.15.0/lib/ST4-4.0.4.jar:/opt/pig-0.15.0/lib/trevni-avro-1.7.5.jar:/opt/pig-0.15.0/lib/trevni-core-1.7.5.jar:/opt/pig-0.15.0/lib/zookeeper-3.4.5.jar:/opt/hbase-1.0.1.1/lib/activation-1.1.jar:/opt/hbase-1.0.1.1/lib/aopalliance-1.0.jar:/opt/hbase-1.0.1.1/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase-1.0.1.1/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase-1.0.1.1/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase-1.0.1.1/lib/api-util-1.0.0-M20.jar:/opt/hbase-1.0.1.1/lib/asm-3.1.jar:/opt/hbase-1.0.1.1/lib/avro-1.7.4.jar:/opt/hbase-1.0.1.1/lib/commons-beanutils-1.7.0.jar:/opt/hbase-1.0.1.1/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase-1.0.1.1/lib/commons-cli-1.2.jar:/opt/hbase-1.0.1.1/lib/commons-codec-1.9.jar:/opt/hbase-1.0.1.1/lib/commons-collections-3.2.1.jar:/opt/hbase-1.0.1.1/lib/commons-compress-1.4.1.jar:/opt/hbase-1.0.1.1/lib/commons-configuration-1.6.jar:/opt/hbase-1.0.1.1/lib/commons-daemon-1.0.13.jar:/opt/hbase-1.0.1.1/lib/commons-digester-1.8.jar:/opt/hbase-1.0.1.1/lib/commons-el-1.0.jar:/opt/hbase-1.0.1.1/lib/commons-httpclient-3.1.jar:/opt/hbase-1.0.1.1/lib/commons-io-2.4.jar:/opt/hbase-1.0.1.1/lib/commons-lang-2.6.jar:/opt/hbase-1.0.1.1/lib/commons-logging-1.2.jar:/opt/hbase-1.0.1.1/lib/commons-math-2.2.jar:/opt/hbase-1.0.1.1/lib/commons-math3-3.1.1.jar:/opt/hbase-1.0.1.1/lib/commons-net-3.1.jar:/opt/hbase-1.0.1.1/lib/disruptor-3.3.0.jar:/opt/hbase-1.0.1.1/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase-1.0.1.1/lib/guava-12.0.1.jar:/opt/hbase-1.0.1.1/lib/guice-3.0.jar:/opt/hbase-1.0.1.1/lib/guice-servlet-3.0.jar:/opt/hbase-1.0.1.1/lib/hadoop-annotations-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-auth-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-client-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-common-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hadoop-yarn-server-nodemanager-2.5.1.jar:/opt/hbase-1.0.1.1/lib/hbase-annotations-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-annotations-1.0.1.1-tests.jar:/opt/hbase-1.0.1.1/lib/hbase-checkstyle-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-client-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-common-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-common-1.0.1.1-tests.jar:/opt/hbase-1.0.1.1/lib/hbase-examples-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-hadoop2-compat-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-hadoop-compat-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-it-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-it-1.0.1.1-tests.jar:/opt/hbase-1.0.1.1/lib/hbase-prefix-tree-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-protocol-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-rest-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-server-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-server-1.0.1.1-tests.jar:/opt/hbase-1.0.1.1/lib/hbase-shell-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-testing-util-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/hbase-thrift-1.0.1.1.jar:/opt/hbase-1.0.1.1/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase-1.0.1.1/lib/httpclient-4.2.5.jar:/opt/hbase-1.0.1.1/lib/httpcore-4.1.3.jar:/opt/hbase-1.0.1.1/lib/jackson-core-asl-1.8.8.jar:/opt/hbase-1.0.1.1/lib/jackson-jaxrs-1.8.8.jar:/opt/hbase-1.0.1.1/lib/jackson-mapper-asl-1.8.8.jar:/opt/hbase-1.0.1.1/lib/jackson-xc-1.8.8.jar:/opt/hbase-1.0.1.1/lib/jamon-runtime-2.3.1.jar:/opt/hbase-1.0.1.1/lib/jasper-compiler-5.5.23.jar:/opt/hbase-1.0.1.1/lib/jasper-runtime-5.5.23.jar:/opt/hbase-1.0.1.1/lib/javax.inject-1.jar:/opt/hbase-1.0.1.1/lib/java-xmlbuilder-0.4.jar:/opt/hbase-1.0.1.1/lib/jaxb-api-2.2.2.jar:/opt/hbase-1.0.1.1/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase-1.0.1.1/lib/jcodings-1.0.8.jar:/opt/hbase-1.0.1.1/lib/jersey-client-1.9.jar:/opt/hbase-1.0.1.1/lib/jersey-core-1.9.jar:/opt/hbase-1.0.1.1/lib/jersey-guice-1.9.jar:/opt/hbase-1.0.1.1/lib/jersey-json-1.9.jar:/opt/hbase-1.0.1.1/lib/jersey-server-1.9.jar:/opt/hbase-1.0.1.1/lib/jets3t-0.9.0.jar:/opt/hbase-1.0.1.1/lib/jettison-1.3.3.jar:/opt/hbase-1.0.1.1/lib/jetty-6.1.26.jar:/opt/hbase-1.0.1.1/lib/jetty-sslengine-6.1.26.jar:/opt/hbase-1.0.1.1/lib/jetty-util-6.1.26.jar:/opt/hbase-1.0.1.1/lib/joni-2.1.2.jar:/opt/hbase-1.0.1.1/lib/jruby-complete-1.6.8.jar:/opt/hbase-1.0.1.1/lib/jsch-0.1.42.jar:/opt/hbase-1.0.1.1/lib/jsp-2.1-6.1.14.jar:/opt/hbase-1.0.1.1/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase-1.0.1.1/lib/jsr305-1.3.9.jar:/opt/hbase-1.0.1.1/lib/junit-4.11.jar:/opt/hbase-1.0.1.1/lib/leveldbjni-all-1.8.jar:/opt/hbase-1.0.1.1/lib/libthrift-0.9.0.jar:/opt/hbase-1.0.1.1/lib/log4j-1.2.17.jar:/opt/hbase-1.0.1.1/lib/metrics-core-2.2.0.jar:/opt/hbase-1.0.1.1/lib/netty-3.2.4.Final.jar:/opt/hbase-1.0.1.1/lib/netty-all-4.0.23.Final.jar:/opt/hbase-1.0.1.1/lib/paranamer-2.3.jar:/opt/hbase-1.0.1.1/lib/protobuf-java-2.5.0.jar:/opt/hbase-1.0.1.1/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase-1.0.1.1/lib/servlet-api-2.5.jar:/opt/hbase-1.0.1.1/lib/slf4j-api-1.7.7.jar:/opt/hbase-1.0.1.1/lib/slf4j-log4j12-1.7.7.jar:/opt/hbase-1.0.1.1/lib/snappy-java-1.0.4.1.jar:/opt/hbase-1.0.1.1/lib/xmlenc-0.52.jar:/opt/hbase-1.0.1.1/lib/xz-1.0.jar:/opt/hbase-1.0.1.1/lib/zookeeper-3.4.6.jar:/opt/zookeeper-3.4.6/zookeeper-3.4.6.jar:/opt/pig-0.15.0/pig-0.15.0-core-h2.jar:/opt/pig-0.15.0/lib/h2/avro-mapred-1.7.5-hadoop2.jar:/opt/pig-0.15.0/lib/h2/commons-collections4-4.0.jar:/opt/pig-0.15.0/lib/h2/hbase-client-0.98.12-hadoop2.jar:/opt/pig-0.15.0/lib/h2/hbase-common-0.98.12-hadoop2.jar:/opt/pig-0.15.0/lib/h2/hbase-hadoop2-compat-0.98.12-hadoop2.jar:/opt/pig-0.15.0/lib/h2/hbase-hadoop-compat-0.98.12-hadoop2.jar:/opt/pig-0.15.0/lib/h2/hbase-protocol-0.98.12-hadoop2.jar:/opt/pig-0.15.0/lib/h2/hbase-server-0.98.12-hadoop2.jar:/opt/pig-0.15.0/lib/h2/hive-shims-0.23-0.14.0.jar:/opt/pig-0.15.0/lib/h2/tez-api-0.7.0.jar:/opt/pig-0.15.0/lib/h2/tez-common-0.7.0.jar:/opt/pig-0.15.0/lib/h2/tez-dag-0.7.0.jar:/opt/pig-0.15.0/lib/h2/tez-mapreduce-0.7.0.jar:/opt/pig-0.15.0/lib/h2/tez-runtime-internals-0.7.0.jar:/opt/pig-0.15.0/lib/h2/tez-runtime-library-0.7.0.jar:/opt/pig-0.15.0/lib/h2/tez-yarn-timeline-history-with-acls-0.7.0.jar:
HADOOP_OPTS:
HADOOP_CLIENT_OPTS: -Xmx1000m  -Dpig.log.dir=/opt/pig-0.15.0/logs -Dpig.log.file=pig.log -Dpig.home.dir=/opt/pig-0.15.0 -Dpig.additional.jars.uris=file:///opt/apache-hive-0.14.0-bin/lib/hive-metastore-0.14.0.jar,file:///opt/apache-hive-0.14.0-bin/lib/libthrift-0.9.0.jar,file:///opt/apache-hive-0.14.0-bin/lib/hive-exec-0.14.0.jar,file:///opt/apache-hive-0.14.0-bin/lib/libfb303-0.9.0.jar,file:///opt/apache-hive-0.14.0-bin/lib/jdo-api-3.0.1.jar,file://,file:///opt/apache-hive-0.14.0-bin/lib/hive-hbase-handler-0.14.0.jar,file:///opt/apache-hive-0.14.0-bin/hcatalog/share/hcatalog/hive-hcatalog-core-0.14.0.jar,file://,file:///opt/apache-hive-0.14.0-bin/hcatalog/share/hcatalog/hive-hcatalog-pig-adapter-0.14.0.jar
/opt/hadoop-2.4.1/bin/hadoop jar /opt/pig-0.15.0/pig-0.15.0-core-h2.jar


{quote}

Also I try to find this class org.apache.hadoop.hbase.client.Scan, there is no other jar contains it, So I am not sure why there is such incompatible. From the source code, setCacheBlocks, this method should exist.  

{quote}
[hadoop@hadoop-master-1 opt]$ find . -name ""*.jar"" -exec grep -l org.apache.hadoop.hbase.client.Scan {} \;

./hbase-1.0.1.1/lib/hbase-client-1.0.1.1.jar
./pig-0.15.0/lib/h2/hbase-client-0.98.12-hadoop2.jar
./pig-0.15.0/lib/h1/hbase-client-0.98.12-hadoop1.jar
{quote}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14182,"I use docker to deploy my hbase cluster, and the RS ip changed. When restart this RS,  hmaster webUI shows it connect to hmaster, but regions num. is zero after a long time. I check the hmaster log and found that master still use old ip to connect this rs.

This is hmaster's log below:
PS: 10.11.21.140 is old ip of  rs dx-ape-regionserver1-online
{code}
2015-08-04 17:24:00,081 INFO  [AM.ZK.Worker-pool2-t14141] master.AssignmentManager: Assigning solar_image,\x01Y\x8E\xA3y,1434968237206.4a1bdeec85b9f55b962596f9fb2cd07f. to dx-ape-regionserver1-online,60020,1438679950072
2015-08-04 17:24:06,800 WARN  [AM.ZK.Worker-pool2-t14133] master.AssignmentManager: Failed assignment of solar_image,\x00\x94\x09\x8D\x95,1430991781025.b0f5b755f443d41cf306026a60675020. to dx-ape-regionserver1-online,60020,1438679950072, trying to assign elsewhere instead; try=3 of 10
java.net.ConnectException: Connection timed out
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
        at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:578)
        at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:868)
        at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
        at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
        at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
        at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
        at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.openRegion(AdminProtos.java:20964)
        at org.apache.hadoop.hbase.master.ServerManager.sendRegionOpen(ServerManager.java:671)
        at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:2097)
        at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1577)
        at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1550)
        at org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.process(ClosedRegionHandler.java:104)
        at org.apache.hadoop.hbase.master.AssignmentManager.handleRegion(AssignmentManager.java:999)
        at org.apache.hadoop.hbase.master.AssignmentManager$6.run(AssignmentManager.java:1447)
        at org.apache.hadoop.hbase.master.AssignmentManager$3.run(AssignmentManager.java:1260)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
2015-08-04 17:24:06,801 WARN  [AM.ZK.Worker-pool2-t14140] master.AssignmentManager: Failed assignment of solar_image,\x00(.\xE7\xB1L,1430024620929.534025fcf4cae5516513b9c9a4cf73dc. to dx-ape-regionserver1-online,60020,1438679950072, trying to assign elsewhere instead; try=2 of 10
java.net.ConnectException: Call to dx-ape-regionserver1-online/10.11.21.140:60020 failed on connection exception: java.net.ConnectException: Connection timed out
        at org.apache.hadoop.hbase.ipc.RpcClient.wrapException(RpcClient.java:1483)
        at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1461)
        at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
        at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
        at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.openRegion(AdminProtos.java:20964)
        at org.apache.hadoop.hbase.master.ServerManager.sendRegionOpen(ServerManager.java:671)
        at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:2097)
        at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1577)
        at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1550)
        at org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.process(ClosedRegionHandler.java:104)
        at org.apache.hadoop.hbase.master.AssignmentManager.handleRegion(AssignmentManager.java:999)
        at org.apache.hadoop.hbase.master.AssignmentManager$6.run(AssignmentManager.java:1447)
        at org.apache.hadoop.hbase.master.AssignmentManager$3.run(AssignmentManager.java:1260)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection timed out
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
        at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:578)
        at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:868)
        at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
        at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
        ... 16 more
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14074,"I found hbase clutser crashed on-the-hour
HBase master running log as follows

""2015-07-14 14:41:49,832 DEBUG [master:10.240.131.18:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: 10-241-125-46%2C60020%2C1436841063572.1436851865226
2015-07-14 14:45:49,822 DEBUG [master:10.240.131.18:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: 10-241-85-137%2C60020%2C1436841341086.1436852143141
2015-07-14 15:00:03,481 INFO  [main] util.VersionInfo: HBase 0.96.2-hadoop2
2015-07-14 15:00:03,481 INFO  [main] util.VersionInfo: Subversion https://svn.apache.org/repos/asf/hbase/tags/0.96.2RC2 -r 1581096
2015-07-14 15:00:03,481 INFO  [main] util.VersionInfo: Compiled by stack on Mon Mar 24 16:03:18 PDT 2014
2015-07-14 15:00:03,729 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2015-07-14 15:00:03,730 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=10-240-131-18
2015-07-14 15:00:03,730 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_72

...

2015-07-14 15:00:03,749 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=clean znode for master connecting to ZooKeeper ensemble=10.240.131.17:2200,10.240.131.16:2200,10.240.131.15:2200,10.240.131.14:2200,10.240.131.18:2200
2015-07-14 15:00:03,751 INFO  [main-SendThread(10-240-131-18:2200)] zookeeper.ClientCnxn: Opening socket connection to server 10-240-131-18/10.240.131.18:2200. Will not attempt to authenticate using SASL (unknown error)
2015-07-14 15:00:03,757 INFO  [main-SendThread(10-240-131-18:2200)] zookeeper.ClientCnxn: Socket connection established to 10-240-131-18/10.240.131.18:2200, initiating session
2015-07-14 15:00:03,764 INFO  [main-SendThread(10-240-131-18:2200)] zookeeper.ClientCnxn: Session establishment complete on server 10-240-131-18/10.240.131.18:2200, sessionid = 0x34e8a64b453024a, negotiated timeout = 40000
2015-07-14 15:00:04,835 INFO  [main] zookeeper.ZooKeeper: Session: 0x34e8a64b453024a closed
2015-07-14 15:00:04,835 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down""


After print "" Didn't find this log in ZK..."" every hour at a time
The master dead


Zookeeper  running log as follows

""2015-07-14 15:00:03,756 [myid:3] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2200:NIOServerCnxnFactory@197] - Accepted socket connection from /10.240.131.18:52733
2015-07-14 15:00:03,761 [myid:3] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2200:ZooKeeperServer@868] - Client attempting to establish new session at /10.240.131.18:52733
2015-07-14 15:00:03,762 [myid:3] - INFO  [CommitProcessor:3:ZooKeeperServer@617] - Established session 0x34e8a64b453024a with negotiated timeout 40000 for client /10.240.131.18:52733
2015-07-14 15:00:04,836 [myid:3] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2200:NIOServerCnxn@1007] - Closed socket connection for client /10.240.131.18:52733 which had sessionid 0x34e8a64b453024a""
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13724,"A little background, 

We run our server in -ea mode and have seen quite a few replication sources silently die over the past few months.

Note: the stacktrace I posted below comes from a regionserver running 0.94 but quickly looking at this issue, I believe this will happen in 98 too.  

Should we harden replication source to deal with these types of assertion errors by catching throwables, should we be dealing with this at the sequence file reader level?  Still looking into the root cause of this issue but when manually shutdown our regionservers the regionserver that recovered its queue replicated that log just fine.  So in our case a simple retry would've worked just fine.  

{code}
2015-05-08 11:04:23,348 ERROR org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Unexpected exception in ReplicationSource, currentPath=hdfs://hm6.xxx.flurry.com:9000/hbase/.logs/xxxxx.yy.flurry.com,60020,1426792702998/xxxxx.atl.flurry.com%2C60020%2C1426792702998.1431107922449
java.lang.AssertionError
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader$WALReader$WALReaderFSDataInputStream.getPos(SequenceFileLogReader.java:121)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1489)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1479)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1474)
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader$WALReader.<init>(SequenceFileLogReader.java:55)
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.init(SequenceFileLogReader.java:178)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.getReader(HLog.java:734)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.openReader(ReplicationHLogReaderManager.java:69)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.openReader(ReplicationSource.java:583)
        at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:373)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14056,"This afternoon,HBase access failure锛寀se command  'hbase hbck' Check data inconsistencies銆?Hmaster on the log is as follows锛?2015-07-10 16:24:41,285 INFO  [FifoRpcScheduler.handler1-thread-43] master.HMaster: Client=hadoop//192.168.28.12 assign dama:lowprice_intl_roundtrip_20150311,002687951001426005490000,1426090250918.01b4e069174f6bb786b4e0632f4e4740.
2015-07-10 16:24:41,285 DEBUG [FifoRpcScheduler.handler1-thread-43] master.AssignmentManager: Force region state offline {01b4e069174f6bb786b4e0632f4e4740 state=OPEN, ts=1436433547853, server=l-hbase1.dba.cn1.qunar.com,60020,1436433434134}
2015-07-10 16:24:56,285 INFO  [FifoRpcScheduler.handler1-thread-43] master.AssignmentManager: Server l-hbase1.dba.cn1.qunar.com,60020,1436433434134 returned java.net.ConnectException: Connection timed out for dama:lowprice_intl_roundtrip_20150311,002687951001426005490000,1426090250918.01b4e069174f6bb786b4e0632f4e4740., try=1 of 10
java.net.ConnectException: Connection timed out
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)
        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
        at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:578)
        at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:868)
        at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
        at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
        at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
        at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
        at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
        at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1717)
        at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:730)
        at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1705)
        at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1822)
        at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1453)
        at org.apache.hadoop.hbase.master.HMaster.assignRegion(HMaster.java:2500)
        at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:42259)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2031)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
        at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)

Regionserver on the log is as follows锛?2015-07-10 16:34:35,672 WARN  [B.defaultRpcServer.handler=18,queue=0,port=60020] regionserver.HRegion: Failed getting lock in batch put, row=LEDHKTABPNCB4RU004001150711999999
org.apache.hadoop.hbase.regionserver.WrongRegionException: Requested row out of range for row lock on HRegion atpco:atp_fare,M,1435898852855.e2f9f303a434f3f27dfc839c01c3d9eb., startKey='M', getEndKey()='N', row='LEDHKTABPNCB4RU004001150711999999'
        at org.apache.hadoop.hbase.regionserver.HRegion.checkRow(HRegion.java:3456)
        at org.apache.hadoop.hbase.regionserver.HRegion.getRowLock(HRegion.java:3474)
        at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2394)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2261)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2213)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2217)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:4386)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doNonAtomicRegionMutation(HRegionServer.java:3588)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3477)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29593)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2031)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
        at java.lang.Thread.run(Thread.java:744)

What's the problem锛?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,2015-07-10 16:56:20.457,,false,,,,,,,,,,,,,9223372036854775807,,,,,Fri Jul 10 16:56:20 UTC 2015,,,,,,0|i2h3cf:,9223372036854775807,,,,,,,,10/Jul/15 16:56;stack;Please do not file an issue and ask a question on the mailing list. Resolving as invalid.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBase Srores NULL Value from delimited File Input,HBASE-14023,12842653,Bug,Resolved,HBASE,HBase,software,stack,Apache HBase is an open-source",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6578,"Right now, because sync-on-block-close is enabled, HLog causes the disk to stall out on large writes (esp when we cross block boundary).

We currently use 256MB blocks. The idea is that if we use smaller block sizes, we should be able to spray the data across more disks (because of round robin scheduling) and this would cause more uniform disk usage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13962,"hi every body
my table has some cell that load with bulk load scenario and some cells for increment.
we use 2 job to load data into table, first job use increment in reduce site and second job use bulk load.
first we run increment job, next run bulk job and run completebulkload job, after that we got this exception:
2015-06-24 17:40:01,557 INFO  [regionserver60020-smallCompactions-1434448531302] regionserver.HRegion: Starting compaction on c2 in region table1,\x04C#P1""\x07\x94 ,1435065082383.0fe38a6c782600e4d46f1f148144b489.
2015-06-24 17:40:01,558 INFO  [regionserver60020-smallCompactions-1434448531302] regionserver.HStore: Starting compaction of 3 file(s) in c2 of table1,\x04C#P1""\x07\x94 ,1435065082383.0fe38a6c782600e4d46f1f148144b489. into tmpdir=hdfs://m2/hbase2/data/default/table1/0fe38a6c782600e4d46f1f148144b489/.tmp, totalSize=43.1m
2015-06-24 17:40:01,558 DEBUG [regionserver60020-smallCompactions-1434448531302] regionserver.StoreFileInfo: reference 'hdfs://m2/hbase2/data/default/table1/0fe38a6c782600e4d46f1f148144b489/c2/6b1249a3b474474db5cf6c664f2d98dc.d21f8ee8b3c915fd9e1c143a0f1892e5' to region=d21f8ee8b3c915fd9e1c143a0f1892e5 hfile=6b1249a3b474474db5cf6c664f2d98dc
2015-06-24 17:40:01,558 DEBUG [regionserver60020-smallCompactions-1434448531302] compactions.Compactor: Compacting hdfs://m2/hbase2/data/default/table1/0fe38a6c782600e4d46f1f148144b489/c2/6b1249a3b474474db5cf6c664f2d98dc.d21f8ee8b3c915fd9e1c143a0f1892e5-hdfs://m2/hbase2/data/default/table1/d21f8ee8b3c915fd9e1c143a0f1892e5/c2/6b1249a3b474474db5cf6c664f2d98dc-top, keycount=575485, bloomtype=ROW, size=20.8m, encoding=NONE, seqNum=9, earliestPutTs=1434875448405
2015-06-24 17:40:01,558 DEBUG [regionserver60020-smallCompactions-1434448531302] compactions.Compactor: Compacting hdfs://m2/hbase2/data/default/table1/0fe38a6c782600e4d46f1f148144b489/c2/41e13b20ee79435ebc260d11d3bf9920_SeqId_11_, keycount=562988, bloomtype=ROW, size=10.1m, encoding=NONE, seqNum=11, earliestPutTs=1435076732205
2015-06-24 17:40:01,558 DEBUG [regionserver60020-smallCompactions-1434448531302] compactions.Compactor: Compacting hdfs://m2/hbase2/data/default/table1/0fe38a6c782600e4d46f1f148144b489/c2/565c45ff05b14a419978834c86defa1a_SeqId_12_, keycount=554577, bloomtype=ROW, size=12.2m, encoding=NONE, seqNum=12, earliestPutTs=1435136926850
2015-06-24 17:40:01,560 ERROR [regionserver60020-smallCompactions-1434448531302] regionserver.CompactSplitThread: Compaction failed Request = regionName=table1,\x04C#P1""\x07\x94 ,1435065082383.0fe38a6c782600e4d46f1f148144b489., storeName=c2, fileCount=3, fileSize=43.1m (20.8m, 10.1m, 12.2m), priority=1, time=6077271921381072
java.io.IOException: Could not seek StoreFileScanner[org.apache.hadoop.hbase.io.HalfStoreFileReader$1@1d1eb574, cur=null] to key /c2:/LATEST_TIMESTAMP/DeleteFamily/vlen=0/mvcc=0
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:164)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.seekScanners(StoreScanner.java:329)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.<init>(StoreScanner.java:252)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.<init>(StoreScanner.java:214)
        at org.apache.hadoop.hbase.regionserver.compactions.Compactor.createScanner(Compactor.java:299)
        at org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:87)
        at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:112)
        at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1113)
        at org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1519)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:498)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to read compressed block at 10930320, onDiskSizeWithoutHeader=22342, preReadHeaderSize=33, header.length=33, header bytes: \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1549)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1413)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:394)
        at org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.loadDataBlockWithScanInfo(HFileBlockIndex.java:253)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:539)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:560)
        at org.apache.hadoop.hbase.io.hfile.AbstractHFileReader$Scanner.seekTo(AbstractHFileReader.java:308)
        at org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(HalfStoreFileReader.java:205)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:244)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:152)
        ... 12 more
Caused by: java.io.IOException: Invalid HFile block magic: \x00\x00\x00\x00\x00\x00\x00\x00
        at org.apache.hadoop.hbase.io.hfile.BlockType.parse(BlockType.java:154)
        at org.apache.hadoop.hbase.io.hfile.BlockType.read(BlockType.java:165)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock.<init>(HFileBlock.java:252)
        at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1546)
        ... 21 more",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13818,"manual region split from HBase shell, I found that split command acts incorrectly with hex split keys

hbase(main):001:0> split 'sdb,\x00\x00+Ug\xD60\x00\x00\x01\x00\x10\xC0,1432909366893.6b601fa4eb9e1244d049bde93e340736.'
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/data/xiaoju/hbase-0.96.2-hadoop2/lib/phoenix-4.1.0-client-hadoop2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/data/xiaoju/hbase-0.96.2-hadoop2/lib/slf4j-log4j12-1.6.4.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/data/xiaoju/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
2015-06-01 11:40:46,986 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

ERROR: Illegal character code:44, <,> at 3. User-space table qualifiers can only contain 'alphanumeric characters': i.e. [a-zA-Z_0-9-.]: sdb,""\x00\x00+Ug\xD60\x00\x00\x01\x00\x10\xC0"",1432909366893.6b601fa4eb9e1244d049bde93e340736.

Here is some help for this command:
Split entire table or pass a region to split individual region.  With the 
second parameter, you can specify an explicit split key for the region.  
Examples:
    split 'tableName'
    split 'namespace:tableName'
    split 'regionName' # format: 'tableName,startKey,id'
    split 'tableName', 'splitKey'
    split 'regionName', 'splitKey'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13808,"Found a few NPEs in unit tests.
org.apache.phoenix.end2end.RegexpSplitFunctionIT Time elapsed: 0.002 sec <<< ERROR!
java.lang.NullPointerException: null
at org.apache.phoenix.query.BaseTest.disableAndDropNonSystemTables(BaseTest.java:1629)
at org.apache.phoenix.query.BaseTest.dropNonSystemTables(BaseTest.java:519)
at org.apache.phoenix.end2end.BaseHBaseManagedTimeIT.doTeardown(BaseHBaseManagedTimeIT.java:59)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
at org.junit.runners.Suite.runChild(Suite.java:128)
at org.junit.runners.Suite.runChild(Suite.java:27)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:107)
at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeLazy(JUnitCoreWrapper.java:88)
at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:57)
at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:144)
at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)
at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13705,"I've found the issue during code review, so I don't have tests and I even didn't test this case manualy. So I'll try to describe it in words.
Pre-condition: we're using scan with MultiRowRangeFilter with some RowRange's with startRowInclusive = false. This means that we want to include all rows that are strictly greater than startRow (and less then stopRow, but it doesn't matter for now). 
What happens in MultiRowRangeFilter.filterRowKey (worth case is described):
1. Line 91: Check if current range contains a row. Lets follow the case when it doesn't.
2. Line 94: Search for the next RowRange in method getNextRangeIndex.
3. Line 238: We've found a RowRange, check if startRowInclusive == false and set EXCLUSIVE = true. This variable indicates if next row should be excluded.
4. Line 105: Check if EXCLUSIVE == true, if so skip this row.
The problem: we've skipped first row we got in this range, but we never checked if this row is a RowRange.startRow . In distributed system may not get RowRange.startRow on current instance, so we may exclude some another row. Moreover, we may not have RowRange.startRow at all in the DB, we will exclude some rows that are (possible) close to RowRange.startRow, but not equals to it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13678,"When batch get some data from cluster, the client will block some threads base on region server amount

In code client use Future.get block a thread for each related region servers and wait them finish one by one.

In our case we have 12 region servers, so most of time the client will cost 12 threads for a batch get, if we have many concurrent request it will OOM by can not create native threads.

I suggest we use some kind async or call back to process region server's response.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13189,PrefixTreeCell should implement HeapSize. The CellUtil.estimatedHeapSize getting used in scanner estimates.  With PrefixTreecell not implementing HeapSize we may get an incorrect result.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6148,"Recently RegionServer allocates very large objects when reading some corrupted RPC calls, which may caused by client-server version incompatibility. We need to add a protection before allocating the objects. 

Apache trunk won't suffer from this problem since it had moved to the versioned invocation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9683,Port HTrace (HBASE-6524) to 0.94. This patch includes a wire-format change on writable RPC. It serializes the traceID and spanID in class Invocation. This should be compatible with old versions.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8720,"{code}
    SnapshotSubprocedurePool(String name, Configuration conf) {
      // configure the executor service
      long keepAlive = conf.getLong(
        RegionServerSnapshotManager.SNAPSHOT_TIMEOUT_MILLIS_KEY,
        RegionServerSnapshotManager.SNAPSHOT_TIMEOUT_MILLIS_DEFAULT);
      int threads = conf.getInt(CONCURENT_SNAPSHOT_TASKS_KEY, DEFAULT_CONCURRENT_SNAPSHOT_TASKS);
      this.name = name;
      executor = new ThreadPoolExecutor(1, threads, keepAlive, TimeUnit.MILLISECONDS,
          new LinkedBlockingQueue<Runnable>(), new DaemonThreadFactory(""rs(""
              + name + "")-snapshot-pool""));
      taskPool = new ExecutorCompletionService<Void>(executor);
    }
{code}
ThreadPoolExecutor锛?
corePoolSize锛?
maximumPoolSize锛?
workQueue锛歀inkedBlockingQueue锛寀nlimited
so when a new task submit to the ThreadPoolExecutor, if there is a task is running, the new task is queued in the queue, so all snapshot region tasks execute one by one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3577,"The current thrift interface has the getTableRegions() interface like below.

{code}
  list<TRegionInfo> getTableRegions(
    /** table name */
    1:Text tableName)
    throws (1:IOError io)
{code}
{code}
struct TRegionInfo {
  1:Text startKey,
  2:Text endKey,
  3:i64 id,
  4:Text name,
  5:byte version
}
{code}

But the method don't have the region location information (where the region is located).

I want to add the Thrift interfaces like below in HTable.java.

{code}
public Map<HRegionInfo, HServerAddress> getRegionsInfo() throws IOException
{code}
{code}
public HRegionLocation getRegionLocation(final String row)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4337,"In HADOOP-6255, a proposal was made for common directory layout for Hadoop ecosystem.  This jira is to track the necessary work for making HBase directory structure aligned with Hadoop for better integration.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4635,"Comment from HBASE-3606:

Eric, it looks like hbase rpm spec file sets dependency on jdk. Can we remove the jdk dependency ? As everyone will not be installing jdk through rpm.

There are multiple ways to install Java on Linux.  It would be better to remove Java dependency declaration for packaging.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6480,"Current if the callQueueSize exceed maxQueueSize, all call will be rejected, Should we let the priority Call pass through?

Current:
{code}
if ((callSize + callQueueSize.get()) > maxQueueSize) {
  Call callTooBig = xxx
  return ;
}
if (priorityCallQueue != null && getQosLevel(param) > highPriorityLevel) {
  priorityCallQueue.put(call);
  updateCallQueueLenMetrics(priorityCallQueue);
} else {
  callQueue.put(call);              // queue the call; maybe blocked here
  updateCallQueueLenMetrics(callQueue);
}
{code}
Should we change it to :
{code}
if (priorityCallQueue != null && getQosLevel(param) > highPriorityLevel) {
  priorityCallQueue.put(call);
  updateCallQueueLenMetrics(priorityCallQueue);
} else {
  if ((callSize + callQueueSize.get()) > maxQueueSize) {
   Call callTooBig = xxx
   return ;
  }
  callQueue.put(call);              // queue the call; maybe blocked here
  updateCallQueueLenMetrics(callQueue);
}
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13474,"during selecting Hfiles for the Stripe Compaction,
If includeL0==true, int minFiles set to the number of allFiles in the stripe.
It make compaction for All of files in the stripe 
or No compaction at all (which is the problem). 

the Stripe compaction uses exploring compaction inside.
some of HFiles in the stripe is too big, these all files are gonna never pass the ratio check
and compaction will be cancelled 
next time the compaction is occurred, includeL0 will be true again. 
so compactions (even minor compactions) will not happen almost forever.
Flushing makes more small HFiles and no compaction happening,
so numerous tiny HFiles are gonna file up in the stripe, and it鈥檚 going to be a problem.

there is no such thing as major compaction in the stripe compaction.
But we need to compact every file of the stripe to drop deletes at some point.

IMHO  there is not one stripe in the region, there are many.
when includeL0==true, compact all HFiles in the stripe without selecting is reasonable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13461,"I try to dump  thread stack below:

""RpcServer.handler=63,port=60020"" daemon prio=10 tid=0x00007fdcddc5d000 nid=0x5f9 waiting for monitor entry [0x00007fd289194000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:98)
        - waiting to lock <0x00007fd36c023728> (a org.apache.hadoop.hdfs.DFSOutputStream)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:59)
        at java.io.DataOutputStream.write(DataOutputStream.java:90)
        - locked <0x00007fd510cfdc28> (a org.apache.hadoop.hdfs.client.HdfsDataOutputStream)
        at com.google.protobuf.CodedOutputStream.refreshBuffer(CodedOutputStream.java:833)
        at com.google.protobuf.CodedOutputStream.flush(CodedOutputStream.java:843)
        at com.google.protobuf.AbstractMessageLite.writeDelimitedTo(AbstractMessageLite.java:91)
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.append(ProtobufLogWriter.java:87)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$LogSyncer.hlogFlush(FSHLog.java:1026)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.syncer(FSHLog.java:1075)
        - locked <0x00007fd2d9bbfad0> (a java.lang.Object)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.sync(FSHLog.java:1240)
        at org.apache.hadoop.hbase.regionserver.HRegion.syncOrDefer(HRegion.java:5593)
        at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2315)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2028)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:4094)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doNonAtomicRegionMutation(HRegionServer.java:3380)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3284)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26935)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2185)
        at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1889)

""RpcServer.handler=12,port=60020"" daemon prio=10 tid=0x00007fdcddf2c800 nid=0x5c6 in Object.wait() [0x00007fd28c4c7000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.DFSOutputStream.waitForAckedSeqno(DFSOutputStream.java:1803)
        - locked <0x00007fd45857c540> (a java.util.LinkedList)
        at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1697)
        at org.apache.hadoop.hdfs.DFSOutputStream.hflush(DFSOutputStream.java:1590)
        at org.apache.hadoop.hdfs.DFSOutputStream.sync(DFSOutputStream.java:1575)
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:121)
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:135)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.syncer(FSHLog.java:1098)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.sync(FSHLog.java:1240)
        at org.apache.hadoop.hbase.regionserver.HRegion.syncOrDefer(HRegion.java:5593)
        at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2315)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2028)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:4094)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doNonAtomicRegionMutation(HRegionServer.java:3380)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3284)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26935)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2185)
        at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1889)

""RpcServer.handler=11,port=60020"" daemon prio=10 tid=0x00007fdcdd9e1000 nid=0x5c5 in Object.wait() [0x00007fd28c5c8000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.DFSOutputStream.waitForAckedSeqno(DFSOutputStream.java:1803)
        - locked <0x00007fd45857c540> (a java.util.LinkedList)
        at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1697)
        at org.apache.hadoop.hdfs.DFSOutputStream.hflush(DFSOutputStream.java:1590)
        at org.apache.hadoop.hdfs.DFSOutputStream.sync(DFSOutputStream.java:1575)
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:121)
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:135)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.syncer(FSHLog.java:1098)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.sync(FSHLog.java:1240)
        at org.apache.hadoop.hbase.regionserver.HRegion.syncOrDefer(HRegion.java:5593)
        at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2315)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2028)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:4094)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doNonAtomicRegionMutation(HRegionServer.java:3380)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3284)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26935)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2185)
        at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1889)


""RpcServer.handler=95,port=60020"" daemon prio=10 tid=0x00007fdcdc50b800 nid=0x619 in Object.wait() [0x00007fd287174000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:485)
        at org.apache.hadoop.hdfs.DFSOutputStream.waitAndQueueCurrentPacket(DFSOutputStream.java:1475)
        - locked <0x00007fd45857c540> (a java.util.LinkedList)
        at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1688)
        - locked <0x00007fd36c023728> (a org.apache.hadoop.hdfs.DFSOutputStream)
        at org.apache.hadoop.hdfs.DFSOutputStream.hflush(DFSOutputStream.java:1590)
        at org.apache.hadoop.hdfs.DFSOutputStream.sync(DFSOutputStream.java:1575)
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:121)
        at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:135)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.syncer(FSHLog.java:1098)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.sync(FSHLog.java:1240)
        at org.apache.hadoop.hbase.regionserver.HRegion.syncOrDefer(HRegion.java:5593)
        at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2315)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2028)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:4094)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doNonAtomicRegionMutation(HRegionServer.java:3380)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3284)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:26935)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2185)
        at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1889)




""DataStreamer for file /hbase/WALs/hdp910.qq.diditaxi.com,60020,1428079391214/hdp910.qq.diditaxi.com%2C60020%2C1428079391214.1428919313998 block BP-1892361854-10.231.149.77-1397112594861:blk_1320569732_10997627
53479"" daemon prio=10 tid=0x00007fdccda8f800 nid=0x4c34 in Object.wait() [0x00007fd23646c000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:491)
        - locked <0x00007fd45857c540> (a java.util.LinkedList)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4630,"I've been doing some isolated benchmarking of a single RS and can repeatedly trigger some craziness in the master if I shutdown the RS.  It is never able to recover after bringing RSs back online.  I seem to see different behavior across different branches / revisions of the 92 branch, but there does seem to be an issue in several of them.

Putting against 0.92.1 so we don't hold up the release of 0.92.  Should not be a blocker.

Working on a unit test now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5265,"The 'revoke' shell command needs to be reworked for the AccessControlProtocol implementation that was finalized for 0.92. The permissions being removed must exactly match what was previously granted. No wildcard matching is done server side.

Allow two forms of the command in the shell for convenience:

Revocation of a specific grant:
{code}
revoke <user>, <table>, <column family> [ , <column_qualifier> ]
{code}

Have the shell automatically do so for all permissions on a table for a given user:
{code}
revoke <user>, <table>
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5905,"After a short discussion with Stack, I create a jira.
--
I'am a little bit confused by the protobuf interface for closeRegion.

We have two types of closeRegion today:
1) the external ones; available in client.HBaseAdmin. They take the server and the region identifier as a parameter and nothing else.
2) The internal ones, called for example by the master. They have more parameters (like versionOfClosingNode or transitionInZK).

When I look at protobuf.ProtobufUtil, I see:

  public static void closeRegion(final AdminProtocol admin,
      final byte[] regionName, final boolean transitionInZK) throws IOException {
    CloseRegionRequest closeRegionRequest =
      RequestConverter.buildCloseRegionRequest(regionName, transitionInZK);
    try {
      admin.closeRegion(null, closeRegionRequest);
    } catch (ServiceException se) {
      throw getRemoteException(se);
    }
  }


In other words, it seems that we merged the two interfaces into a single one. Is that the intend?
I checked, the internal fields in closeRegionRequest are all optional (that's good). Still, it means that the end user could use them or at least would need to distinguish between the ""optional for functional reasons"" and the ""optional - do not use"".
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5846,"Here is how I executed rpm build: 
{noformat}
MAVEN_OPTS=""-Xmx2g"" mvn clean package assembly:single -Prpm -DskipTests
{noformat}

The issues with the rpm build are: 
* There is no clean (%clean) section in the hbase.spec file . Last run can leave stuff in RPM_BUILD_ROOT which in turn will fail build. As a fix I added 'rm -rf $RPM_BUILD_ROOT' to %clean section

* The Buildroot is set to _build_dir . The build fails with this error. 
{noformat}
cp: cannot copy a directory, `/data/9adda425-1f1e-4fe5-8a53-83bd2ce5ad45/app/jenkins/workspace/hbase.92/target/rpm/hbase/BUILD', into itself, `/data/9adda425-1f1e-4fe5-8a53-83bd2ce5ad45/app/jenkins/workspace/hbase.92/target/rpm/hbase/BUILD/BUILD'
{noformat}
If we set it to ' %{_tmppath}/%{name}-%{version}-root' build passes

* The src/packages/update-hbase-env.sh script will leave inconsistent state if 'yum update hbase' is executed. It deletes data from /etc/init.d/hbase* and does not put scripts back during update. 


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5832,"From IRC this morning:

{code}
07:26 < ntelford> is there a way to monitor the number and size of
store files *per region*?
07:26 < ntelford> I know region servers expose a metric on the total
across all regions, but that's fairly unhelpful to us
...
08:11 < St^Ack> ntelford: no. number is easy but when you say size,
you mean size of all the storefiles in the region, not the size per
storefile (asking because one of the lads is exposing per region
metrics at mo and those would be easy to add)
08:12 < ntelford> St^Ack, for size we're actually interested in the
individual store file size
08:13 < St^Ack> ntelford: how would we do that in metric?  metric
would be dynamic
08:13 < ntelford> specifically, we want to monitor: the maximum,
minimum, mean (and some percentiles) number of store files within a
region
...
08:13 < ntelford> and the maximum, minimum, mean (+ percentiles) size
of individual store files
08:13 < ntelford> :)
08:13 < St^Ack> now you are verging on abuse!
...
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4835,"Mikhail reported this from a five-node, three-RS cluster test:

{code}
2011-11-21 01:30:15,188 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: ABORTING region server <machine_name>,60020,1321867814890: Initialization of RS failed. Hence aborting RS.
java.util.ConcurrentModificationException
at java.util.Hashtable$Enumerator.next(Hashtable.java:1031)
at org.apache.hadoop.conf.Configuration.iterator(Configuration.java:1042)
at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:75)
at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:245)
at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:144)
at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:124)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getZooKeeperWatcher(HConnectionManager.java:1262)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.setupZookeeperTrackers(HConnectionManager.java:568)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:559)
at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:183)
at org.apache.hadoop.hbase.catalog.CatalogTracker.<init>(CatalogTracker.java:177)
at org.apache.hadoop.hbase.regionserver.HRegionServer.initializeZooKeeper(HRegionServer.java:575)
at org.apache.hadoop.hbase.regionserver.HRegionServer.preRegistrationInitialization(HRegionServer.java:534)
at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:642)
at java.lang.Thread.run(Thread.java:619)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5543,"On the user list someone wrote in with a connection failure due to a long running coprocessor:
{quote}
On Wed, Mar 7, 2012 at 10:59 PM, raghavendhra rahul wrote:
2012-03-08 12:03:09,475 WARN org.apache.hadoop.ipc.HBaseServer: IPC Server Responder, call execCoprocessor([B@50cb21, getProjection(), rpc version=1, client version=0, methodsFingerPrint=0), rpc version=1, client version=29, methodsFingerPrint=54742778 from 10.184.17.26:46472: output error
2012-03-08 12:03:09,476 WARN org.apache.hadoop.ipc.HBaseServer: IPC Server handler 7 on 60020 caught: java.nio.channels.ClosedChannelException
{quote}

I suggested in response we might consider give our RPC a keepalive option for calls that may run for a long time (like execCoprocessor).

LarsH +1ed the idea:
{quote}
+1 on ""keepalive"". It's a shame (especially for long running server code) to do all the work, just to find out at the end that the client has given up.

Or maybe there should be a way to cancel an operation if the clients decides it does not want to wait any longer (PostgreSQL does that for example). Here that would mean the server would need to check periodically and coprocessors would need to be written to support that - so maybe that's no-starter.
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5530,We currently have major versions 0 and 1. The HBase checksum patch introduces minor version 0 and 1. Then the columnar HFileBlock might introduce yet another disk format version. We need a simple but elegant framework to test the compatibility of code with all these disk format versions. We also want to do this without much code duplication in TestHFileBlockCompatibility.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5262,"Creating this JIRA to open a discussion about a structured (machine-readable) log that will record events such as compaction start/end times, compaction input/output files, their sizes, the same for flushes, etc. This can be stored e.g. in a new system table in HBase itself. The data from this log can then be analyzed and used to optimize compactions at run time, or otherwise auto-tune HBase configuration to reduce the number of knobs the user has to configure.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5462,"We have a big table which have 30k regions but the request is not very high (about 50K per day).
We use the hbase.master.cluster_request metrics to monitor the cluster request but find that lots of requests is generated by master, which scan the meta table at regular intervals.
It is hard for us to monitor the real request from the client, it is possible to filter the scanning meta table or create a new metric which could show the real request from client.

Thank you.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5374,"SchemaMetrics.useTableNameGlobally is a Boolean object that is not initialized. It depends on public static method configureGlobally() to initialize it based on the configuration file. But this is only done for writer, not for reader. So when invoking hfile tool,
{code}
hbase/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile -v -f YourFile
{code}
where HFileReaderV2 is invoked, it throws exception complaining the flag is null. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5301,"Mikael Sitruk commented on this back in Nov 2011 and after looking at this I completely agree with him.  For example, ""flushSize_avg_time"" makes no sense.  ""flushSize"" is in bytes, so is this the average flush size?  Or the average time per flush?  In which case, why not call the measure ""flush_avg_time"".  But to add to the confusion there is already a ""flushTime_avg_time"" metric.  There is also ""flushTime_num_ops"" and ""flushSize_num_ops"" that are confusing.  Is the former the number of flushes?  In which case, why have ""time"" in the metric name?  


On 11/22/11 5:23 PM, ""Mikael Sitruk"" <mikael.sitruk@gmail.com> wrote:

Hi

I have enabled metrics on Hbase cluster (0.90.1), and mapped the metrics
to
3 categories (missing, Present but not documented/Incomplete
documentation,Ok) according to their status in the book (
http://hbase.apache.org/book.html#hbase_metrics). Is it possible to udpate
the book accordingly?
It seems also that rpc metrics are not documented at all.

And now some questions on the metrics:
I can see some metrics present a num_ops and avg_time suffix (like rpc)
but
it seems that for certain metrics is it totally unclear (to me at least)
or
their name is missleading - for example what
means compactionTime_avg_time/compactionTime_num_ops? or
flushSize_avg_time
and flushSize_num_ops? I mean I would have understood compaction_avg_time
and flushSize or flush_avg_time.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5316,"Currently HTable and HBaseAdmin read configurations based on the same config key, such as hbase.client.retries.number and hbase.client.retries.number
Actually in some cases, the client needs different settings for HTable operations and HBaseAdmin operations.
One way is to pass different HBaseConfiguration objects to HTable and HBaseAdmin.
Another much clearer way is to separate the configurations for HTable and HBaseAdmin by using different config keys.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5272,"Currently the body of DefaultLoadBalancer.balanceCluster() is 250 lines long.
It involves multiple iterations which deal with various kinds of corner cases.

We should simplify this part of code.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5135,"The jar adding methods of TableMapReduceUtil seem to be bypassing the DistributedCache API by plugging in the jar lists themselves to the actual property. This is not a good practice and must be avoided if possible.

_Observed during HBASE-3274_.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5132,Consider exposing master event handler state as monitored tasks.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1254,"Chatting up on IRC, 2G seems like way outer reaches of what we could ever handle.  Add checks to client.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5067,"In STANDALONE mode:
When setting the configuration option ""hbase.master.dns.interface"" (and optional ""hbase.master.dns.nameserver"") to non-default values,

it is EXPECTED that the master node would report its fully qualified dns name when registering in ZooKeeper,
BUT INSTEAD, the machines hostname is taken instead.

For example, my machine is called (aka ""its hostname is..."") ""machine1"" but it's name in the network is ""machine1.our-dev-network.my-corp.com"", so to find this machine's IP anywhere on the network i would need to query for the whole name (because trying to find ""machine1"" is ambiguous on a network).

Why is this a bug, because when trying to connect to this stand-alone hbase installation from outside the machine it is running on, when querying ZK for /hbase/master we get only the ""machine1"" part, and then fail with an unresolvable address for the master (which later even gives a null pointer because of a missing null check).

This is the stack trace when calling HTable's c'tor:
java.lang.IllegalArgumentException: hostname can't be null
	at java.net.InetSocketAddress.<init>(InetSocketAddress.java:139) ~[na:1.7.0_02]
	at org.apache.hadoop.hbase.HServerAddress.getResolvedAddress(HServerAddress.java:108) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.HServerAddress.<init>(HServerAddress.java:64) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.zookeeper.RootRegionTracker.dataToHServerAddress(RootRegionTracker.java:82) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.zookeeper.RootRegionTracker.waitRootRegionLocation(RootRegionTracker.java:73) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:579) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:559) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:688) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:590) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:559) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:688) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:594) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:559) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:173) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:147) ~[hbase-0.90.4.jar:0.90.4]

==============

Why this happens?
1. When building the HMaster object we correctly use the static 'getMyAddress(conf)' to read the configuration options, and then to try and resolve the machine's ip. This method returns the full qualified name correctly, and this is then used to construct an 'HServerAddress' object which is locally stored as 'a'.
2. So far so good, but now, instead of using this object as the value for the master's 'address' field the code goes on to initialize the 'rpcServer' field. As part of this calls the static 'HBaseRPC.getServer' method is called with, among others, the HServerAddress's BIND ADDRESS (aka the IP) that we have just built.
3. But now, when we finally get to setting the value for HMaster's 'address' field, we initialize a NEW HServerAddress initialized with rpcServer.getListenerAddress() (which is basically the IP we just gave it, with a new listening port.
4. HServerAddress calls 'getAddress().getHostName()' on this address object, which would return the local hostname of the machine, because the IP would be resolved locally by the machine, and not using a nameserver.

So eventually, the fully qualified name computed in step 1 is NOT USED in any way, instead, all further processing is done on the IP address of the host (and its local resolving to the hostname).

=======

What should happen?
The 'HMaster.address' field should be set to an address which is made of the fully qualified name retrieved in step 1, combined with the port retrieved from the rpcServer computed at step 2.

====

Notes:

1. It seems that the 'HBaseServer' c'tor (which is called when 'HBaseRPC.getServer()' static method is called) is faulty as it doesn't use the port number sent to it in effect (it sets the local 'port' field to it, but then overrides it without ever reading it later on, with the port returned from the new 'Listener' object. This might be a bug, but i have not checked it enough.

2. The same bug with the master node could repeat itself in the region server code, but i haven't checked that at all.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4961,"I was logged into the ASF build machines and saw about 10-15 HBase precommit builds that have been hung for weeks. I took a jstack of each, which I'll attach here. I then kill -9ed them to free up the resources.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4902,"i have 13 millions keys, I use presplit of 1000 regions.
while looking at the regions created, i see 

Region Name : TC,sub_10386999,1322603111143.5b36001298f3dab177edf3a7265c628a.
Start Key: sub_10386999
End Key:   sub_103999 

That is instead sub_10386999 + 13000 = sub_10399999 the ui will only show sub_1039999 (missing last 9 digit)
It occurs in several place in different region
for another key also:
Start: sub_4406999
End:   sub_441999
instead of sub_4419999

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4887,"Currently the ordinal of compression algorithms is used.
This places unnecessary constraint when new compress algorithm is added.

We should write full enum name of Compression.Algorithm into HFile",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4873,"HBASE-4863 introduced bounded thread pool for Thrift server.
thrift2/ThriftServer should have this enhancement as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4846,"the shell script:${HBASE_HOME}/bin/hbase load the hadoop native lib like this:

if [ -d ""/usr/lib/hadoop-0.20/lib/native/${JAVA_PLATFORM}"" ] ; then
  JAVA_LIBRARY_PATH=$(append_path ""${JAVA_LIBRARY_PATH}"" /usr/lib/hadoop-0.20/lib/native/${JAVA_PLATFORM})
fi

It should work like this:

if [ -d ""${HADOOP_HOME}/lib/native/${JAVA_PLATFORM}"" ] ; then
  JAVA_LIBRARY_PATH=$(append_path ""${JAVA_LIBRARY_PATH}"" ${HADOOP_HOME}/lib/native/${JAVA_PLATFORM})
fi",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4431,Do the rebalance_based_off_region_hits_but_native_balancer_must_be_disabled part of hbase-3507.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4586,"For write-heavy/bulk-load environments, two common recommendations are to disable autoFlush and increase the size of the write buffer:

HTable.setAutoFlush(false)
HTable.setWriteBufferSize(long writeBufferSize)

Neither of exposed via the Thrift API, which seems to preclude using the Thrift interface for write-heavy environments.

As a workaround, we could specify hbase.client.write.buffer in hbase-site.xml, but there is unfortunately not an equivalent configuration setting for autoflush.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4569,"I spent a little bit of time last night hacking on the slab cache implementation to make it a little simpler. The change is:
- no longer has the composition of SlabCache containing a SingleSizeCache per slab size. SlabCache holds its own slabs
- no longer use guava's map implementations to handle a size-bounded cache. Instead, manages its own LRU linked list
- significantly less clever about synchronization. since this is an L2 cache, it should be less contended than the L1 cache, and I think we can afford to be dumb.
- should have less memory usage since there's only one map entry per key instead of several.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4514,"The current coprocessor RegionObserver API takes in a bunch of arguments into each of the method calls. Instead, it will be better if we encapsulate these arguments into a single object.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4067,It would be a good idea to make the compaction intervals of regions into a table-level property instead of an instance-wide one.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3284,"In AssignmentManager.handleSplitReport() we do:

{noformat}
    regionOffline(parent);
    regionOnline(a, hsi);
    regionOnline(b, hsi);
{noformat}

Within each of these, there is locking, but there is no locking around this entire operation.  There should be.

This might be the cause of HBASE-3278",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3067,"On Fri, Oct 1, 2010 at 8:31 AM, Stack <stack@duboce.net> wrote:
Blockcache is made of blocks pulled from HDFS.  It'd be a little awkward inserting hot records into the block cache w/o going via HDFS.

But, yes, you have a good point that flush is disruptive of hot records.

In the past we talked of a keyvalue cache on top of the block cache but it fell out of favor because block cache seemed to be good enough but sounds like we need to revive it or do some fancy dancing if column family is marked in-memory, we keep around the snapshot of memstore until we know the block cache has been populated?

Any other suggestions?

On Fri, Oct 1, 2010 at 1:26 AM, Abhijit Pol <apol@rocketfuel.com> wrote:
> we are trying to read efficiently a hot column family (in_memory=true, blockcaching=true) that get writes at say 500 qps and reads at 10,000 qps.
> - as long as writes are in memstore we get them from memstore and its fast
> - if we have read it once it will be at least in block cache (gets priority due to in_memory=true) and subsequent reads are faster
> - however memstore flush puts records on disk which demands for disk IO to get them back in block cache
>
> is there a way for memstore flush to go to blockcache?
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4133,"One desirable feature for hbck is snapshot.
hbck found 650 inconsistencies for 0.90.3 in our staging cluster. I upgraded to 0.90.4
It would be nice if I can take snapshot of the inconsistencies so that I can detect new problems (delta) after we run 0.90.4 for some time using the diff capability.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4066,"Right now, major compaction interval settings affects ALL the tables including .META. and -ROOT- as well.

It would be a good addition to let .META. compaction intervals be managed separately with its own configuration so it isn't a hassle having to do it manually like the rest of the tables.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1530,"As discussed in HBASE-1207 and to build on what was implemented in HBASE-1503, we should modify the existing KeyValueHeap in place by reusing any open scanners possible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3479,improve our javadoc!,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1764,"Working on new getClosestAtOrBefore in HBASE-1761, the way hfile scanner works where it gets the asked for key or the one just before makes for our doing more work than we should.   See the code in Store where we want to get to first element in row.  We have to go to the row before and then walk forward skipping the item that is in row before.

Consider flipping catalog tables to be regions by end-key rather than start-key at same time (RE: conversation had on the saturday night at the SUSF hackathon).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2809,"A lot of data is going through the ReplicationSources, we need to take it into our general accounting.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1667,"0.20 supports multi masters. However,

bin/hbase-daemon.sh stop master

on backup masters will bring the whole cluster down.

Per rolling upgrade wiki that stack pointed out, kill -9 for backup master is the only way to go currently.

I think it's better to make some sort of magic that we can use something like

bin/hbase-daemon.sh stop master

to properly stop either the backup master or the whole cluster.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3526,"If you have a table with TTL, the memstore will grow until it hits flush size, at which point the flush code will prune the KVs going to hfile. If you have a small TTL, it may not be necessary to flush, since pruning data in memory would ensure that we never grow too big.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4550,"when master passed regionserver different address, regionserver didn't create new zookeeper znode, master store new address in ServerManager, when call stop-hbase.sh , RegionServerTracker.nodeDeleted received path is old address, serverManager.expireServer is not be called. so stop-hbase.sh is hang.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5165,"Concurrent processing of DeleteTableHandler and ServerShutdownHandler may cause following situation
1.Table has already be disabled.
2.ServerShutdownHandler is doing MetaReader.getServerUserRegions.
3.When step2 is processing or is completed just now, DeleteTableHandler starts to delete region(Remove region from META and Delete region from FS)
4.DeleteTableHandler set table enabled.
4.ServerShutdownHandler is starting to assign region which is alread deleted by DeleteTableHandler.

The result of above operations is producing an invalid record in .META.  and can't be fixed by hbck ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11035,We can use online configuration change to specify the active list of coprocessors in CoprocessorHost (RegionCoprocessorHost). That way we don't need to close regions when we want to add/remove new coprocessors (regionobservers),,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9972,"I was debugging something in the swift branch, and found that HBase doesn't export to JMX by default. The JMX server is being spun-up anyways in single node setup, we might as well export the metrics to it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9891,"Add counters for retried puts, and succeeded puts in HTableMultiplexer.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10945,"In case of DNS errors on the machine, locating a ZK quorum might throw UnknownHostException-s, but this might be a temporary issue in most cases. Retrying a couple of times, might resolve this problem. We already retry while getting ZK node data, it only makes sense to do the same while creating the connection.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10901,"createMultiRegions and its friends have a problem that leads a bug getting null HRegionInfo from the .META. table in metaScan.

The reason is : After createMultiRegions creates new regions, it deletes old region  info from the META table. But some region server may have been openning the regions (though with a very low probability). After the rows of the openning region is completely removed, the region is openned. Then the region server tells the master its server and startCode. The master then write a row of only server address and startCode back to the META. Then a row without HRegionInfo in META table is generated.

Suggestion of fix is not to use this method. Create tables directly with specified start/stop keys.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10177,"The netty developers changed their group id from org.jboss.netty to io.netty. As a result, the zookeeper and hadoop dependencies pull in the older netty (3.2.2) and swift related dependencies pull in the newer netty (3.7.0). As a result we get ClassNotFoundExceptions, when the older 3.2.2 jar is picked up in place of 3.7.0. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11254,"The failed puts in HTableMultiplexer.HTableFlushWorker are immediately resubmitted in the original queue. This queue is being flushed every 100ms (default configuration) and the maximal retry of a failed put is by default 10 times (client configurable). That leaves us with ~1 second to complete a Put (with default configuration). We can improve this by gradually increasing the time for retrying, each time when the put fails. (example: first time retry after 100ms, then after 200ms, 400ms, etc). ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8227,Umbrella task to investigate outliers in the get and put path.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11592,We would like to make the number of SplitLogWorkers online configurable with this JIRA.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10910,"batchGet(List<Get>) is more performant since it splits the list of Gets on regionserver level, and get(List<Get>) does that on region level. 
If we have a list of gets for regions on a same regionserver, get(List<Get>) will do #regions rpc calls and batchGet(List<Get>) will do just one rpc call. 

Changing HTable.get(List<Get>) to internally call HTable.batchGet(List<Get>)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11015,"Use `ScheduledThreadPoolExecutor`
Change some logic
Add testcase
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10042,"Updating the libthrift, zookeeper, mockito, log4j and slf4j jars, since one of the customers is running into problems with the old jars that HBase pulls in. 

Also added the requireUpperBoundDeps as a rule during the building process. This will force us to specify the correct version of a dependency, if it is required transitively by multiple dependencies.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12244,"In our testing we keep running into https://jira.codehaus.org/browse/SUREFIRE-1091

My guess is that bug is also somewhat responsible fore our zombie tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8713,"Testing 0.95.1 RC1, I see these 2 lines every time the WAL is rolled:

{noformat}
2013-06-07 17:19:33,182 INFO  [RS_CLOSE_REGION-ip-10-20-46-44:50653-1] util.FSUtils: FileSystem doesn't support getDefaultReplication
2013-06-07 17:19:33,182 INFO  [RS_CLOSE_REGION-ip-10-20-46-44:50653-1] util.FSUtils: FileSystem doesn't support getDefaultBlockSize
{noformat}

It only happens on hadoop1.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12566,"I've discovered after HBASE-12550 that Phoenix has a class that was broken by a change to a package scoped method in HRegion:
{code}
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/reg
index 39a9fdc..3377e6b 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
@@ -4628,11 +4628,12 @@ public class HRegion implements HeapSize { // , Writable{
   /**
    * Create a daughter region from given a temp directory with the region data.
    * @param hri Spec. for daughter region to open.
+   * @param expectedReferenceFileCount
    * @throws IOException
    */
-  HRegion createDaughterRegionFromSplits(final HRegionInfo hri) throws IOException {
+  HRegion createDaughterRegionFromSplits(final HRegionInfo hri, int expectedReferenceFileCount) throws IOException {
     // Move the files from the temporary .splits to the final /table/region directory
-    fs.commitDaughterRegion(hri);
+    fs.commitDaughterRegion(hri, expectedReferenceFileCount);
{code}

We should change the HRegion InterfaceAudience to LimitedPrivate(COPROC, PHOENIX).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12937,"See HTRACE-92 for more detail. I'm hoping that adding calls to Tracer.getInstance().continueSpan(null) in the correct place(s) will do the trick. This is rendering tracing unusable by Phoenix. Not sure if it impact general HTrace use in HBase or not.

FYI, [~samarthjain], [~jesse_yates].",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7631,"Of a sudden on a prod cluster, a table's rows gained girth... hundreds of thousands of rows... and the application was pulling them all back every time but only once a second or so.  Regionserver was carrying hundreds of regions.  Was plain that there was lots of network out traffic.  It was tough figuring which region was the culprit (JD's trick was moving the regions off one at a time while watching network out traffic on cluster to see whose spiked next -- it worked but just some time).

If we had per region read/write sizes in metrics, that would have saved a bunch of diagnostic time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6362,"When user uploads logs / images / non-trunk patches, Hadoop QA would complain that the file couldn't be applied as a patch (for trunk).

We should make this script smarter by recognizing image files and non-trunk patches.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7734,"In RegionScanner.nextRows, checking filter's done value to ensure that null, which was the expected value by the client, was returned. This check was removed when ScanPrefetcher was introduced.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6486,Idea is to know how many MB/sec of throughput we are able to get by writing into HBase using a simple tool.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6235,"The max and min values for time varying metrics are not reset to 0 correctly. 
The fix is to reset them during the JMX refresh time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6943,"When getting a regionserver connection in 0.89-fb in HBaseClient, we catch all types of Throwable. I have observed a real case when the client looked stuck. On debugging it turned out that a NoSuchMethodError was thrown and caught, leaving the connection in an inconsistent state (initialized socket but null streams). All following attempts resulted in NPEs that were also caught, and no errors were logged. From the user's perspective the client was just stuck. The root cause was the absence of a required jar (hence the NoSuchMethodError) but it was not reported properly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4963,"We need to make sure we get per-(table, CF) get size metrics in 0.89-fb, similarly to what was done in https://reviews.facebook.net/D483 for the trunk. Currently we only get metrics such as 

  hadoop.regionserver_cf.<cf>.getsize

even with per-table metrics turned on.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2161,"the client side code has this in ClientScanner.next():

            if (e instanceof UnknownScannerException &&
                lastNext + scannerTimeout < System.currentTimeMillis()) {
              ScannerTimeoutException ex = new ScannerTimeoutException();
              ex.initCause(e);
              throw ex;
            }

This will cause the client-side to timeout after the 'scannerTimeout'. There doesn't seem to be any good reason for this - we can just restart the scanner at the last row.  Leave the server-side scanner as is, but clients should be able to have a 5 day scan that is continuously being restarted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5703,"We need to bound the number of threads spawned in HRegionThriftServer, similarly to what was done in HBASE-4863 to the standalone Thrift gateway.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7112,"the ZK_CLIENT_PORT_KEY is declared as followed:
private static final String ZK_CFG_PROPERTY = ""hbase.zookeeper.property."";
  private static final String ZK_CLIENT_PORT_KEY = ZK_CFG_PROPERTY
      + ""clientPort"";

i think it is not correct exactly, it should not contain the prefix  ZK_CFG_PROPERTY.

IMO, need to change it to private static final String ZK_CLIENT_PORT_KEY = ""clientPort"";",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7267,"In HBASE-6059, it introduced a new behavior that the compaction would create the HFileWriter no mater whether there is any key/value as the output or not. This new behavior actually is conflicts with HBASE-5199 (Delete out of TTL store files before compaction selection) so that compacting the expired hfiles would generate one more expired hfiles.

Actually we only needs to create the dummy hfile IFF the maxSequenceID among the compaction candidates is equal to the maxSequenceID among all the on-disk hfiles. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3663,"This is an interesting starvation case. There are 2 conditions to trigger this problem.
Condition1: r/s - r/(s+1) << 1 
Let r: the number of regions
Let s: the number of servers

Condition2: for each server, the load of each server is less or equal the ceil of avg load.

Here is the unit test to verify this problem: 
For example, there are 16 servers and 62 regions. The avg load is 
3.875. And setting the slot to 0 to keep the load of each server either 3 or 4. 
When a new server is coming,  no server needs to assign regions to this new server, since no one is larger the ceil of the avg.
(Setting slot to 0 is to easily trigger this situation, otherwise it needs much larger numbers)

Solutions is pretty straightforward. Just compare the floor of the avg instead of the ceil. This solution will evenly balance the load from the servers which is little more loaded than others. 

I also attached the comparison result  for the case mentioned above between the old balance algorithm and new balance algorithm. (I set the slot = 0 when testing)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6279,I don't see a reason for having the RPC methods (like HMasterInterface) define methods with the RpcController argument (which is always passed as null during invocation). ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6425,Currently it needs to be specified in millisecs when it usually is a big duration. It would make more sense to specify it in hours.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4525,"When we build the hbase, we can say which version of hadoop we want to build with.
For example:
 mvn  -DskipTests=true package
 mvn -Dhadoop.profile=22 -DskipTests=true package

However during the runtime, bin/hbase scripts will call add_maven_deps_to_classpath, which will always add the default hadoop version(0.20-append) to classpath (targets/cached_classpath.txt).

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6006,I noticed that TestDelayedRpc is flaky - testTooManyDelayedRpcs fails quite often in my setup. Seems to me that the test needs to be fixed for it to not depend on the (unpredictable) thread scheduling order in the RPC server/clients that the test creates.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5079,"The DLS interrupt can kill the regionserver if happens while conversation w/ namenode is going on.

The interrupt is used to end a task on regionserver when done whether successful or to interrupt an ongoing split since assumed by another server.

I saw this issue testing because I was killing servers.  I also was suffering ""HBASE-5078 DistributedLogSplitter failing to split file because it has edits for lots of regions"" which made it more likely to happen.

Here is what it looks like on the regionserver that died:

{code}
2011-12-20 17:54:58,009 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A7000%2Fhbase%2F.logs%2Fsv4r31s44%2C7003%2C1324365396770-splitting%2Fsv4r31s44%252C7003%252C1324365396770.1324403495463 preempted from sv4r13s38,7003,1324365396583, current task state and owner=owned sv4r27s44,7003,1324365396664
2011-12-20 17:54:58,009 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2011-12-20 17:54:59,133 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A7000%2Fhbase%2F.logs%2Fsv4r31s44%2C7003%2C1324365396770-splitting%2Fsv4r31s44%252C7003%252C1324365396770.1324403495463 preempted from sv4r13s38,7003,1324365396583, current task state and owner=owned sv4r27s44,7003,1324365396664
2011-12-20 17:54:59,134 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
...
2011-12-20 17:55:25,505 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: task /hbase/splitlog/hdfs%3A%2F%2Fsv4r11s38%3A7000%2Fhbase%2F.logs%2Fsv4r31s44%2C7003%2C1324365396770-splitting%2Fsv4r31s44%252C7003%252C1324365396770.1324403495463 preempted from sv4r13s38,7003,1324365396583, current task state and owner=unassigned sv4r11s38,7001,1324365395047
2011-12-20 17:55:25,505 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
{code}

Three interrupts are sent over period of 31 seconds or so.

Eventually the interrupt has an effect and I get:

{code}
2011-12-20 17:55:25,505 INFO org.apache.hadoop.hbase.regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2011-12-20 17:55:48,022 DEBUG org.apache.hadoop.hbase.regionserver.LogRoller: HLog roll requested
2011-12-20 17:55:58,070 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Call to sv4r11s38/10.4.11.38:7000 failed on local exception: java.nio.channels.ClosedByInterruptException
        at org.apache.hadoop.ipc.Client.wrapException(Client.java:1103)
        at org.apache.hadoop.ipc.Client.call(Client.java:1071)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
        at $Proxy9.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor37.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at $Proxy9.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.locateFollowingBlock(DFSClient.java:3507)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:3370)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2700(DFSClient.java:2586)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2826)
Caused by: java.nio.channels.ClosedByInterruptException
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)
        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:779)
        at org.apache.hadoop.ipc.Client.call(Client.java:1047)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
        at $Proxy9.getFileInfo(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at $Proxy9.getFileInfo(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:875)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:513)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:768)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.convertRegionEditsToTemp(HLogSplitter.java:1097)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.createWAP(HLogSplitter.java:1066)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.convertRegionEditsToTemp(HLogSplitter.java:1097)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.createWAP(HLogSplitter.java:1066)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:410)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:351)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:113)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.grabTask(SplitLogWorker.java:266)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.taskLoop(SplitLogWorker.java:197)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.run(SplitLogWorker.java:165)
        at java.lang.Thread.run(Thread.java:662)
2011-12-20 17:55:58,070 WARN org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Could not prepare temp staging area
java.io.IOException: Call to sv4r11s38/10.4.11.38:7000 failed on local exception: java.nio.channels.ClosedByInterruptException
        at org.apache.hadoop.ipc.Client.wrapException(Client.java:1103)
        at org.apache.hadoop.ipc.Client.call(Client.java:1071)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
        at $Proxy9.getFileInfo(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at $Proxy9.getFileInfo(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:875)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:513)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:768)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.convertRegionEditsToTemp(HLogSplitter.java:1097)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.createWAP(HLogSplitter.java:1066)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:410)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFileToTemp(HLogSplitter.java:351)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:113)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.grabTask(SplitLogWorker.java:266)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.taskLoop(SplitLogWorker.java:197)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker.run(SplitLogWorker.java:165)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.nio.channels.ClosedByInterruptException
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)
        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:779)
        at org.apache.hadoop.ipc.Client.call(Client.java:1047)
        ... 20 more
{code}

Now here is the wacky part.  Above we are trying to go to the namenode it looks like and the interrupt is closing socket.  At same, time, I'm trying to flush and it fails with same stack trace ... and because we failed a flush, regionserver goes down:

{code}
2011-12-20 17:55:58,071 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_-6239131583587622790_187561 bad datanode[0] nodes == null
2011-12-20 17:55:58,073 WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file ""/hbase/TestTable/9f98e6764d322832c845b740336e5750/.tmp/0df1673c96274028bda24c9cb49e9c3e"" - Aborting...
2011-12-20 17:55:58,074 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: ABORTING region server sv4r13s38,7003,1324365396583: Replay of HLog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: TestTable,0134394898,1323822783216.9f98e6764d322832c845b740336e5750.
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1276)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1160)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1102)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:400) 
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:374)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:243)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: Call to sv4r11s38/10.4.11.38:7000 failed on local exception: java.nio.channels.ClosedByInterruptException
        at org.apache.hadoop.ipc.Client.wrapException(Client.java:1103)
        at org.apache.hadoop.ipc.Client.call(Client.java:1071)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
        at $Proxy9.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor37.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at $Proxy9.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.locateFollowingBlock(DFSClient.java:3507)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:3370)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2700(DFSClient.java:2586)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2826)
Caused by: java.nio.channels.ClosedByInterruptException
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)
        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:779)
        at org.apache.hadoop.ipc.Client.call(Client.java:1047)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
        at $Proxy9.getFileInfo(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at $Proxy9.getFileInfo(Unknown Source)
...
{code}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5250,"From Benoit... 
{code}2012-01-20 17:13:20,634 INFO org.apache.hadoop.ipc.HBaseServer: IPC
Server Responder: doAsyncWrite threw exception java.io.IOException:
Broken pipe
2012-01-20 17:13:20,635 WARN org.apache.hadoop.ipc.HBaseServer: IPC
Server listener on 52146: readAndProcess threw exception
java.lang.NullPointerException. Count of bytes read: 0
java.lang.NullPointerException
       at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.readAndProcess(HBaseServer.java:1119)
       at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.doRead(HBaseServer.java:703)
       at org.apache.hadoop.hbase.ipc.HBaseServer$Listener$Reader.doRunLoop(HBaseServer.java:495)
       at org.apache.hadoop.hbase.ipc.HBaseServer$Listener$Reader.run(HBaseServer.java:470)
       at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
       at java.lang.Thread.run(Thread.java:680)

This is when I unexpectedly close a connection to a RS.  When the
channel gets disconnected, some buffer is nulled out, but then if
readAndProcess() is called again, it triggers the NPE above.  Not a
huge deal, but also indicates that maybe some logic in the RS's error
handling is incorrect.
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5109,"TestAvroServer has the following issue
 
    impl.modifyTable(tableAname, tableA);
    // It can take a while for the change to take effect. Wait here a while.
    while(impl.describeTable(tableAname) == null ) {
      Threads.sleep(100);
    }
    assertTrue(impl.describeTable(tableAname).maxFileSize == 123456L);
 
impl.describeTable(tableAname) returns the default maxSize 256M right away as modifyTable is async. Before HBASE-4328 is fixed, we can fix the test code to wait for say max of 5 seconds to check if impl.describeTable(tableAname).maxFileSize is uploaded to 123456L. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4619,"This appears in TableOutputFormat.java: 

{code}
@Override
    public void close(TaskAttemptContext context)
    throws IOException {
      table.flushCommits();
      // The following call will shutdown all connections to the cluster from
      // this JVM.  It will close out our zk session otherwise zk wil log
      // expired sessions rather than closed ones.  If any other HTable instance
      // running in this JVM, this next call will cause it damage.  Presumption
      // is that the above this.table is only instance.
      HConnectionManager.deleteAllConnections(true);
    }
{code}

It's not a safe assumption that a single TableOutputFormat is the only HBase client in a JVM.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4264,"The TestMergeTool.testMergeTool failure in build 2154 was due to the following check:
{noformat}
      HBaseAdmin.checkHBaseAvailable(getConf());
      LOG.fatal(""HBase cluster must be off-line."");
{noformat}
HBase cluster from some other test(s) was hanging since ""merging regions 0 and 1"" is the first merge.
The test can be made more robust by calling HBaseAdmin.shutdown() before making the first merge.

In Merge.java, -1 is returned in 5 places. I think we should return different values so that it is more obvious what the cause was.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12800,"Hi:
I am getting constant stability problems with the HBase Regionserver, it dies randomly everyday or every other day. It normally dies shortly after printing the following:

2014-12-30 23:06:17,091 ERROR [regionserver60020.logRoller] wal.ProtobufLogWriter: Got IOException while writing trailer
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/zjdx107,60020,1418269148759/zjdx107%2C60020%2C1418269148759.1419977176935 could only be replicated to 0 nodes instead of minReplication (=1).  There are 12 datanode(s) running and no node(s) are excluded in this operation.
at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1430)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2659)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:569)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:440)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)

        at org.apache.hadoop.ipc.Client.call(Client.java:1409)
        at org.apache.hadoop.ipc.Client.call(Client.java:1362)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:361)
        at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1437)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1260)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:525)
2014-12-30 23:06:17,092 ERROR [regionserver60020.logRoller] wal.FSHLog: Failed close of HLog writer
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/zjdx107,60020,1418269148759/zjdx107%2C60020%2C1418269148759.1419977176935 could only be replicated to 0 nodes instead of minReplication (=1).  There are 12 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1430)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2659)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:569)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:440)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7962,"I was trying to install Snappy.  Found this link.
http://www.spaggiari.org/index.php/hbase/how-to-install-snappy-with#.US7JNzDX_D4.

As per this link there is a native folder under lib directory in the HBase installation path and it is available in 0.94.

But when i install HBase trunk i could not see one

If am not finding this in the correct place, pls invalidate the issue. Will try figuring out what could be the problem",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12780,"Invalid issue, please ignore it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1900,Add back native lib when hadoop 0.21 is built.  Temporarily removed by hbase-1893.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5284,"Here's how to reproduce:

{noformat}
$ mvn clean -DskipTests -Dhadoop.profile=23 -Dinstall site assembly:assembly -Dmaven.repo.local=/home/rvs/.m2/repository
........
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.0.2:testCompile (default-testCompile) on project hbase: Compilation failure
[ERROR] /home/rvs/src/bigtop/output/hbase/hbase-0.92.0/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java:[341,33] cannot find symbol
[ERROR] symbol  : variable dnRegistration
[ERROR] location: class org.apache.hadoop.hdfs.server.datanode.DataNode
[ERROR] -> [Help 1]
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3815,"the loadbalancer should remember which region server is constantly having trouble opening regions and it should take that rs out of the equation ... otherwise the lb goes into an unproductive loop ... 

I don't have logs handy for this one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5149,"The following code will not return the cluster configuration but the local one which is somewhat misleading.

{code}
conn = (HConnection) HConnectionManager.getConnection(m_hbConfig); //here the configuration is local
Configuration conf = conn.getConfiguration()
conf.getString(""hbase.hregion.majorcompaction""); // will return the parameter from the local config instead of the cluster the connection is connected to.
{code}

It is suggested that once a connection has been acquired the configuration object should be the one of the cluster.

As a general observation it is not possible to retrieve the used configuration on the cluster
It is suggested to add API at {{HRegionServerInterface}}, {{HMasterInterface}} to get the configuration used by the component appropriately (note in 0.90.4 the getConfiguration exist on the Server interface implemented by HRegionServer and HMaster classes) but this interface is not visible/extended by HRegionServerInterface/HMasterInterface, therefore not accessible from client code.

Also an API like {{HashMap<HserverInfo,Configuration> getClusterConfigurations()}} can be added on the HConnection object.


Additional notes:
Since servers can have different properties values (like disk, tmp dir,...) it can be acceptable that the configuration object returned by the connection returns special value to indicate - conflict between value or that multiple values exist.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4475,"As discussed over in HBASE-4460, the current approach to ThriftServer authentication (provided in HBASE-4099) will not work in an embedded context, since the region server will already does a login for the process.

We could make the embedded thrift server still run as a separate user, though, by doing something like the following:

* add a {{User.loginAndReturnUser()}} variant that delegates to {{UserGroupInformation.loginUserFromKeytabAndReturnUGI()}}, then returns a wrapping {{User}} instance
* call this method on startup for the embedded thrift server to get the thrift user instance
* use {{User.runAs()}} to execute the body of {{HRegionThriftServer.run()}} as the logged in thrift user
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3651,"A lot of systems management is using ""role"" packages to indicate what services should run on which node.  These role packages usually contain only /etc/init.d scripts and depend on the 'core' package (see HBASE-3606) to provide the binaries.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12310,"hbase-annotations includes a custom doclet used for filtering APIs out of the user API javadoc given our project specific interface annotations. However, this is problematic for a few reasons:
- To build the doclet we include a system scope dependency to tools.jar. Default Nexus rules disallow that. Staging downstream HBase artifacts will be problematic. I don't know how we were able to release 0.98.7 with this in place. I think someone will be looking into the Apache Nexus configuration.
- As I understand it, system scope dependencies will not be supported by Maven 4 because they've been determined to be generally problematic. 
- As [~busbey] mentioned on HBASE-12299, the root pom specifies the javadoc dependency for all modules and it creates a circular need with the hbase-annotations module.

Do we really need a custom doclet? Can we simply remove all of this?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12598,"HBASE-12490 changed the 2.0.0 branch.  This is a similar change to branch-1.

The various uses of setAutoFlush() seem to need some tlc. There's a note in HTableInterface: ""@deprecated in 0.99 since setting clearBufferOnFail is deprecated. Use setAutoFlushTo(boolean) instead."" It would be ideal to change all internal uses of setAutoFlush(boolean, boolean) to use setAutoFlushTo, if possible.
HTable.setAutoFlush(boolean, boolean) is used in a handful of places. setAutoFlush(false, false) has the same results as HTable.setAutoFlush(false). Calling HTable.setAutoFlush(false, true) has the same affect as Table.setAutoFlushTo(false), assuming HTable.setAutoFlush(false) was not called previously (by default, the second parameter, clearBufferOnFail, is true and should remain true according to the comments).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12588,"Currently we don't fail write operations when can't acquiring row locks as shown below in HRegion#doMiniBatchMutation. 
{code}
...
        RowLock rowLock = null;
        try {
          rowLock = getRowLock(mutation.getRow(), shouldBlock);
        } catch (IOException ioe) {
          LOG.warn(""Failed getting lock in batch put, row=""
            + Bytes.toStringBinary(mutation.getRow()), ioe);
        }
        if (rowLock == null) {
          // We failed to grab another lock
          assert !shouldBlock : ""Should never fail to get lock when blocking"";
          break; // stop acquiring more rows for this batch
        } else {
          acquiredRowLocks.add(rowLock);
        }
...
{code}

We saw this issue when there is meta corruption problem and checkRow fails with error:
{noformat}
org.apache.hadoop.hbase.regionserver.WrongRegionException: Requested row out of range for row lock on HRegion
{noformat}

While current code still continues with writes. In all cases, this is so dangerous because row locks have to be acquired before update operations to guarantee row update atomicity.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12571,"you can follow these steps to repeat the bug:

hbase shell
create 'test', 'cf'  
disable 'test'

reboot hbase


hbase shell
enable 'test'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12453,"Currently (in trunk, with zk-less assignment), a region is available to serving requests only after RS notifies the master the region is open, and the meta is updated with the new location. We may be able to do better than this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12303,"Currently we seek to the next column when we encounter a family delete marker.
I think we safely seek the current store to next row.

We ran into a scenario with very slow scans after a lot of rows have been deleted with family delete markers. Some profiling revealed that we seek for once for each row and column.

This won't make this go away entirely, but at least we can seek once per row rather than once per column.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12175,"Trying to create a table from hbase shell and couldn't get region assigned:

{noformat}
^Gdefault^R^Dtest
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2213)
        at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1879)
Caused by: java.lang.IllegalArgumentException: Illegal character <10> at 0. Namespaces can only contain 'alphanumeric characters': i.e. [a-zA-Z_0-9]:
^Gdefault^R^Dtest
        at org.apache.hadoop.hbase.TableName.isLegalNamespaceName(TableName.java:215)
        at org.apache.hadoop.hbase.TableName.isLegalNamespaceName(TableName.java:204)
        at org.apache.hadoop.hbase.TableName.<init>(TableName.java:302)
        at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:339)
        at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:460)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12097,"Hbase shows an increasing number of IPC Threads in BLOCKED state

Hundreds of these,more and more appearing over hours, performance degrading, requiring regionserver restart to restore performance.

Thread:

Thread 421 (IPC Server handler 368 on 60201):
  State: BLOCKED
  Blocked count: 19314
  Waited count: 322565
  Blocked on org.apache.hadoop.metrics.util.MetricsIntValue@1ec5ca55
  Blocked by 236 (IPC Server handler 183 on 60201)
  Stack:
    org.apache.hadoop.metrics.util.MetricsIntValue.set(MetricsIntValue.java:73)
org.apache.hadoop.hbase.ipc.HBaseServer.updateCallQueueLenMetrics(HBaseServer.java:1360)   org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1399)

i dont actually know how to troubleshoot this much further... Happy to take suggestions...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12063,"2014-09-23 14:57:02,161 DEBUG [RS_OPEN_META-logs05:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-logs05:60020-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2014-09-23 14:57:02,161 INFO  [RS_OPEN_META-logs05:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-logs05:60020-0-WAL.AsyncWriter exiting
2014-09-23 14:57:02,161 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://logs01.yz.bj.uar.nsn:8020/apps/hbase/data/WALs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:02,161 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 10.136.172.105:50010 are bad. Aborting...
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1128)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)
2014-09-23 14:57:02,163 ERROR [regionserver60020] regionserver.HRegionServer: Metalog close and delete failed
java.io.IOException: All datanodes 10.136.172.105:50010 are bad. Aborting...
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1128)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:924)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:486)
2014-09-23 14:57:02,163 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2014-09-23 14:57:02,163 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2014-09-23 14:57:02,163 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2014-09-23 14:57:02,163 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2014-09-23 14:57:02,163 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2014-09-23 14:57:02,163 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2014-09-23 14:57:02,164 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2014-09-23 14:57:02,164 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2014-09-23 14:57:02,164 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2014-09-23 14:57:02,164 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2014-09-23 14:57:02,164 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2014-09-23 14:57:02,164 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2014-09-23 14:57:02,164 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2014-09-23 14:57:02,164 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2014-09-23 14:57:02,165 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://logs01.yz.bj.uar.nsn:8020/apps/hbase/data/WALs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:02,591 ERROR [regionserver60020] regionserver.HRegionServer: Close and delete failed
org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /apps/hbase/data/WALs/logs05.yz.bj.uar.nsn,60020,1411454591351/logs05.yz.bj.uar.nsn%2C60020%2C1411454591351.1411454597278: File does not exist. [Lease.  Holder: DFSClient_hb_rs_logs05.yz.bj.uar.nsn,60020,1411454591351_1603749335_33, pendingcreates: 1]
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2946)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3010)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2990)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:641)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1557)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:97)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkThrowable(RemoteExceptionHandler.java:49)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.closeWAL(HRegionServer.java:1188)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:998)
        at java.lang.Thread.run(Thread.java:662)
2014-09-23 14:57:02,692 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2014-09-23 14:57:02,692 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2014-09-23 14:57:08,460 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2014-09-23 14:57:08,461 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2014-09-23 14:57:08,466 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2014-09-23 14:57:08,467 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/replication/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:08,467 INFO  [regionserver60020] util.RetryCounter: Sleeping 1000ms before retry #0...
2014-09-23 14:57:09,468 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/replication/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:09,468 INFO  [regionserver60020] util.RetryCounter: Sleeping 2000ms before retry #1...
2014-09-23 14:57:11,468 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/replication/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:11,468 INFO  [regionserver60020] util.RetryCounter: Sleeping 4000ms before retry #2...
2014-09-23 14:57:15,469 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/replication/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:15,469 INFO  [regionserver60020] util.RetryCounter: Sleeping 8000ms before retry #3...
2014-09-23 14:57:23,469 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/replication/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:23,469 ERROR [regionserver60020] zookeeper.RecoverableZooKeeper: ZooKeeper getChildren failed after 4 attempts
2014-09-23 14:57:23,490 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:23,490 INFO  [regionserver60020] util.RetryCounter: Sleeping 1000ms before retry #0...
2014-09-23 14:57:24,490 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:24,490 INFO  [regionserver60020] util.RetryCounter: Sleeping 2000ms before retry #1...
2014-09-23 14:57:26,491 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:26,491 INFO  [regionserver60020] util.RetryCounter: Sleeping 4000ms before retry #2...
2014-09-23 14:57:30,492 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:30,492 INFO  [regionserver60020] util.RetryCounter: Sleeping 8000ms before retry #3...
2014-09-23 14:57:38,492 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=logs02.yz.bj.uar.nsn:2181,logs01.yz.bj.uar.nsn:2181,logs03.yz.bj.uar.nsn:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
2014-09-23 14:57:38,492 ERROR [regionserver60020] zookeeper.RecoverableZooKeeper: ZooKeeper delete failed after 4 attempts
2014-09-23 14:57:38,492 WARN  [regionserver60020] regionserver.HRegionServer: Failed deleting my ephemeral node
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase-unsecure/rs/logs05.yz.bj.uar.nsn,60020,1411454591351
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:127)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
        at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)
        at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.delete(RecoverableZooKeeper.java:156)
        at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1270)
        at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1259)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.deleteMyEphemeralNode(HRegionServer.java:1286)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1016)
        at java.lang.Thread.run(Thread.java:662)
2014-09-23 14:57:38,502 INFO  [regionserver60020] regionserver.HRegionServer: stopping server logs05.yz.bj.uar.nsn,60020,1411454591351; zookeeper connection closed.
2014-09-23 14:57:38,502 INFO  [regionserver60020] regionserver.HRegionServer: regionserver60020 exiting
2014-09-23 14:57:38,503 ERROR [main] regionserver.HRegionServerCommandLine: Region server exiting
java.lang.RuntimeException: HRegionServer Aborted
        at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:66)
        at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2403)
2014-09-23 14:57:38,506 INFO  [Thread-11] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@6e75d758
2014-09-23 14:57:38,506 INFO  [Thread-11] regionserver.HRegionServer: STOPPED: Shutdown hook
2014-09-23 14:57:38,507 INFO  [Thread-11] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2014-09-23 14:57:38,508 INFO  [Thread-11] regionserver.ShutdownHook: Shutdown hook finished.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11954,"When I want to create snapshot of a table, I get some exception like this:
{code}
hbase(main):004:0> snapshot 'booking', 'booking-snapshot-20140912'

ERROR: org.apache.hadoop.hbase.snapshot.HBaseSnapshotException: Snapshot { ss=booking-snapshot-20140912 table=booking type=FLUSH } had an error.  Procedure booking-snapshot-20140912 { waiting=[hbase1.data.cn,60020,1407930968832, hbase45.data.cn,60020,1408609189376, hbase23.data.cn,60020,1407930978740, hbase37.data.cn,60020,1408608587411, hbase46.data.cn,60020,1408609190515, hbase6.data.cn,60020,1407930958926, hbase44.data.cn,60020,1408609188252, hbase7.data.cn,60020,1407930960021, hbase49.data.cn,60020,1408609193897, hbase47.data.cn,60020,1408609191647, hbase21.data.cn,60020,1407930976874, hbase39.data.cn,60020,1408608669063, hbase13.data.cn,60020,1407930966976, hbase15.data.cn,60020,1407930969235, hbase19.data.cn,60020,1407930973863, hbase16.data.cn,60020,1407930971152, hbase18.data.cn,60020,1407930972762, hbase43.data.cn,60020,1408609187126, hbase12.data.cn,60020,1407930966365, hbase10.data.cn,60020,1407930963512, hbase3.data.cn,60020,1407930955378, hbase11.data.cn,60020,1407930965112, hbase24.data.cn,60020,1407930979654, hbase2.data.cn,60020,1407930954308, hbase9.data.cn,60020,1407930962354, hbase38.data.cn,60020,1408608663894, hbase40.data.cn,60020,1408608674240, hbase41.data.cn,60020,1408609184867, hbase4.data.cn,60020,1407930956670, hbase36.data.cn,60020,1408608406292, hbase17.data.cn,60020,1407930972505, hbase35.data.cn,60020,1408607982898, hbase20.data.cn,60020,1407930974993, hbase48.data.cn,60020,1408609192763, hbase22.data.cn,60020,1407930978159, hbase8.data.cn,60020,1407930961333] done=[] }
	at org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isSnapshotDone(SnapshotManager.java:342)
	at org.apache.hadoop.hbase.master.HMaster.isSnapshotDone(HMaster.java:2905)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:40494)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2012)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:73)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.hadoop.hbase.errorhandling.ForeignException$ProxyThrowable via timer-java.util.Timer@69db0cb4:org.apache.hadoop.hbase.errorhandling.ForeignException$ProxyThrowable: org.apache.hadoop.hbase.errorhandling.TimeoutException: Timeout elapsed! Source:Timeout caused Foreign Exception Start:1410453067992, End:1410453127992, diff:60000, max:60000 ms
	at org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.rethrowException(ForeignExceptionDispatcher.java:83)
	at org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.rethrowExceptionIfFailed(TakeSnapshotHandler.java:320)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isSnapshotDone(SnapshotManager.java:332)
	... 10 more
Caused by: org.apache.hadoop.hbase.errorhandling.ForeignException$ProxyThrowable: org.apache.hadoop.hbase.errorhandling.TimeoutException: Timeout elapsed! Source:Timeout caused Foreign Exception Start:1410453067992, End:1410453127992, diff:60000, max:60000 ms
	at org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector$1.run(TimeoutExceptionInjector.java:70)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)
{code}

I find the solution by google, and somebody say it maybe caused by the flush snapshot attempting to take a region lock. See [HBASE-7703|https://issues.apache.org/jira/browse/HBASE-7703]. But this exception  has different features.

After I flush the table, it success to create snapshot. 
{code}
hbase(main):005:0> flush 'booking'
0 row(s) in 4.5220 seconds

hbase(main):006:0> snapshot 'booking', 'booking-snapshot-20140912'
0 row(s) in 4.1270 seconds
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11944,"Just ran an upgrade that finished but it wasn't able to move the descriptor.

The cluster had a bad /tmp permissions, but the command should have failed out.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11818,"2014-08-25 20:55:55,899 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: Stats: total=118.29 MB, free=11.87 GB, max=11.99 GB, blocks=2046, accesses=1173812, hits=96283, hitRatio=8.20%, , cachingAccesses=98331, cachingHits=96254, cachingHitsRatio=97.88%, , evictions=0, evicted=31, evictedPerRun=Infinity
2014-08-25 20:58:00,058 INFO org.apache.hadoop.hdfs.DFSClient: Could not complete file /hbase/month_keyword/f8362a663438796ee0396aba456a53e3/.tmp/1c24f7879da241d38d699f37601ce8ce retrying...
2014-08-25 20:58:00,098 INFO org.apache.hadoop.hdfs.DFSClient: Could not complete file /hbase/month_keyword/17fd4fd7b516ae6fdabd6b769db04177/.tmp/ce608124f41f49c4811edcb31b681394 retrying...
2014-08-25 20:58:00,098 INFO org.apache.hadoop.hdfs.DFSClient: Could not complete file /hbase/month_keyword/b10d7cd47416d11e62e66c76a9167183/.tmp/6f6853a11ea74df8ae03a04c49607cda retrying...

Environment锛欻adoop 1.1.2 and HBase 0.94.13
For me, this sounds like a HDFS issue, but I cannot find the root cause.
any idea is welcome.
I checked OS file descriptors, HDFS file xcievers, anything looks ok.

Thanks in advance",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3480,"When faced with a gigabit ethernet network connection, things are pretty slow actually.  For example, let's take a 2 MB reply, using a 120MB/sec line rate, we are talking about about 16ms to transfer that data across a gige line.  This is a pretty significant amount of time.

So this JIRA is about reducing the size of the Result[] serialization.  By exploiting family and qualifier and rowkey duplication, I created a simple encoding scheme to use a dictionary instead of literal strings.  

in my testing, I am seeing some success with the sizes.  Average serialized size is about 1/2 of previous, but time to serialize on the regionserver side is way up, by a factor of 10x.  This might be due to the simplistic first implementation however.

Here is the post change size:
grep 'Serialized size' * | perl -ne '/Serialized size: (\d+?) in (\d+?) ns/ ; print $1, "" "", $2, ""\n"" if $1 > 10000;' | cut -f1 -d' ' | perl -ne '$sum += $_; $count++; END {print $sum/$count, ""\n""}'
377047.1125

Here is the pre change size:
grep 'Serialized size' * | perl -ne '/Serialized size: (\d+?) in (\d+?) ns/ ; print $1, "" "", $2, ""\n"" if $1 > 10000;' | cut -f1 -d' ' | perl -ne '$sum += $_; $count++; END {print $sum/$count, ""\n""}'
601078.505882353

That is about a 60% improvement in size.

But times are not so good, here are some samples of the old, in (size) (time in ns)
3874599 10685836
5582725 11525888

so that is about 11ms to serialize 3-5mb of data.

In the new implementation:
1898788 118504672
1630058 91133003

this is 118-91ms for serialized sizes of 1.6-1.8 MB.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3206,"Something that has been bothering me for a while was to understand when a region server was being slow because of frequent and small GC pauses. I usually go into that RS's GC output, watch it going for a while then decide if it's under some kind of memory pressure. Here's an example (grepped ""Full"" from the GC log):

{noformat}
12:03:42.460-0800: [Full GC [CMS2010-11-08T12:03:43.081-0800: [CMS-concurrent-mark: 4.381/5.819 secs] [Times: user=60.51 sys=2.54, real=5.82 secs] 
12:04:06.916-0800: [Full GC [CMS2010-11-08T12:04:07.316-0800: [CMS-concurrent-mark: 4.006/5.080 secs] [Times: user=55.16 sys=2.13, real=5.08 secs] 
12:04:32.559-0800: [Full GC [CMS2010-11-08T12:04:33.286-0800: [CMS-concurrent-mark: 4.133/5.303 secs] [Times: user=53.61 sys=2.40, real=5.30 secs] 
12:05:24.299-0800: [Full GC [CMS2010-11-08T12:05:25.397-0800: [CMS-concurrent-sweep: 1.325/1.388 secs] [Times: user=4.66 sys=0.15, real=1.38 secs] 
12:05:50.069-0800: [Full GC [CMS2010-11-08T12:05:50.240-0800: [CMS-concurrent-mark: 4.831/6.346 secs] [Times: user=69.43 sys=2.76, real=6.35 secs] 
12:06:16.146-0800: [Full GC [CMS2010-11-08T12:06:16.631-0800: [CMS-concurrent-mark: 4.942/7.010 secs] [Times: user=69.25 sys=2.69, real=7.01 secs] 
12:07:08.899-0800: [Full GC [CMS2010-11-08T12:07:10.033-0800: [CMS-concurrent-sweep: 1.197/1.202 secs] [Times: user=1.96 sys=0.04, real=1.20 secs] 
12:08:01.871-0800: [Full GC [CMS2010-11-08T12:08:01.949-0800: [CMS-concurrent-mark: 4.154/5.443 secs] [Times: user=61.11 sys=2.29, real=5.44 secs] 
12:08:53.343-0800: [Full GC [CMS2010-11-08T12:08:53.549-0800: [CMS-concurrent-mark: 4.447/5.713 secs] [Times: user=65.19 sys=2.42, real=5.72 secs] 
12:09:42.841-0800: [Full GC [CMS2010-11-08T12:09:43.664-0800: [CMS-concurrent-mark: 4.025/5.053 secs] [Times: user=51.40 sys=2.02, real=5.06 secs]
{noformat}

In this case, that RS's TT was down so it was getting all the non-local maps at the end of the job at the same time... generating a >1000% CPU usage. With scanner caching set to 10k, it's easy to understand that there's memory pressure since we have all those objects in flight that we don't account for.

One solution I was thinking of was to have a sleeper thread that sleeps for 1 sec all the time and outputs when it sees that it slept for a bit more than 1 sec. Then let's say the region server records that it saw a few of those under x minutes and decides to somehow throttle the traffic.

What I often saw is that if this situation is kept unnoticed, we end up GCing more and more and in some cases I saw a region server going almost zombie for 2 hours before finally getting it's lease expired.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1177,"During testing of HBASE-80, we uncovered a strange 40ms delay for random reads.  We ran a series of tests and found that it only happens when the client is on the same node as the RS and for a certain range of payloads (not specifically related to number of columns or size of them, only total payload).  It appears to be precisely 40ms every time.

Unsure if this is particular to our architecture, but it does happen on all nodes we've tried.  Issue completely goes away with very large payloads or moving the client.

Will post a test program tomorrow if anyone can test on a different architecture.

Making a blocker for 0.20.  Since this happens when you have an MR task running local to the RS, and this is what we try to do, might also consider making this a blocker for 0.19.1.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3475,MetaScanner in client package is a little more involved but MetaReader does similar.   Both allow you specify a Visitor on .META. and -ROOT-.  We should dump one of them.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11675,"The bug mentioned in http://hbase.apache.org/book.html

5.9.2.2. Major compactions change query results
鈥?..create three cell versions at t1, t2 and t3, with a maximum-versions setting of 2. So when getting all versions, only the values at t2 and t3 will be returned. But if you delete the version at t2 or t3, the one at t1 will appear again. Obviously, once a major compaction has run, such behavior will not be the case anymore...鈥?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,2014-08-05 12:03:36.518,,false,,,,,,,,,,,,,410007,,,,,Tue Aug 05 15:42:40 UTC 2014,,,,,,0|i1yjiv:,410000,,,,,,,,05/Aug/14 12:03;jmspaggi;Hi [~tobe]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11618,"After much digging, I finally figured out how to get the classpaths just right to run the ExportSnapshot command: 
{code}
/usr/bin/hbase -classpath '/usr/lib/hbase/lib/*:/usr/lib/hadoop/client/*' org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot 'myTable_hbaseSnapshot_20140730' -copy-to hdfs://10.0.1.21:8020/hbase -mappers 4
{code}

only to run into the following error: 

{code}
Exception in thread ""main"" org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException: Couldn't read snapshot info from:hdfs://ip-10-0-1-31.ec2.internal:8020/tmp/hbase-hbase/hbase/.hbase-snapshot/myTable_hbaseSnapshot_20140730/.snapshotinfo
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7372,"January 1st is deadline for changing how we publish our website.  We may no longer rsync out to people.apache.org.  Apache infrastructure supplies two options here: http://www.apache.org/dev/project-site.html  We could redo our site in apache cms format.  Or we could just use svnpubsub and keep on w/ how the site is currently generated and on checkin, have it autopublished.  I'll go the latter route unless I hear otherwise.

For svnpubsub, we need to point apache infrastructure at a directory that has our checkedin site in it.  I was thinking ${hbasedir}/hbase.apache.org

Let me raise this on the dev list too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11563,"STEPS:
-------
1. start HBase cluster.
2. Navigate to the RegionServer UI.
3. Instance not found exception is throwing.
{code}
2014-07-22 12:16:41,504 DEBUG [257789301@qtp-605399375-0] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1094)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:662)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:638)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmplImpl.__jamon_innerUnit__memoryStats(ServerMetricsTmplImpl.java:217)
	at org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmplImpl.renderNoFlush(ServerMetricsTmplImpl.java:68)
	at org.apache.hadoop.hbase.tmpl.regionserver.ServerMetricsTmpl.renderNoFlush(ServerMetricsTmpl.java:133)
	at org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmplImpl.renderNoFlush(RSStatusTmplImpl.java:104)
	at org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.renderNoFlush(RSStatusTmpl.java:170)
	at org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.render(RSStatusTmpl.java:161)
	at org.apache.hadoop.hbase.regionserver.RSStatusServlet.doGet(RSStatusServlet.java:56)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1089)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3588,"The ReadWriteConsistencyControl (RWCC) mechanism facilitates making a set of memstore updates atomically visible to readers. Also, the rwcc.completeMemstoreInsert() blocks till the memstore read point advances to the current writeNumber. This is done to ensure that if an application that does a put immediately issues a new get call for the same key, then the get should see the values inserted by the previous call to put. The current implementation assumes this worst-case and penalizes the put rpc to not return to the client until the read point advances to this transaction's write number.

In many use-cases, the application never actually issues a get for the most recent put that it inserted. In this case, it would be nice if we can transfer the penalty (of blocking) to the get call that follows the initial put.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3567,"There was [this Bug-Report (HBASE-2791)|https://issues.apache.org/jira/browse/HBASE-2791], which was dismissed as 'redone in the master rewrite'. But for the InterruptedException nothing has changed.
InterruptedException is swallowed or wrapped in other Exceptions at many places, which is just not right. Please read [this|http://www.ibm.com/developerworks/java/library/j-jtp05236.html].",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3467,"Timestamps are allowed to be negative values, since they're stored as type long.  However, using the Get object to search for versions by setting setMaxVersions() misses them.

I'm not sure where this code lives, but my suspicion is that the code which scans for matching value timestamps has a min value of 0 when it should be using {{java.lang.Long.MIN_VALUE}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3491,"Hello.
I'm working in progress hbase-jdo-util
You can download here. 
http://code.google.com/p/hbase-jdo/downloads/list



- connect table
- table scan
- setting(configuration)
- hadoop explorer

I'll update hbase wiki page also.
Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3486,"we have unit tests that cover durability, but they did not detect the problem outlined in HBASE-3481.  We should fix those tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3463,"It would be great if the HBase management user interface provided more bullet-proof reporting in terms of region counts and status. The regions counts go up and down and different views show different counts and they don't always add up. It makes one less than confident of what is going on. 

Cluster wide And per table it would be great to get summary counts of all regions in the various states. It would also be useful to see this state in the description of the region. There is a compaction count, but what about in split, memstore flush, read/write lock, disabled, etc. Fundamentally this is the health monitor of the system and as a dba one really needs to know the 100% count of regions and where they are all at in terms of availability. Are they disabled, blocked for writes, blocked for reads, in compaction, etc. etc.

The first step is to define and document exactly what states a region could be in and what impact that state could have on performance, write blocking, read blocking, compaction, disabling, etc. etc. This needs to be defined and well documented. Once these states are defined and well understood (and explain every problem one could have reading/writing/pausing/disabling) then adding to the UI view to show a count of all regions within each state (with a percentage) and also report this state in the detailed list of regions it would give one an holistic view of exactly what is going on. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3461,"Hello.
first of all, thanks to hbase members so much ,
you helped me a lot.

I wrote simple jdo module for hbase newbie. I wish this module can help them.

Some features
- simple jdo(used reflection)
- HTable pool ( I already know HTablePool in habse )
- simple query classes ( insert,delete,update,select)
- some convinent mehtods.
- table sequence generator

I want to contribute this module to hbase
absolutely, I'll do upgrade that more than more.

again, thanks for help.

[http://code.google.com/p/hbase-jdo/]
---------------------------------------------
{code} 

AbstractHBaseDBO dbo = new HBaseDBOImpl();
		
		//drop if table is already exist.
		if(dbo.isTableExist(""user"")){
			dbo.deleteTable(""user"");
		}
		
		//create table
		dbo.createTableIfNotExist(""user"",HBaseOrder.DESC,""account"");
		//dbo.createTableIfNotExist(""user"",HBaseOrder.ASC,""account"");
		
		//create index.
		String[] cols={""id"",""name""};
		dbo.addIndexExistingTable(""user"",""account"",cols);
		
		//insert
		InsertQuery insert = dbo.createInsertQuery(""user"");
		UserBean bean = new UserBean();
		bean.setFamily(""account"");
		bean.setAge(20);
		bean.setEmail(""ncanis@gmail.com"");
		bean.setId(""ncanis"");
		bean.setName(""ncanis"");
		bean.setPassword(""1111"");
		insert.insert(bean);
		
		//select 1 row
		SelectQuery select = dbo.createSelectQuery(""user"");
		UserBean resultBean = (UserBean)select.select(bean.getRow(),UserBean.class);
		
		// select column value.
		String value = (String)select.selectColumn(bean.getRow(),""account"",""id"",String.class);
		
		// search with option (QSearch has EQUAL, NOT_EQUAL, LIKE)
		// select id,password,name,email from account where id='ncanis' limit startRow,20
		HBaseParam param = new HBaseParam();
		param.setPage(bean.getRow(),20);
		param.addColumn(""id"",""password"",""name"",""email"");
		param.addSearchOption(""id"",""ncanis"",QSearch.EQUAL);
		select.search(""account"", param, UserBean.class);
		
		// search column value is existing.
		boolean isExist = select.existColumnValue(""account"",""id"",""ncanis"".getBytes());
		
		// update password.
		UpdateQuery update = dbo.createUpdateQuery(""user"");
		Hashtable<String, byte[]> colsTable = new Hashtable<String, byte[]>();
		colsTable.put(""password"",""2222"".getBytes());
		update.update(bean.getRow(),""account"",colsTable);
		
		//delete
		DeleteQuery delete = dbo.createDeleteQuery(""user"");
		delete.deleteRow(resultBean.getRow());
	
		////////////////////////////////////
		// etc
		
		// HTable pool with apache commons pool
		// borrow and release. HBasePoolManager(maxActive, minIdle etc..)
		IndexedTable table = dbo.getPool().borrow(""user"");
		dbo.getPool().release(table);
		
		// upload bigFile by hadoop directly.
		HBaseBigFile bigFile = new HBaseBigFile();
		File file = new File(""doc/movie.avi"");
		FileInputStream fis = new FileInputStream(file);
		Path rootPath = new Path(""/files/"");
		String filename = ""movie.avi"";
		bigFile.uploadFile(rootPath,filename,fis,true);
		
		// receive file stream from hadoop.
		Path p = new Path(rootPath,filename);
		InputStream is = bigFile.path2Stream(p,4096);

{code} ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3459,"usually, we need to find column's value is existing.

in db) select count(*)  from user where id='ncanis'

if we use EqualsColumnValueGetFilter filter

we can find out column value is existing.
{code}
----------------------
	public EqualsColumnValueGetFilter(final byte[] colName, final byte[] value, final int limit) {
		this.colName = colName;
		this.value = value;
		this.limit = limit;
	}

------------------------
{code}


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2796,"Backport the hbase-2707 fix to the 0.20 branch.  If 2707 happens, it hoses cluster...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3165,"in an attempt to improve the profile of the serialization of results in the regionserver side I did a large number of things to reduce buffer copies, improve the API usage efficiency (using the BB API directly) and so on.

Using a YCSB config like so:
recordcount=10000
#recordcount=5
operationcount=1000
workload=com.yahoo.ycsb.workloads.CoreWorkload

readallfields=true


readproportion=0
updateproportion=0
scanproportion=1
insertproportion=0

fieldlength=10
fieldcount=100

requestdistribution=zipfian


scanlength=300
scanlengthdistribution=zipfian

threadcount=1

columnfamily=data

Doing a medium sized scan of 1-300 rows.

Top line performance was at about 67ms, but these micro improvements didnt budge that needle, and it didnt change the scale of the CPU profiler - ie: cpu time spent in serialization was the same.

Since then I also made an improvement to HBase-YCSB which may have been masking the performance gains.  I have suspended this work in favor of 0.90 pre-release work for now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2237,"From the list from Erik Rozendaal:

{code}

We're getting about 2500 gets/sec max per regionserver when it serves data from the block cache using HBase 0.20.3. All data is in the same region and the region has just one store file for the family we're querying. HBASE-2180 didn't seem to help here. At this point the region server is using about 1.5 cores. Since we have 8 cores available the bottleneck does not seem to be CPU.

The number of clients does not seem to matter (we tested with 1-4 clients).

The only other bottleneck that I can think of is network, but we test on a local 1 Gbit LAN. Our web server can handle 15,000 requests/sec, so that doesn't seem to be the case.

Maybe there is some synchronization going limiting the CPU scalability of a single region server?
{code}

If same speed whether 1 or 4 clients, it would seem to indicate a synchronization issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2478,"HDFS keeps a separate ""checksum"" file for every  block. By default, io.bytes.per.checksum is set at 512, and the checksums are 4 bytes... i.e. for every 512 bytes of data in the block we maintain a 4 byte checksum. For 4TB of data, for instance, that's about 31GB of checksum data.

A read that needs to read a small section (such as a 64k HFile block) from a HDFS block, especially on a cold access, is likely to end up doing two random disk reads--- one from the data file for the block and one from the checksum file.

A though was that instead of keeping a checksum for every 512 bytes, given  that HBase will interact with HDFS on reads at the granularity of HBase block size (typically 64k, but smaller if compressed), should we consider keeping checksums at a coarser granularity (e.g, for every 8k bytes) for HFiles?  The advantage
with this would be that the checksum files would be much smaller (in proportion to the data) and the hot working set for ""checksum data""  should fit better in the OS buffer cache (thus eliminating a good majority of the disk seeks for checksum data).

The intent of the JIRA is to experiment with different settings for ""io.bytes.per.checksum"" for HFiles. 

Note: For the previous example, of 4TB of data, with an io.bytes.per.checksum setting of 8k, the size of the checksum data would drop to about 2Gig.

Making the io.bytes.per.checksum too big might reduce the effectiveness of the checksum. So that needs to be taken into account as well in terms of determining a good value.

[For HLogs files, on the other hand, I suspect we would want to leave the checksum at finer granularity because my understanding is that if we are doing lots of small writes/syncs (as we do to HLogs), finer grained checksums are better (because the code currently doesn't do a rolling checksum, and needs to rewind to the nearest checksum block boundary and recomputed the checksum on every edit).]


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3428,"I know I am new Hbase user.
When I learn Hbase, I was to hard about learning that.
I couldn't find well made examples

now, I wrote somd examples for Hbase starter.

I wish this examples can help you.

few more days later, I'll write more good examples.

sources.

AbstractHBase.java
HBaseClient.java
StressTest.java

Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3325,"Currently when the master splits logs, it outputs all edits it finds, even those that have already been obsoleted by flushes. At replay time on the RS we discard the edits that have already been flushed.

We could do a pretty simple optimization here - basically the RS should replicate a map ""region id -> last flushed seq id"" into ZooKeeper (this can be asynchronous by some seconds without any problems). Then when doing log splitting, if we have this map available, we can discard any edits found in the logs that were already flushed, and thus output a much smaller amount of data.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3397,The 'getRow' method can be misleading and should be renamed to 'getRowKey' to better describe its functionality.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3385,"table.jsp should allow user to initiate reassignment of region(s) whose row in .META. doesn't have serverinfo
There should be two options for such request:
1. regions without serverinfo are assigned
2. all regions for the table are reassigned (round-robin)

Option 2 is especially useful when table's regions don't have even distribution among region servers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3329,"After a RS dies or the cluster goes down and we are recovering, we first split HLogs into the logs for the regions. Then the region servers that host the regions replay the logs and open the regions.

This can be made more efficient by directly creating HFiles from the HLogs (instead of producing a split HLogs file).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3242,"Currently, our memstore flush algorithm is pretty trivial.  We let it grow to a flushsize and flush a region or grow to a certain log count and then flush everything below a seqid.  In certain situations, we can get big wins from being more intelligent with our memstore flush algorithm.  I suggest we look into algorithms to intelligently handle HLog compactions.  By compaction, I mean replacing existing HLogs with new HLogs created using the contents of a memstore snapshot.  Situations where we can get huge wins:

1. In the incrementColumnValue case,  N HLog entries often correspond to a single memstore entry.  Although we may have large HLog files, our memstore could be relatively small.
2. If we have a hot region, the majority of the HLog consists of that one region and other region edits would be minuscule.

In both cases, we are forced to flush a bunch of very small stores.  Its really hard for a compaction algorithm to be efficient when it has no guarantees of the approximate size of a new StoreFile, so it currently does unconditional, inefficient compactions.  Additionally, compactions & flushes suck because they invalidate cache entries: be it memstore or LRUcache.  If we can limit flushes to cases where we will have significant HFile output on a per-Store basis, we can get improved performance, stability, and reduced failover time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2584,"Currently HBase clients can only acquire row locks via the blocking lockRow() method in HTable. As ryan described on the mailing list, relying on this method in rare highly contended situations can lead to (temporary) deadlock. This deadlock occurs if a client acquires the lock, and a large number of other clients attempt to acquire the lock and block. Each blocked client awaiting lock acquisition consumes one of the limited I/O handler threads on the regionserver. When lock holder wishes to release the lock, he will be unable to as all I/O threads are currently serving clients that are blocking on lock acquisition -- and thus no I/O threads are open to process the unlock request.

To avoid deadlock situations such as the one described above, I have added support for 'tryLock' in HTable (and on the regionservers). The 'tryLock' method will attempt to acquire a row lock. In the event that a lock is already held, tryLock immediately returns null rather than blocking and waiting for the lock to be acquire. Clients can then implement their own backoff/retry policy to re-acquire the lock, determine their own timeout values, etc based on their application performance characteristics rather than block on the regionserver and tie up precious I/O regionserver handler threads for an indefinite amount of time. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3300,"Background: For use cases that explicitly set versions, after a delete, it is not possible to insert values with older versions. So for example if you did a puts (v1) and delete (@ v2), subsequent puts with an older version (e.g., v1) will not take effect since the delete has a higher version.

{code}
#1. PUT(row, col, version1,  old-value)
#2. DELETE(row, col, version2)
#3. PUT(row, col, version1, new-value)
{code}

The row/col stays deleted, and this is expected behavior since the delete has a higher timestamp.

Feature Request: It would be good to provide a ""force"" delete mechanism -- something that allows the row or a specific column to be started with a clean slate. i.e. forget about everything that happened to this item earlier, and lets you start afresh. Without this there is no good cleanup mechanism for use cases that set versions explicitly.

[Note: The only workaround for this depends on a subtle implementation detail that major compactions discard delete markers. So if a major compaction happened between steps #2 & #3, then you would in fact be able to put a value with an older version.]

Thoughts?


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3246,"In the new Increment class, the API to add columns is {{addColumn()}}.  If you do this multiple times for an individual column, the amount to increment by is replaced.  I think this is the right way for this method to work and it is javadoc'd with the behavior.

We should add a new method, {{incrementColumn()}} which will increment any existing amount for the specified column rather than replacing it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3254,"We are running HBase on EC2 and I'm trying to get a client external from EC2 to connect to the cluster.  But, each of the nodes appears to be publishing its IP address into zookeeper.  The problem is that the nodes on EC2 see a 10. IP address that is only resolvable inside of EC2.

Specifically for EC2, there is a DNS name that will resolve properly both externally and internally, so it would be nice if I could tell each of the processes what host to publish into zookeeper via a property.  As it stands, I have to do ssh tunnelling/muck with the hosts file in order to get my client to connect.
 
This problem could occur anywhere that you have a different DNS entry for public vs. private access.  That might only ever happen on EC2, but it might happen elsewhere.  I don't really know :).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3251,"We saw this in our integration test log - packageindex table was 'broekn':
{code}
2010-11-19 05:12:42,216 Thread-20 ERROR [StripedHBaseTable] Could not create packageindex
org.apache.hadoop.hbase.TableExistsException: org.apache.hadoop.hbase.TableExistsException: packageindex
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:799)
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:763)
	at sun.reflect.GeneratedMethodAccessor25.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:998)
...
2010-11-19 05:12:42,218 Thread-20 INFO  [HBasePackageIndexTableMapperNew] Creating table packageindex - Done
2010-11-19 05:12:42,235 Thread-20 INFO  [CodecPool] Got brand-new decompressor
2010-11-19 05:12:42,262 Thread-20 INFO  [HBasePackageIndexTableMapperNew] OnClose called
2010-11-19 05:12:42,263 Thread-20 WARN  [LocalJobRunner] job_local_0001
org.apache.hadoop.hbase.TableNotFoundException: packageindex
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:698)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:634)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:601)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:134)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:112)
{code}

In HConnectionManager.listTables():
{code}
           byte[] value = result.getValue(CATALOG_FAMILY,
REGIONINFO_QUALIFIER);
           HRegionInfo info = null;
           if (value != null) {
             info = Writables.getHRegionInfo(value);
           }
           // Only examine the rows where the startKey is zero length
           if (info != null && info.getStartKey().length == 0) {
             uniqueTables.add(info.getTableDesc());
           }
{code}
For a broken table, there would be a row in .META (see below). but the table wouldn't be included in uniqueTables.

We need a way for listTables() to mark the broken table and return it so that master.jsp can show the table in prominent way.

{code}
 packageindex,E70888DD48276D column=info:regioninfo, timestamp=1290188566363, value=REGION => {NAME => 'packag
 FAD4D26FEB08DC7045,12901630 eindex,E70888DD48276DFAD4D26FEB08DC7045,1290163034864', STARTKEY => 'E70888DD4827
 34864                       6DFAD4D26FEB08DC7045', ENDKEY => 'E83A8362462AF0D097810F96ED7103C2', ENCODED => 2
                             080544777, OFFLINE => true, TABLE => {{NAME => 'packageindex', FAMILIES => [{NAME
                              => 'i', COMPRESSION => 'GZ', VERSIONS => '1', TTL => '31536000', BLOCKSIZE => '6
                             5536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'u', COMPRESSION =>
                             'GZ', VERSIONS => '1', TTL => '31536000', BLOCKSIZE => '65536', IN_MEMORY => 'fal
                             se', BLOCKCACHE => 'true'}]}}
{code}

Here is what led to broken table in our cluster.

2010-11-19 12:49:23,067 main INFO  [PackageIndexTableTest]
[10:57am] tyu: Deleting packageindex content ...

From hbase-hadoop-regionserver-us01-ciqps1-grid05.ciq.com.log:
{code}
2010-11-19 12:49:41,119 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Caches flushed, doing commit now (which includes update scanners)
2010-11-19 12:49:41,121 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~16.0k for region .META.,,1 in 83ms, sequence id=48465684, compaction requested=true
2010-11-19 12:49:41,121 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for region .META.,,1/1028785192 because: regionserver/10.202.50.105:60020.cacheFlusher
2010-11-19 12:54:11,353 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 6416258050001207387 lease expired
2010-11-19 12:54:11,353 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: Cache Stats: Sizes: Total=633.5422MB (664317096), Free=161.05789MB (168881432), Max=794.60004MB (833198528), Counts: Blocks=75276, Access=90464772, Hit=86854034, Miss=3610738, Evictions=222, Evicted=2121113, Ratios: Hit Ratio=96.00868225097656%, Miss Ratio=3.9913196116685867%, Evicted/Run=9554.5634765625
2010-11-19 12:54:11,353 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 269945ms, ten times longer than scheduled: 10000
2010-11-19 12:54:11,353 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: Cache Stats: Sizes: Total=633.5422MB (664317096), Free=161.05789MB (168881432), Max=794.60004MB (833198528), Counts: Blocks=75276, Access=90464772, Hit=86854034, Miss=3610738, Evictions=222, Evicted=2121113, Ratios: Hit Ratio=96.00868225097656%, Miss Ratio=3.9913196116685867%, Evicted/Run=9554.5634765625
2010-11-19 12:54:11,353 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -1270857692790249130 lease expired
2010-11-19 12:54:11,354 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: Cache Stats: Sizes: Total=633.5422MB (664317096), Free=161.05789MB (168881432), Max=794.60004MB (833198528), Counts: Blocks=75276, Access=90464772, Hit=86854034, Miss=3610738, Evictions=222, Evicted=2121113, Ratios: Hit Ratio=96.00868225097656%, Miss Ratio=3.9913196116685867%, Evicted/Run=9554.5634765625
...
2010-11-19 12:54:11,354 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12c520945433100 to sun.nio.ch.SelectionKeyImpl@78317d11
java.io.IOException: TIMED OUT
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:906)
2010-11-19 12:54:11,391 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12c520945432f46 to sun.nio.ch.SelectionKeyImpl@727d3468
java.io.IOException: TIMED OUT
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:906)
2010-11-19 12:54:11,354 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
org.apache.hadoop.hbase.UnknownScannerException: Name: 6416258050001207387 on us01-ciqps1-grid05.carrieriq.com,60020,1290003836762
        at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1885)
        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:998)
2010-11-19 12:54:11,354 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
org.apache.hadoop.hbase.UnknownScannerException: Name: -1270857692790249130 on us01-ciqps1-grid05.carrieriq.com,60020,1290003836762
        at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1885)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1873)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:998)
2010-11-19 12:54:11,354 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: unable to report to master for 270306 milliseconds - retrying
2010-11-19 12:54:11,415 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 16 on 60020, call next(6416258050001207387, 100) from 10.202.36.42:37477: error: org.apache.hadoop.hbase.UnknownScannerException: Name: 6416258050001207387 on us01-ciqps1-grid05.carrieriq.com,60020,1290003836762
org.apache.hadoop.hbase.UnknownScannerException: Name: 6416258050001207387 on us01-ciqps1-grid05.carrieriq.com,60020,1290003836762
        at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1885)
        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:998)
...
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3226,"It exists in HBase 0.20.5 , and also exist in TRUNK
org.apache.hadoop.hbase.filter.CompareFilter.doCompare(CompareOp, WritableByteArrayComparable, byte[], int, int),
  ---------------------------------------------
  switch (compareOp) {
      case LESS:
        return compareResult <= 0;   
      case LESS_OR_EQUAL:     
        return compareResult < 0;
      case EQUAL:
        return compareResult != 0;
      case NOT_EQUAL:
        return compareResult == 0;
      case GREATER_OR_EQUAL:
        return compareResult > 0;
      case GREATER:
        return compareResult >= 0;
      default:
        throw new RuntimeException(""Unknown Compare op "" +
          compareOp.name());
    }
-----------------------------------------------------
!!! modified code:
    switch (compareOp) {
      case LESS:
        return compareResult < 0;
      case LESS_OR_EQUAL:
        return compareResult <= 0;
      case EQUAL:
        return compareResult == 0;
      case NOT_EQUAL:
        return compareResult != 0;
      case GREATER_OR_EQUAL:
        return compareResult >= 0;
      case GREATER:
        return compareResult >0;
      default:
        throw new RuntimeException(""Unknown Compare op "" +
          compareOp.name());
    }",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3106,"Each region's memtable size is 64M, global memtable limit is 4G on one region server
In heavy write scenario, especially disable WAL, sequential put  fills memtable to full very quickly, and will generates too many storefiles in a short time.
Then there are more and more compaction tasks put into compactionQueue, single thread excutes compaction task too slowly, finally forms a vicious cycle.
This will block some region's data importing for a long time

We simplely using ThreadPoolExecutor as multi-thread compaction sulution
(As we know, 0.90 or 0.92 will optimize memflush, compaction, open, close...etc using multi-thread, but this magnificent version hasn't bee released yet)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3099,"Right now log splitting is slower than we'd like.  The slow pace of log splitting is one of the reasons why we have to keep a short, bounded, limit of the outstanding log files.  It would be nice to up that limit, to allow perhaps hundreds of logs.  It would increase efficiency because we would not be force-flushing regions at non-ideal sizes.

But more data means more to process.  Except that not all of the logs for a regionserver are actually useful.  This is because some regions got flushed before the oldest log was trimmed.  So during log recovery if we read the most recent sequenceid, we could skip, during log splitting (in the master), those entries and avoid writing them to the per-region log recovery.  It would reduce the IO by part, and if our serialization/deser code was clever we might be able to avoid deserializing much.  

It's not clear how effective or worthwhile this might be.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3084,"Nicolas reviewed HBASE-2437 after it had been committed and raised some issues that need addressing.  The main issue is that splitLog will ignore user interrupts (aka: InterruptException).  Currently, data loss can occur (with 'skip.errors' == true) if a user calls 'kill <master-pid>"" during splits because the code will consider the interrupted file completely split.  If the master receives an interrupt during splitLog, it needs to abort splitting, delete all partially-complete split files, and exit gracefully.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3075,"New master makes it so enable/disable show as near instantaneous but behind the scenes we still have to do the region close/opens.  These can take time.  HBASE-3063 adds into the disable table handler a wait on regions leaving regions in transition but, what if the user did enable/disable/enable/disable then delete.  Turns out we don't do this well.  It confuses.  See the TestThriftServer where we've disabled such a sequence.  This issue is about working on making delete work better; e.g. why bother closing stuff if we're going to delete it --- just abort the tables regions and save all the flushing, etc., that slows the close-before-delete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2492,"See tail of hbase-2180 for detail on this issue.  If a lot of random reading, we start to us up descriptors because sockets stuck in TIME_WAIT.  Workaround described over in hbase-2180.  This issue covers fix for hdfs so we don't open a socket each pread.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2789,"If HBase config is modified when HBase cluster is running, the changes wouldn't propagate to region servers after restarting cluster.

This is different from hadoop behavior where changes get automatically copied to data nodes.

This feature is desirable when enabling JMX, e.g.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2957,"Is there a reason to hold on to the row-lock while waiting for the WAL-sync to be completed by the logSyncer thread?

I think data consistency will be guaranteed even if the following happens (a) the row lock is held while the row is updated in memory (b) the row lock is released after queuing the KV record for WAL-syncing (c) the log-sync system guarantees that the log records for any given row are synced in order (d) the HBase client only receives a success notification after the sync completes (no change from the current state)

I think this should be a huge win. For my use case, and I am sure for others,  the handler thread spends the bulk of its row-lock critical section  time waiting for sync to complete.

Even if the log-sync system cannot guarantee the orderly completion of sync records, the ""Don't hold row lock while waiting for sync"" option should be available to HBase clients on a per request basis.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2891,"Currently rowcounter accepts one table for each run.
It is desirable to add capability to process multiple tables in one run.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2693,"Need to also be clear that if need patched hadoop, then the patched hadoop needs to be put under hbase/lib.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2686,"J-D just pointed out the fact that LogRollListener Interface cannot listen.  It has a single method named logRollRequested.   Lets fix.  Rename the interface LogRoll (and the method name while we're at it... its past tense but returns a void?)

Lets fix this stuff.  It makes the code base hard to grok.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2659,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1969,"The issue that HBASE-1626 tried to fix is that we can hand in Put or Delete instances to the TableOutputFormat. So the explicit Put reference was changed to Writable in the process. But that does not work as expected:

{code}09/11/04 13:35:56 INFO mapred.JobClient: Task Id : attempt_200911031030_0004_m_000013_2, Status : FAILED
java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Writable, recieved org.apache.hadoop.hbase.client.Put
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:812)
        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:504)
        at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)
        at com.worldlingo.hadoop.mapred.RestoreTable$RestoreMapper.map(RestoreTable.java:140)
        at com.worldlingo.hadoop.mapred.RestoreTable$RestoreMapper.map(RestoreTable.java:69)
        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:583)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305){code}

The issue is that the MapReduce framework checks not polymorphic for the type using ""instanceof"" but with a direct class comparison. In MapTask.java you find this code

{code}
    public synchronized void collect(K key, V value, int partition
                                     ) throws IOException {
      reporter.progress();
      if (key.getClass() != keyClass) {
        throw new IOException(""Type mismatch in key from map: expected ""
                              + keyClass.getName() + "", recieved ""
                              + key.getClass().getName());
      }
      if (value.getClass() != valClass) {
        throw new IOException(""Type mismatch in value from map: expected ""
                              + valClass.getName() + "", recieved ""
                              + value.getClass().getName());
      }
      ... {code}

So it does not work using a Writable as the MapOutputValueClass for the job and then hand in a Put or Delete! The test case TestMapReduce did not pick this up as it has this line in it

{code}
      TableMapReduceUtil.initTableMapperJob(
        Bytes.toString(table.getTableName()), scan,
        ProcessContentsMapper.class, ImmutableBytesWritable.class, 
        Put.class, job);{code}

which sets the value class to Put

{code}if (outputValueClass != null) job.setMapOutputValueClass(outputValueClass);{code}

To fix this (for now) one can set the class to Put the same way or explicitly in their code 

{code}job.setMapOutputValueClass(Put.class);{code}
 
But the whole idea only seems feasable if a) the Hadoop class is amended to use ""instanceof"" instead (lodge Hadoop MapRed JIRA issue?) or b) we have a combined class that represent a Put *and* a Delete - which seems somewhat wrong, but doable. It would only really find use in that context and would require the user to make use of it when calling context.write(). This is making things not easier to learn.

Suggestions?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2634,"HRegion now has four different lock objects:
- splitsAndClosesLock (RWLock)
- newScannerLock (RWLock)
- updatesLock (RWLock)
- splitLock (Object)

It's not well documented what the purpose of each is, and I imagine we may be able to get rid of at least one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2554,"At http://hadoop.apache.org/hbase/docs/r0.20.4/api/org/apache/hadoop/hbase/HTableDescriptor.html, we currently have both HColumnDescriptor[] getColumnFamilies() and Collection<HColumnDescriptor> getFamilies(); perhaps only one is needed?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2362,"Right now, we get one KeyValue at a time and run it through the matcher even if the query is to fetch the entire row (or even an entire column family for a key). This causes the blocks to be fetched serially from HDFS. We can optimize this by looking at the block map, and fetching all the blocks spanned by the key in one request to HDFS.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2159,Its an error if HFOF is passed a KV with a timestamp of LATEST_TIMESTAMP (see HBASE-2157).  Add a check for it to HFOF and throw an exception if we see it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2015,"HBase does not get privileges to run access controlled code, such as when using Sockets.

------------------------------------------
A DataNucleus, HBase user posted this:
http://www.jpox.org/servlet/forum/viewthread_thread,5869

He is having trouble to run DataNucleus HBase in a JVM running with
security manager activated.

The permission required for the codebase is a SocketPermission,
however the HBase client api does not run in a privileged block.

To workaround we've added the doPrivileged block in DataNucleus, and
the user grants datanucleus-hbase jar the SocketPermission.

However, I think you should add these doPrivileged blocks to HBase
code. Could you please look at these, and let me know when it's
solved, so we can remove the doPrivileged blocks from DataNucleus
code?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1353,The regex filters are odd in a world of byte arrays.  This is brought home in the world of KeyValue -- hbase-1234 -- where we are going out of our way to avoid Object creations.  The regex fitlers are extremely expensive to run.   The regex filters should be redone otherwise or at least get some attention to clean them up.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1510,"instead of configuring IPs in zoo.conf, allow retrieving the IPs from DNS.  This way we don't have to supply zoo.conf or any hbase-site.xml to clients.  

eg, one quorum might ahve a dns name of 'quorum1', the hbase path, you could specify the cluster in code like:
HTable table = new HTable(""/quorum1/hbase/table_name"");

and avoid having to distribute hbase-site.xml or zoo.cfg.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1248,"I have an HBase table where items are keyed by a sequential row id. When doing bulk appends to this table, the last region of the table gets pretty large until enough compactions can be done to sort everything out.

In this type of case, it'd be better if when the region serving the largest keys doesn't split at the midkey, but on the last key. One way to implement this would be by saying that when the top region reaches MAX_REGION_SIZE/2, create a new region, with the lower half getting all the data and the top half empty. For bulk sequential inserts, this should avoid the need for any compactions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-893,Client-side logging shows on console if you are using shell but otherwise goes to /dev/null.  Set up logging so it goes somewhere -- into a file under logs or some such.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2585,"While inserting a large number of rows into a HBase table (approx 100M) we got this error many times (usually do to multiple attempts) on one of our region servers:

2010-05-19 16:51:30,745 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: Attempt=1
java.io.IOException: java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.master.ServerManager.assignSplitDaughter(ServerManager.java:535)
        at org.apache.hadoop.hbase.master.ServerManager.processSplitRegion(ServerManager.java:512)
        at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:463)
        at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:414)
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:323)
        at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:724)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkThrowable(RemoteExceptionHandler.java:48)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:66)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:577)
        at java.lang.Thread.run(Thread.java:619)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2464,"When the master is told to shut down, it calls stopScanners() before setting master.closed. If root isn't assigned, the root scanner gets stuck in the loop in RegionManager.waitForRootRegionLocation. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1120,"{code}
hbase(main):003:0> close_region '-ROOT-,,0'
NativeException: java.io.IOException: java.io.IOException: java.lang.NullPointerException
 at org.apache.hadoop.hbase.master.HMaster.modifyTable(HMaster.java:830)
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
 at java.lang.reflect.Method.invoke(Method.java:597)
...
{code}

Presumption is that its a region that can be found in .META. whereas, I have a cluster where master and regionserver don't agree on -ROOT- and want to close '-ROOT-,,0' but get the NPE when I try.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11494,"Table鈥檚 cell having a large number of versions, it works fine when I read 100K VERSIONS from the cell, but regionServer gives exception when I attempted to read upto 1M VERSIONS. error happens with both hbase shell , and happy base client

2014-07-10 10:45:30,098 WARN [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooLarge): {鈥減rocessingtimems鈥?104,鈥漜all鈥?鈥滸et(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)鈥?鈥漜lient鈥?鈥?7.203.54.172:56290鈥?鈥漵tarttimems鈥?1405014329979,鈥漲ueuetimems鈥?0,鈥漜lass鈥?鈥滺RegionServer鈥?鈥漴esponsesize鈥?157334052,鈥漨ethod鈥?鈥滸et鈥潁
2014-07-10 10:45:30,923 INFO [RpcServer.reader=6,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: count of bytes read: 0
java.io.IOException: Connection reset by peer
at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
at sun.nio.ch.IOUtil.read(IOUtil.java:197)
at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
at org.apache.hadoop.hbase.ipc.RpcServer.channelRead(RpcServer.java:2224)
at org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess(RpcServer.java:1415)
at org.apache.hadoop.hbase.ipc.RpcServer$Listener.doRead(RpcServer.java:790)
at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:581)
at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:556)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:744)
2014-07-10 10:45:30,923 WARN [RpcServer.responder] ipc.RpcServer: RpcServer.respondercallId: 93 service: ClientService methodName: Get size: 225 connection: 17.203.54.172:56290: output error
2014-07-10 10:45:30,924 INFO [RpcServer.responder] ipc.RpcServer: RpcServer.responder: asyncWrite
java.io.IOException: Broken pipe
at sun.nio.ch.FileDispatcherImpl.writev0(Native Method)
at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
at sun.nio.ch.IOUtil.write(IOUtil.java:148)
at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:524)
at org.apache.hadoop.hbase.ipc.BufferChain.write(BufferChain.java:106)
at org.apache.hadoop.hbase.ipc.RpcServer.channelWrite(RpcServer.java:2204)
at org.apache.hadoop.hbase.ipc.RpcServer$Responder.processResponse(RpcServer.java:1004)
at org.apache.hadoop.hbase.ipc.RpcServer$Responder.doAsyncWrite(RpcServer.java:944)
at org.apache.hadoop.hbase.ipc.RpcServer$Responder.doRunLoop(RpcServer.java:873)
at org.apache.hadoop.hbase.ipc.RpcServer$Responder.run(RpcServer.java:849)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11495,"Now in HBase the REST server is started as a non daemon process.
It will be better it is supported as process from hbase-daemon.sh

Also can support stop and autorestart commands for REST server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11498,ipc.server.callqueue.read.share and ipc.server.callqueue.handler.factor are missing docs to help elucidate how they work for mere mortals. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11478,"In a Java Pig UDF including an Hbase Client, which fetches the desired record from Hbase, 'hbase-site.xml' is not read from the Classpath.

// Set Zookeeper Quorum used by HBASE
            // Read hbase-site.xml from CLASSPATH
            Configuration config = HBaseConfiguration.addHbaseResources(UDFContext.getUDFContext().getJobConf());

We have verified that the directory 'etc/hbase/conf' where 'hbase-site.xml' is in, is on the HADOOP_CLASSPATH . I have tried everything, including the 'etc/hbase/conf' or '/etc/hbase/conf/hbase-site.xml' to PIG_CLASSPATH, CLASSPATH environment variables. We also tried adding the hbase-site.xml to our HADOOP_CONF_DIR and HBASE_CONF_DIR is set.

I have also tried REGISTER '/etc/hbase/conf/hbase-site.xml' in Pig. Finally the following did not work either:

conf.addResource(""/etc/hbase/conf/hbase-site.xml"");

I hope this helps.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11365,"Maybe this is a misconception on my side, but I assumed that the 'cells' returned by a reverse scanner (HBASE-4811) would be in reverse order, not just the rows.

Was I wrong in my assumption?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10882,"I came across the problem in the early morning several days ago. It happened when I used hadoop completebulkload command to bulk load some hdfs files into hbase table. Several regions hung and after retried three times they all threw RegionTooBusyExceptions. Fortunately, I caught one of the exceptional region鈥檚 HRegionServer process鈥檚 jstack info just in time.
I found that the bulkload process was waiting for a write lock:
at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.tryLock(ReentrantReadWriteLock.java:1115)
The lock id is 0x00000004054ecbf0.
In the meantime, many other Get/Scan operations were also waiting for the same lock id. And, of course, they were waiting for the read lock:
at java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.tryLock(ReentrantReadWriteLock.java:873)
The most ridiculous thing is NO ONE OWNED THE LOCK! I searched the jstack output carefully, but cannot find any process who claimed to own the lock.
When I restart the bulk load process, it failed at different regions but with the same RegionTooBusyExceptions. 
I guess maybe the region was doing some compactions at that time and owned the lock, but I couldn鈥檛 find compaction info in the hbase-logs.
Finally, after several days鈥?hard work, the only temporary solution to this problem was found, that is TRIGGERING A MAJOR COMPACTION BEFORE THE BULKLOAD, 
So which process owned the lock? Has anyone came across the same problem before?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11271,The [ref guide chapter on testing discusses|http://hbase.apache.org/book/hbase.tests.html#integration.tests] Chaos Monkey and speaks extensively of running it standalone on a deployed cluster. This functionality hasn't been in HBase since 0.94 and so should probably be taken out of the documentation or updated with some sort deprecation notice.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9965,"Having installed the latest stable hbase-0.94.13 version, and following the instructions at    hbase-0.94.13/docs/book/quickstart.html  ,  
the hbase master fails to start and hbase is unusable, owing to this Java RuntimeException occurring, as shown in the log file :

2013-11-13 13:52:06,316 INFO org.apache.hadoop.hbase.master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/jvds,52926,1384350725521 from backup master directory
2013-11-13 13:52:06,318 INFO org.apache.zookeeper.server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x14251bbb3d40000 type:delete cxid:0x13 zxid:0xb txntype:-1 reqpath:n/a Error Path:/hbase/backup-masters/jvds,52926,1384350725521 Error:KeeperErrorCode = NoNode for /hbase/backup-masters/jvds,52926,1384350725521
2013-11-13 13:52:06,320 WARN org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper: Node /hbase/backup-masters/jvds,52926,1384350725521 already deleted, and this is not a retry
2013-11-13 13:52:06,320 INFO org.apache.hadoop.hbase.master.ActiveMasterManager: Master=jvds,52926,1384350725521
2013-11-13 13:52:06,348 INFO org.apache.hadoop.hbase.master.SplitLogManager: timeout = 300000
2013-11-13 13:52:06,348 INFO org.apache.hadoop.hbase.master.SplitLogManager: unassigned timeout = 180000
2013-11-13 13:52:06,348 INFO org.apache.hadoop.hbase.master.SplitLogManager: resubmit threshold = 3
2013-11-13 13:52:06,352 INFO org.apache.hadoop.hbase.master.SplitLogManager: found 0 orphan tasks and 0 rescan nodes
2013-11-13 13:52:06,385 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2013-11-13 13:52:06,385 ERROR org.apache.hadoop.hbase.master.HMasterCommandLine: Failed to start master
java.lang.RuntimeException: Failed suppression of fs shutdown hook: Thread[Thread-27,5,main]
	at org.apache.hadoop.hbase.regionserver.ShutdownHook.suppressHdfsShutdownHook(ShutdownHook.java:196)
	at org.apache.hadoop.hbase.regionserver.ShutdownHook.install(ShutdownHook.java:83)
	at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:191)
	at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:420)
	at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:149)
	at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:104)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:76)
	at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2120)
2013-11-13 13:52:06,386 ERROR org.apache.hadoop.io.nativeio.NativeIO: Unable to initialize NativeIO libraries
java.lang.NoSuchFieldError: workaroundNonThreadSafePasswdCalls
	at org.apache.hadoop.io.nativeio.NativeIO.initNative(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO.<clinit>(NativeIO.java:58)
	at org.apache.hadoop.fs.FileUtil.setPermission(FileUtil.java:653)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:509)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:286)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:385)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:364)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:555)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:536)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:435)
	at org.apache.hadoop.hbase.util.FSUtils.setVersion(FSUtils.java:475)
	at org.apache.hadoop.hbase.util.FSUtils.setVersion(FSUtils.java:375)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:436)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:148)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:133)
	at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:573)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:432)
	at org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster.run(HMasterCommandLine.java:226)
	at java.lang.Thread.run(Thread.java:744)
2013-11-13 13:52:06,388 DEBUG org.apache.hadoop.hbase.util.FSUtils: Created version file at file:/home/jason/3P/hbase/data set its version at:7

I would expect after downloading the latest stable version and following the instructions closely that the hbase master should start and hbase should be usable.  

As specified in quickstart.html, the only file I edited was conf/hbase-site.xml, which is :
 <configuration>

  <property>
    <name>hbase.rootdir</name>
    <value>file:///home/jason/3P/hbase/data</value>
  </property>

  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/home/jason/3P/hbase/zookeeper-data</value>
  </property>

</configuration>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11197,"When looking into test failure: testVisibilityLabelsOnKillingOfRSContainingLabelsTable

and find this is what has happened:

1. try to assign a region a region server;
2. master creates a znode, and send an openRegion request to the rs;
3. rs gets the request and sends back a response, then crashed;
4. try to assign the region again with forceNewPlan = true;
5. since the region is in transition, master tries to close it and get region server stopped exception;
6. master offlines the region and removes it from transition; but can't assign the region since the dead server is not processed;
7. now SSH finally kicks in, tries to assign this region again;
8. SSH will fail to assign it since the znode is there already.

We should clean up the znode in force offline a region.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10625,"In reseekTo we find this
{code}
...
        compared = compareKey(reader.getComparator(), key, offset, length);
        if (compared < 1) {
          // If the required key is less than or equal to current key, then
          // don't do anything.
          return compared;
        } else {
           ...
           return loadBlockAndSeekToKey(this.block, this.nextIndexedKey,
              false, key, offset, length, false);
...
{code}
loadBlockAndSeekToKey already does the right thing when a we pass a key that sorts before the current key. It's less efficient than this early check, but in the vast (all?) cases we pass forward keys (as required by the reseek contract). We're optimizing the wrong thing.

Scanning with the ExplicitColumnTracker is 20-30% faster.
(I tested with rows of 5 short KVs selected the 2nd and or 4th column)

I propose simply removing that check.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1197,Several instances of OOME when trying to serve up large cells to clients have been observed. IPC should send large cell content in chunks instead of as one large naive copy. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9240,"Over on HADOOP-9876, Hadoop enumerates the benefits of protobuf 2.5.0. We have the same considerations for our RPC and elsewhere after HBASE-8165",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7030,"The coprocessor class loader should allow the user to supply a list of packages or classes to resolve directly with the parent (RegionServer) classloader.

See HBASE-6843 for some background.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3707,Memstore upsert performance may be impacted by having a large number of values in the map. Consider flushing the store after a configurable number of inserts.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1477,"From  Jeremy Pinkham up on hbase-users@: 

bq. A typical mapper in the job takes several minutes, how many minutes depends on whether I use the the region partitioner and how many I let run concurrently... it's been anywhere from 2 minutes with no partitioner and small concurrency (5 mappers) to 8 minutes with the region partitioner and high concurrency (150 mappers).  This seems to directly correlate with how long it takes to do a simple count of .META. while each job is running (2 seconds to 1 minute)

bq. I was able to get past this issue affecting my data load by reorganizing some of my workflow and data structures to force the ordering of keys without the region partitioner.  Those changes appear to have side stepped the problem for me as I can now load from 100+ mappers without seeing the degradation that I was seeing with 40 when using the partitioner (and getting some sweet numbers in the requests column of the UI).  It's still an interesting scaling situation with the region partitioner, but I'm good to go without it.

I have seen this also in the form of freezing of master UI during high load, where the UI comes back as soon as load is reduced. When I thread dump it looks like all IPC handlers on the region server hosting .META. are busy. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5343,"To use the access control mechanism added in HBASE-3025, users should either use the shell interface, or use the coprocessor API directly, which is not very user friendly. We can add grant/revoke/user_permission commands similar to the shell interface to HBaseAdmin assuming HBASE-5341 is in. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11091,"Running  Hbase utilities from 0.98.1-hadoop2 with Hadoop 2.3.0 hihgligh incompatibility of client versions. For example ""hbase org.apache.hadoop.hbase.PerformanceEvaluation  randomWrite 5"" fails at the end with ""No enum constant org.apache.hadoop.mapreduce.JobCounter.MB_MILLIS_REDUCES""

This seem to be related with https://issues.apache.org/jira/browse/HBASE-10601 and https://issues.apache.org/jira/browse/MAPREDUCE-5831
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11066,"Configuration conf = HBaseConfiguration.create();
conf.addResource(""hbase-site.xml"");

this code could not work find, all configuration in hbase-site.xml could not be loaded, and log will show as below:
14/04/24 12:06:13 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x26f997aa, quorum=localhost:2181, baseZNode=/hbase
14/04/24 12:06:13 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x26f997aa connecting to ZooKeeper ensemble=localhost:2181
14/04/24 12:06:13 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
14/04/24 12:06:13 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
14/04/24 12:06:13 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14572d37f6a00c1, negotiated timeout = 40000
14/04/24 12:06:13 INFO client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null

but if I set properties like this:
conf.set(""hbase.zookeeper.quorum"", ""mater"");
conf.set(""hbase.zookeeper.property.clientPort"", ""8181"");
conf.set(""hbase.master.port"", ""60000"");
it will work fine.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9933,"See HRegionServer::mutate switch statement. For puts/deletes it checks condition, for i/a it just does the operation. Discovered while doing stuff for HBASE-3787",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10920,"          Configuration conf = HBaseConfiguration.create();
          conf.set(""hbase.zookeeper.quorum"",""znode-1"");
          conf.set(""hbase.zookeeper.property.clientPort"",""2181"");
          conf.set(""hbase.master"",master:16000"");
          hconnection = HConnectionManager.createConnection(conf); //(Parser.java:40)
=====================
Results In
======================
Error: java.io.IOException: java.lang.reflect.InvocationTargetException at org.apache.hadoop.hbase.client.ConnectionManager.createConnection(ConnectionManager.java:341) at org.apache.hadoop.hbase.client.ConnectionManager.createConnectionInternal(ConnectionManager.java:234) at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:215) at com.example.job.Mapper.setup(Parser.java:40) at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1597) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169) Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at org.apache.hadoop.hbase.client.ConnectionManager.createConnection(ConnectionManager.java:339) ... 11 more Caused by: java.lang.NoClassDefFoundError: org/htrace/Trace at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:195) at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:480) at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65) at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:84) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:779) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:588) ... 16 more Caused by: java.lang.ClassNotFoundException: org.htrace.Trace at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ... 22 more",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10878,"I used setup similar to that from HBASE-10863, with fix for HBASE-10863 :
{code}
hbase(main):003:0> scan 'hbase:labels'
ROW                                          COLUMN+CELL
 \x00\x00\x00\x01                            column=f:\x00, timestamp=1395944796030, value=system
 \x00\x00\x00\x01                            column=f:hbase, timestamp=1395944796030, value=
 \x00\x00\x00\x02                            column=f:\x00, timestamp=1395951045442, value=TOP_SECRET
 \x00\x00\x00\x02                            column=f:hrt_qa, timestamp=1395951229682, value=
 \x00\x00\x00\x02                            column=f:hrt_qa1, timestamp=1395951270297, value=
 \x00\x00\x00\x02                            column=f:mapred, timestamp=1395958442326, value=
 \x00\x00\x00\x03                            column=f:\x00, timestamp=1395952069731, value=TOP_TOP_SECRET
 \x00\x00\x00\x03                            column=f:mapred, timestamp=1395956032141, value=
 \x00\x00\x00\x04                            column=f:\x00, timestamp=1395971516605, value=A
 \x00\x00\x00\x04                            column=f:oozie, timestamp=1395971647859, value=
 \x00\x00\x00\x05                            column=f:\x00, timestamp=1395971520327, value=B
5 row(s) in 0.0580 seconds
{code}
I did the following as user oozie using hbase shell:
{code}
hbase(main):001:0> scan 'tb', { AUTHORIZATIONS => ['A']}
ROW                                          COLUMN+CELL
 row                                         column=f1:q, timestamp=1395971660859, value=v1
 row2                                        column=f1:q, timestamp=1395972271343, value=v2
 row3                                        column=f1:q, timestamp=1396067477702, value=v3
3 row(s) in 0.2050 seconds

hbase(main):002:0> scan 'tb', { AUTHORIZATIONS => ['A|B']}
ROW                                          COLUMN+CELL
 row2                                        column=f1:q, timestamp=1395972271343, value=v2
1 row(s) in 0.0150 seconds

hbase(main):003:0> scan 'tb', { AUTHORIZATIONS => ['B|A']}
ROW                                          COLUMN+CELL
 row2                                        column=f1:q, timestamp=1395972271343, value=v2
1 row(s) in 0.0260 seconds
{code}
Rows 'row' and 'row3' were inserted with label 'A'.
Row 'row2' was inserted without label.
Row 'row1' was inserted with label 'B'.

I would expect row1 to also be returned.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7118,"org.apache.hadoop.hbase.replication.TestReplicationPeer

Running org.apache.hadoop.hbase.replication.TestReplicationPeer
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 25.89 sec <<< FAILURE!
	--- stable failures, new for hbase 0.92.0, need to be fixed firstly.

--------------------------------	
 target/surefire-reports/org.apache.hadoop.hbase.replication.TestReplicationPeer.txt output:

Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 28.245 sec <<< FAILURE!
testResetZooKeeperSession(org.apache.hadoop.hbase.replication.TestReplicationPeer)  Time elapsed: 25.247 sec  <<< FAILURE!
junit.framework.AssertionFailedError: ReplicationPeer ZooKeeper session was not properly expired.
        at junit.framework.Assert.fail(Assert.java:50)
        at org.apache.hadoop.hbase.replication.TestReplicationPeer.testResetZooKeeperSession(TestReplicationPeer.java:73)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37)
        at java.lang.reflect.Method.invoke(Method.java:611)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:62)
        

target/surefire-reports/org.apache.hadoop.hbase.replication.TestReplicationPeer-output.txt content:
       
2012-03-25 20:52:42,979 INFO  [main] zookeeper.MiniZooKeeperCluster(174): Started MiniZK Cluster and connect 1 ZK server on client port: 21818

2012-03-25 20:52:43,023 DEBUG [main] zookeeper.ZKUtil(96): connection to cluster: clusterId opening connection to ZooKeeper with ensemble (localhost:21818)

2012-03-25 20:52:43,082 INFO  [main] zookeeper.RecoverableZooKeeper(89): The identifier of this process is 4095@svltest116.svl.ibm.com

2012-03-25 20:52:43,166 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(257): connection to cluster: clusterId Received ZooKeeper Event, type=None, state=SyncConnected, path=null

2012-03-25 20:52:43,175 INFO  [Thread-9] replication.TestReplicationPeer(53): Expiring ReplicationPeer ZooKeeper session.

2012-03-25 20:52:43,196 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(334): connection to cluster: clusterId-0x1364d226a3d0000 connected

2012-03-25 20:52:43,308 INFO  [Thread-9] hbase.HBaseTestingUtility(1234): ZK Closed Session 0x1364d226a3d0000; sleeping=25000

2012-03-25 20:53:08,323 INFO  [Thread-9] replication.TestReplicationPeer(57): Attempting to use expired ReplicationPeer ZooKeeper session.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10872,This issue is a regression caused by v94 patch of HBASE-10648,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9368,"Follow on from hbase-8567.  See https://builds.apache.org/view/H-L/view/HBase/job/hbase-0.95-on-hadoop2/275/testReport/junit/org.apache.hadoop.hbase.master/TestDistributedLogSplitting/testDelayedDeleteOnFailure/
{code}
org.apache.hadoop.hbase.master.TestDistributedLogSplitting.testDelayedDeleteOnFailure

Failing for the past 1 build (Since Failed#275 )
Took 7 ms.
add description
Error Message

test timed out after 30000 milliseconds
Stacktrace

java.lang.Exception: test timed out after 30000 milliseconds
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:640)
	at org.apache.zookeeper.ClientCnxn.start(ClientCnxn.java:403)
	at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:450)
	at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:380)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.<init>(RecoverableZooKeeper.java:114)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.connect(ZKUtil.java:135)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:167)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:136)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1788)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:778)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:618)
	at sun.reflect.GeneratedConstructorAccessor38.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:377)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:358)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:293)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:191)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:887)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:853)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.startCluster(TestDistributedLogSplitting.java:156)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.startCluster(TestDistributedLogSplitting.java:141)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.testDelayedDeleteOnFailure(TestDistributedLogSplitting.java:970)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

{code}

We seem stuck.   Nothing happens after master initializes... we just wait:

{code}
2013-08-28 00:42:53,492 INFO  [M:0;quirinus:56658] master.HMaster(901): Master has completed initialization
2013-08-28 00:42:53,496 DEBUG [NamespaceJanitor-quirinus:56658] client.ClientScanner(218): Finished {ENCODED => 5fb8721e18f122319e47336ad5221a58, NAME => 'hbase:namespace,,1377650558736.5fb8721e18f122319e47336ad5221a58.', STARTKEY => '', ENDKEY => ''}
2013-08-28 00:42:53,534 DEBUG [CatalogJanitor-quirinus:56658] client.ClientScanner(218): Finished {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2013-08-28 00:43:34,443 INFO  [Thread-2407] zookeeper.RecoverableZooKeeper(122): Process identifier=hconnection-0x958cd8 connecting to ZooKeeper ensemble=localhost:60031
2013-08-28 00:43:34,443 FATAL [pool-1-thread-1] master.HMaster(2240): Master server abort: loaded coprocessors are: [org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint]
2013-08-28 00:43:34,443 FATAL [pool-1-thread-1] master.HMaster(2245): closing...
java.lang.Exception: Trace info
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.after(TestDistributedLogSplitting.java:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-08-28 00:43:34,444 INFO  [pool-1-thread-1] master.HMaster(2434): Aborting
2013-08-28 00:43:34,443 WARN  [Thread-2407] zookeeper.ZKUtil(489): hconnection-0x958cd8 Unable to set watcher on znode (/hbase/hbaseid)
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1309)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1036)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:202)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:482)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:83)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:778)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:618)
	at sun.reflect.GeneratedConstructorAccessor38.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:377)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:358)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:293)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:191)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:887)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:853)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.startCluster(TestDistributedLogSplitting.java:156)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.startCluster(TestDistributedLogSplitting.java:141)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.testDelayedDeleteOnFailure(TestDistributedLogSplitting.java:970)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
...
{code}

What you think [~jeffreyz]?  Thanks boss.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9636,"{noformat}

Problem:
HBase shell/client 'scan table' operation is getting failed inbetween the when the regions are shifted from one Region Server to another Region Server

When the table regions data moved from one Region Server to another Region Server then the client/shell should be able to handle the data from the 
new Region server automatically (because when we have huge data in terms of GB/TB at that time one of the Region Server going down in the cluster is frequent)


Procedure:
1. Setup Non HA Hadoop Cluster with two nodes (Node1-XX.XX.XX.XX,  Node2-YY.YY.YY.YY)
2. Install Zookeeper, HMaster & HRegionServer in Node-1
3. Install HRegionServer in Node-2
4. From Node2 create HBase Table ( table name 't1' with one column family 'cf1' )
5. add around 367120 rows to the table
6. scan the table 't1' using hbase shell & at the same time switch the region server 1 & 2 (so that the table 't1' regions data are moved from Region Server 1 to 1 & vice versa)
7. During this time hbase shell is getting failed in between of the scan operation as below

...................................................................                                
 row172266                        column=cf1:a, timestamp=1379680737307, value=100                                              
 row172267                        column=cf1:a, timestamp=1379680737311, value=100                                              
 row172268                        column=cf1:a, timestamp=1379680737314, value=100                                              
 row172269                        column=cf1:a, timestamp=1379680737317, value=100                                              
 row17227                         column=cf1:a, timestamp=1379679668631, value=100                                              
 row17227                         column=cf1:b, timestamp=1379681090560, value=200                                             

ERROR: java.lang.RuntimeException: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=7, exceptions:
Fri Sep 20 18:20:58 IST 2013, org.apache.hadoop.hbase.client.ScannerCallable@1999dc4f, java.net.ConnectException: Connection refused
Fri Sep 20 18:20:59 IST 2013, org.apache.hadoop.hbase.client.ScannerCallable@1999dc4f, org.apache.hadoop.hbase.ipc.HBaseClient$FailedServerException: This server is in the failed servers list: HOST-YY.YY.YY.YY/YY.YY.YY.YY:61020
Fri Sep 20 18:21:00 IST 2013, org.apache.hadoop.hbase.client.ScannerCallable@1999dc4f, java.net.ConnectException: Connection refused
Fri Sep 20 18:21:01 IST 2013, org.apache.hadoop.hbase.client.ScannerCallable@1999dc4f, org.apache.hadoop.hbase.ipc.HBaseClient$FailedServerException: This server is in the failed servers list: HOST-YY.YY.YY.YY/YY.YY.YY.YY:61020
Fri Sep 20 18:21:07 IST 2013, org.apache.hadoop.hbase.client.ScannerCallable@1999dc4f, java.net.ConnectException: Connection refused
Fri Sep 20 18:21:09 IST 2013, org.apache.hadoop.hbase.client.ScannerCallable@1999dc4f, java.net.ConnectException: Connection refused
Fri Sep 20 18:21:17 IST 2013, org.apache.hadoop.hbase.client.ScannerCallable@1999dc4f, java.net.ConnectException: Connection refused

hbase(main):014:0> 


{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10421,"Testing the ""internal friction"" of scanning in HBase (all data in the block cache, and all rows filtered at the server by a ValueFilter, so that one really measures the work HBase does internally), I found that 0.98 is almost 35% slower than 0.94.

Scanning 50m rows (one col each, 8 byte keys, 8 byte values) takes 13.2 in 0.94.17-SNAPSHOT and 18.5s in 0.98.

This probably came about with all the protobuf changes in 0.96.
It should be possible to bring back to par with 0.94.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4464,"balancer.balanceCluster() generates RegionPlans for HMaster.balance() to execute.
We don't retract any RegionPlan in balancer.balanceCluster().
In the near future, more complex algorithm would be introduced to try achieving maximum block location affinity for the regions to be moved. This means balancer.balanceCluster() would take longer to return.

This JIRA makes region balancing parallel with balancer.balanceCluster()
Meaning region balancing would be performed when balancer.balanceCluster() is still running.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4136,"I observed in our staging cluster that load balancer didn't run for a long period of time.
I saw the following in master log:
{code}
2011-07-24 15:56:32,333 DEBUG org.apache.hadoop.hbase.master.HMaster: Not running balancer because 2 region(s) in transition: {4e7416833e3bbd6a8ade26f6986529bf=TABLE-1311419946465,E'\xFD\xDDu\xC3\x894\xF4$\xC0K\xA3!\x82\xB9\xD0\x7F|>\xAC\xDA81\xB6\x92\xED\xA9\x9C\xA6^\xF4,1311419961631.4e7416833e3bbd6a8ade26f6986529bf. state=PENDING_CLOSE, ts=...
{code}
This means we need to find a better way of permitting one balance run at a time. In HMaster.balance():
{code}
      if (this.assignmentManager.isRegionsInTransition()) {
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3644,"See HBASE-3387 or http://www.ibm.com/developerworks/java/library/j-jtp05273.html#N10184 .  Basically, 'a' denotes HServerAddress(DNS) & 'b' denotes HServerAddress(nslookup(DNS)).  This is extremely common within HBase when 'conf/regionserver' contains DNS entries because ClusterStatus.getServers() is IP-based. You have a.address.equals(b.address) && !a.stringValue.equals(b.stringValue).  In this case, a.equals(b) while a.hashCode() != b.hashCode().  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3611,hbase-default.xml isnt getting updated when the version number is changed.  mvn clean is required all the time now.  The result is a jar that is unrunnable. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3556,"{code}
2011-02-18 10:08:14,873 ERROR org.apache.hadoop.hbase.HServerAddress: Could not resolve the DNS name of zcl.local:60020
2011-02-18 10:08:14,874 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_SERVER_SHUTDOWN
java.lang.IllegalArgumentException: Could not resolve the DNS name of zcl.local:60020
        at org.apache.hadoop.hbase.HServerAddress.checkBindAddressCanBeResolved(HServerAddress.java:105)
        at org.apache.hadoop.hbase.HServerAddress.<init>(HServerAddress.java:66)
        at org.apache.hadoop.hbase.catalog.MetaReader.metaRowToRegionPairWithInfo(MetaReader.java:407)
        at org.apache.hadoop.hbase.catalog.MetaReader.getServerUserRegions(MetaReader.java:594)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:124)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
{code}

We never go back and reprocess.  Meantime, balancer never runs because server stuck in dead list.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3549,"To minimize cost of migration, it is desirable to pull new APIs into 0.20.6 (0.89)
This way client code compiles against both hbase jars.

Our changes include:
making MetaScanner public class
adding the following ctor for Put
{code}
  public Put(byte[] row, long ts) {
    this(row, null);
    setTimeStamp(ts);
  }
{code}
adding the following ctor for HColumnDescriptor:
{code}
  public HColumnDescriptor(final byte [] familyName, final int maxVersions,
	      final String compression, final boolean inMemory,
	      final boolean blockCacheEnabled,
	      final int timeToLive, final String bloomFilter) {
	  this(familyName, maxVersions,
	       compression, inMemory,
	       blockCacheEnabled,
	       timeToLive,!bloomFilter.equals(""NONE""));
  }
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3469,Andrew suggests we add 611 to append branch: See http://mail-archives.apache.org/mod_mbox/hbase-user/201101.mbox/%3C4D3D6EBF.8010302@gmail.com%3E,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3429,"Presently, an exception is actually thrown when deserializing the output of HBaseObjectWritable.writeObject(SomeSubclassOfWritable[]).

The issue is pretty difficult to debug.

This patch adds support for arrays whose contents are subtypes of both Serializable and Writable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3236,"jdcryans suggests a page in book where we list major changes in API -- the deprecated stuff removed in 0.90.

Ted Yu started a list up in mailing list:

I am trying to compile our code against 0.90
Result.getCellValue() is no longer available.

Can you tell me the alternative ?
..


HConstants is final class now instead of interface
RowFilterInterface is gone
org.apache.hadoop.hbase.io.Cell is gone
org.apache.hadoop.hbase.io.RowResult is gone
constructor
HColumnDescriptor(byte[],int,java.lang.String,boolean,boolean,int,boolean)
is gone
Put.setTimeStamp() is gone
org.apache.hadoop.hbase.filter.Filter has added
getNextKeyHint(org.apache.hadoop.hbase.KeyValue)

If you know the alternative to some of the old classes, please share.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3177,"Add a search into the hbase book as per the example pointed to here: https://issues.apache.org/jira/browse/HBASE-2650?focusedCommentId=12885581&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#action_12885581

Also add some of the hbase navbar if possible to make navigation back to the cite from within the manual easier?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2416,"It is desirable to provide HBase table export/import capability through table.jsp, similar to compaction/split buttons.

For import/export button, an input field allows user to specify source/destination hdfs directory.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10410,"This is frustrating. On some JREs (Java 7) I am seeing hbase-server fail due to timeout, without any test actually reporting a timeout.  This StackOverflow answer talks about how JUnit < 4.12-SNAPSHOT may report a timeout if the test throws an InterruptedException: http://stackoverflow.com/questions/17016011/junit-test-times-out-despite-executing-quickly  Those happen at various points when shutting down the minicluster. We may be letting one escape. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10387,"I was running Hoya load test which uses LoadTestTool.
The load was successful. However Hoya test failed with:
{code}
[ERROR] Command was/bin/sh -c cd /home/yarn/hoya/hoya-funtest && /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.9.x86_64/jre/bin/java -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError -jar /home/yarn/hoya/hoya-funtest/target/surefire/surefirebooter274017860635722411.jar /home/yarn/hoya/hoya-funtest/target/surefire/surefire6543037778494048137tmp /home/yarn/hoya/hoya-funtest/target/surefire/surefire_07364766695548839031tmp
[ERROR] -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.16:test (default-test) on project hoya-funtest: Execution default-test of goal org.apache.maven.plugins:maven-surefire-plugin:2.16:test failed: The forked VM terminated without saying properly goodbye. VM crash or System.exit called ?
Command was/bin/sh -c cd /home/yarn/hoya/hoya-funtest && /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.9.x86_64/jre/bin/java -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError -jar /home/yarn/hoya/hoya-funtest/target/surefire/surefirebooter274017860635722411.jar /home/yarn/hoya/hoya-funtest/target/surefire/surefire6543037778494048137tmp /home/yarn/hoya/hoya-funtest/target/surefire/surefire_07364766695548839031tmp
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:224)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:317)
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84)
        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59)
        at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183)
        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)
        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:317)
        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:152)
        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:555)
        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:214)
        at org.apache.maven.cli.MavenCli.main(MavenCli.java:158)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)
        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)
        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)
        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)
Caused by: org.apache.maven.plugin.PluginExecutionException: Execution default-test of goal org.apache.maven.plugins:maven-surefire-plugin:2.16:test failed: The forked VM terminated without saying properly goodbye. VM crash or System.exit called ?
Command was/bin/sh -c cd /home/yarn/hoya/hoya-funtest && /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.9.x86_64/jre/bin/java -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError -jar /home/yarn/hoya/hoya-funtest/target/surefire/surefirebooter274017860635722411.jar /home/yarn/hoya/hoya-funtest/target/surefire/surefire6543037778494048137tmp /home/yarn/hoya/hoya-funtest/target/surefire/surefire_07364766695548839031tmp
        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:115)
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)
        ... 19 more
Caused by: java.lang.RuntimeException: The forked VM terminated without saying properly goodbye. VM crash or System.exit called ?
Command was/bin/sh -c cd /home/yarn/hoya/hoya-funtest && /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.9.x86_64/jre/bin/java -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError -jar /home/yarn/hoya/hoya-funtest/target/surefire/surefirebooter274017860635722411.jar /home/yarn/hoya/hoya-funtest/target/surefire/surefire6543037778494048137tmp /home/yarn/hoya/hoya-funtest/target/surefire/surefire_07364766695548839031tmp
        at org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:485)
        at org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:352)
        at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:158)
        at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:958)
        at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:822)
        at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:720)
        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:106)
        ... 20 more
{code}
This was due to the following call in doStaticMain():
{code}
    System.exit(ret);
{code}
A config option can be added so that the above call is skipped in the case where LoadTestTool is activated from maven and load test succeeds.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10325,"Unknown option or illegal argument: -XX:OnOutOfMemoryError=kill -9 %p. 
Please check for incorrect spelling or review documentation of startup options.

Could not create the Java virtual machine.
starting master, logging to /home/hadoop/hbase-0.96.1.1-hadoop2/logs/hbase-hadoop-master-namenode0.hadoop.out
Unknown option or illegal argument: -XX:OnOutOfMemoryError=kill -9 %p. 
Please check for incorrect spelling or review documentation of startup options",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10305,"In our use case, we use a small number (~5) of proxy programs that read from a queue and batch update to HBase. Our program is multi-threaded and HBase client will batch mutations to each RS.

We found we're getting lower TPS when there are more regions. I think the reason is RS syncs HLog for each region. Suppose there is a single region, the batch update will only touch one region and therefore syncs HLog once. And suppose there are 10 regions per server, in RS#multi() it have to process update for each individual region and sync HLog 10 times.

Please note that in our scenario, batched mutations usually are independent with each other and need to touch a various number of regions.

We are using the 0.94 series, but I think the trunk should have the same problem after a quick look into the code.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10293,"My issue manifests when I uncomment the line {{export SERVER_GC_OPTS=...}} in hbase-env.sh and start HBase. It's a single node in distributed mode, so both a Master and RegionServer are started on that host. Both start commands are run in the same minute, so only one gc.log-`date` file is created. `lsof` indicates two processes are writing to that file and the output of `ps` confirms they both received the same {{-Xloggc:/grid/0/var/log/hbase/gc.log-201401071515}} argument.

Presumably, the same will happen for folks running the thrift and rest gateways on the same box (any java process itemized in the server_cmds array in bin/hbase).

Related (the reason I discovered this issue in the first place), stopping the master process results in its gc.log being truncated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10300,"As discussed on HBASE-10292, we may not be throwing DoNotRetryIOExceptions back to the client when aborting the server, especially when handling fatal coprocessor exceptions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10290,"I suffering an issue is, I only get one _KeyValue_ object (five expected) from one row if I use _FilterList_ with _Operator.MUST_PASS_ALL_ to add both _QualifierFiter_ and _Operator.MUST_PASS_ALL_, the details as follows

h4.Test for Operator.MUST_PASS_ALL
1. I generate 10 rows of test data, two column familys and five column qualifiers for each row.
{code:title=Test Data}
r=keyvalues={row001/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row001/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row001/cf1:port-10/1389104461530/Put/vlen=5/mvcc=0, row001/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row001/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row002/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row002/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row002/cf1:port-20/1389104461530/Put/vlen=5/mvcc=0, row002/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row002/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row003/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row003/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row003/cf1:port-30/1389104461530/Put/vlen=5/mvcc=0, row003/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row003/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row004/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row004/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row004/cf1:port-40/1389104461530/Put/vlen=5/mvcc=0, row004/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row004/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row005/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row005/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row005/cf1:port-50/1389104461530/Put/vlen=5/mvcc=0, row005/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row005/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row006/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row006/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row006/cf1:port-60/1389104461530/Put/vlen=5/mvcc=0, row006/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row006/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row007/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row007/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row007/cf1:port-70/1389104461530/Put/vlen=5/mvcc=0, row007/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row007/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row008/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row008/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row008/cf1:port-80/1389104461530/Put/vlen=5/mvcc=0, row008/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row008/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row009/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row009/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row009/cf1:port-80/1389104461530/Put/vlen=5/mvcc=0, row009/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row009/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
r=keyvalues={row010/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row010/cf1:ip/1389104461530/Put/vlen=11/mvcc=0, row010/cf1:port-80/1389104461530/Put/vlen=5/mvcc=0, row010/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row010/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
{code}

2. Then I use following code to try to filter out only one row I want
{code:title=FilterList codes}
//...
fl = new FilterList(Operator.MUST_PASS_ALL);

filter =
    new SingleColumnValueFilter(CF_1_NAME_B, Bytes.toBytes(""ip""), CompareOp.EQUAL,
        Bytes.toBytes(""127.0.0.80""));
fl.addFilter(filter);

filter = new QualifierFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(""port-80"")));
fl.addFilter(filter);

scan.setFilter(fl);
rs = table.getScanner(scan);

for (Result r : rs) {
  //...
}
{code}
3. I get the right and only one row returned, but not get whole data (_KeyValue_s) of this row.
{code:title=Results not expected}
r=keyvalues={row008/cf1:port-80/1389104629712/Put/vlen=5/mvcc=0}
{code}
Actually, I expect following data would return, whole record data, two column families and five column qualifiers.
{code:tittle=Results I expected}
r=keyvalues={row008/cf1:dummy/1389104461530/Put/vlen=5/mvcc=0, row008/cf1:ip/1389104461530/Put/vlen=10/mvcc=0, row008/cf1:port-80/1389104461530/Put/vlen=5/mvcc=0, row008/cf2:dummy1/1389104461530/Put/vlen=6/mvcc=0, row008/cf2:dummy2/1389104461530/Put/vlen=6/mvcc=0}
{code}

h4.Test for Operator.MUST_PASS_ONE
then I test the same code except to change the _Operator.MUST_PASS_ALL_ to _Operator.MUST_PASS_ONE_, and things getting more worse...
{code:title=Result not expected}
r=keyvalues={row001/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0}
r=keyvalues={row002/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0}
r=keyvalues={row003/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0}
r=keyvalues={row004/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0}
r=keyvalues={row005/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0}
r=keyvalues={row006/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0}
r=keyvalues={row007/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0, row007/cf1:ip/1389113376745/Put/vlen=10/mvcc=0, row007/cf1:port-70/1389113376745/Put/vlen=5/mvcc=0, row007/cf2:dummy1/1389113376745/Put/vlen=6/mvcc=0, row007/cf2:dummy2/1389113376745/Put/vlen=6/mvcc=0}
r=keyvalues={row008/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0, row008/cf1:ip/1389113376745/Put/vlen=10/mvcc=0, row008/cf1:port-80/1389113376745/Put/vlen=5/mvcc=0, row008/cf2:dummy1/1389113376745/Put/vlen=6/mvcc=0, row008/cf2:dummy2/1389113376745/Put/vlen=6/mvcc=0}
r=keyvalues={row009/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0, row009/cf1:port-80/1389113376745/Put/vlen=5/mvcc=0}
r=keyvalues={row010/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0, row010/cf1:port-80/1389113376745/Put/vlen=5/mvcc=0}
{code}

But I only expected following two row got returned
{code:title=Results I expected}
r=keyvalues={row007/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0, row007/cf1:ip/1389113376745/Put/vlen=10/mvcc=0, row007/cf1:port-70/1389113376745/Put/vlen=5/mvcc=0, row007/cf2:dummy1/1389113376745/Put/vlen=6/mvcc=0, row007/cf2:dummy2/1389113376745/Put/vlen=6/mvcc=0}
r=keyvalues={row008/cf1:dummy/1389113376745/Put/vlen=5/mvcc=0, row008/cf1:ip/1389113376745/Put/vlen=10/mvcc=0, row008/cf1:port-80/1389113376745/Put/vlen=5/mvcc=0, row008/cf2:dummy1/1389113376745/Put/vlen=6/mvcc=0, row008/cf2:dummy2/1389113376745/Put/vlen=6/mvcc=0}
{code}

Test code attached to demo this issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10287,"HRegionServer#addResult() is called by HRegionServer#mutate() where controller parameter could be null.

HRegionServer#addResult() should check whether rpcc is null.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10238,"In TestAccessController#verifyDenied there is code attempting to deal with UTEs with AccessDeniedException as a nested cause. Although it would seem the code intends to handle the exception reported by a recently failed test on the 0.98 Hadoop 1.1 Jenkins build here:

{noformat}
java.lang.reflect.UndeclaredThrowableException: Unknown exception in doAs
Caused by: java.security.PrivilegedActionException: com.google.protobuf.ServiceException: Error calling method PingService.noop
Caused by: com.google.protobuf.ServiceException: Error calling method PingService.noop
Caused by: org.apache.hadoop.hbase.security.AccessDeniedExceptionorg.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions (user=UserB, scope=testCoprocessorExec, family=, action=EXEC)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions (user=UserB, scope=testCoprocessorExec, family=, action=EXEC)
...
{noformat}

it didn't work properly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10208,"These are APIs related to split keys avaiable in HTable same can be to HTI
getStartKeys()
getEndKeys()
getStartEndKeys()
getSplitKeys() - New
and 3 more APIs related to find region location when we specify row also can be added to HTI
getRegionLocation(final String row)
getRegionLocation(final byte [] row)
getRegionLocation(final byte [] row, boolean reload)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10192,"In HBase-8101, we added a check and disallowed empty rowkey.  However, it is allowed in 0.94. I was wondering if there is any special reason for that, i.e., is it by intention or by mistake?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2719,"Hudson is failing the tests from HBASE-2400: http://hudson.hbase.org/job/hbase-trunk/119/#showFailuresLink. These tests pass locally, so it's not clear why they are failing with Hudson.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9553,"In order to make it easy on the garbage collector and to avoid full compaction phases we should make sure that all (or at least a large percentage) of the HFile blocks as cached in the block cache are exactly the same size.

Currently an HFile block is typically slightly larger than the declared block size, as the block will accommodate that last KV on the block. The padding would be a ColumnFamily option. In many cases 100 bytes would probably be a good value to make all blocks exactly the same size (but of course it depends on the max size of the KVs).

This does not have to be perfect. The more blocks evicted and replaced in the block cache are of the exact same size the easier it should be on the GC.

Thoughts?
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9671,"In our integration test we saw the following:
{code}
2013-09-26 19:29:47,852|beaver.machine|INFO|2013-09-26 19:29:47,852 INFO  [main] client.HBaseAdmin: Started disable of IntegrationTestLoadAndVerify
...
2013-09-26 19:30:03,459|beaver.machine|INFO|2013-09-26 19:30:03,458 DEBUG [Thread-6] actions.Action: Compacting region IntegrationTestLoadAndVerify,\x8B\xC8\x06\x00\x00\x00\x00\x00/000031_0,1380220935462.da93e4f26dbb801b0da03ffc70b6145d.
...
2013-09-26 19:30:03,500|beaver.machine|INFO|2013-09-26 19:30:03,500 WARN  [Thread-6] policies.Policy: Exception occured during performing action: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: da93e4f26dbb801b0da03ffc70b6145d
2013-09-26 19:30:03,500|beaver.machine|INFO|at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2576)
2013-09-26 19:30:03,501|beaver.machine|INFO|at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:3961)
2013-09-26 19:30:03,501|beaver.machine|INFO|at org.apache.hadoop.hbase.regionserver.HRegionServer.compactRegion(HRegionServer.java:3776)
2013-09-26 19:30:03,501|beaver.machine|INFO|at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:19803)
2013-09-26 19:30:03,502|beaver.machine|INFO|at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2146)
2013-09-26 19:30:03,502|beaver.machine|INFO|at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1851)
2013-09-26 19:30:03,502|beaver.machine|INFO|
2013-09-26 19:30:03,502|beaver.machine|INFO|at sun.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
2013-09-26 19:30:03,503|beaver.machine|INFO|at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
2013-09-26 19:30:03,503|beaver.machine|INFO|at java.lang.reflect.Constructor.newInstance(Constructor.java:525)
2013-09-26 19:30:03,503|beaver.machine|INFO|at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
2013-09-26 19:30:03,503|beaver.machine|INFO|at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)
2013-09-26 19:30:03,503|beaver.machine|INFO|at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:235)
2013-09-26 19:30:03,504|beaver.machine|INFO|at org.apache.hadoop.hbase.client.HBaseAdmin.compact(HBaseAdmin.java:1638)
2013-09-26 19:30:03,504|beaver.machine|INFO|at org.apache.hadoop.hbase.client.HBaseAdmin.compact(HBaseAdmin.java:1602)
2013-09-26 19:30:03,504|beaver.machine|INFO|at org.apache.hadoop.hbase.client.HBaseAdmin.compact(HBaseAdmin.java:1495)
2013-09-26 19:30:03,504|beaver.machine|INFO|at org.apache.hadoop.hbase.chaos.actions.CompactRandomRegionOfTableAction.perform(CompactRandomRegionOfTableAction.java:69)
2013-09-26 19:30:03,504|beaver.machine|INFO|at org.apache.hadoop.hbase.chaos.policies.PeriodicRandomActionPolicy.runOneIteration(PeriodicRandomActionPolicy.java:59)
{code}
CompactRandomRegionOfTableAction didn't check that table IntegrationTestLoadAndVerify was enabled before issuing compaction request.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6656,"I'm trying to call a Coprocessor Endpoint from within the preGet handler of a RegionObserver, and it's throwing Class Loader issues.
The exact same Coprocessor Endpoint works perfectly from remote Java client, however, fails from within the same Region Server.
For our particular test environment, only 1 Region Server is available, so I guess it's a ""local"" call that fails, and perhaps a remote RegionServer wouldn't fail, but that doesn't justify the issue :).

The Code within the RegionObserver is roughly (way reduced) as follows:

---
	@Override
	public void preGet(ObserverContext<RegionCoprocessorEnvironment> e, Get get, List<KeyValue> results)
     throws IOException {
		Map<byte[], Set<byte[]>> results;

		// scan: for all regions
		try {
			Batch.Call<PlatformStatsIndexEndpointProtocol,Set<byte[]>> batchCall = new Batch.Call<PlatformStatsIndexEndpointProtocol,Set<byte[]>>() {
				  public Set<byte[]> call(PlatformStatsIndexEndpointProtocol instance) throws IOException{
				    return instance.getKeyTokenByPrefix(index, match, additionalMatches);
				  }
				};
			results = indexTable.coprocessorExec(PlatformStatsIndexEndpointProtocol.class, null, null, batchCall);
		} catch (Throwable e1) {
			e1.printStackTrace();
			throw new IOException(e1);
		}
		
		Set<byte[]> finalResultSet = new HashSet<byte[]>();
		for (Map.Entry<byte[], Set<byte[]>> e : results.entrySet()) {
			finalResultSet.addAll(e.getValue());
		}
	}
---

The Code for the Coprocessor Endpoint is irrelevant, as it never gets executed.

This is the Exception I get on the Client side (Server side logged exception below).

---
Thu Aug 23 17:37:45 CST 2012, org.apache.hadoop.hbase.client.HTable$5@26659db7,java.io.IOException: java.io.IOException: java.io.IOException: java.lang.IllegalArgumentException: interface com.company.hbase.platformstats.PlatformStatsIndexEndpointProtocol is not visible from class loader
        at com.company.hbase.platformstats.IndexQueryRegionObserver.preGet(IndexQueryRegionObserver.java:100)
        at org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preGet(RegionCoprocessorHost.java:553)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3737)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3639)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1785)
        at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1336)
Caused by: java.io.IOException: java.lang.IllegalArgumentException: interface com.company.hbase.platformstats.PlatformStatsIndexEndpointProtocol is not visible from class loader
        at com.company.hbase.platformstats.PlatformStatsIndexer.getKeyTokens(PlatformStatsIndexer.java:390)
        at com.company.hbase.platformstats.PlatformStatsIndexer.getKeyTokensBySubstring(PlatformStatsIndexer.java:348)
        at com.company.hbase.platformstats.IndexQueryRegionObserver.searchTokens(IndexQueryRegionObserver.java:148)
        at com.company.hbase.platformstats.IndexQueryRegionObserver.preGet(IndexQueryRegionObserver.java:97)
        ... 9 more
Caused by: java.lang.IllegalArgumentException: interface com.company.hbase.platformstats.PlatformStatsIndexEndpointProtocol is not visible from class loader
        at java.lang.reflect.Proxy.getProxyClass(Proxy.java:353)
        at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:581)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$4.call(HConnectionManager.java:1451)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)


        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getRegionServerWithRetries(HConnectionManager.java:1345)
        at org.apache.hadoop.hbase.client.HTable.get(HTable.java:657)
        at Test.queryIndex(Test.java:109)
        at Test.main(Test.java:42)
---

This is the Server Side exception logged:

---
2012-08-23 19:37:44,705 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
java.io.IOException: java.io.IOException: java.lang.IllegalArgumentException: interface com.company.hbase.platformstats.PlatformStatsIndexEndpointProtocol is not
visible from class loader
        at com.company.hbase.platformstats.IndexQueryRegionObserver.preGet(IndexQueryRegionObserver.java:100)
        at org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost.preGet(RegionCoprocessorHost.java:553)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3737)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3639)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1785)
        at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1336)
Caused by: java.io.IOException: java.lang.IllegalArgumentException: interface com.company.hbase.platformstats.PlatformStatsIndexEndpointProtocol is not visible from class loader
        at com.company.hbase.platformstats.PlatformStatsIndexer.getKeyTokens(PlatformStatsIndexer.java:390)
        at com.company.hbase.platformstats.PlatformStatsIndexer.getKeyTokensBySubstring(PlatformStatsIndexer.java:348)
        at com.company.hbase.platformstats.IndexQueryRegionObserver.searchTokens(IndexQueryRegionObserver.java:148)
        at com.company.hbase.platformstats.IndexQueryRegionObserver.preGet(IndexQueryRegionObserver.java:97)
        ... 9 more
Caused by: java.lang.IllegalArgumentException: interface com.company.hbase.platformstats.PlatformStatsIndexEndpointProtocol is not visible from class loader
        at java.lang.reflect.Proxy.getProxyClass(Proxy.java:353)
        at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:581)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$4.call(HConnectionManager.java:1451)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)

---

I'm not senior java developer, so this Class Loader visibility issue goes beyond my reach. I have the theory that because it's a local call, the ClassLoaders for the very same Protocol interface may be different (1 reads from the .jar, another from the remote HTable client call); but I have not been able to prove nor fix this behavior.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9872,"This issue (if it is an expected behaviour I can close this) exists in all versions.
If i do modifyColumn and change an HCDs parameter I am able to get back the modified HCD with the latest data.
But when i do modifyTable and in that modify an HCD parameter say for eg. the SCOPE of it then as we don't persist the HCD information as in TableModifyFamilyHandler used for modifycolumn
{code}
  HTableDescriptor htd =
      this.masterServices.getMasterFileSystem().modifyColumn(tableName, familyDesc);
{code}
we are not able to get the updated HCD information on the RegionServer.  So incases of replication where I need to modify the HCD's scope we are not able to make the replication happen. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6609,"When starting up the cluster using

	@BeforeClass
	public static void setUp() throws Exception {
		utility = new HBaseTestingUtility();
		utility.startMiniCluster();
	}

I get the following stack trace under Windows in Eclipse.  Note it is looking for ""ls"" which is not present under Windows.

java.lang.RuntimeException: Error while running command to get file permissions : java.io.IOException: Cannot run program ""ls"": CreateProcess error=2, The system cannot find the file specified
	at java.lang.ProcessBuilder.start(Unknown Source)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:200)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.fs.FileUtil.execCommand(FileUtil.java:710)
	at org.apache.hadoop.fs.RawLocalFileSystem$RawLocalFileStatus.loadPermissionInfo(RawLocalFileSystem.java:443)
	at org.apache.hadoop.fs.RawLocalFileSystem$RawLocalFileStatus.getPermission(RawLocalFileSystem.java:418)
	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsAndPermissionCheck(DiskChecker.java:146)
	at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:162)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1574)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1521)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1496)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:417)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:430)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:598)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:554)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:523)
	at net.trajano.nosql.hbase.test.FrameworkTest.setUp(FrameworkTest.java:17)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: java.io.IOException: CreateProcess error=2, The system cannot find the file specified
	at java.lang.ProcessImpl.create(Native Method)
	at java.lang.ProcessImpl.<init>(Unknown Source)
	at java.lang.ProcessImpl.start(Unknown Source)
	... 37 more

	at org.apache.hadoop.fs.RawLocalFileSystem$RawLocalFileStatus.loadPermissionInfo(RawLocalFileSystem.java:468)
	at org.apache.hadoop.fs.RawLocalFileSystem$RawLocalFileStatus.getPermission(RawLocalFileSystem.java:418)
	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsAndPermissionCheck(DiskChecker.java:146)
	at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:162)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1574)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1521)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1496)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:417)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:430)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:598)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:554)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:523)
	at net.trajano.nosql.hbase.test.FrameworkTest.setUp(FrameworkTest.java:17)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9974,"Rest sometimes return incomplete xml/json data.

We found these exceptions in rest server.

13/11/15 11:40:51 ERROR mortbay.log:/log/1A:23:11:0C:06:22*
javax.ws.rs.WebApplicationException: javax.xml.bind.MarshalException
 - with linked exception:
[org.mortbay.jetty.EofException]
	at com.sun.jersey.core.provider.jaxb.AbstractRootElementProvider.writeTo(AbstractRootElementProvider.java:159)
	at com.sun.jersey.spi.container.ContainerResponse.write(ContainerResponse.java:306)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1437)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:699)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:847)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
	at org.apache.hadoop.hbase.rest.filter.GzipFilter.doFilter(GzipFilter.java:73)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:322)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Caused by: javax.xml.bind.MarshalException
 - with linked exception:
[org.mortbay.jetty.EofException]
	at com.sun.xml.bind.v2.runtime.MarshallerImpl.write(MarshallerImpl.java:325)
	at com.sun.xml.bind.v2.runtime.MarshallerImpl.marshal(MarshallerImpl.java:249)
	at javax.xml.bind.helpers.AbstractMarshallerImpl.marshal(AbstractMarshallerImpl.java:75)
	at com.sun.jersey.json.impl.JSONMarshallerImpl.marshal(JSONMarshallerImpl.java:74)
	at com.sun.jersey.core.provider.jaxb.AbstractRootElementProvider.writeTo(AbstractRootElementProvider.java:179)
	at com.sun.jersey.core.provider.jaxb.AbstractRootElementProvider.writeTo(AbstractRootElementProvider.java:157)
	... 24 more
Caused by: org.mortbay.jetty.EofException
	at org.mortbay.jetty.HttpGenerator.flush(HttpGenerator.java:791)
	at org.mortbay.jetty.AbstractGenerator$Output.blockForOutput(AbstractGenerator.java:551)
	at org.mortbay.jetty.AbstractGenerator$Output.flush(AbstractGenerator.java:572)
	at org.mortbay.jetty.HttpConnection$Output.flush(HttpConnection.java:1012)
	at org.mortbay.jetty.AbstractGenerator$Output.write(AbstractGenerator.java:651)
	at org.mortbay.jetty.AbstractGenerator$Output.write(AbstractGenerator.java:580)
	at com.sun.jersey.spi.container.servlet.WebComponent$Writer.write(WebComponent.java:307)
	at com.sun.jersey.spi.container.ContainerResponse$CommittingOutputStream.write(ContainerResponse.java:134)
	at com.sun.xml.bind.v2.runtime.output.UTF8XmlOutput.flushBuffer(UTF8XmlOutput.java:416)
	at com.sun.xml.bind.v2.runtime.output.UTF8XmlOutput.text(UTF8XmlOutput.java:369)
	at com.sun.xml.bind.v2.runtime.unmarshaller.Base64Data.writeTo(Base64Data.java:303)
	at com.sun.xml.bind.v2.runtime.output.UTF8XmlOutput.text(UTF8XmlOutput.java:310)
	at com.sun.xml.bind.v2.runtime.XMLSerializer.text(XMLSerializer.java:425)
	at com.sun.xml.bind.v2.model.impl.RuntimeBuiltinLeafInfoImpl$PcdataImpl.writeText(RuntimeBuiltinLeafInfoImpl.java:177)
	at com.sun.xml.bind.v2.runtime.reflect.TransducedAccessor$CompositeTransducedAccessorImpl.writeText(TransducedAccessor.java:261)
	at com.sun.xml.bind.v2.runtime.property.ValueProperty.serializeBody(ValueProperty.java:87)
	at com.sun.xml.bind.v2.runtime.ClassBeanInfoImpl.serializeBody(ClassBeanInfoImpl.java:344)
	at com.sun.xml.bind.v2.runtime.XMLSerializer.childAsXsiType(XMLSerializer.java:700)
	at com.sun.xml.bind.v2.runtime.property.ArrayElementNodeProperty.serializeItem(ArrayElementNodeProperty.java:69)
	at com.sun.xml.bind.v2.runtime.property.ArrayElementProperty.serializeListBody(ArrayElementProperty.java:172)
	at com.sun.xml.bind.v2.runtime.property.ArrayERProperty.serializeBody(ArrayERProperty.java:159)
	at com.sun.xml.bind.v2.runtime.ClassBeanInfoImpl.serializeBody(ClassBeanInfoImpl.java:344)
	at com.sun.xml.bind.v2.runtime.XMLSerializer.childAsXsiType(XMLSerializer.java:700)
	at com.sun.xml.bind.v2.runtime.property.ArrayElementNodeProperty.serializeItem(ArrayElementNodeProperty.java:69)
	at com.sun.xml.bind.v2.runtime.property.ArrayElementProperty.serializeListBody(ArrayElementProperty.java:172)
	at com.sun.xml.bind.v2.runtime.property.ArrayERProperty.serializeBody(ArrayERProperty.java:159)
	at com.sun.xml.bind.v2.runtime.ClassBeanInfoImpl.serializeBody(ClassBeanInfoImpl.java:344)
	at com.sun.xml.bind.v2.runtime.XMLSerializer.childAsSoleContent(XMLSerializer.java:597)
	at com.sun.xml.bind.v2.runtime.ClassBeanInfoImpl.serializeRoot(ClassBeanInfoImpl.java:328)
	at com.sun.xml.bind.v2.runtime.XMLSerializer.childAsRoot(XMLSerializer.java:498)
	at com.sun.xml.bind.v2.runtime.MarshallerImpl.write(MarshallerImpl.java:320)
	... 29 more
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:69)
	at sun.nio.ch.IOUtil.write(IOUtil.java:26)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:336)
	at org.mortbay.io.nio.ChannelEndPoint.flush(ChannelEndPoint.java:170)
	at org.mortbay.io.nio.SelectChannelEndPoint.flush(SelectChannelEndPoint.java:221)
	at org.mortbay.jetty.HttpGenerator.flush(HttpGenerator.java:725)
	... 59 more
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9109,"This problem is observed when region server dies while an endpoint coprocessor is executing. On the client side channel.getLastRegion() returns null and we get null pointer exception while updating result map. 
Following stack-trace is seen on client:

Caused by: java.lang.NullPointerException
at org.apache.hadoop.hbase.util.Bytes.compareTo(Bytes.java:981)
at org.apache.hadoop.hbase.util.Bytes$ByteArrayComparator.compare(Bytes.java:128)
at org.apache.hadoop.hbase.util.Bytes$ByteArrayComparator.compare(Bytes.java:119)
at java.util.TreeMap.put(TreeMap.java:530)
at java.util.Collections$SynchronizedMap.put(Collections.java:1979)
at org.apache.hadoop.hbase.client.HTable$17.update(HTable.java:1372)
at org.apache.hadoop.hbase.client.HTable$18.call(HTable.java:1401)
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
at java.util.concurrent.FutureTask.run(FutureTask.java:138)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9923,"Need to Delete a row based on the column name and value, not using rowkey in hbase. Please provide query.

Need to Delete a row based on partial rowkey in hbase.Please provide query.

Thanks in advance.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9803,"Use hbase-daemon.sh start regionserver 锛?but no regionserver start锛宼he log is

Fri Oct 18 20:01:47 CST 2013 Starting regionserver on h021046.eos.grid.xxx.com.cn
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 513920
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 65536
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 65536
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
Fri Oct 18 20:14:21 CST 2013 Starting regionserver on h021046.eos.grid.xxx.com.cn
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 513920
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 65536
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 65536
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9592,"When a downstream project depends on hbase, and uses hadoop.profile in it's build, then maven craps out because the pom file generated by generate-hadoopX-poms.sh will not activate the relevant hadoop profile:

{code}
mvn -Dhadoop.profile=2 dependency:tree 
[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building foo-app 1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[WARNING] The POM for org.apache.hbase:hbase-common:jar:0.96.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[WARNING] The POM for org.apache.hbase:hbase-common:jar:tests:0.96.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[WARNING] The POM for org.apache.hbase:hbase-client:jar:0.96.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[WARNING] The POM for org.apache.hbase:hbase-server:jar:0.96.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[WARNING] The POM for org.apache.hbase:hbase-server:jar:tests:0.96.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[WARNING] The POM for org.apache.hbase:hbase-hadoop-compat:jar:tests:0.96.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[WARNING] The POM for org.apache.hbase:hbase-hadoop2-compat:jar:tests:0.96.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
{code}

Note that a lot of downstream components like flume, mahout, sqoop use this property. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8976,"http://54.241.6.143/job/HBase-TRUNK/424/org.apache.hbase$hbase-server/testReport/junit/org.apache.hadoop.hbase.client/TestFromClientSideWithCoprocessor/testClientPoolThreadLocal/

{code}
Error Message

expected null, but was:<java.lang.AssertionError: The number of versions of '[B@755d828f:[B@4e26b67b did not match 4 expected:<4> but was:<3>>
Stacktrace

java.lang.AssertionError: expected null, but was:<java.lang.AssertionError: The number of versions of '[B@755d828f:[B@4e26b67b did not match 4 expected:<4> but was:<3>>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotNull(Assert.java:664)
	at org.junit.Assert.assertNull(Assert.java:646)
	at org.junit.Assert.assertNull(Assert.java:656)
	at org.apache.hadoop.hbase.client.TestFromClientSide.testClientPoolThreadLocal(TestFromClientSide.java:4687)
...
{code}

I do not think I have seen this fail recently.  Making this issue so can keep an eye on it.  If anyone wants to take this on in meantime, they are welcome.  Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9069,"This is second time I've seen this fail.  Anyone want to take a look?  I am filing this as placeholder to keep account of failures.

https://builds.apache.org/job/HBase-TRUNK/4306/testReport/junit/org.apache.hadoop.hbase.thrift/TestThriftServerCmdLine/testRunThriftServer_18_/

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8765,"I noticed that the current split behavior is rather suboptimal with regard to compactions. On large regions, HFile size limit triggers a split. Split is followed by major compaction to get rid of the partial reference files. However, HFile size limit is surpassed after compaction most of the time.
So, first we rewrite a lot of data into a new file. Then we say ""Oh look! A large file!"", split the region and rewrite everything again.

Perhaps region split should be based on store size, or incoming compaction size - large enough compaction should be converted into splits.

Thoughts? I think basing off store size is a simple fix, and will code it up soon if there are no objections",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4814,"I've seen a situation where regions were splitting almost exactly at the same time as an alter command was issued and those regions' daughters were left unaltered. It would even seem that the daughters' daughters also share this situation.

Reopening all the regions fixes the problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3937,"I describe the scenario of how this problem happened:

1.HMaster assigned the region A to RS1. So the RegionState was set to PENDING_OPEN.
2.For there's too many opening requests, the open process on RS1 was blocked.
3.Some time later, TimeoutMonitor found the assigning of A was timeout. For the RegionState was in PENDING_OPEN, went into the following handler process(Just put the region into an waiting-assigning set):

   case PENDING_OPEN:
      LOG.info(""Region has been PENDING_OPEN for too "" +
          ""long, reassigning region="" +
          regionInfo.getRegionNameAsString());
      assigns.put(regionState.getRegion(), Boolean.TRUE);
      break;
So we can see that, under this case, we consider the ZK node state was OFFLINE. Indeed, in an normal disposal, it's OK.

4.But before the real-assigning, the requests of RS1 was disposed. So that affected the new-assigning. For it update the ZK node state from OFFLINE to OPENING. 

5.The new assigning started, so it send region to open in RS2. But while the opening, it should update the ZK node state from OFFLINE to OPENING. For the current state is OPENING, so this operation failed.
So this region couldn't be open success anymore.

So I think, to void this problem , under the case of PENDING_OPEN of TiemoutMonitor, we should transform the ZK node state to OFFLINE first.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7135,"2012-11-07 08:35:36,082 ERROR org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache: Deserializer threw an exception. This may indicate a bug.
java.io.IOException: Invalid HFile block magic: \x00\x00\x00\x00\x00\x00\x00\x00
at org.apache.hadoop.hbase.io.hfile.BlockType.parse(BlockType.java:153)
at org.apache.hadoop.hbase.io.hfile.BlockType.read(BlockType.java:164)
at org.apache.hadoop.hbase.io.hfile.HFileBlock.<init>(HFileBlock.java:254)
at org.apache.hadoop.hbase.io.hfile.HFileBlock$1.deserialize(HFileBlock.java:148)
at org.apache.hadoop.hbase.io.hfile.HFileBlock$1.deserialize(HFileBlock.java:140)
at org.apache.hadoop.hbase.io.hfile.slab.SingleSizeCache.getBlock(SingleSizeCache.java:166)
at org.apache.hadoop.hbase.io.hfile.slab.SlabCache.getBlock(SlabCache.java:245)
at org.apache.hadoop.hbase.io.hfile.DoubleBlockCache.getBlock(DoubleBlockCache.java:100)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getBlockFromCache(HFileReaderV2.java:267)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:349)
at org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.loadDataBlockWithScanInfo(HFileBlockIndex.java:257)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:498)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:522)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:226)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:145)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7627,"While testing snapshot branch I found this exception.  

{code}
2013-01-18 05:42:09,832 ERROR org.apache.hadoop.hbase.master.CatalogJanitor: Caught exception
java.lang.UnsupportedOperationException
	at java.util.AbstractList.remove(AbstractList.java:144)
	at org.apache.hadoop.hbase.client.HTable.delete(HTable.java:738)
	at org.apache.hadoop.hbase.catalog.MetaEditor.deleteFromMetaTable(MetaEditor.java:145)
	at org.apache.hadoop.hbase.catalog.MetaEditor.deleteFromMetaTable(MetaEditor.java:132)
	at org.apache.hadoop.hbase.catalog.MetaEditor.deleteDaughtersReferencesInParent(MetaEditor.java:372)
	at org.apache.hadoop.hbase.master.CatalogJanitor.removeDaughtersFromParent(CatalogJanitor.java:288)
	at org.apache.hadoop.hbase.master.CatalogJanitor.cleanParent(CatalogJanitor.java:239)
	at org.apache.hadoop.hbase.master.CatalogJanitor.scan(CatalogJanitor.java:142)
	at org.apache.hadoop.hbase.master.CatalogJanitor.initialChore(CatalogJanitor.java:74)
	at org.apache.hadoop.hbase.Chore.run(Chore.java:65)
	at java.lang.Thread.run(Thread.java:662)
{code}

This was introduced by HBASE-7365 (currently committed in snapshot branch, soon to be committed to trunk.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7751,"From https://builds.apache.org/job/HBase-TRUNK/3846/testReport/org.apache.hadoop.hbase.ipc/TestDelayedRpc/testDelayedRpcImmediateReturnValue/:
{code}
java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
	at java.util.ArrayList.rangeCheck(ArrayList.java:604)
	at java.util.ArrayList.get(ArrayList.java:382)
	at org.apache.hadoop.hbase.ipc.TestDelayedRpc.testDelayedRpc(TestDelayedRpc.java:96)
	at org.apache.hadoop.hbase.ipc.TestDelayedRpc.testDelayedRpcImmediateReturnValue(TestDelayedRpc.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:722)
Standard Output

2013-02-02 07:49:26,693 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: ipc.TestDelayedRpc#testDelayedRpcImmediateReturnValue Thread=5, OpenFileDescriptor=81, MaxFileDescriptor=4096, ConnectionCount=0
2013-02-02 07:49:31,746 WARN  [pool-1-thread-1] impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-hbase.properties, hadoop-metrics2.properties
Exception in thread ""Thread-7"" java.lang.AssertionError: Unexpected exception: null	at org.junit.Assert.fail(Assert.java:88)	at org.apache.hadoop.hbase.ipc.TestDelayedRpc$TestThread.run(TestDelayedRpc.java:249)Exception in thread ""Thread-8"" java.lang.AssertionError: Unexpected exception: null	at org.junit.Assert.fail(Assert.java:88)	at org.apache.hadoop.hbase.ipc.TestDelayedRpc$TestThread.run(TestDelayedRpc.java:249)2013-02-02 07:49:36,410 WARN  [IPC Client (47) connection to /127.0.0.1:36850 from jenkins] ipc.HBaseClient$Connection(640): Unexpected exception receiving call responses
java.lang.RuntimeException: java.lang.NullPointerException
	at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.receiveResponse(HBaseClient.java:1003)
	at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.run(HBaseClient.java:637)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.receiveResponse(HBaseClient.java:999)
	... 1 more
Exception in thread ""Thread-9"" java.lang.AssertionError: Unexpected exception: null	at org.junit.Assert.fail(Assert.java:88)	at org.apache.hadoop.hbase.ipc.TestDelayedRpc$TestThread.run(TestDelayedRpc.java:249)2013-02-02 07:49:36,449 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: ipc.TestDelayedRpc#testDelayedRpcImmediateReturnValue Thread=21 (was 5)
{code}
Here is related code where NPE was thrown:
{code}
            rpcResponseType = ProtobufRpcClientEngine.Invoker.getReturnProtoType(
                getMethod(remoteId.getProtocol(),
                          call.param.getMethodName()));
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4614,Kinger on IRC found out that it's currently impossible to CopyTable between clusters if there's a zoo.cfg on the classpath as it will take precedence over the --peer.adr or whatever else the user passes.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4697,"After the introduction of CacheConfig, over in HBASE-4641 we dealt with a bug of the block cache being instantiated in the master.  A short-term fix was done there.

This is the real fix.  The block cache should not be a static reference, it should be instantiated within HRS construction/initialization.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4538,"Saw this in a failed TestAdmin on 0.92

{code}
2011-10-05 01:18:58,890 ERROR [MASTER_OPEN_REGION-sv4r9s38,52146,1317777098450-2] executor.EventHandler(171): Caught throwable while processing event RS_ZK_REGION_OPENED
java.lang.NullPointerException
        at org.apache.hadoop.hbase.master.AssignmentManager.updateTimers(AssignmentManager.java:1053)
        at org.apache.hadoop.hbase.master.AssignmentManager.regionOnline(AssignmentManager.java:1027)
        at org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.process(OpenedRegionHandler.java:108)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:168)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5958,"ByteString.copyFrom makes a copy of a byte array in case it is changed in other thread.
In most case, we don't need to worry about that.  We should avoid copying the bytes
for performance issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6323,"Most of the metrics in replication were written with 1 slave in mind but with multiple slaves the issue really shows. Most of the metrics are set directly:

{code}
public void enqueueLog(Path log) {
  this.queue.put(log);
  this.metrics.sizeOfLogQueue.set(queue.size());
}
{code}

So {{sizeOfLogQueue}} is always showing the size of the queue that updated the metric last.

I'm not sure what's the right way to fix this since we can't have dynamic metrics. Merging them would work here but it wouldn't work so well with {{ageOfLastShippedOp}} since the age can be different and it definitely cannot be summed.

Assigning to Elliott since he seems to dig metrics these days. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7813,"Try a BulkDeleteEndpoint using DeleteType.COLUMN or DeleteType.VERSION and give it a set of Columns which are not in the row.

A Delete is constructed using just the row alone. No family/column/version is added and it is applied, thus deleting the entire row.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9479,"Right now, HBase contains so many dependencies, that using the most basic HBase functionality such as HConnection in a larger application is unreasonably hard.  For example, trying to include HBase connectivity in a Spring web app leads to hundreds of JarClassLoader errors such as:

{code}
JarClassLoader: Warning: org/apache/commons/collections/FastHashMap$CollectionView.class in lib/commons-collections-3.2.1.jar is hidden by lib/commons-beanutils-core-1.8.3.jar (with different bytecode)
JarClassLoader: Warning: org/apache/commons/collections/FastHashMap$EntrySet.class in lib/commons-collections-3.2.1.jar is hidden by lib/commons-beanutils-core-1.8.3.jar (with different bytecode)
JarClassLoader: Warning: org/apache/commons/collections/FastHashMap$KeySet.class in lib/commons-collections-3.2.1.jar is hidden by lib/commons-beanutils-core-1.8.3.jar (with different bytecode)
JarClassLoader: Warning: org/apache/commons/collections/FastHashMap$Values.class in lib/commons-collections-3.2.1.jar is hidden by lib/commons-beanutils-core-1.8.3.jar (with different bytecode)
JarClassLoader: Warning: org/apache/commons/collections/FastHashMap.class in lib/commons-collections-3.2.1.jar is hidden by lib/commons-beanutils-core-1.8.3.jar (with different bytecode)
JarClassLoader: Warning: javax/servlet/Filter.class in lib/servlet-api-2.5-6.1.14.jar is hidden by lib/javax.servlet-3.0.0.v201112011016.jar (with different bytecode)
JarClassLoader: Warning: javax/servlet/FilterChain.class in lib/servlet-api-2.5-6.1.14.jar is hidden by lib/javax.servlet-3.0.0.v201112011016.jar (with different bytecode)
JarClassLoader: Warning: javax/servlet/FilterConfig.class in lib/servlet-api-2.5-6.1.14.jar is hidden by lib/javax.servlet-3.0.0.v201112011016.jar (with different bytecode)
JarClassLoader: Warning: javax/servlet/GenericServlet.class in lib/servlet-api-2.5-6.1.14.jar is hidden by lib/javax.servlet-3.0.0.v201112011016.jar (with different bytecode)
JarClassLoader: Warning: javax/servlet/http/Cookie.class in lib/servlet-api-2.5-6.1.14.jar is hidden by lib/javax.servlet-3.0.0.v201112011016.jar (with different bytecode)
{code}


Why is this all bundled together?  Why not have an ""hbase-client"" or ""hbase-client-dev"" package which is friendly for creating applications?

I have spent 2+ days attempting to run a web service which is backed by HBase with no luck.  I have created several stack overflow questions:

http://stackoverflow.com/questions/18703903/java-massive-class-collision

http://stackoverflow.com/questions/18690582/how-to-create-jetty-spring-app-with-hbase-connection

The use of BeanUtils is also known to have a very bad issue:

""The three jars contain wrong classes""
https://issues.apache.org/jira/browse/BEANUTILS-398

Why is this so difficult?  How do I include what I need to make an HBase app.  So far I have tried using Maven, but this approach is draconian, and I have not succeeded.  Am I Pwned?

{code}
   <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.jboss.netty</groupId>
                <artifactId>netty</artifactId>
                <version>3.2.4.Final</version>
            </dependency>
            <dependency>
                <groupId>org.codehaus.jackson</groupId>
                <artifactId>jackson-core-asl</artifactId>
                <version>1.9.12</version>
            </dependency>
            <dependency>
                <groupId>org.codehaus.jackson</groupId>
                <artifactId>jackson-jaxrs</artifactId>
                <version>1.9.12</version>
            </dependency>
            <dependency>
                <groupId>com.sun.xml.bind</groupId>
                <artifactId>jackson-jaxrs</artifactId>
                <version>2.2.6</version>
            </dependency>
            <dependency>
                <groupId>com.sun.xml.bind</groupId>
                <artifactId>jaxb-impl</artifactId>
                <version>2.2.6</version>
            </dependency>
            <dependency>
                <groupId>log4j</groupId>
                <artifactId>log4j</artifactId>
                <version>1.2.16</version>
            </dependency>
            <dependency>
                <groupId>asm</groupId>
                <artifactId>asm</artifactId>
                <version>3.3.1</version>
            </dependency>
            <dependency>
                <groupId>commons-codec</groupId>
                <artifactId>commons-codec</artifactId>
                <version>1.4</version>
            </dependency>
            <dependency>
                <groupId>commons-lang</groupId>
                <artifactId>commons-lang</artifactId>
                <version>2.5</version>
            </dependency>
            <dependency>
                <groupId>org.slf4j</groupId>
                <artifactId>slf4j-api</artifactId>
                <version>1.7.5</version>
            </dependency>
            <dependency>
                <groupId>commons-logging</groupId>
                <artifactId>commons-logging</artifactId>
                <version>1.1.1</version>
            </dependency>
            <dependency>
                <groupId>org.codehaus.jackson</groupId>
                <artifactId>jackson-mapper-asl</artifactId>
                <version>1.9.12</version>
            </dependency>
            <dependency>
                <groupId>org.slf4j</groupId>
                <artifactId>slf4j-log4j12</artifactId>
                <version>1.6.1</version>
            </dependency>
            <dependency>
                <groupId>org.apache.httpcomponents</groupId>
                <artifactId>httpcore</artifactId>
                <version>4.1.3</version>
            </dependency>
            <dependency>
                <groupId>commons-httpclient</groupId>
                <artifactId>commons-httpclient</artifactId>
                <version>3.1</version>
            </dependency>
            <dependency>
                <groupId>org.codehaus.jackson</groupId>
                <artifactId>jackson-xc</artifactId>
                <version>1.9.12</version>
            </dependency>
            <dependency>
                <groupId>commons-beanutils</groupId>
                <artifactId>commons-beanutils-core</artifactId>
                <version>1.8.3</version>
            </dependency>
            <dependency>
                <groupId>commons-beanutils</groupId>
                <artifactId>commons-beanutils</artifactId>
                <version>1.8.3</version>
            </dependency>

        </dependencies>
    </dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>commons-beanutils</groupId>
            <artifactId>commons-beanutils-core</artifactId>
            <version>1.8.3</version>
        </dependency>
        <dependency>
            <groupId>commons-beanutils</groupId>
            <artifactId>commons-beanutils</artifactId>
            <version>1.8.3</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.cxf</groupId>
            <artifactId>cxf-rt-frontend-jaxrs</artifactId>
            <version>2.7.2</version>
        </dependency>
        <dependency>
            <groupId>org.apache.cxf</groupId>
            <artifactId>cxf-rt-frontend-jaxws</artifactId>
            <version>2.7.2</version>
        </dependency>
        <dependency>
            <groupId>org.codehaus.jackson</groupId>
            <artifactId>jackson-core-asl</artifactId>
            <version>1.9.12</version>
        </dependency>
        <dependency>
            <groupId>org.codehaus.jackson</groupId>
            <artifactId>jackson-mapper-asl</artifactId>
            <version>1.9.12</version>
        </dependency>
        <dependency>
            <groupId>org.codehaus.jackson</groupId>
            <artifactId>jackson-jaxrs</artifactId>
            <version>1.9.12</version>
        </dependency>
        <dependency>
            <groupId>org.codehaus.jackson</groupId>
            <artifactId>jackson-xc</artifactId>
            <version>1.9.12</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-core</artifactId>
            <version>3.2.4.RELEASE</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-context</artifactId>
            <version>3.2.4.RELEASE</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-webmvc</artifactId>
            <version>3.2.4.RELEASE</version>
        </dependency>
        <dependency>
            <groupId>ch.qos.logback</groupId>
            <artifactId>logback-classic</artifactId>
            <version>1.0.13</version>
        </dependency>
        <dependency>
            <groupId>ch.qos.logback</groupId>
            <artifactId>logback-core</artifactId>
            <version>1.0.13</version>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>4.11</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>net.sf.opencsv</groupId>
            <artifactId>opencsv</artifactId>
            <version>2.3</version>
        </dependency>
        <dependency>
            <groupId>javax.inject</groupId>
            <artifactId>javax.inject</artifactId>
            <version>1</version>
        </dependency>
        <dependency>
            <groupId>org.eclipse.jetty</groupId>
            <artifactId>jetty-server</artifactId>
            <version>9.0.4.v20130625</version>
        </dependency>
        <dependency>
            <groupId>org.eclipse.jetty</groupId>
            <artifactId>jetty-webapp</artifactId>
            <version>9.0.4.v20130625</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase</artifactId>
            <version>0.94.11</version>
            <exclusions>
                <exclusion>
                    <groupId>org.codehaus.jackson</groupId>
                    <artifactId>jackson-core-asl</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.codehaus.jackson</groupId>
                    <artifactId>jackson-jaxrs</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.codehaus.jackson</groupId>
                    <artifactId>jackson-mapper-asl</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.codehaus.jackson</groupId>
                    <artifactId>jackson-xc</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jersey-core</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jersey-json</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jersey-server</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.mortbay.jetty</groupId>
                    <artifactId>jetty</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jetty-util</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jsp-2.1</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jsp-api-2.1</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>servlet-api-2.5</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>javax.xml.bind</groupId>
                    <artifactId>jaxb-api</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>tomcat</groupId>
                    <artifactId>jasper-compiler</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>tomcat</groupId>
                    <artifactId>jasper-runtime</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.slf4j</groupId>
                    <artifactId>slf4j-api</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.slf4j</groupId>
                    <artifactId>slf4j-log4j12</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.apache.thrift</groupId>
                    <artifactId>libthrift</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-core</artifactId>
            <version>1.2.1</version>
            <exclusions>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jersey-core</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jersey-json</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.sun.jersey</groupId>
                    <artifactId>jersey-server</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>tomcat</groupId>
                    <artifactId>jasper-compiler</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>tomcat</groupId>
                    <artifactId>jasper-runtime</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
    </dependencies>
{code}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9363,REST/Thrift web UI is not working properly any more.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8950,"Currently, the HbaseTestingUtility is not importable in versions 0.94.x without Sonatype Aether dynamic classpath modification. Please change this to make the HbaseTestingUtility visible and importable without special classpath modifications.

That is:
{code}
import org.apache.hadoop.hbase.HBaseTestingUtility;
{code}
should succeed after placing org.apache.hbase/hbase ""0.94.X"" and higher on the classpath.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9037,"From Stack on the mailing list:
{quote}
I see this every 4ms or so when reading.

21 2013-07-24 10:55:24,594 DEBUG
org.apache.hadoop.hbase.io.hfile.LruBlockCache: Block cache LRU eviction
completed; freed=24.78 MB, total=185.13 MB, single=0 KB, multi=207.88 MB,
memory=0.64 KB
20 2013-07-24 10:55:28,975 DEBUG
org.apache.hadoop.hbase.io.hfile.LruBlockCache: Block cache LRU eviction
started; Attempting to free 24.75 MB of total=209.91 MB

Loads of it.
{quote}
Should either limit the log frequency of this, or change to trace.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8973,"While trying to test some things, ended up modifying the rowcounter job a little. Proposing a patch with these changes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8708,"How can i load data in a file that is resides in hdfs in to a hbase table?

Is Hbase have any external table facility like as hive provides?






",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8677,"These days, I test one of available clients REST. When I startup two REST servers and put these servers into Cluster instance using the REST client classes, I get the wrong results by getScanner interface. 

Code like this(37, 38 are two rest servers):
        Cluster cluster = new Cluster();
        cluster.add(""10.28.171.37"", 8080);
        cluster.add(""10.28.171.38"", 8080);
        Client client = new Client(cluster);
        RemoteHTable table = new RemoteHTable(client, ""demotime"");
        
        ResultScanner resultScanner = table.getScanner(new Scan());
        for (Result result: resultScanner) {
            System.out.println(""Scan row[""+        Bytes.toString(result.getRow())+""]:""+result);
        }

I find server-side codes of REST maybe the cause. They use ""static final Map<String, ScannerInstanceResource> scanners"" to cache the last scanner context, so if there are multi REST servers, client may navigate to the other server, which has not scanner conext of it and return the wrong results.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8464,"In FastDiffEncoder
Inside compressSingleKeyValue()
{code}
 currentState.prevOffset = in.position();
    int keyLength = in.getInt();
    int valueOffset =
        currentState.prevOffset + keyLength + KeyValue.ROW_OFFSET;
    int valueLength = in.getInt();
    byte flag = 0;
{code}
Before seeing the bug, whenever we write something into encoders, we take the ByteBuffer that is created by Writer.append().
This basically writes
keyLength, valueLength, keyarray, valuearray, <memstoreTS> 
Now consider a case where the keyarray size is 20 and valuearray size is 20.
As per the above code for the first KV
Read keyLength (4  bytes), value length (4 bytes).
First time the prevOffset is 0 so our value Offset is - 0+20+8 =28.
This is correct.
After the first KV is read when we take up the next KV,
Now the currentState.prevOffset => 28+20 = 48 (the value is also read)
The above calculation will give us
28+20+8 = 56.
But the bytebuffer has only 48 bytes in it.

Why our testcases did not catch this bug?
========================================
It is because in the TestDataBlockEncoders we create a ByteBuffer directly from the KVs and we do not create the way the HFileWriterV2 does it.
See RedundantKVGenerator.convertKvToByteBuffer().

Pls correct me if am wrong.  I can provide a patch for the same if my above analysis is correct.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8385,"Expected behavior:
A user should be able to:
1. Take a snapshot of a table
2. Delete that table
3. Use the snapshot to restore that deleted table

Observed behavior:
During a restore, we attempt to create a snapshot of the table should the restore go awry. However, the snapshot fails because the table that we want to snapshot is not present.

{code}
Stack trace:

org.apache.hadoop.hbase.exceptions.SnapshotCreationException: org.apache.hadoop.hbase.exceptions.SnapshotCreationException: Could not build snapshot handler
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:79)
	at org.apache.hadoop.hbase.ipc.ProtobufRpcClientEngine$Invoker.invoke(ProtobufRpcClientEngine.java:146)
	at $Proxy24.snapshot(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterProtocolHandler.invoke(HConnectionManager.java:1703)
	at org.apache.hadoop.hbase.client.$Proxy25.snapshot(Unknown Source)
	at org.apache.hadoop.hbase.client.HBaseAdmin$18.call(HBaseAdmin.java:2337)
	at org.apache.hadoop.hbase.client.HBaseAdmin$18.call(HBaseAdmin.java:1)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:2637)
	at org.apache.hadoop.hbase.client.HBaseAdmin.execute(HBaseAdmin.java:2612)
	at org.apache.hadoop.hbase.client.HBaseAdmin.takeSnapshotAsync(HBaseAdmin.java:2334)
	at org.apache.hadoop.hbase.client.HBaseAdmin.snapshot(HBaseAdmin.java:2279)
	at org.apache.hadoop.hbase.client.HBaseAdmin.snapshot(HBaseAdmin.java:2252)
	at org.apache.hadoop.hbase.client.HBaseAdmin.snapshot(HBaseAdmin.java:2204)
	at org.apache.hadoop.hbase.client.HBaseAdmin.restoreSnapshot(HBaseAdmin.java:2417)
	at org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.testRestoreSnapshotOfDeleted(TestRestoreSnapshotFromClient.java:266)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException: org.apache.hadoop.hbase.exceptions.SnapshotCreationException: Could not build snapshot handler
	at org.apache.hadoop.hbase.master.snapshot.SnapshotManager.snapshotDisabledTable(SnapshotManager.java:573)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotManager.takeSnapshot(SnapshotManager.java:524)
	at org.apache.hadoop.hbase.master.HMaster.snapshot(HMaster.java:2521)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine$Server.call(ProtobufRpcServerEngine.java:174)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1871)
Caused by: java.io.IOException: HTableDescriptor missing for testtb-1366407250932
	at org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.loadTableDescriptor(TakeSnapshotHandler.java:125)
	at org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.prepare(TakeSnapshotHandler.java:136)
	at org.apache.hadoop.hbase.master.snapshot.DisabledTableSnapshotHandler.prepare(DisabledTableSnapshotHandler.java:77)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotManager.snapshotDisabledTable(SnapshotManager.java:557)
	... 8 more

	at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:1321)
	at org.apache.hadoop.hbase.ipc.ProtobufRpcClientEngine$Invoker.invoke(ProtobufRpcClientEngine.java:131)
	... 44 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8184,"thrift2 is what our thrift interface should be.  It is unfinished though and without an owner.  While in place, it prompts why a thrift2 and a thrift1 questions.  Meantime, thrift1 is what folks use and it is getting bug fixes.  Suggest we remove thrift2 till it gets carried beyond thrift1.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8647,"Running tests I see this from time to time:

{code}
 19 2013-05-29 13:42:37,868 INFO  [Thread-476] util.ChaosMonkey$RestartRandomRs(274): Performing action: Restart random region server
 20 2013-05-29 13:42:37,869 WARN  [Thread-476] util.ChaosMonkey$PeriodicRandomActionPolicy(578): Exception occured during performing action: java.lang.NullPointerException
 21 ,...at org.apache.hadoop.hbase.util.ChaosMonkey$Action.getCurrentServers(ChaosMonkey.java:160)
 22 ,...at org.apache.hadoop.hbase.util.ChaosMonkey$RestartRandomRs.perform(ChaosMonkey.java:275)
 23 ,...at org.apache.hadoop.hbase.util.ChaosMonkey$PeriodicRandomActionPolicy.runOneIteration(ChaosMonkey.java:576)
 24 ,...at org.apache.hadoop.hbase.util.ChaosMonkey$PeriodicPolicy.run(ChaosMonkey.java:488)
 25 ,...at org.apache.hadoop.hbase.util.ChaosMonkey$CompositeSequentialPolicy.run(ChaosMonkey.java:458)
 26 ,...at java.lang.Thread.run(Thread.java:680)
{code}

Our monkey has killed everything.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6523,During some testing here at Salesforce.com we found another scenario where an HConnectionImplementation would never recover from a lost ZK connection.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8554,"Currently Scan.startRow() is only used for determining which Region to look up the row into but we do not seek within the region to the start row. Since its not uncommon to run with large sized regions these days 5G, this is suboptimal.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3669,"After going crazy killing region servers after HBASE-3668, most of the cluster recovered except for 3 regions that kept being refused by the region servers.

One the master I would see:
{code}
2011-03-17 22:23:14,828 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  supr_rss_items,ea0a3ac6c8779dab:872333599:ed1a7ad00f076fd98fcd3adcd98b62c6,1285707378709.f11849557c64c4efdbe0498f3fe97a21. state=PENDING_OPEN, ts=1300400554826
2011-03-17 22:23:14,828 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_OPEN for too long, reassigning region=supr_rss_items,ea0a3ac6c8779dab:872333599:ed1a7ad00f076fd98fcd3adcd98b62c6,1285707378709.f11849557c64c4efdbe0498f3fe97a21.
2011-03-17 22:23:14,828 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=supr_rss_items,ea0a3ac6c8779dab:872333599:ed1a7ad00f076fd98fcd3adcd98b62c6,1285707378709.f11849557c64c4efdbe0498f3fe97a21. state=PENDING_OPEN, ts=1300400554826
2011-03-17 22:23:14,828 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for supr_rss_items,ea0a3ac6c8779dab:872333599:ed1a7ad00f076fd98fcd3adcd98b62c6,1285707378709.f11849557c64c4efdbe0498f3fe97a21. so generated a random one; hri=supr_rss_items,ea0a3ac6c8779dab:872333599:ed1a7ad00f076fd98fcd3adcd98b62c6,1285707378709.f11849557c64c4efdbe0498f3fe97a21., src=, dest=sv2borg171,60020,1300399357135; 17 (online=17, exclude=null) available servers
2011-03-17 22:23:14,828 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region supr_rss_items,ea0a3ac6c8779dab:872333599:ed1a7ad00f076fd98fcd3adcd98b62c6,1285707378709.f11849557c64c4efdbe0498f3fe97a21. to sv2borg171,60020,1300399357135

{code}

Then on the region server:

{code}
2011-03-17 22:23:14,829 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22d627c142707d2 Attempting to transition node f11849557c64c4efdbe0498f3fe97a21 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2011-03-17 22:23:14,832 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: regionserver:60020-0x22d627c142707d2 Retrieved 166 byte(s) of data from znode /hbase/unassigned/f11849557c64c4efdbe0498f3fe97a21; data=region=supr_rss_items,ea0a3ac6c8779dab:872333599:ed1a7ad00f076fd98fcd3adcd98b62c6,1285707378709.f11849557c64c4efdbe0498f3fe97a21., server=sv2borg180,60020,1300384550966, state=RS_ZK_REGION_OPENING
2011-03-17 22:23:14,832 WARN org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22d627c142707d2 Attempt to transition the unassigned node for f11849557c64c4efdbe0498f3fe97a21 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING failed, the node existed but was in the state RS_ZK_REGION_OPENING
2011-03-17 22:23:14,832 WARN org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Failed transition from OFFLINE to OPENING for region=f11849557c64c4efdbe0498f3fe97a21
{code}

I'm not sure I fully understand what was going on... the master was suppose to OFFLINE the znode but then that's not what the region server was seeing? In any case, I was able to recover by doing a force unassign for each region and then assign.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2522,"If for any reason the master takes too much time to process a MSG_REPORT_SPLIT_INCLUDES_DAUGHTERS, and that a user successfully disables the table, then the daughter regions will still be assigned and marked as offline in .META.

A test case I'm uploading to HBASE-2515 shows the issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7539,No point in having stale META record when the server that put it has already closed the region.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5912,"I ran oprofile on a YCSB client and found that a large percentage of the CPU time was going to this function:

51991     0.4913  25361.jo                 java                     java.lang.reflect.Method[] java.lang.Class.copyMethods(java.lang.reflect.Method[])
51384     0.4856  25361.jo                 java                     int org.apache.hadoop.hbase.ipc.ProtocolSignature.getFingerprint(java.lang.reflect.Method)
50428     0.4766  25361.jo                 java                     void java.util.Arrays.sort1(int[], int, int)

We should introduce a simple cache to avoid this overhead.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4794,"In AssignmentManager.getReopenStatus, it calls a version of MetaReader.getTableRegions that sets excludeOfflinedSplitParents to false meaning that the offline parents are returned. What this means is that if one of them was already closed before the alter command was issued (and I believe there are a few other cases) then the alter will hang until the CatalogJanitor sweeps the parent .META. row.

Since the CJ sleep time is 5 minutes, the worst case scenario is an alter that takes almost 5 minutes.

Here's an example:

{quote}
925/948 regions updated.
920/943 regions updated.
913/934 regions updated.
912/928 regions updated.
912/928 regions updated.

(5 minutes later)

912/928 regions updated.
912/928 regions updated.
905/918 regions updated.
897/906 regions updated.
891/892 regions updated.
891/891 regions updated.
Done.
{quote}

I can confirm with the log that 37 parent regions were cleaned up.

Also it's pretty nice to see how the number fluctuates up and down :)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5086,"I got this twice during the same test.

If the region servers are slow enough and you run an online alter, it's possible for the RS to change the znode status to CLOSED and have the master send an OPEN before the region server is able to remove the region from it's list of RITs.

This is what the master sees:

{quote}
011-12-21 22:24:09,498 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f. (offlining)
2011-12-21 22:24:09,498 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:62003-0x134589d3db033f7 Creating unassigned node for 43123e2e3fc83ec25fe2a76b4f09077f in a CLOSING state
2011-12-21 22:24:09,524 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Sent CLOSE to sv4r25s44,62023,1324494325099 for region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.
2011-12-21 22:24:15,656 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_CLOSED, server=sv4r25s44,62023,1324494325099, region=43123e2e3fc83ec25fe2a76b4f09077f
2011-12-21 22:24:15,656 DEBUG org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED event for 43123e2e3fc83ec25fe2a76b4f09077f
2011-12-21 22:24:15,656 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f. state=CLOSED, ts=1324506255629, server=sv4r25s44,62023,1324494325099
2011-12-21 22:24:15,656 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:62003-0x134589d3db033f7 Creating (or updating) unassigned node for 43123e2e3fc83ec25fe2a76b4f09077f with OFFLINE state
2011-12-21 22:24:15,663 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Found an existing plan for test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f. destination server is + sv4r25s44,62023,1324494325099
2011-12-21 22:24:15,663 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Using pre-existing plan for region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.; plan=hri=test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f., src=, dest=sv4r25s44,62023,1324494325099
2011-12-21 22:24:15,663 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f. to sv4r25s44,62023,1324494325099
2011-12-21 22:24:15,664 ERROR org.apache.hadoop.hbase.master.AssignmentManager: Failed assignment in: sv4r25s44,62023,1324494325099 due to org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: Received:OPEN for the region:test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f. ,which we are already trying to CLOSE.
{quote}

After that the master abandons.

And the region server:
{quote}
2011-12-21 22:24:09,523 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received close region: test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.
2011-12-21 22:24:09,523 DEBUG org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler: Processing close of test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.
2011-12-21 22:24:09,524 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Closing test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.: disabling compactions & flushes
2011-12-21 22:24:09,524 INFO org.apache.hadoop.hbase.regionserver.HRegion: Running close preflush of test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.
2011-12-21 22:24:09,524 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memstore flush for test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f., current region memstore size 40.5m
2011-12-21 22:24:09,524 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished snapshotting test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f., commencing wait for mvcc, flushsize=42482936
2011-12-21 22:24:13,368 DEBUG org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://sv4r11s38:9100/hbase/test1/43123e2e3fc83ec25fe2a76b4f09077f/.tmp/87d6944c54c7417e9a34a9f9542bcb72 to hdfs://sv4r11s38:9100/hbase/test1/43123e2e3fc83ec25fe2a76b4f09077f/actions/87d6944c54c7417e9a34a9f9542bcb72
2011-12-21 22:24:13,568 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://sv4r11s38:9100/hbase/test1/43123e2e3fc83ec25fe2a76b4f09077f/actions/87d6944c54c7417e9a34a9f9542bcb72, entries=54209, sequenceid=31451012, memsize=40.5m, filesize=31.4m
2011-12-21 22:24:14,381 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~40.5m/42482936, currentsize=218.9k/224128 for region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f. in 4856ms, sequenceid=31451012, compaction requested=true
2011-12-21 22:24:15,267 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.
2011-12-21 22:24:15,267 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memstore flush for test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f., current region memstore size 218.9k
2011-12-21 22:24:15,267 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished snapshotting test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f., commencing wait for mvcc, flushsize=224128
2011-12-21 22:24:15,330 DEBUG org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://sv4r11s38:9100/hbase/test1/43123e2e3fc83ec25fe2a76b4f09077f/.tmp/0a744b85cec5454e873a7c27bf9b3c53 to hdfs://sv4r11s38:9100/hbase/test1/43123e2e3fc83ec25fe2a76b4f09077f/actions/0a744b85cec5454e873a7c27bf9b3c53
2011-12-21 22:24:15,346 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://sv4r11s38:9100/hbase/test1/43123e2e3fc83ec25fe2a76b4f09077f/actions/0a744b85cec5454e873a7c27bf9b3c53, entries=286, sequenceid=31451619, memsize=218.9k, filesize=170.2k
2011-12-21 22:24:15,347 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~218.9k/224128, currentsize=0.0/0 for region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f. in 80ms, sequenceid=31451619, compaction requested=true
2011-12-21 22:24:15,365 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.
2011-12-21 22:24:15,365 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:62023-0x134589d3db03403 Attempting to transition node 43123e2e3fc83ec25fe2a76b4f09077f from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2011-12-21 22:24:15,637 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:62023-0x134589d3db03403 Successfully transitioned node 43123e2e3fc83ec25fe2a76b4f09077f from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2011-12-21 22:24:15,670 DEBUG org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler: set region closed state in zk successfully for region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f. sn name: sv4r25s44,62023,1324494325099
2011-12-21 22:24:15,670 DEBUG org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler: Closed region test1,db6db6b4,1324501004642.43123e2e3fc83ec25fe2a76b4f09077f.
{quote}

Doing a force unassign in the shell fixes it.

A small-ish fix would be to add to RegionAlreadyInTransitionException which state it's in so that we can detect this case and then just retry or open on another region server.

This is critical for online altering to work, but I don't think it's likely to happen in other situations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1241,"This issue is to batch all of the edits and additions we make to ZooKeeper for its use in HBase. Rather than wasting lots of our (and ZK's) time with little edit patches, we will send them batch patches from here when things stabilize.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1193,"I would wait for HBASE-880 which will change the client API
in a way that I think would be easier to create the abstractions
you are looking at.

---
Jim Kellerman, Powerset (Live Search, Microsoft Corporation)
- Hide quoted text -


> -----Original Message-----
> From: edward@udanax.org [mailto:edward@udanax.org] On Behalf Of Edward J.
> Yoon
> Sent: Tuesday, February 03, 2009 1:01 AM
> To: hbase-dev@hadoop.apache.org; hama-dev@incubator.apache.org
> Subject: Hbase client
>
> I would like to have abstraction layers for the HTable and RowResult
> because My project uses the two classes to implement Graph and AdjList
> (or Matrix and Vector). w/o abstraction layers, the codes are becoming
> very messy.
>
> What do you think?
> --
> Best Regards, Edward J. Yoon @ NHN, corp.
> edwardyoon@apache.org
> http://blog.udanax.org
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8445,"when I update a coprocessor jar, then I disable and enable the table with the coprocessor, but the new features in the updated coprocessor jar doesn't make any sense. Follow into the class 'org.apache.hadoop.hbase.coprocessor.CoprocessorHost', I found that there's a coprocessor class loader cache , of which the key is the coprocessor jar path(although the key is a weak reference), so when I disable/enable the table, it got a cached coprocessor class loader from the cache with the jar path, and it didn't try to reload the coprocessor jar from the hdfs. Here I give a patch, in which I add an extra info which is 'FileCheckSum' with the coprocessor class loader cache, if the checksum is changed, try to reload the jar from the hdfs path",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2827,"A client on our beta tier was stuck in this exception loop when we issued a new HMaster after the old one died:

Exception while trying to connect hBase
java.lang.reflect.UndeclaredThrowableException
at $Proxy1.getClusterStatus(Unknown Source)
at org.apache.hadoop.hbase.client.HBaseAdmin.getClusterStatus(HBaseAdmin.java:912)
at org.apache.hadoop.hbase.client.HTable.getCurrentNrHRS(HTable.java:170)
at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:143)
...
at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
at java.lang.Thread.run(Thread.java:619)
Caused by: java.net.SocketTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.18.34.212:60000]
at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:213)
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:406)
at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.setupIOstreams(HBaseClient.java:309)
at org.apache.hadoop.hbase.ipc.HBaseClient.getConnection(HBaseClient.java:856)
at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:724)
at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:252)
... 20 more
12:52:55,863 [pool-4-thread-5182] INFO PersistentUtil:153 - Retry after 1 second...

Looking at the client code, the HConnectionManager does not watch ZK for NodeDeleted & NodeCreated of /hbase/master",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2887,"Refactored the way the HBaseFsck tool works -- it now loads all the info it can find into RAM first, and then looks over the in-memory structures for inconsistencies. It's still a work in progress, but detects more kinds of problems now (eg multiple assignment, etc) and has some very basic functional tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2990,"This is something I've seen here since we upgraded to 0.89 since Gets are now Scans, although I don't currently have any strong evidence that it wasn't happening in 0.20.

I saw this when we began getting alerts on the frontend that some requests were taking more than 8 seconds to complete. Even getting a value could take more than 3 minutes in the shell. The first thing I did was major compacting the table that was slow and the problem went away immediately. Looking in the logs, it seems the compaction transformed 2 files of (total) 550MB into 5.2MB. Looking back in the logs for September, it appears that that table was never major compacted and was slowly growing everyday. Some more grepping around showed that quite a few regions were never major compacted.

I'm still looking at the code, but the issue seems to be that the minor compactions are always happening on all store files more than once per day on certain regions, meaning that the oldest timestamp is always smaller than hbase.hregion.majorcompaction and major compactions are never triggered.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8120,"When working on HBASE-8116, Enis discovered that TestSnapshotCloneIndependence.java was missing in 0.94

We should add the test in 0.94",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8273,"See discussion on dev@ mailing list, entitled 'Does compatibility between versions also mean binary compatibility?'

Synopsis from that thread:

HBASE-5357 ""Use builder pattern in HColumnDescriptor"" changed the
method signatures by changing ""void"" to ""HColumnDescriptor"" so it' not
the same methods anymore.

if you invoke setters
on HColumnDescriptor as you'll get:

java.lang.NoSuchMethodError:
org.apache.hadoop.hbase.HColumnDescriptor.setMaxVersions(I)V",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7893,"For disabling auto major compaction, I configured hbase.hregion.majorcompaction = 0 in the config file and restarted the cluster. In spite of this, major compaction continues to run everyday. Here is the config I set:

<property>
  <name>hbase.hregion.majorcompaction</name>
  <value>0</value>
</property>

What other way can I disable auto major compaction? I expected this config to work. What am I doing wrong here? 

Please advice. Thanks a lot.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8168,"When I used to start Hbase, for the first time Hmaster is running. If i type JPS for second consecutive time, Hmaster is not working. It is showing some thing like the below.

rg.apache.zookeeper.ClientCnxn: Opening socket connection to server ubuntu-1/172.16.78.122:2222. Will not attempt to authenticate using SASL (unknown error)
 2013-03-20 22:04:33,491 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to ubuntu-1/172.16.78.122:2222, initiating session
 2013-03-20 22:04:33,492 INFO org.apache.zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
 2013-03-20 22:04:33,592 WARN org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper exception: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
 2013-03-20 22:04:33,593 INFO org.apache.hadoop.hbase.util.RetryCounter: Sleeping 4000ms before retry #2...
 2013-03-20 22:04:33,760 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server CLBBLR-6196/172.16.78.91:2222. Will not attempt to authenticate using SASL (unknown error)
 2013-03-20 22:04:33,760 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to CLBBLR-6196/172.16.78.91:2222, initiating session
 2013-03-20 22:04:33,761 INFO org.apache.zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
 2013-03-20 22:04:34,840 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server CLBBLR-6176/172.16.78.136:2222. Will not attempt to authenticate using SASL (unknown error)
 2013-03-20 22:04:34,840 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to CLBBLR-6176/172.16.78.136:2222, initiating session
 2013-03-20 22:04:34,841 INFO org.apache.zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
 2013-03-20 22:04:36,026 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server ubuntu-1/172.16.78.122:2222. Will not attempt to authenticate using SASL (unknown error)
 2013-03-20 22:04:36,027 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to ubuntu-1/172.16.78.122:2222, initiating session
 2013-03-20 22:04:36,028 INFO org.apache.zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
 2013-03-20 22:04:36,570 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server CLBBLR-6196/172.16.78.91:2222. Will not attempt to authenticate using SASL (unknown error)
 2013-03-20 22:04:36,571 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to CLBBLR-6196/172.16.78.91:2222, initiating session
 2013-03-20 22:04:36,572 INFO org.apache.zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
 2013-03-20 22:04:37,505 INFO org.apache.zookeeper.ClientCnxn: Op

As discussed.Hbase is starting properly without any issue. When we are trying to list the tables in Hbase or create the table, HMaster is not running.

 
 
 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8110,Get#setMaxVersions() -> Get#getMaxVersions(). Looks like a fat finger mistake.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7985,4 failures of this test in the last 6 builds.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7697,"The user experience for importing data into HBase and getting a dump out of HBase is pretty poor. The existing tools as I understand them include:
- org.apache.hadoop.hbase.mapreduce.Export,
- org.apache.hadoop.hbase.mapreduce.Import,
- org.apache.hadoop.hbase.mapreduce.ImportTsv,
- org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles, and
- org.apache.hadoop.hbase.mapreduce.CopyTable

Each one provides specific features that do not necessarily overlap with the others. For instance, Import and ImportTsv could have most of their logic combined, sharing common driver code and leaving the details of the file-format up to the user to provide via a pluggable mapper. Export and CopyTable both map over a target table; it's only the detail of what they do with the data that is different. Bulk operations via HFiles could be a more common use-case as well, not just a special case of ImportTsv.

The list of [open issues|https://issues.apache.org/jira/issues/?filter=-1&jql=project%20%3D%20HBASE%20AND%20status%20in%20(Open%2C%20%22In%20Progress%22%2C%20Reopened%2C%20%22Patch%20Available%22)%20AND%20text%20~%20%22ImportTsv%22%20ORDER%20BY%20updatedDate%20DESC] against ImportTsv alone indicates users are using the tool, and I certainly advise it for people getting started with a new HBase deployment.

I propose a single interface for getting data into and out of HBase. It would be pluggable, allowing users to override details of their file formats and schemas. We can provide implementations that replicate existing tool behaviors as example modules. These tools are also a reasonable place, IMHO, to include support for creation and loading of snapshots.

I started down the path of a specific tool intended to overcome some of the limitations of ImportTsv and it has since refactored into a more general purpose application. Initial patches forthcoming. Comments strongly encouraged.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7973,"{{HFile.getWriterFactory(Configuration)}} has migrated to {{HFile.getWriterFactoryNoCache(Configuration)}} and {{HFile.WriterFactory.createWriter(...)}} is now protected in {{HFile.WriterFactory}}

As the result, Bigtop integration tests won't compile.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3907,"Add plumbing needed to add various types of per ColumnFamily metrics. And to start with add a bunch per-CF metrics such as:

1) Blocks read, cache hit, avg time of read for a column family.
2) Similar stats for compaction related reads.
3) Stats for meta block reads per CF
4) Bloom Filter stats per CF
etc.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7863,"See HBASE-7843, I figured the patch could be split for easier review.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7860,"We are currently unable to use ACLs without having Kerberos setup.  That is a pain for testing and environments that have other authentication methods that are not Kerberos-centric.

safety valve:
<property>
     <name>hbase.security.authorization</name>
     <value>true</value>
</property>
<property>
     <name>hbase.coprocessor.master.classes</name>
     <value>org.apache.hadoop.hbase.security.access.AccessController</value>
</property>
<property>
     <name>hbase.coprocessor.region.classes</name>
     <value>org.apache.hadoop.hbase.security.token.TokenProvider,org.apache.hadoop.hbase.security.access.AccessController</value>
</property>

[root@cdh4-oozie-1 ~]# hbase shell
hbase(main):001:0> create 't1', 'cf1'

ERROR: org.apache.hadoop.hbase.security.AccessDeniedException: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions for user 'null' (global, action=CREATE)
	at org.apache.hadoop.hbase.security.access.AccessController.requirePermission(AccessController.java:402)
	at org.apache.hadoop.hbase.security.access.AccessController.preCreateTable(AccessController.java:525)
	at org.apache.hadoop.hbase.master.MasterCoprocessorHost.preCreateTable(MasterCoprocessorHost.java:89)
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1056)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1345)

[root@cdh4-oozie-1 ~]# su hbase
bash-4.1$ hbase shell

hbase(main):001:0> create 't1', 'cf1'

ERROR: org.apache.hadoop.hbase.security.AccessDeniedException: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions for user 'null' (global, action=CREATE)
	at org.apache.hadoop.hbase.security.access.AccessController.requirePermission(AccessController.java:402)
	at org.apache.hadoop.hbase.security.access.AccessController.preCreateTable(AccessController.java:525)
	at org.apache.hadoop.hbase.master.MasterCoprocessorHost.preCreateTable(MasterCoprocessorHost.java:89)
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1056)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1345)

It looks like we are relying on Kerberos to tell us who the user is, but since we are not using authentication, we are just passing NULL.  We should be able to just rely on the local fs account.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7762,"When hbase is used to store external table in conjunction with hive, the create table in hive fails with the following error:

{code}
Failed with exception java.lang.RuntimeException: hbase-default.xml file seems to be for and old version of HBase (0.94.2), this version is 0.9
4.5.5.1302010003
{code}

Looking at the classpath I don't see multiple version of hbase jar. Not sure where the 0.94.2 is coming from. It works fine if _hbase.defaults.for.version.skip_ is set to _true_.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7668,"I have a problem that I have been trap weeks, can somebody can help me?
 With full of appreciate
The problem is below:
I have writed about 1G data to the hbase ,then it does not work.
when I set the  hadoop dfsadmin -safemode leave ,then the hbase can use ""list"" command,but when i use ""count 'tableTest' or get ,put and so on ,finaly ,It tell me below锛?
hbase(main):002:0> count 'zsfTest'

ERROR: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region is not online: -ROOT-,,0
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2862)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1768)
        at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1336)

Here is some help for this command:
Courows in a table. This operation may take a LONG
time (Run '$HADOOP_HOME/bin/hadoop jar hbase.jar rowcount' to run a
counting mapreduce job). Current count is shown every 1000 rows by
default. Count interval may be optionally specified. Scan caching
is enabled on count scans by default. Default cache size is 10 rows.
If your rows are small in size, you may want to increase this
parameter. Examples:

 hbase> count 't1'
 hbase> count 't1', INTERVAL => 100000
 hbase> count 't1', CACHE => 1000
 hbase> count 't1', INTERVAL => 10, CACHE => 1000


hbase(main):003:0> ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7650,And it strange that everything seems to work despite this...,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7573,"We have deployed a hbase cluster without kerberos.And for security issue, we want to upgrade it to a hbase cluster with kerberos. After we config hbase cluster with kerberos, we found that the hmaster can not read/write the data in zookeeper the the hbase cluster without kerberos left.

How can we migrate to a hbase cluster with kerberos from  a hbase cluster without kerberos? We want to keep the data in the hbase cluster.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6324,When handling Thrift calls in the regionserver we should not go through RPC to talk to the local regionserver.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7324,"We should always move the logs to .oldlogs instead of deleting them directly. 
The negative effect of this bug may cause data-loss if we enabled replication.
The below code is extracted from SplitLogManager#splitLogDistributed:
{code}
for(Path logDir: logDirs){
      status.setStatus(""Cleaning up log directory..."");
      try {
        if (fs.exists(logDir) && !fs.delete(logDir, false)) {
          LOG.warn(""Unable to delete log src dir. Ignoring. "" + logDir);
        }
      } catch (IOException ioe) {
        FileStatus[] files = fs.listStatus(logDir);
        if (files != null && files.length > 0) {
          LOG.warn(""returning success without actually splitting and "" + 
              ""deleting all the log files in path "" + logDir);
        } else {
          LOG.warn(""Unable to delete log src dir. Ignoring. "" + logDir, ioe);
        }
      }
      tot_mgr_log_split_batch_success.incrementAndGet();
    }
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7313,"ColumnPaginationFilter does not reset count to zero on moving to next row. Hence, if we have already gotten ""limit"" number of columns - the subsequent rows will always return 0 columns.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7261,"Put uses batchMutate to do the actual work.  Put calls startRegionOperation/closeRegionOperation.  BatchMutate does the same.  If the same thread already holds the lock, lock it again doesn't increase the lock count.
However, releasing lock is a little different.  If the lock is already released, IllegalMonitorStateException will throw if it is released again.

There could be other calls. I will look into it more.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5281,"In {{AssignmentManager}}'s {{CreateUnassignedAsyncCallback}}, we have the following condition:

{code}
if (rc != 0) {
        // Thisis resultcode.  If non-zero, need to resubmit.
        LOG.warn(""rc != 0 for "" + path + "" -- retryable connectionloss -- "" +
          ""FIX see http://wiki.apache.org/hadoop/ZooKeeper/FAQ#A2"");
        this.zkw.abort(""Connectionloss writing unassigned at "" + path +
          "", rc="" + rc, null);
        return;
}
{code}

While a similar structure inside {{ExistsUnassignedAsyncCallback}} (which the above is linked to), does not have such a force abort.

Do we really require the abort statement here, or can we make do without?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7144,"In working on HBASE-7131, we noticed that the client still retries the same server in case a NotServingRegionException.  It should relocate the region instead using the same region server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7117,"UnixOperationSystemMXBean compile  error with open JDK 1.6.

UnixOperatingSystemMXBean doesn't existed in open JDK 1.6, open JDK doesn't have any get*FileDescriptorCount method in OperatingSystemMXBean at all, we need to provide a corresponding method for it.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6563,"2012-05-05 00:49:43,265 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker: Caught exception
java.lang.NullPointerException
at org.apache.hadoop.hbase.regionserver.Store.isMajorCompaction(Store.java:938)
at org.apache.hadoop.hbase.regionserver.Store.isMajorCompaction(Store.java:917)
at org.apache.hadoop.hbase.regionserver.HRegion.isMajorCompaction(HRegion.java:3250)
at org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker.chore(HRegionServer.java:1222)
at org.apache.hadoop.hbase.Chore.run(Chore.java:66)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7102,"The culster is started normally. It can work when the I/O pressure is small.

However, when I run a large pressure job (with a lot of threads, each of which writes and reads frequently) about one hour, one of the region server will crash.

I investigated the logs of the HRegionServer, they didn't contain any exception log.

Specifically, the log of the down server ends with some normal log (info level log).

This bug can be replayed easily, and each time the crashed server is different. Even more, the log of the crashed server ends with different information for different experiment.

I really don't know why the process of HRegionServer disappear so weirdly.
If the process is crashed due to my configuration or the enviornment, the log should contain some exception information, right?

So, I doubt the reason is the JVM crashed. But I didn't find any error log in JVM.

How to go on the test to find the reason?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7094,"In previous jira I made locks and leases usable from coprocessors.
I think the same should be a possible for MVCC.
As seens in HBASE-4583 and HBASE-7051 it is not possible anymore to implement atomic operations correctly without some control over MVCC.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6615,"when we close region锛宻torefile.closeReader(true) is invoked, it seems that hbase.rs.evictblocksonclose is ineffective.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2407,"PE --nomapred randomWrite 15

{noformat}
Exception in thread ""13"" java.lang.NullPointerException
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.deleteCachedLocation(HConnectionManager.java:876)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.processBatchOfPuts(HConnectionManager.java:1402)
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:645)
        at org.apache.hadoop.hbase.client.HTable.put(HTable.java:511)
        at org.apache.hadoop.hbase.PerformanceEvaluation$RandomWriteTest.testRow(PerformanceEvaluation.java:940)
        at org.apache.hadoop.hbase.PerformanceEvaluation$Test.testTimed(PerformanceEvaluation.java:781)
        at org.apache.hadoop.hbase.PerformanceEvaluation$Test.test(PerformanceEvaluation.java:766)
        at org.apache.hadoop.hbase.PerformanceEvaluation.runOneClient(PerformanceEvaluation.java:1099)
        at org.apache.hadoop.hbase.PerformanceEvaluation$1.run(PerformanceEvaluation.java:510)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5853,"2012-04-23 12:51:07,474 WARN org.apache.hadoop.ipc.Client: Unexpected error reading responses on connection Thread[IPC Client (1260987126) connection to server121/172.16.40.121:9000 from smp,5,main]
java.lang.RuntimeException: readObject can't find class org.apache.hadoop.hdfs.protocol.HdfsFileStatus
	at org.apache.hadoop.io.ObjectWritable.loadClass(ObjectWritable.java:372)
	at org.apache.hadoop.io.ObjectWritable.readObject(ObjectWritable.java:223)
	at org.apache.hadoop.io.ObjectWritable.readFields(ObjectWritable.java:75)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:832)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:756)
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.hdfs.protocol.HdfsFileStatus not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1151)
	at org.apache.hadoop.io.ObjectWritable.loadClass(ObjectWritable.java:368)
	... 4 more
2012-04-23 12:51:07,797 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: ABORTING region server server124,60020,1335152900476: Replay of HLog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: hbase_cdr,e0072b2b-5e19-431f-bb69-a6427765eac4,1334902272934.8365a7cbf90dd558f297d70224113c8a.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1278)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1162)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1104)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:400)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushOneForGlobalPressure(MemStoreFlusher.java:202)
	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:223)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: Failed on local exception: java.io.IOException: Error reading responses; Host Details : local host is: ""server124/172.16.40.124""; destination host is: """"server121"":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:724)
	at org.apache.hadoop.ipc.Client.call(Client.java:1094)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:193)
	at $Proxy10.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:65)
	at $Proxy10.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1172)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:725)
	at org.apache.hadoop.hbase.regionserver.StoreFile.computeHDFSBlockDistribution(StoreFile.java:449)
	at org.apache.hadoop.hbase.regionserver.StoreFile.open(StoreFile.java:473)
	at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:548)
	at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:595)
	at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:506)
	at org.apache.hadoop.hbase.regionserver.Store.access$100(Store.java:89)
	at org.apache.hadoop.hbase.regionserver.Store$StoreFlusherImpl.flushCache(Store.java:1905)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1254)
	... 6 more
Caused by: java.io.IOException: Error reading responses
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:763)
Caused by: java.lang.RuntimeException: readObject can't find class org.apache.hadoop.hdfs.protocol.HdfsFileStatus
	at org.apache.hadoop.io.ObjectWritable.loadClass(ObjectWritable.java:372)
	at org.apache.hadoop.io.ObjectWritable.readObject(ObjectWritable.java:223)
	at org.apache.hadoop.io.ObjectWritable.readFields(ObjectWritable.java:75)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:832)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:756)
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.hdfs.protocol.HdfsFileStatus not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1151)
	at org.apache.hadoop.io.ObjectWritable.loadClass(ObjectWritable.java:368)
	... 4 more",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5331,"It looks like there's an off by one bug in the OfflineMerger constructor in util.HMerge:

      InternalScanner rootScanner =
        root.getScanner(scan);

      try {
        List<KeyValue> results = new ArrayList<KeyValue>();
        while(rootScanner.next(results)) {
          for(KeyValue kv: results) {
            HRegionInfo info = Writables.getHRegionInfoOrNull(kv.getValue());
            if (info != null) {
              metaRegions.add(info);
            }
          }
        }
      } finally {
	...
      }

That call to InternalScanner.next() in the while condition returns true if there's another result *after* the one it just loaded into the out param.  That is, after it reads the last row into the 'results' collection, it returns false and the loop exits with that last row unread.  It probably wants to be structured more like this:

final InternalScanner metaScanner = meta.getScanner(scan); List<KeyValue> results = Lists.newArrayList();

while (true) {

	boolean hasMore = metaScanner.next(results);

	for (KeyValue kv : results) {
		HRegionInfo hri = Writables.getHRegionInfoOrNull(kv.getValue());
		if (hri != null) {
			regionInfo.add(hri);
		}
	}
					
	if (!hasMore) {
		break;
	}
}

The loop in util.HMerge is scanning ROOT for META regions.  So this bug will only be hit when there is more than one region of META.  Personally, I don't have any installations with more than one META region, and I'm not sure if anyone does, so this might be a moot point.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6699,"We recently had a requirement where we need to log the information about various users who were using non-secure HBase cluster. 
The user level logging is supported as part of security, but in 0.92, 0.94 security related code is separate. This jira is about adding that support in non-secure code.

This feature is already there in trunk, after we merge the security related code.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3801,"When the HMaster crash, the Backup HMaster blocked for waiting the ZK notify.
The Backup HMaster's thread stack is :
""master-hp1:60000"" prio=10 tid=0x00000000484c6800 nid=0x4b56 waiting on condition [0x0000000040209000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hbase.master.HMaster.stallIfBackupMaster(HMaster.java:251)
        at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:279)

   Locked ownable synchronizers:
        - None",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6745,"Currently, memstore flusher always chooses the biggest memstore region to flush.

Suppose I have two tables: one is very actively updated, while the other is periodically updated. The active one has biggest memstore all the time and is flushed all the time.  But the in-active one never gets a chance to flush.  Since it is not flushed, the hlog file can't be archived, although there are lots of hlog files.

If the active table happens to have big updates all the time, the hlog files could cause huge disk space pressure.

Other than the memstore size, periodically flushing regions based on hlog roll time is helpful in hlog archiving/replication.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3918,"This one came up in the case where the data was copied from one cluster to another.  The first cluster was running 0.89.x.  The second 0.90.x.  On startup of 0.90.x, it wanted to verify .META. was in the location -ROOT- said it was at, so it tried connect to the FIRST cluster.  The attempt failed because of mismatched RPCs.  The master then actually aborted.

{code}
org.apache.hadoop.hbase.ipc.HBaseRPC$VersionMismatch: Protocol org.apache.hadoop.hbase.ipc.HRegionInterface version mismatch. (client = 27, server = 24)
at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:424)
at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:393)
at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:444)
at org.apache.hadoop.hbase.ipc.HBaseRPC.waitForProxy(HBaseRPC.java:349)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getHRegionConnection(HConnectionManager.java:965)
at org.apache.hadoop.hbase.catalog.CatalogTracker.getCachedConnection(CatalogTracker.java:386)
at org.apache.hadoop.hbase.catalog.CatalogTracker.getMetaServerConnection(CatalogTracker.java:285)
at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyMetaRegionLocation(CatalogTracker.java:486)
at org.apache.hadoop.hbase.master.HMaster.assignRootAndMeta(HMaster.java:442)
at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:389)
at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:283)
2011-05-23 22:38:07,720 INFO org.apache.hadoop.hbase.master.HMaster: Aborting
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-846,"Looking in log, I see:

{code}
2008-08-26 18:57:23,602 INFO org.apache.hadoop.dfs.DFSClient: org.apache.hadoop.ipc.RemoteException: java.io.IOException: File /hbase/aa0-000-8.u.powerset.com/log_208.76.45.95_1218666613846_60020/hlog.dat.1219776799293 could only be replicated to 0 nodes, instead of 1
        at org.apache.hadoop.dfs.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1145)
        at org.apache.hadoop.dfs.NameNode.addBlock(NameNode.java:300)
        at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:446)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

        at org.apache.hadoop.ipc.Client.call(Client.java:557)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:212)
        at org.apache.hadoop.dfs.$Proxy1.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at org.apache.hadoop.dfs.$Proxy1.addBlock(Unknown Source)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.locateFollowingBlock(DFSClient.java:2335)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2220)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.access$1700(DFSClient.java:1702)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1842)
{code}

... and then:

{code}
2008-08-26 18:57:28,423 WARN org.apache.hadoop.dfs.DFSClient: Error Recovery for block null bad datanode[0]
2008-08-26 18:57:28,424 FATAL org.apache.hadoop.hbase.regionserver.HLog: Could not append. Requesting close of log
java.io.IOException: Could not get block locations. Aborting... 
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2081)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.access$1300(DFSClient.java:1702)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1818)
2008-08-26 18:57:28,424 INFO org.apache.hadoop.hbase.regionserver.LogRoller: Rolling hlog. Number of entries: 127
2008-08-26 18:57:28,424 ERROR org.apache.hadoop.hbase.regionserver.LogRoller: Log rolling failed
java.io.IOException: Could not get block locations. Aborting...
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2081)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.access$1300(DFSClient.java:1702)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1818)
...
{code}
... and so on.

Meantime clients are trying to do updates and getting below:

{code}
2008-08-26 22:49:42,834 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate([B@40e830f1, row => IKwQLMJ3rKRvtAv_ZkQlAk==, {column => page:url, value => '...', column => page:contents, value => '...'}) from 208.76.45.3:51164: error: java.io.IOException: Could not get block locations. Aborting... 
java.io.IOException: Could not get block locations. Aborting...
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2081)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.access$1300(DFSClient.java:1702)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1818)
..
{code}

DFSClient seems horked.

Need to be able to ride out these kind of event.  

Restart is needed.

Test this by filling HDFS.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4888,"A ResultScanner is created in client side, If the user doesn't invoke the ""ResultScanner.close()"" ,it happens that the memory of RegionServer increase rapidly and hold for a long time. Finally,the cluster goes to an abnormal status
 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6100,"Fix the flaky tests in 0.94 branch after #209.  Many test cases like the org.apache.hadoop.hbase.TestLocalHBaseCluster.testLocalHBaseCluster
org.apache.hadoop.hbase.TestZooKeeper.testClientSessionExpired 
org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.testSingleMethod

are failing frequently.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6566,"current, hfile and hlog use the same block replication, some times we can set different block replication, for example in some cluster that not every important, we may set the block replication to 2 for hlog to improve performance.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6511,"When I did HBASE-6334 and HBASE-6379, I only focused on the unit test and didn't think to test the system test as well.

The problem is that those JIRAs introduced a reliance on the miniCluster:
{code}
    // Add a flusher
    ctx.addThread(new RepeatingTestThread(ctx) {
      public void doAnAction() throws Exception {
        util.flush();
      }
    });
{code}

util.flush requires a miniCluster, so doesn't work with a system test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6472,"This is visible in the logs:

{noformat}
2012-07-17 00:00:29,081 INFO org.apache.hadoop.hbase.regionserver.Store: Started compaction of 1 file(s) in cf=m into hdfs://nn:9000/hbase/t1/27889b3c9257e8dff4cddae5eedfd064/.tmp, seqid=1918186410, totalSize=124.7m 
2012-07-17 00:00:29,081 DEBUG org.apache.hadoop.hbase.regionserver.Store: Compacting hdfs://nn:9000/hbase/t1/27889b3c9257e8dff4cddae5eedfd064/m/5478928132066935241, keycount=1435991, bloomtype=NONE, size=124.7m 
2012-07-17 00:00:34,538 INFO org.apache.hadoop.hbase.regionserver.Store: Completed major compaction of 1 file(s), new file=hdfs://nn:9000/hbase/t1/27889b3c9257e8dff4cddae5eedfd064/m/7554093203376406441, size=124.7m; total size for store is 124.7m
{noformat}

I assume the reason is that the Store.java check is reversed:

{code}
      // skip selection algorithm if we don't have enough files
      if (compactSelection.getFilesToCompact().size() < this.minFilesToCompact) {
        if(LOG.isDebugEnabled()) {
          LOG.debug(""Not compacting files because we only have "" +
            compactSelection.getFilesToCompact().size() +
            "" files ready for compaction.  Need "" + this.minFilesToCompact + "" to initiate."");
        }
        compactSelection.emptyFileList();
        return compactSelection;
      }

      // remove bulk import files that request to be excluded from minors
      compactSelection.getFilesToCompact().removeAll(Collections2.filter(
          compactSelection.getFilesToCompact(),
          new Predicate<StoreFile>() {
            public boolean apply(StoreFile input) {
              return input.excludeFromMinorCompaction();
            }
          }));
{code}

The bulk files should be removed first, and +then+ it should check if there are enough files.

There are other places doing the same things, i.e. removing the bulk files and check what needs to be done, so this needs some extra care to get it all right.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6418,"Timestamp updation in Delete flow is not considering all flavors (Delete record, Delete Family, Delete Column) of Delete API. Currently its considering Delete Record only. 
 
org.apache.hadoop.hbase.regionserver.HRegion.prepareDeleteTimestamps(Delete, byte[])

{code}
      for (KeyValue kv: kvs) {
        //  Check if time is LATEST, change to time of most recent addition if so
        //  This is expensive.
        if (kv.isLatestTimestamp() && kv.isDeleteType()) {
{code}

Basically used a wrong API.
kv.isDeleteType() should be KeyValue.isDelete(type);
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6171,HBck related testcases are frequently failing from build #245.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6346,I've only started looking at this but became concerned when a completely quiescent cluster loads up 20% CPU (system+user) once HBase comes up.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6349,"I am trying to compile the latest svn checkout of HBase source 
code using Maven.
This is the error I am facing 

[ERROR] Failed to execute goal on project hbase-server: Could not resolve dependencies for project org.apache.hbase:hbase-server:jar:0.95-SNAPSHOT: Could not find artifact org.apache.hbase:hbase-common:jar:0.95-SNAPSHOT in cloudbees netty (http://repository-netty.forge.cloudbees.com/snapshot/)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6339,"I noticed that right now, under a bulkLoadHFiles call to an RS, we grab the HRegion write lock as soon as we determine that it is a multi-family bulk load we'll be attempting. The file copy from the caller's source FS is done after holding the lock.

This doesn't seem right. For instance, we had a recent use-case where the bulk load running cluster is a separate HDFS instance/cluster than the one that runs HBase and the transfers between these FSes can get slower than an intra-cluster transfer. Hence I think we should begin to hold the write lock only after we've got a successful destinationFS copy of the requested file, and thereby allow more write throughput to pass.

Does this sound reasonable to do?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6298,"Despite regions being unbalanced, the load balancer takes no action. On my cluster the least-loaded regionserver has 33 regions and the most-loaded regionserver has 44 regions. My cluster has 1084 regions and 29 servers. It might be relevant that a 30th server used to belong to the cluster but was removed.

The master log has some strange entries when the balancer runs. The attached log file was generated by restarting the master, then running ""balancer"" in the shell.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6304,"mvn test -Dhadoop.profile=2.0 -Dtest=TestPBOnWritrableRpc

{code}
java.lang.NoSuchMethodError: org.apache.hadoop.net.NetUtils.getInputStream(Ljava/net/S
ocket;)Ljava/io/InputStream;"" type=""java.io.IOException"">java.io.IOException: java.lang.NoSuchMethodError:
 org.apache.hadoop.net.NetUtils.getInputStream(Ljava/net/Socket;)Ljava/io/InputStream;
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine.getProxy(WritableRpcEngine.java:211)
        at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:336)
        at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:313)
        at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:365)
        at org.apache.hadoop.hbase.ipc.HBaseRPC.waitForProxy(HBaseRPC.java:237)
        at org.apache.hadoop.hbase.ipc.TestPBOnWritableRpc.testCallsInternal(TestPBOnWritableRpc.java:98)
        at org.apache.hadoop.hbase.ipc.TestPBOnWritableRpc.testCalls(TestPBOnWritableRpc.java:80)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:62)
Caused by: java.lang.NoSuchMethodError: org.apache.hadoop.net.NetUtils.getInputStream(Ljava/net/Socket;)Lj
ava/io/InputStream;
        at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.setupIOstreams(HBaseClient.java:676)
        at org.apache.hadoop.hbase.ipc.HBaseClient.getConnection(HBaseClient.java:1286)
        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:1138)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:152)
        at $Proxy10.getProtocolVersion(Unknown Source)
        at org.apache.hadoop.hbase.ipc.WritableRpcEngine.getProxy(WritableRpcEngine.java:196)
        ... 15 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5632,"The first cut of HBASE-5128 failed fast and tried to avoid cases handling partial recovery failures.  We can improve this.

- collecting faults and recovering from them
- Handling RejectedExectionException exceptions when using executor.execute.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6208,"2012-06-14 15:06:54,902 WARN org.apache.hadoop.hbase.regionserver.wal.HLog: IPC Server handler 188 on 60020 took 8872 ms appending an edit to hlog; editcount=15730, len~=2.2k

we have many this log , and the write request will be blocked .  i find no solution.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6172,TestHRegion.java for eg does not run from #245. There are few more testcases that does not run.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5988,"we use thrift to access the hbase. but The problems we for a long time.
the hbase would be blocked writing for a few seconds. we check the log but find nothing.
eachtime, it will effect 48 or 96 request.

hbase have 13 regionserver, 3 zookeeper and 3 masterserver
hadoop have 16 datanodeserver.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4559,"TestAvroServer is a beefy test, spins up a mini cluster, does a large series of manipulations and then spins it down. It take about 2 mins to run on a local machine, which on the high side for a 'unit' test. 

This is part of the implentation discussed in http://search-hadoop.com/m/L9OzBNEOJK1",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5951,"FilterList listOfFilters = new FilterList (FilterList.Operator.MUST_PASS_ALL);
FilterList listOfFilters1 = new FilterList (FilterList.Operator.MUST_PASS_ALL);
FilterList listOfFilters2 = new FilterList (FilterList.Operator.MUST_PASS_ALL);

SingleColumnValueFilter SingleFilter1 = new
SingleColumnValueFilter(Bytes.toBytes(""cf""),
Bytes.toBytes(""country""), CompareOp.EQUAL,
Bytes.toBytes(""USA""));
listOfFilters.addFilter(SingleFilter1);

ValueFilter VF1= new ValueFilter (CompareOp.EQUAL, 
new SubstringComparator(""ABC""));
ColumnPrefixFilter CF1= new ColumnPrefixFilter(Bytes.toBytes(""name""));
listOfFilters1.addFilter(CF1);
listOfFilters1.addFilter(VF1);
listOfFilters.addFilter(listOfFilters1);

ValueFilter VF2= new ValueFilter (CompareOp.EQUAL, 
new SubstringComparator(""ED""));
ColumnPrefixFilter CF2= new ColumnPrefixFilter (Bytes.toBytes(""CRS""));
listOfFilters2.addFilter(CF2);
listOfFilters2.addFilter(VF2);
listOfFilters.addFilter(listOfFilters2);

When i do a combibation of SingleFilter1 and listOfFilters1
 the result is correct, same way the combination of 
SingleFilter1 and listOfFilters2 is returing correct result.
But when all the three is combined im not getting any result..

Is it the problem with multiple ColumnPrefixFilter??? 
Value ""ABC"" exist in name.0 and value ""ED"" exist in CRS.0 and it is in
the same row under same Column Family.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5917,"i want to custom filter hbase.
i created jar file by eclipse, copy to sever and in file hbase-env.xml i set ""export HBASE_CLASSPATH=/cldo/hadoop/conf;/cldo/customfilter.jar

but when start have error 

/cldo/hbase/bin/../conf/hbase-env.sh: line 29: /cldo/customfilter.jar: cannot execute binary file
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/filter/FilterBase
at java.lang.ClassLoader.defineClass1(Native Method)
at java.lang.ClassLoader.defineClassCond(ClassLoader.java:631)
at java.lang.ClassLoader.defineClass(ClassLoader.java:615)
at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)
at java.net.URLClassLoader.access$000(URLClassLoader.java:58)
at java.net.URLClassLoader$1.run(URLClassLoader.java:197)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:190)

thank
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5501,"In a live cluster, we do the following step
1.kill the master;
1.start the master, and master is initializing锛?3.master complete splitLog
4.kill the META server
5.master start assigning ROOT and META
6.Now meta region data will loss since we may assign meta region before SSH finish split log for dead META server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5424,"We meet NPE when call getRegionInfo() in testing environment.
Exception in thread ""main"" java.lang.NullPointerException
at org.apache.hadoop.hbase.util.Writables.getWritable(Writables.java:75)
at org.apache.hadoop.hbase.util.Writables.getHRegionInfo(Writables.java:119)
at org.apache.hadoop.hbase.client.HTable$2.processRow(HTable.java:395)
at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:190)
at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:95)
at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:73)
at org.apache.hadoop.hbase.client.HTable.getRegionsInfo(HTable.java:418)

This NPE also make the table.jsp can't show the region information of this table.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5429,"HCatStorageHandler was moved for the ""storageHandler"" package to ""mapreduce"". For some reason it wasn't move but copied. I need to remove this as well as the HCatStorageHandlerImpl which I believe is no longer used. There is one class which depends on this instead of the mapreduce one. I need to fix that as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5381,"Currently the region server will flush mem store of the region based on the limitation of the global mem store flush size and global low water mark. However, It will cause the hot tables, which serve more write traffic, to flush too frequently even though the overall mem store heap usage is quite low. Too frequently flush would also contribute to too many minor compactions. 
So if we can make memstore.flush.size as a table level configuration, it would be more flexible to config different tables with different desired mem store flush size based on compaction ratio, recovery time and put ops.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2628,"getRowOrBefore, if I point it a table other than .META., does the below....

{code}
java.io.IOException: java.io.IOException: java.lang.StackOverflowError
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:887)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:877)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1734)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
Caused by: java.lang.StackOverflowError
        at org.apache.hadoop.hbase.KeyValue$KeyComparator.compare(KeyValue.java:1776)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:148)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.seekBefore(HalfHFileReader.java:150)
{code}

Here is some code to do it:

{code}
hbase(main):018:0> t = HTable.new(@configuration, ""TestTable"")    
hbase(main):018:0> r = t.getRowOrBefore(Bytes.toString(''), Bytes.toString('info'))     
... spew....
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5126,"[Notice this in 89 branch. Possibly an issue in trunk also.]

A test which does a columnPrefixFilter(""tag0"") AND columnPrefixFilter(""tag1"") should return 0 kvs; instead it returns kvs with prefix ""tag0"".

{code}
table = HTable.new(conf, tableName)

put = Put.new(Bytes.toBytes(""row""))
put.add(cf1name, Bytes.toBytes(""tag0""), Bytes.toBytes(""value0""))
put.add(cf1name, Bytes.toBytes(""tag1""), Bytes.toBytes(""value1""))
put.add(cf1name, Bytes.toBytes(""tag2""), Bytes.toBytes(""value2""))

table.put(put)

# Test for AND Two Column Prefix Filters                                                                                                                                                   
filter1 = ColumnPrefixFilter.new(Bytes.toBytes(""tag0""));
filter2 = ColumnPrefixFilter.new(Bytes.toBytes(""tag2""));

filters = FilterList.new(FilterList::Operator::MUST_PASS_ALL);
filters.addFilter(filter1);
filters.addFilter(filter2);

get = Get.new(Bytes.toBytes(""row""))
get.setFilter(filters)
get.setMaxVersions();
keyValues = table.get(get).raw()

keyValues.each do |keyValue|
  puts ""Key=#{Bytes.toStringBinary(keyValue.getQualifier())}; Value=#{Bytes.toStringBinary(keyValue.getValue())}; Timestamp=#{keyValue.getTimestamp()}"" 
end
{code}

outputs:

{code}
Key=tag0; Value=value0; Timestamp=1325719223523
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5095,"When I put one row into Hbase Table, it throws IOException.(NullPointerException). I could make sure that I have add values into the Row. But when it runs at table.put(row). The exception comes out.

Here is part of my code.

public HbaseInterface() {
        HBaseConfiguration config = new HBaseConfiguration();
        try {
            config.set(""hbase.zookeeper.quorum"", ""127.0.0.1"");
            config.set(""hbase.zookeeper.property.clientPort"", ""2222"");
            table = new HTable(config, urlstable);
        } catch (Exception ex) {
            if (LOGGER.isErrorEnabled()) {
                LOGGER.error(""error"", ex);
            }
        }
    }

public boolean put(String url, String category) {
        
        Put row = new Put(Bytes.toBytes(url));
        row.add(Bytes.toBytes(lifetime), null, Bytes.toBytes(""99999""));
        row.add(Bytes.toBytes(categories), null, Bytes.toBytes(category));
        row.add(Bytes.toBytes(digest), null, Bytes.toBytes(m_encry.encrypt(url)));
        try {
            table.put(row);
        } catch (Exception ex) {
            if (LOGGER.isErrorEnabled()) {
                LOGGER.error(""hbase put error :"", ex);
            }
            return false;
        }
        return true;
    }

This is the table description.
{NAME => 'urls', FAMILIES => [{NAME => 'categories', COMPRESSION => 'N true    
 ONE', VERSIONS => '3', TTL => '2147483647', BLOCKSIZE => '65536', IN_M         
 EMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'digest', COMPRESSIO         
 N => 'NONE', VERSIONS => '3', TTL => '2147483647', BLOCKSIZE => '65536         
 ', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'lifetime', C         
 OMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647', BLOCKSIZE          
 => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}]}   
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5037,"same as https://issues.apache.org/jira/browse/HBASE-2849
thrift log:
org.apache.zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x1343b1b1fbf0005, likely server has closed socket, closing socket connection and attempting reconnect
hbase log:
2011-12-15 14:58:03,793 INFO org.apache.zookeeper.server.NIOServerCnxn: Accepted socket connection from /127.0.0.1:19035
2011-12-15 14:58:03,793 INFO org.apache.zookeeper.server.NIOServerCnxn: Refusing session request for client /127.0.0.1:19035 as it has seen zxid 0x169 our last zxid is 0x15c client must try another server
2011-12-15 14:58:03,793 INFO org.apache.zookeeper.server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:19035 (no session established for client)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4901,"I create a class named HBaseInterfaceHolder who will hold ThreadLocal<HBaseInterface> hBaseInterfaceHolder. But when the program run at the line (HBaseConfiguration config = new HBaseConfiguration();), it throws a java.io.IOException:config()
at 
org.apache.hadoop.conf.Configuration.<init>(Configuration.java:211)
org.apache.hadoop.conf.Configuration.<init>(Configuration.java:198)
org.apache.hadoop.hbase.HBaseConfiguration.<init>(Configuration.java:33)
com.netentsec.niudian.phoenix.web2.hbaseinterface.HBaseInterfaceHolder$1.initialValue(HBaseInterfaceHolder.java:24) this line is my own program which is the content in previous bracket.

I search online to find out the reason. But no forum related it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4546,"HBase is still depending on 3.3.1.  There many critical bug fixes in 3.3.2 and two more critical fixes in 3.3.3.

We recently tripped on ZOOKEEPER-822 which was fixed in 3.3.2.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4355,"This unit test has been failing on my machine with the following error.

testTableWithStringName(org.apache.hadoop.hbase.client.TestHTablePool$TestHTableThreadLocalPool): Cluster already running at /hbase-core-trunk/target/test-data/2e41efb9-7b96-4ab3-abec-c58f467b220c/af01017e-ee3c-46fc-b908-078a3a4e8b52/bfd8e9b4-66da-4322-96bd-6db4564d8f41/d9a97e3d-8ffb-4945-a71e-d059e3bc7274/6cdf0b73-b9a0-45f4-856d-53cd02ecebce/34c41612-9311-4199-9902-cf30a9cb7b9d/33e7bfd5-2519-4349-9a44-d05000e00526/dbc60fd9-756d-4263-9ed1-bbff69ec7a80/0e1bde7e-c966-4c3e-a01c-50ded9cb166b/415e8d51-46f2-4d50-879a-870298a9e1f8/fb165bb9-7d6c-4cf8-970a-e281b9818e97

It looks like TestHTablePool uses nested classes TestHTableReusablePool and TestHTableThreadLocalPool. Both classes could be instantiated by junit framework in mulitple threads fashion. Both classes call HBaseTestingUtilility.startMiniCluster. HBaseTestingUtilility.isRunningCluster throws this exception.


Is the understanding about junit framework correctly? I don't know why others haven't got such error.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4502,"I have set up hadoop 0.20.2 as Pseduo distributed. This is running fine.

And trying to integrate hbase-0.90.4/3 with hadoop. But while starting, getting following error at Master log.


2011-09-27 15:01:16,295 INFO org.apache.zookeeper.server.NIOServerCnxn: Client attempting to establish new session at /127.0.0.1:37643
2011-09-27 15:01:16,296 INFO org.apache.zookeeper.server.NIOServerCnxn: Established session 0x132ace7f4fa0002 with negotiated timeout 40000 for client /127.0.0.1:37643
2011-09-27 15:01:16,296 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x132ace7f4fa0002, negotiated timeout = 40000
2011-09-27 15:01:16,468 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
java.io.IOException: Call to localhost/127.0.0.1:8020 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1139)
	at org.apache.hadoop.ipc.Client.call(Client.java:1107)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:226)
	at $Proxy6.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:398)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:384)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:111)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:213)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:180)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:89)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1514)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:1548)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1530)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:228)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:183)
	at org.apache.hadoop.hbase.util.FSUtils.getRootDir(FSUtils.java:364)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:81)
	at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:346)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:282)
	at org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster.run(HMasterCommandLine.java:193)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:375)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:812)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:720)
2011-09-27 15:01:16,470 INFO org.apache.hadoop.hbase.master.HMaster: Aborting
2011-09-27 15:01:16,470 DEBUG org.apache.hadoop.hbase.master.HMaster: Stopping service threads
2011-09-27 15:01:16,470 INFO org.apache.hadoop.ipc.HBaseServer: Stopping server on 51567



hbase-site.xml file structure is as follows....

<configuration>
<property>
    <name>hbase.rootdir</name>
    <value>hdfs://localhost:8020/hbase</value>
  </property>

<property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>


Please help me to fix this error............ 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4372,"Currently, IS_SECURE_HADOOP is set to true if UserGroupInformation has a method isSecurityEnabled. It should be set to true only if security is turned on as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2158,A Ryan Rawson suggestion.  See HBASE-2149 for more context.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4332,"On hbase 0.90.3, describing a table which is disabled, on hbase shell shows the table as being ENABLED i.e.

{noformat}
hbase> create 't1','c1'
hbase> describe 't1'
       DESCRIPTION ENABLED   
hbase> drop 't1'
       ERROR: Table t1 is enabled. Disable it first.'
hbase> disable 't1'
hbase> describe 't1'
       DESCRIPTION ENABLED   
hbase> drop 't1'
Table dropped

{noformat}

The describe option can be useful to know if the table is disabled/enabled. I looked through jiras to find if an issue already exists but could not find one. Please mark it as duplicate if one already exists.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4111,"    We found a strange problem in our read test. 

    It is a 5 nodes cluster.Four of our 5 regionservers set ""hfile.block.cache.size""=0.4, one of them is 0.1(we call it node A). When we random read from a 2TB data table we found node A's network reached 100MB, and others are less than 10MB. So the read speed is low.

    We set node A's ""hfile.block.cache.size""=0.2, then all the nodes's network are 10MB, that's right. To find why is this we debug with btrace and find ""readBlock"" in HFile.Reader become abnormal.We know hbase read a block which is 64 KB from disks and put it into blockcache. But when we set ""hfile.block.cache.size""=0.1, it is not 64KB, it is 5~6MB one time after about 1 minute we restart hbase.

    Why not 64 KB? The btrace code and results are in the attachments. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4042,"There's a couple of issues going on here.  Its taken me a while to figure whats up and am still not done.  Here's what I found so far:

+ The last test testWorkerAbort has been hanging because there is no one to process the log split the final assert is expecting completed; we've killed the lone RS that this test put up.  This test passes most of the time for me locally; luck has the log processed before the RS with its splitLogWorker processes the log before we go out.  Putting up a new RS with a splitLogWorker makes this test pass for me most of the time now but I've seen an error in testing so need to dig in still.
+ The first test, testThreeRSAbort is a good test.  Its turning up a issue that has nothing to do w/ log splitting.  If .META. is on one of the RSs that goes down -- we launch w/ 6 RSs -- then we get stuck in catalog tracker waiting on meta to be up again (though it deploys fin -- we don't notice its deploy in master).  I'm on this one at mo. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4018,"Currently, block caches are limited by heap size, which is limited by garbage collection times in Java.

We can get around this by using memcached w/JNI as a secondary block cache. This should be faster than the linux file system's caching, and allow us to very quickly gain access to a high quality slab allocated cache.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3977,An unintended change of HBASE-3873 (sorry about that),,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2290,We need to add maven made jars to bin/hbase CLASSPATH,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3822,"The regionserver is not able to exit because the rs thread is stuck here



""regionserver60020"" prio=10 tid=0x00002ab2b039e000 nid=0x760a waiting on condition [0x000000004365e000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hbase.util.Threads.sleep(Threads.java:126)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.waitOnAllRegionsToClose(HRegionServer.java:736)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:689)
        at java.lang.Thread.run(Thread.java:619)


===

In CloseRegionHandler.process() we do not call removeFromOnlineRegions() if there is an exception. (In this case I suspect there was a log-rolling exception because of another issue)

    // Close the region
    try {
      // TODO: If we need to keep updating CLOSING stamp to prevent against
      // a timeout if this is long-running, need to spin up a thread?
      if (region.close(abort) == null) {
        // This region got closed.  Most likely due to a split. So instead
        // of doing the setClosedState() below, let's just ignore and continue.
        // The split message will clean up the master state.
        LOG.warn(""Can't close region: was already closed during close(): "" +
          regionInfo.getRegionNameAsString());
        return;
      }
    } catch (IOException e) {
      LOG.error(""Unrecoverable exception while closing region "" +
        regionInfo.getRegionNameAsString() + "", still finishing close"", e);
    }

    this.rsServices.removeFromOnlineRegions(regionInfo.getEncodedName());


===

I think we set the closing flag on the region, it won't be taking any more requests, it is as good as offline.

Either we should refine the check in waitOnAllRegionsToClose() or CloseRegionHandler.process() should remove the region from online-regions set.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3824,"When replaying a large log file, mestore flushes can happen. But there is no Progressible report being sent during memstore flushes. That can lead to master timing out the region server during region open.

===
Another related issue and Jonathan's response

> So if a region server that is handed a region for opening and has done part of
> the work ... it has created some HFiles (because the logs were so huge that
> the mestore got flushed while the logs were being replayed) ... and then it is
> asked to give up because the master thought the region server was taking
> too long to open the region.
> 
> When the region server gives up on the region then will it make sure that it
> removes all the HFiles it had created for that region?


Will need to check the code, but would it matter?  One issue is whether it cleans up after itself (I'm guessing not).  Another issue is whether the replay is idempotent (duplicate KVs across files shouldn't matter in most cases).

===

2011-04-25 09:11:36,844 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_RS_OPEN_REGION
java.lang.NullPointerException
at org.apache.hadoop.hbase.util.Writables.getWritable(Writables.java:75)
at org.apache.hadoop.hbase.executor.RegionTransitionData.fromBytes(RegionTransitionData.java:198)
at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNode(ZKAssign.java:672)
at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNodeOpened(ZKAssign.java:621)
at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:168)
at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:619)

byte [] existingBytes =
ZKUtil.getDataNoWatch(zkw, node, stat);
RegionTransitionData existingData =
RegionTransitionData.fromBytes(existingBytes);

existingBytes can be null. have to return -1 if null.


===

master logs

2011-04-25 05:24:03,250 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Creating writer path=hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/recovered.edits/0000000057528037047 region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:09:19,246 INFO org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Closed path hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/recovered.edits/0000000057528037047 (wrote 4342690 edits in 46904ms)
2011-04-25 09:09:26,134 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x32f7bb74e8a0000 Creating (or updating) unassigned node for e7a478b4bd164525052f1dedb832de0a with OFFLINE state
2011-04-25 09:09:26,136 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. so generated a random one; hri=realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a., src=, dest=pumahbase107.snc5.facebook.com,60020,1303450731227; 70 (online=70, exclude=null) available servers
2011-04-25 09:09:26,136 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. to pumahbase107.snc5.facebook.com,60020,1303450731227
2011-04-25 09:09:26,139 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase107.snc5.facebook.com,60020,1303450731227, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:09:44,045 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase107.snc5.facebook.com,60020,1303450731227, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:09:59,050 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase107.snc5.facebook.com,60020,1303450731227, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:10:14,054 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase107.snc5.facebook.com,60020,1303450731227, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:10:29,055 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase107.snc5.facebook.com,60020,1303450731227, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:10:44,060 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase107.snc5.facebook.com,60020,1303450731227, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:10:59,062 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase107.snc5.facebook.com,60020,1303450731227, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:10:59,388 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase107.snc5.facebook.com,60020,1303450731227, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:11:33,411 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out: realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. state=OPENING, ts=1303747859386
2011-04-25 09:11:33,411 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been OPENING for too long, reassigning region=realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a.
2011-04-25 09:11:33,412 INFO org.apache.hadoop.hbase.master.AssignmentManager: Successfully transitioned region=realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. into OFFLINE and forcing a new assignment
2011-04-25 09:11:33,412 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. so generated a random one; hri=realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a., src=, dest=pumahbase150.snc5.facebook.com,60020,1303450731207; 70 (online=70, exclude=null) available servers
2011-04-25 09:11:33,413 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. to pumahbase150.snc5.facebook.com,60020,1303450731207
2011-04-25 09:11:33,414 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=M_ZK_REGION_OFFLINE, server=pumahbase162.snc5.facebook.com:60000, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:11:33,416 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase150.snc5.facebook.com,60020,1303450731207, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:11:33,825 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=pumahbase150.snc5.facebook.com,60020,1303450731207, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:11:36,804 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=pumahbase150.snc5.facebook.com,60020,1303450731207, region=e7a478b4bd164525052f1dedb832de0a
2011-04-25 09:11:36,804 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for e7a478b4bd164525052f1dedb832de0a; deleting unassigned node
2011-04-25 09:11:36,804 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x32f7bb74e8a0000 Deleting existing unassigned node for e7a478b4bd164525052f1dedb832de0a that is in expected state RS_ZK_REGION_OPENED
2011-04-25 09:11:36,805 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x32f7bb74e8a0000 Successfully deleted unassigned node for region e7a478b4bd164525052f1dedb832de0a in expected state RS_ZK_REGION_OPENED
2011-04-25 09:11:36,805 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Opened region realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. on pumahbase150.snc5.facebook.com,60020,1303450731207


===

region server log

2011-04-25 09:09:26,136 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received request to open region: realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a.
2011-04-25 09:09:26,136 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a.
2011-04-25 09:09:26,136 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Attempting to transition node e7a478b4bd164525052f1dedb832de0a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2011-04-25 09:09:26,138 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Successfully transitioned node e7a478b4bd164525052f1dedb832de0a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2011-04-25 09:09:26,139 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region: REGION => {NAME => 'realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a.', STARTKEY => 'afffffbe', ENDKEY => 'b040ebdbf81a3750f0eaa71842ff09dagr.insomnia li 294576344998', ENCODED => e7a478b4bd164525052f1dedb832de0a, TABLE => {{NAME => 'realtime_domain_imps_urls', FAMILIES => [{NAME => 'COUNTERS_0', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'LZO', VERSIONS => '1', TTL => '2147483647', BLOCKSIZE => '16384', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'COUNTERS_3600', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'LZO', VERSIONS => '1', TTL => '172800', BLOCKSIZE => '16384', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'COUNTERS_86400', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'LZO', VERSIONS => '1', TTL => '2592000', BLOCKSIZE => '16384', IN_MEMORY => 'false', BLOCKCACHE => 'true'}]}}
2011-04-25 09:09:26,140 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Instantiated realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a.
2011-04-25 09:09:26,140 INFO org.apache.hadoop.hbase.regionserver.logger.HRegionLogger: HRegionLogger for region realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a., category nectar_titan_hbase_updates
2011-04-25 09:09:26,190 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_0/87cf11f68701404b862d631ba3d20213, isReference=false, isBulkLoadResult=false, seqid=58137870275, majorCompaction=false
2011-04-25 09:09:28,572 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_0/c58d9a33653a4e5e966c426b33a57598, isReference=false, isBulkLoadResult=false, seqid=57847795298, majorCompaction=true
2011-04-25 09:09:28,796 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_3600/1bc513e915b741d59d4f113c273e67d4, isReference=false, isBulkLoadResult=false, seqid=58137870275, majorCompaction=false
2011-04-25 09:09:28,826 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_3600/5a50b17f3ad045368229680414987ae7, isReference=false, isBulkLoadResult=false, seqid=57847795298, majorCompaction=true
2011-04-25 09:09:28,850 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_86400/23648dce8d4243c5b804c0e766f5a235, isReference=false, isBulkLoadResult=false, seqid=58137870275, majorCompaction=false
2011-04-25 09:09:29,016 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_86400/d6820d86715049c087fa5c3f4355f2fc, isReference=false, isBulkLoadResult=false, seqid=57847795298, majorCompaction=true
2011-04-25 09:09:29,017 INFO org.apache.hadoop.hbase.regionserver.HRegion: Replaying edits from hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/recovered.edits/0000000057528037047; minSequenceid=58137870275
2011-04-25 09:09:44,041 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Attempting to transition node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:09:44,044 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Successfully transitioned node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:09:59,046 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Attempting to transition node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:09:59,050 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Successfully transitioned node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:10:14,050 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Attempting to transition node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING

832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:10:29,055 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Successfully transitioned node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:10:44,056 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Attempting to transition node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:10:44,059 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Successfully transitioned node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:10:59,057 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Attempting to transition node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:10:59,062 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Successfully transitioned node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:10:59,154 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memstore flush for realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a., current region memstore size 18.9m; wal is null, using passed sequenceid=58140219688
2011-04-25 09:10:59,277 INFO org.apache.hadoop.hbase.regionserver.Store: Flushed , sequenceid=58140219688, memsize=12.4m, into tmp file hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/.tmp/a1df4f1ac37a4c7fbf4067f3bcff49a5
2011-04-25 09:10:59,312 INFO org.apache.hadoop.hbase.regionserver.Store: Flushed , sequenceid=58140219688, memsize=3.2m, into tmp file hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/.tmp/eefd1540ca644f06b251201894ef5dd8
2011-04-25 09:10:59,357 INFO org.apache.hadoop.hbase.regionserver.Store: Flushed , sequenceid=58140219688, memsize=3.2m, into tmp file hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/.tmp/83c87fcdbf7147ceac873a1e97e2990f
2011-04-25 09:10:59,357 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/.tmp/a1df4f1ac37a4c7fbf4067f3bcff49a5 to hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_0/a1df4f1ac37a4c7fbf4067f3bcff49a5
2011-04-25 09:10:59,372 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_0/a1df4f1ac37a4c7fbf4067f3bcff49a5, entries=45626, sequenceid=58140219688, filesize=549.1k
2011-04-25 09:10:59,372 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/.tmp/eefd1540ca644f06b251201894ef5dd8 to hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_3600/eefd1540ca644f06b251201894ef5dd8
2011-04-25 09:10:59,375 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_3600/eefd1540ca644f06b251201894ef5dd8, entries=11411, sequenceid=58140219688, filesize=167.9k
2011-04-25 09:10:59,375 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/.tmp/83c87fcdbf7147ceac873a1e97e2990f to hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_86400/83c87fcdbf7147ceac873a1e97e2990f
2011-04-25 09:10:59,378 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/COUNTERS_86400/83c87fcdbf7147ceac873a1e97e2990f, entries=11404, sequenceid=58140219688, filesize=161.5k
2011-04-25 09:10:59,378 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~18.9m for region realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. in 224ms, sequenceid=58140219688, compaction requested=true; wal=null
2011-04-25 09:10:59,385 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Deleted recovered.edits file=hdfs://pumahbase002-snc5-dfs.data.facebook.com:9000/PUMAHBASE002-SNC5-HBASE/realtime_domain_imps_urls/e7a478b4bd164525052f1dedb832de0a/recovered.edits/0000000057528037047
2011-04-25 09:10:59,385 INFO org.apache.hadoop.hbase.regionserver.HRegion: Onlined realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a.; next sequenceid=58140219689
2011-04-25 09:10:59,385 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Attempting to transition node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:10:59,388 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Successfully transitioned node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2011-04-25 09:11:36,843 INFO org.apache.hadoop.hbase.catalog.MetaEditor: Updated row realtime_domain_imps_urls,afffffbe,1295556905482.e7a478b4bd164525052f1dedb832de0a. in region .META.,,1 with server=pumahbase107.snc5.facebook.com:60020, startcode=1303450731227
2011-04-25 09:11:36,843 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x22f7bb74e8e000a Attempting to transition node e7a478b4bd164525052f1dedb832de0a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
java.lang.NullPointerException

===",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1992,"Here is our fail reporting a split.  Lets make sure that this kinda event is not dropped as part of master rewrite
{code}

2009-11-17 20:57:51,943 INFO org.apache.hadoop.hbase.regionserver.HRegion: region dds-test,k\x12\xB3\xA6\x02\xE9H\xDC,1258520203767/459329844 available; sequence id is 25187748
2009-11-17 20:57:51,944 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed dds-test,k\x12\xB3\xA6\x02\xE9H\xDC,1258520203767
2009-11-17 20:57:52,007 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: region split, META updated, and report to master all successful. Old region=REGION => {NAME => 'dds-test,j\xFD\xD7e\x8B\x1
0\xFC\xFE,1258446041463', STARTKEY => 'j\xFD\xD7e\x8B\x10\xFC\xFE', ENDKEY => 'k\x27q6\xCA\xC8\x15,', ENCODED => 1069248233, OFFLINE => true, SPLIT => true, TABLE => {{NAME => 'dds-test', FAMILIES => [{NAME =
> 'data', COMPRESSION => 'NONE', VERSIONS => '1', TTL => '2147483647', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'meta', COMPRESSION => 'NONE', VERSIONS => '1', TTL => '21474
83647', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}]}}, new regions: dds-test,j\xFD\xD7e\x8B\x10\xFC\xFE,1258520203767, dds-test,k\x12\xB3\xA6\x02\xE9H\xDC,1258520203767. Split took 1min
s, 8sec
2009-11-17 20:57:52,007 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region dds-test,\x7C\x98\xB4\x91\xE7L\xDC\xC7,1258436623505
2009-11-17 20:57:54,779 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: MSG_REGION_OPEN: dds-test,k\x12\xB3\xA6\x02\xE9H\xDC,1258520203767
2009-11-17 20:57:54,780 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_OPEN: dds-test,k\x12\xB3\xA6\x02\xE9H\xDC,1258520203767
2009-11-17 20:57:54,864 INFO org.apache.hadoop.hbase.regionserver.HRegion: region dds-test,k\x12\xB3\xA6\x02\xE9H\xDC,1258520203767/459329844 available; sequence id is 25187748
2009-11-17 20:58:16,166 WARN org.apache.hadoop.hbase.regionserver.HLog: IPC Server handler 6 on 60020 took 2967ms appending an edit to hlog; editcount=58
2009-11-17 20:58:16,166 WARN org.apache.hadoop.hbase.regionserver.HLog: regionserver/10.10.0.180:60020.logFlusher took 2854ms optional sync'ing hlog; editcount=59
2009-11-17 20:58:34,340 WARN org.apache.hadoop.hbase.regionserver.HLog: IPC Server handler 6 on 60020 took 7615ms appending an edit to hlog; editcount=820
2009-11-17 20:58:34,340 WARN org.apache.hadoop.hbase.regionserver.HLog: regionserver/10.10.0.180:60020.logFlusher took 1019ms optional sync'ing hlog; editcount=821
2009-11-17 21:00:19,366 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region dds-test,\x7C\x98\xB4\x91\xE7L\xDC\xC7,1258436623505 in 2mins, 27sec
2009-11-17 21:00:19,367 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting split of region dds-test,\x7C\x98\xB4\x91\xE7L\xDC\xC7,1258436623505
2009-11-17 21:00:22,237 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed dds-test,\x7C\x98\xB4\x91\xE7L\xDC\xC7,1258436623505
2009-11-17 21:00:32,829 INFO org.apache.hadoop.hbase.regionserver.HRegion: region dds-test,\x7C\x98\xB4\x91\xE7L\xDC\xC7,1258520419408/538348405 available; sequence id is 25188602
2009-11-17 21:00:32,829 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed dds-test,\x7C\x98\xB4\x91\xE7L\xDC\xC7,1258520419408
2009-11-17 21:00:33,002 INFO org.apache.hadoop.hbase.regionserver.HRegion: region dds-test,\x7C\xAD\xCF\x27\x93\x10\x9A5,1258520419408/1604966836 available; sequence id is 25188603
2009-11-17 21:00:33,003 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed dds-test,\x7C\xAD\xCF\x27\x93\x10\x9A5,1258520419408
2009-11-17 21:01:51,211 ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction/Split failed for region dds-test,\x7C\x98\xB4\x91\xE7L\xDC\xC7,1258436623505
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 10.10.0.189:60020 for region .META.,,1, row 'dds-test,\x7C\x98\xB4\x91\xE7L\xDC\xC7,1258436623505', but failed after 1
0 attempts.
Exceptions:
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused
java.net.ConnectException: Connection refused

        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:1001)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$2.doCall(HConnectionManager.java:1192)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$Batch.process(HConnectionManager.java:1114)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.processBatchOfRows(HConnectionManager.java:1200)
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:605)
        at org.apache.hadoop.hbase.client.HTable.put(HTable.java:470)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.split(CompactSplitThread.java:211)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:106)
2009-11-17 21:02:00,709 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region dds-test,d\xC7s\x1B\xD3\x23we,1258519740878
2009-11-17 21:02:11,147 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region dds-test,d\xC7s\x1B\xD3\x23we,1258519740878 in 10sec
2009-11-17 21:02:11,147 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region dds-test,a\x96\x85\xB6fV\xE1\xFB,1258519760278
2009-11-17 21:02:30,950 INFO org.apache.hadoop.hbase.regionserver.HLog: Roll /hbase/.logs/sl0127,60020,1258512074419/hlog.dat.1258520252642, entries=853, calcsize=1428860, filesize=1342144. New hlog /hbase/.l
ogs/sl0127,60020,1258512074419/hlog.dat.1258520550914
2009-11-17 21:02:30,950 WARN org.apache.hadoop.hbase.regionserver.HLog: regionserver/10.10.0.180:60020.logFlusher took 7413ms optional sync'ing hlog; editcount=0
2009-11-17 21:03:29,990 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region dds-test,a\x96\x85\xB6fV\xE1\xFB,1258519760278 in 1mins, 18sec
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1557,"From Irfan up on hbase-users@

I shutdown hbase using the following command

{{$ HBASE_HOME/bin/stop-hbase.sh}}

and it shuts down properly after a few seconds.

here is my observation since last night. If I user TableRecordWriter1 uses HTable.incrementColumnValue, then the table data is not persisted across restarts but if I use TableRecordWriter2 then the table data is persisted across the restarts.

Any clues ...

Thanks,
Irfan

{code}
    protected static class TableRecordWriter extends RecordWriter<ImmutableBytesWritable, Put> {
        ...
        ...
        ...

        /**
        * {@inheritDoc}
        */
        @Override
        public void write(ImmutableBytesWritable key, Put put) throws IOException
        {
            byte[] row = put.getRow();

            for (Map.Entry<byte[], List<KeyValue>> familyEntry : put.getFamilyMap().entrySet()) {
                byte[] family = familyEntry.getKey();

                for (KeyValue keyValue : familyEntry.getValue()) {
                    byte[] qualifier = keyValue.getQualifier();

                    long amount = Bytes.toLong(keyValue.getValue());

                    this.table_.incrementColumnValue(row, family, qualifier, amount);
                }
            }
        }
    }
{code}

------

{code}
    protected static class TableRecordWriter2 extends RecordWriter<ImmutableBytesWritable, Put> {
        ...
        ...
        ...

        /**
        * {@inheritDoc}
        */
        public void write(ImmutableBytesWritable key, Put put) throws IOException {
            this.table_.put(new Put(put));
        }
    }
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3399,"org.apache.hadoop.hbase.regionserver.MemStore.upsert(KeyValue) doesn't match family before deciding to remove a kv in the memstore

      // if the qualifier matches and it's a put, remove it
      if (kv.matchingQualifier(cur)) {

        // to be extra safe we only remove Puts that have a memstoreTS==0
        if (kv.getType() == KeyValue.Type.Put.getCode() &&
            kv.getMemstoreTS() == 0) {
          // false means there was a change, so give us the size.
          addedSize -= heapSizeChange(kv, true);
          it.remove();
        }

shouldn't it be ""if the family and qualifier match and it's a Put, remove it""?

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3398,"In org.apache.hadoop.hbase.regionserver.HRegion.increment(Increment, Integer, boolean) the following loop assumes that the result from geLastIncrement() has a single entry for a given <family, qualifier>. But that is not necessarily true. getLastIncrement() does a union of all entries found in each of the store files ... and multiple versions of the same key are quite possible.

          List<KeyValue> results = getLastIncrement(get);

          // Iterate the input columns and update existing values if they were
          // found, otherwise add new column initialized to the increment amount
          int idx = 0;
          for (Map.Entry<byte [], Long> column : family.getValue().entrySet()) {
            long amount = column.getValue();
            if (idx < results.size() &&
                results.get(idx).matchingQualifier(column.getKey())) {
              amount += Bytes.toLong(results.get(idx).getValue());
              idx++;
            }",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3396,"In getLastIncrement() there is an assumption that memstore only scan will never return multiple versions of a kv

    // found everything we were looking for, done
    if (results.size() == expected) {
      return results;
    }


Based on this assumption the code does an early out after it finds the expected number of key-value pairs in the memstore. But what if there were multiple versions of the same kv returned by the memstore scan? I think it is possible when the memstore has a snapshot pending to be written out. A version of the key can be returned each from the online and from the snapshot memory.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1988,"RegionServers tend to die with an OutOfMemoryError under load. I expected this problem to go away with the fix for HBASE-1927 in 0.20.2 RC1, but it's still happening. Also, when this happens the cluster becomes unresponsive, even once the load on the machines has gone back down. Interestingly there are lots and lots of scanner lease expired messages right before the OOM.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1955,"When i start up HBase cluster, master logs shows zookeeper complaining about being in safe-mode.  Manually deleting the safe-mode file from zk using hbase shell, the WARN logs disappear:

shell> zk 'delete /hbase/safe-mode'



",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1802,"During recovery, the master had opened all the logfiles, but when it went to open the destination files, it crashed.  The logfile is missing, the edits did not get applied.

looks like there is a hole whereby we delete the original logfiles before we confirm the new output logs were written. oops!",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1721,"JGray RS was stuck doing the below:

{code}
IOException: Cannot append; log is closed
{code}

Just kept going on and on.

Was after a zk session timeout.  Regionserver had restarted itself and had been taking on new regions just fine.  I saw this entry from HLog:

{code}
2009-07-29 08:13:13,493 INFO org.apache.hadoop.hbase.regionserver.HLog: HLog configuration: blocksize=67108864, rollsize=63753420, enabled=true, flushlogentries=100, optionallogflushinternal=10000ms
2009-07-29 08:13:13,495 INFO org.apache.hadoop.hbase.regionserver.HLog: New hlog /hbase/.logs/hb2,60020,1248880393481/hlog.dat.1248880393493
{code}

Then two minutes later I saw the 'Cannot append'.

I do not see any close nor on a cursory glance, how this situation might arise -- somethign to do with the restart?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1711,"On deletion or truncation of a table (including major compacting the META), the entries for that table should get deleted in the META table. That doesnt happen and the entries remain. This causes Region Not Hosting exceptions when doing insertions into the table later on. The files for the deleted table do get deleted from the FS though.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1681,"Reproduce: 
1. populate hbase with 100 m records: bin/hadop jar hbase-dev-test.jar --rows=1000000 sequtialWrite 100
2. populate hbase with 10 m records (random writes): bin/hadoop jar hbase-dev-test.jar --rows=1000000 randomWrite 10
3. scan 10 m records: bin/hadoop jar hbase-dev-test.jar --rows=1000000 scan 10
2 scan mapper task failed with NSRE exception for one region:

org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: TestTable,0001724032,1248204794507
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2251)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1862)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)

Grep master log for TestTable,0001724032,1248204794507:

2009-07-21 12:33:18,275 INFO org.apache.hadoop.hbase.master.ServerManager: Recei
ved MSG_REPORT_SPLIT: TestTable,0001724032,1248141721258: Daughters; TestTable,0
001724032,1248204794507, TestTable,0001780000,1248204794507 from snv-it-lin-010.
projectrialto.com,60020,1248115451722; 1 of 3
2009-07-21 12:33:19,169 INFO org.apache.hadoop.hbase.master.RegionManager: Assig
ning region TestTable,0001724032,1248204794507 to snv-it-lin-011.projectrialto.c
om,60020,1248115452051
2009-07-21 12:33:21,464 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Curren
t assignment of TestTable,0001724032,1248204794507 is not valid;  Server '' star
tCode: 0 unknown.
2009-07-21 12:33:22,207 INFO org.apache.hadoop.hbase.master.ServerManager: Recei
ved MSG_REPORT_PROCESS_OPEN: TestTable,0001724032,1248204794507 from snv-it-lin-
011.projectrialto.com,60020,1248115452051; 1 of 1
2009-07-21 12:33:22,208 INFO org.apache.hadoop.hbase.master.RegionManager: Assig
ning region TestTable,0001724032,1248204794507 to snv-it-lin-011.projectrialto.c
om,60020,1248115452051
2009-07-21 12:33:25,245 INFO org.apache.hadoop.hbase.master.ServerManager: Recei
ved MSG_REPORT_PROCESS_OPEN: TestTable,0001724032,1248204794507 from snv-it-lin-
011.projectrialto.com,60020,1248115452051; 1 of 3
2009-07-21 12:33:25,245 INFO org.apache.hadoop.hbase.master.ServerManager: Recei
ved MSG_REPORT_PROCESS_OPEN: TestTable,0001724032,1248204794507 from snv-it-lin-
011.projectrialto.com,60020,1248115452051; 3 of 3
2009-07-21 12:33:28,283 INFO org.apache.hadoop.hbase.master.ServerManager: Recei
ved MSG_REPORT_PROCESS_OPEN: TestTable,0001724032,1248204794507 from snv-it-lin-
011.projectrialto.com,60020,1248115452051; 1 of 7
2009-07-21 12:33:28,283 INFO org.apache.hadoop.hbase.master.ServerManager: Recei
ved MSG_REPORT_PROCESS_OPEN: TestTable,0001724032,1248204794507 from snv-it-lin-
011.projectrialto.com,60020,1248115452051; 3 of 7
2009-07-21 12:33:28,283 INFO org.apache.hadoop.hbase.master.ServerManager: Recei
ved MSG_REPORT_OPEN: TestTable,0001724032,1248204794507 from snv-it-lin-011.proj
ectrialto.com,60020,1248115452051; 5 of 7
2009-07-21 12:33:28,284 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,0001724032,1248204794507 from snv-it-lin-011.proj
ectrialto.com,60020,1248115452051; 5 of 7
2009-07-21 12:33:28,284 INFO org.apache.hadoop.hbase.master.ServerManager: Recei
ved MSG_REPORT_OPEN: TestTable,0001724032,1248204794507 from snv-it-lin-011.proj
ectrialto.com,60020,1248115452051; 7 of 7
2009-07-21 12:33:28,284 DEBUG org.apache.hadoop.hbase.master.ServerManager: regi
on server 10.10.30.105:60020 should not have opened region TestTable,0001724032,
1248204794507
2009-07-21 12:33:28,289 INFO org.apache.hadoop.hbase.master.RegionServerOperatio
n: TestTable,0001724032,1248204794507 open on 10.10.30.105:60020
2009-07-21 12:33:28,289 INFO org.apache.hadoop.hbase.master.RegionServerOperatio
n: updating row TestTable,0001724032,1248204794507 in region .META.,,1 with star
tcode 1248115452051 and server 10.10.30.105:60020


Grep region server log for TestTable,0001724032,1248204794507: 

2009-07-21 12:33:19,163 INFO org.apache.hadoop.hbase.regionserver.HRegionServer:
 MSG_REGION_OPEN: TestTable,0001724032,1248204794507
2009-07-21 12:33:22,202 INFO org.apache.hadoop.hbase.regionserver.HRegionServer:
 MSG_REGION_OPEN: TestTable,0001724032,1248204794507
2009-07-21 12:33:26,183 INFO org.apache.hadoop.hbase.regionserver.HRegionServer:
 Worker: MSG_REGION_OPEN: TestTable,0001724032,1248204794507
2009-07-21 12:33:26,184 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Open
ing region TestTable,0001724032,1248204794507, encoded=3313355
2009-07-21 12:33:26,204 INFO org.apache.hadoop.hbase.regionserver.HRegion: regio
n TestTable,0001724032,1248204794507/3313355 available; sequence id is 45707088
2009-07-21 12:33:26,204 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitT
hread: Compaction requested for region TestTable,0001724032,1248204794507/331335
5 because: Region has references on open
2009-07-21 12:33:26,204 INFO org.apache.hadoop.hbase.regionserver.HRegionServer:
 Worker: MSG_REGION_OPEN: TestTable,0001724032,1248204794507
2009-07-21 12:33:28,278 INFO org.apache.hadoop.hbase.regionserver.HRegionServer:
 MSG_REGION_CLOSE_WITHOUT_REPORT: TestTable,0001724032,1248204794507: Duplicate
assignment
2009-07-21 12:33:28,279 INFO org.apache.hadoop.hbase.regionserver.HRegionServer:
 Worker: MSG_REGION_CLOSE_WITHOUT_REPORT: TestTable,0001724032,1248204794507: Du
plicate assignment
2009-07-21 12:33:28,279 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Clos
ing TestTable,0001724032,1248204794507: compactions & flushes disabled
2009-07-21 12:33:28,279 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Upda
tes disabled for region, no outstanding scanners on TestTable,0001724032,1248204
794507
2009-07-21 12:33:28,279 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No m
ore row locks outstanding on region TestTable,0001724032,1248204794507
2009-07-21 12:33:28,279 INFO org.apache.hadoop.hbase.regionserver.HRegion: Close
d TestTable,0001724032,1248204794507
2009-07-21 12:34:45,728 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Skip
ping compaction on TestTable,0001724032,1248204794507 because closing/closed
org.apache.hadoop.hbase.NotServingRegionException: TestTable,0001724032,12482047
94507
2009-07-21 13:24:35,902 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handl
er 27 on 60020, call openScanner([B@1756ef1, startRow=0001700000, stopRow=, maxV
ersions=1, timeRange=[0,9223372036854775807), families={(family=info, columns={d
ata}}) from 10.10.30.105:50797: error: org.apache.hadoop.hbase.NotServingRegionE
xception: TestTable,0001724032,1248204794507
org.apache.hadoop.hbase.NotServingRegionException: TestTable,0001724032,12482047
94507
org.apache.hadoop.hbase.NotServingRegionException: TestTable,0001724032,12482047
94507
2009-07-21 13:24:37,908 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handl
er 19 on 60020, call openScanner([B@25b414, startRow=0001700000, stopRow=, maxVe
rsions=1, timeRange=[0,9223372036854775807), families={(family=info, columns={da
ta}}) from 10.10.30.105:50797: error: org.apache.hadoop.hbase.NotServingRegionEx
ception: TestTable,0001724032,1248204794507
org.apache.hadoop.hbase.NotServingRegionException: TestTable,0001724032,12482047
94507
org.apache.hadoop.hbase.NotServingRegionException: TestTable,0001724032,12482047
94507
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1673,"Getting 500 in UI:

{code}
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server null for region , row '', but failed after 3 attempts.
Exceptions:
java.net.ConnectException: Call to /208.76.44.141:60020 failed on connection exception: java.net.ConnectException: Connection refused
...
{code}

Doesn't recover.

I think issue is here in HCM:
{code}
        } catch (IOException e) {
          if (e instanceof RemoteException) {
            e = RemoteExceptionHandler.decodeRemoteException(
                (RemoteException) e);
          }
          if (tries < numRetries - 1) {
            if (LOG.isDebugEnabled()) {
              LOG.debug(""locateRegionInMeta attempt "" + tries + "" of "" +
                this.numRetries + "" failed; retrying after sleep of "" +
                getPauseTime(tries), e);
            }
            relocateRegion(parentTable, metaKey);
          } else {
...
{code}

The call to relocateRegion is going to result in an attempt at finding the .META.,,1 region in .META. which will get a ConnectionException again.

On ConnectionException, should be backing up and going to -ROOT- to find new location of .META.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1228,"After an exception that forced an HRegionServer to shut down, I'm seeing it hang in the following method for at least a few minutes:

""regionserver/0:0:0:0:0:0:0:0:60020"" prio=10 tid=0x00002aaaf41a9000 nid=0x10f6 in Object.wait() [0x00000000422dd000..0x00000000422ddb10]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.flushInternal(DFSClient.java:3025)
	- locked <0x00002aaad8fa2410> (a java.util.LinkedList)
	- locked <0x00002aaad8fa2078> (a org.apache.hadoop.hdfs.DFSClient$DFSOutputStream)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3105)
	- locked <0x00002aaad8fa2078> (a org.apache.hadoop.hdfs.DFSClient$DFSOutputStream)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3054)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:61)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:86)
	at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:959)
	- locked <0x00002aaad8fa1f10> (a org.apache.hadoop.io.SequenceFile$Writer)
	at org.apache.hadoop.hbase.regionserver.HLog.close(HLog.java:431)
	- locked <0x00002aaab378b290> (a java.lang.Integer)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:498)
	at java.lang.Thread.run(Thread.java:619)

I believe the file system may have been closed and thus there is trouble flushing the HLog. The HLog should be pro actively closed before shutdown begins, to maximize the chances of it surviving the crash.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1168,"After a HRS goes down on OOME and is restarted, the master acknowledges it but does not assign any regions to it. Stack dump on HRS shows it is up and waiting for work. Relevant lines from tail of master log is:

2009-01-31 03:30:54,377 DEBUG org.apache.hadoop.hbase.master.RegionServerOperation: Removed 10.30.94.38:60020 from deadservers Map
2009-01-31 03:32:49,955 DEBUG org.apache.hadoop.hbase.master.ServerManager: received server report from unknown server: 10.30.94.38:60020
2009-01-31 03:50:37,025 INFO org.apache.hadoop.hbase.master.ServerManager: Received start message from: 10.30.94.38:60020
2009-01-31 04:03:59,822 INFO org.apache.hadoop.hbase.master.ServerManager: Cancelling lease for 10.30.94.38:60020
2009-01-31 04:03:59,823 INFO org.apache.hadoop.hbase.master.ServerManager: Region server 10.30.94.38:60020: MSG_REPORT_EXITING -- lease cancelled
2009-01-31 04:05:31,061 INFO org.apache.hadoop.hbase.master.ServerManager: Received start message from: 10.30.94.38:60020
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1149,"To reproduce:

1) Run HBase in standalone mode
2)

create 'foo', 'bar'

3) kill -9 the HBase server

4) Restart hbase

The table 'foo' will not exist.

Apparently this problem happens because the master and region servers die at the same time. To me that suggests a fairly large flaw -- if your cluster has a systematic failure (say, a power outage) it would cause data loss.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1115,"When compaction fails the affected region is left in an open and writable state, but scanners fail construction. Later a manual reassignment via close_region brings the region all the way back up.

Should there be rollback after a failed compaction somehow?

org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 10.30.94.50:60020 for region content,c84bbfc94b2143e41ba119d159be2958,1231518442461, row 'c84bbfc94b2143e41ba119d159be2958', but failed after 10 attempts.
Exceptions:
java.io.IOException: java.io.IOException: HStoreScanner failed construction
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.(StoreFileScanner.java:70)
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.(HStoreScanner.java:84)
	at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:2119)
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.(HRegion.java:1878)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1162)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1673)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:894)
Caused by: java.io.FileNotFoundException: File does not exist: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/1707725801/url/mapfiles/7039742044868774100/data
	at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:695)
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.(SequenceFile.java:1431)
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.(SequenceFile.java:1426)
	at org.apache.hadoop.hbase.io.MapFile$Reader.createDataFileReader(MapFile.java:310)
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.createDataFileReader(HBaseMapFile.java:96)
	at org.apache.hadoop.hbase.io.MapFile$Reader.open(MapFile.java:292)
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.(HBaseMapFile.java:79)
	at org.apache.hadoop.hbase.io.BloomFilterMapFile$Reader.(BloomFilterMapFile.java:65)
	at org.apache.hadoop.hbase.io.HalfMapFileReader.(HalfMapFileReader.java:86)
	at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:438)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.openReaders(StoreFileScanner.java:96)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.(StoreFileScanner.java:67)
	... 10 more
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-549,"We assign a region to a server.  It takes too long to open (HBASE-505).  Region gets assigned to another server.  Meantime original host returns a MSG_REPORT_CLOSE (because other regions opening messes it up moving files on disk out from under it).  We queue a shutdown which marks the region as needing reassignment.  Second server reports in that it successfully opened the region.  Master tells it it should not have opened it.  Churn ensues.

Fix is to ignore the CLOSE if its reported server/startcode does not match that of the server currently trying to open region.  Fix is not easy because currently we don't keep list of server info in unassigned regions.

Here's master log snippet showing problem:
{code}
...
2008-03-25 19:16:43,711 INFO org.apache.hadoop.hbase.HMaster: assigning region enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 to server XX.XX.XX.220:60020
2008-03-25 19:16:46,725 DEBUG org.apache.hadoop.hbase.HMaster: Received MSG_REPORT_PROCESS_OPEN : enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 from XX.XX.XX.220:60020
2008-03-25 19:18:06,411 DEBUG org.apache.hadoop.hbase.HMaster: shutdown scanner looking at enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482
2008-03-25 19:18:06,811 DEBUG org.apache.hadoop.hbase.HMaster: shutdown scanner looking at enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482
2008-03-25 19:19:46,841 INFO org.apache.hadoop.hbase.HMaster: assigning region enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 to server XX.XX.XX.221:60020
2008-03-25 19:19:49,849 DEBUG org.apache.hadoop.hbase.HMaster: Received MSG_REPORT_PROCESS_OPEN : enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 from XX.XX.XX.221:60020
2008-03-25 19:19:56,883 DEBUG org.apache.hadoop.hbase.HMaster: Received MSG_REPORT_CLOSE : enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 from XX.XX.XX.220:60020
2008-03-25 19:19:56,883 INFO org.apache.hadoop.hbase.HMaster: XX.XX.XX.220:60020 no longer serving regionname: enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482, startKey: <iLStZ0yTnfVUziYcNVVxWV==>, endKey: <jLB27Q4hKls4tSvp64rJfF==
>, encodedName: 1857033608, tableDesc: {name: enwiki_080103, families: {alternate_title:={name: alternate_title, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, alternate_url:={name: al
ternate_url, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, anchor:={name: anchor, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, mi
sc:={name: misc, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, page:={name: page, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, re
direct:={name: redirect, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}}}
2008-03-25 19:19:56,885 DEBUG org.apache.hadoop.hbase.HMaster: Main processing loop: ProcessRegionClose of enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482, true, false
2008-03-25 19:19:56,885 INFO org.apache.hadoop.hbase.HMaster: region closed: enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482
2008-03-25 19:19:56,887 INFO org.apache.hadoop.hbase.HMaster: reassign region: enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482
2008-03-25 19:19:57,288 INFO org.apache.hadoop.hbase.HMaster: assigning region enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 to server XX.XX.XX.189:60020
2008-03-25 19:20:00,296 DEBUG org.apache.hadoop.hbase.HMaster: Received MSG_REPORT_PROCESS_OPEN : enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 from XX.XX.XX.189:60020
2008-03-25 19:20:16,885 DEBUG org.apache.hadoop.hbase.HMaster: Received MSG_REPORT_OPEN : enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 from XX.XX.XX.221:60020
2008-03-25 19:20:16,885 DEBUG org.apache.hadoop.hbase.HMaster: region server XX.XX.XX.221:60020 should not have opened region enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482
2008-03-25 19:23:51,707 DEBUG org.apache.hadoop.hbase.HMaster: shutdown scanner looking at enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482
2008-03-25 19:23:51,834 DEBUG org.apache.hadoop.hbase.HMaster: shutdown scanner looking at enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482
2008-03-25 19:23:53,947 INFO org.apache.hadoop.hbase.HMaster: assigning region enwiki_080103,iLStZ0yTnfVUziYcNVVxWV==,1205393076482 to server XX.XX.XX.97:60020
...
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-70,"Each Store has a Memcache of edits that is flushed on a fixed period (It used to be flushed when it grew beyond a limit). A Region can be made up of N Stores.  A regionserver has no upper bound on the number of regions that can be deployed to it currently.  Add to this that per mapfile, we have read the index into memory.  We're also talking about adding caching of blocks and cells.

We need a means of keeping an account of memory usage adjusting cache sizes and flush rates (or sizes) dynamically -- using References where possible -- to accomodate deployment of added regions.  If memory is strained, we should reject regions proffered by the master with a resouce-constrained, or some such, message.

The manual sizing we currently do ain't going to cut it for clusters of any decent size.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1851,"Master crashed, SIGSEGV (0xb) at pc=0x00000031a40fea07, pid=14689, tid=1133910336.  Four other masters running ready to take the failover.  I see where we move to new master but there is an error:

{code}
2009-09-13 22:07:02,061 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Wrote master address XX.XX.XX.251:20000 to ZooKeeper
2009-09-13 22:07:02,064 WARN org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Failed to set state node in ZooKeeper
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /hbase/shutdown
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:110)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)
        at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:522)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.setClusterState(ZooKeeperWrapper.java:279)
        at org.apache.hadoop.hbase.master.HMaster.writeAddressToZooKeeper(HMaster.java:270)
        at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:255)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
        at java.lang.reflect.Constructor.newInstance(Unknown Source)
        at org.apache.hadoop.hbase.master.HMaster.doMain(HMaster.java:1200)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1241)
{code}

Is /hbase/shutdown now ephemeral?

Otherwise, the transition went off well it seems.

Except, if I look in zk -- this is a good while after teh event -- I do not see a master.. its empty.  Do we not record in zk on failover?

But then a split comes in:

2009-09-17 05:50:05,070 INFO org.apache.hadoop.hbase.master.BaseScanner: All 1 .META. region(s) scanned
2009-09-17 05:50:30,745 INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_SPLIT: enwikibase_dumpurls,,1253145470066: Daughters; enwikibase_dum
purls,,1253166628107, enwikibase_dumpurls,EzAdzwPBtG_o9BLsEqu4bV\x3D\x3D,1253166628107 from aa0-018-6.u.powerset.com,20020,1251458355425; 1 of 3
2009-09-17 05:50:30,745 DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.44.91:20020, startcode: 1251458355425, load: (requests=0, r
egions=3, usedHeap=490, maxHeap=2031): total nregions to assign=2, nregions to reach balance=4, isMetaAssign=false
2009-09-17 05:50:30,838 DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.44.49:20020, startcode: 1250638276455, load: (requests=3, r
egions=4, usedHeap=134, maxHeap=2031): total nregions to assign=2, nregions to reach balance=4, isMetaAssign=false
2009-09-17 05:50:31,117 DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.45.128:20020, startcode: 1250638269214, load: (requests=5, 
regions=4, usedHeap=130, maxHeap=2031): total nregions to assign=2, nregions to reach balance=4, isMetaAssign=false
2009-09-17 05:50:31,119 DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.45.221:20020, startcode: 1250638268709, load: (requests=5, 
regions=4, usedHeap=82, maxHeap=2031): total nregions to assign=2, nregions to reach balance=4, isMetaAssign=false
2009-09-17 05:50:31,150 DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.44.75:20020, startcode: 1250638276632, load: (requests=9, r
egions=4, usedHeap=284, maxHeap=2031): total nregions to assign=2, nregions to reach balance=4, isMetaAssign=false
2009-09-17 05:50:31,215 DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.45.180:20020, startcode: 1250638269143, load: (requests=11,
 regions=4, usedHeap=132, maxHeap=2031): total nregions to assign=2, nregions to reach balance=4, isMetaAssign=false
2009-09-17 05:50:31,265 DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.45.121:20020, startcode: 1250638269297, load: (requests=5, 
regions=4, usedHeap=54, maxHeap=2031): total nregions to assign=2, nregions to reach balance=4, isMetaAssign=false
...

And we never recover from the above (12 hours and still at it).

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1086,"On the jgray cluster, datanodes died.  Subsequently, could read from the table fine but attempts at writing into regions hosted by regionservers that sat beside dead datanodes fail -- connection refused. 

This issue should be easy to replicate, just kill adjacent datanode.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3061,Requirements documentation update. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1468,"if we want to hash KeyValue, we will need a hash that takes int offset, int length.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3004,"Fix would be pretty simple.  In the major compaction look, if file is already major compacted, add check of newest and oldest entries.   If has data older than TTL, re-major compact.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2682,"Imran M Yousuf  writes: (http://permalink.gmane.org/gmane.comp.java.hadoop.hbase.user/10525)

""I am trying to use HBase as maven dependency and am running in an
error for 0.21-SNAPSHOT :(. I have attached the DEBUG maven output and
Maven, Java versions and relevant POMs are as follows.


Maven & Java version:
-------------------------------

Apache Maven 2.1.0 (r755702; 2009-03-19 01:10:27+0600)
Java version: 1.6.0_13
Java home: /opt/jdk1.6.0_13/jre
Default locale: en_US, platform encoding: UTF-8
OS name: ""linux"" version: ""2.6.28-18-generic"" arch: ""i386"" Family: ""unix""
Ubuntu 9.04

Relevant POM files:
----------------------------

http://github.com/imyousuf/smart-dao/blob/master/smart-hbase-dao/pom.xml
http://github.com/imyousuf/smart-dao/blob/master/pom.xml (Line 178)

I would be grateful if someone would kindly help getting it to work.
Please feel free to ask me anything in this regard.

Thank you.""

See link for aforementioned maven output.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1873,"HRegionServer on lines 459 - 463 (part of run()) accesses outboundMsgs in a synchronized fashion, but other uses of the object are not synchronized.

Specifically, the code is

{noformat}
459          synchronized(this.outboundMsgs) {
460            outboundArray =
461              this.outboundMsgs.toArray(new HMsg[outboundMsgs.size()]); 
462            this.outboundMsgs.clear();
463          }
{noformat}

Whereas things are added to this list from calls like

{noformat}
  private void reportOpen(HRegionInfo region) {
    outboundMsgs.add(new HMsg(HMsg.Type.MSG_REPORT_OPEN, region));
  }
{noformat}

And

{noformat}
  void reportSplit(HRegionInfo oldRegion, HRegionInfo newRegionA,
      HRegionInfo newRegionB) {
    outboundMsgs.add(new HMsg(HMsg.Type.MSG_REPORT_SPLIT, oldRegion,
      (""Daughters; "" +
        newRegionA.getRegionNameAsString() + "", "" +
        newRegionB.getRegionNameAsString()).getBytes()));
    outboundMsgs.add(new HMsg(HMsg.Type.MSG_REPORT_OPEN, newRegionA));
    outboundMsgs.add(new HMsg(HMsg.Type.MSG_REPORT_OPEN, newRegionB));
  }
{noformat}

It looks like the object is initialized as

{noformat}
  private final List<HMsg> outboundMsgs =
    Collections.synchronizedList(new ArrayList<HMsg>());
{noformat}

Which would appear to provide security, but it doesn't actually prevent an insert from happening between lines 461 and 462, which would subsequently get removed from the call to clear().  At least, from the Sun HotSpot source code, it looks like Collections.synchronizedList() does the right thing and synchronizes on an inner mutex object instead of synchronizing on the externally visible list object itself.  That means, however, that the synchronized() on line 459 is largely meaningless.

I'm not sure how often this race condition would occur in the wild, but every thread waiting on the mutex around the toArray() call increases the probability that the next person to get the mutex is someone who wants to add something to the List, rather than the thread calling clear().

Simple fix would be to do external synchronization around all accesses to the List.  Barring that, perhaps a SynchronizedList implementation with a ""emptyToArray()"" method that encapsulates the toArray() and subsequent clear().",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1463,"I've seen post-hbase-1457 that if regionserver hosting -ROOT- goes down and then is reassigned, though .META. is happy where it is, and even though -ROOT- edits get picked up and are applied, I see that rootscanner complains the  .META. assignment is invalid because the server and startcode are empty.  Something's up.  Take a look.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1909,"fake on irc found a bug where he truncated his tables and they all ended up getting assigned to the same regionserver.

4 total nodes, root and meta each ended up on one node, another node had 0 regions, and the final one ended up with all 5 regions of user tables.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2900,"I installed the hbase and hadoop under the Pseudo-Distributed mode:

I configure the server side with following configuration:

hadoop: core-site.xml
<property>
    <name>fs.default.name</name>
    <value>hdfs://cluster1.office:9000</value>
  </property>

hadoop:mapred-site.xml
<property>
    <name>mapred.job.tracker</name>
    <value>localhost:9001</value>
  </property>

hadoop:hdfs-site.xml
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>

hbase:hbase-site.xml
 <property>
    <name>hbase.rootdir</name>
    <value>hdfs://cluster1.office:9000/hbase</value>
    <description>The directory shared by region servers.
    </description>
  </property>

I configure my client side(this is not in the same server as the server side) with following configuration:
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://cluster1.office/hbase</value>
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>cluster1.office</value>
  </property>

And then I connect to server side by java API described in the following page:
http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/package-summary.html#package_description

Unfortunately I get the Out of memory error:

2010-08-04 17:57:49,636 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region -ROOT-,,0
2010-08-04 17:57:49,686 INFO org.apache.hadoop.hbase.master.ServerManager: 1 region servers, 0 dead, average load 4.0
2010-08-04 17:57:49,815 DEBUG org.apache.hadoop.hbase.regionserver.Store: Compaction size of info: 4.0k; Skipped 1 file(s), size: 1849
2010-08-04 17:57:49,815 INFO org.apache.hadoop.hbase.regionserver.Store: Started compaction of 4 file(s) in info of -ROOT-,,0  into /hbase/-ROOT-/compaction.dir/70236052, seqid=112
2010-08-04 17:57:49,921 INFO org.apache.hadoop.hbase.regionserver.Store: Completed compaction of 4 file(s) in info of -ROOT-,,0; new storefile is hdfs://cluster1.jsw.office:9000/hbase/-ROOT-/70236052/info/1636337967443011476; store size is 3.0k
2010-08-04 17:57:49,926 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region -ROOT-,,0 in 0sec
2010-08-04 17:57:49,926 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region .META.,,1
2010-08-04 17:57:49,928 DEBUG org.apache.hadoop.hbase.regionserver.Store: historian: no store files to compact
2010-08-04 17:57:49,937 DEBUG org.apache.hadoop.hbase.regionserver.Store: Compaction size of info: 5.5k; Skipped 0 file(s), size: 0
2010-08-04 17:57:49,937 INFO org.apache.hadoop.hbase.regionserver.Store: Started compaction of 5 file(s) in info of .META.,,1  into /hbase/.META./compaction.dir/1028785192, seqid=116
2010-08-04 17:57:50,000 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {server: 192.168.1.81:39859, regionname: -ROOT-,,0, startKey: <>}
2010-08-04 17:57:50,037 INFO org.apache.hadoop.hbase.regionserver.Store: Completed compaction of 5 file(s) in info of .META.,,1; new storefile is hdfs://cluster1.jsw.office:9000/hbase/.META./1028785192/info/254940474272935789; store size is 4.0k
2010-08-04 17:57:50,045 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region .META.,,1 in 0sec
2010-08-04 17:57:50,053 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of 1 row(s) of meta region {server: 192.168.1.81:39859, regionname: -ROOT-,,0, startKey: <>} complete
2010-08-04 17:57:57,278 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: OutOfMemoryError, aborting.
java.lang.OutOfMemoryError: Java heap space
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invocation.readFields(HBaseRPC.java:175)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.processData(HBaseServer.java:867)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.readAndProcess(HBaseServer.java:835)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.doRead(HBaseServer.java:419)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.run(HBaseServer.java:318)
2010-08-04 17:57:57,279 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics: request=0.0, regions=4, stores=5, storefiles=4, storefileIndexSize=0, memstoreSize=0, compactionQueueSize=0, usedHeap=23, maxHeap=695, blockCacheSize=1208688, blockCacheFree=144726880, blockCacheCount=11, blockCacheHitRatio=82, fsReadLatency=0, fsWriteLatency=0, fsSyncLatency=0
2010-08-04 17:57:57,279 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server listener on 39859: exiting on OOME
2010-08-04 17:57:57,793 INFO org.apache.hadoop.ipc.HBaseServer: Stopping server on 39859
2010-08-04 17:57:57,794 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 24 on 39859: exiting
2010-08-04 17:57:57,794 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 0 on 39859: exiting
2010-08-04 17:57:57,794 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 2 on 39859: exiting
2010-08-04 17:57:57,794 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 20 on 39859: exiting
2010-08-04 17:57:57,795 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 21 on 39859: exiting
2010-08-04 17:57:57,795 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Stopping infoServer
2010-08-04 17:57:57,796 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 1 on 39859: exiting
2010-08-04 17:57:57,796 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 3 on 39859: exiting
2010-08-04 17:57:57,796 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 4 on 39859: exiting",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2795,"I committed the hbase-2707 patch yesterday but on second thoughts, it has a flaw in that if nothing in the todo queue, we then poll the delayedtodo queue.  If we fall into the latter and it has not elements, then we'll never come out; there are no notifyalls going on to wake us up.  Patch coming.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2216,Add mapred-test to cp ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1884,"Coming back after a crash, we have region A, and region for __GLOBAL_TRX_LOG. Assuming that there was a pending trx in A at the time of commit, it will find that in the WAL, and need to ask __GLOBAL_TRX_LOG__ what happend with that transaction. However, if we are opening region A before region __GLOBAL_TRX_LOG__ then we will fail to be able to query as we are blocking the opening of the __GLOBAL_TRX_LOG__ region, but we need it to open region A.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2508,"Currently lockIdGenerator is an int. In obtainRowLock(), retry is needed in case of lockId collisions.

We can declare lockIdGenerator as AtomicInteger and use incrementAndGet() to get the next lock Id.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2504,"regionserver log:

Thu Apr 29 13:34:27 CEST 2010 Starting regionserver on dell102
...
2010-04-29 13:34:29,656 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server dell147/10.1.3.147:2181
2010-04-29 13:34:29,657 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to dell147/10.1.3.147:2181, initiating session
2010-04-29 13:34:29,678 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server dell147/10.1.3.147:2181, sessionid = 0x284958aa550001, negotiated timeout = 60000
...
2010-04-29 14:13:30,096 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=dell149:2181,dell148:2181,dell147:2181 sessionTimeout=60000 watcher=org.apache.hadoop.hbase.client.HConnectionManager$ClientZKWatcher@46d895e1
2010-04-29 14:13:30,096 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server dell147/10.1.3.147:2181
2010-04-29 14:13:30,161 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to dell147/10.1.3.147:2181, initiating session
2010-04-29 14:13:30,194 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server dell147/10.1.3.147:2181, sessionid = 0x284958aa550014, negotiated timeout = 60000
2010-04-29 14:13:30,195 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.1.3.123:60020
2010-04-29 14:13:30,226 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT at 10.1.3.123:60020
2010-04-29 14:13:30,243 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Cached location for .META.,,1 is 10.1.3.125:60020
2010-04-29 14:13:30,247 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Read ZNode /hbase/master got 10.1.3.150:60000
...
2010-04-29 22:06:01,637 INFO org.apache.zookeeper.ZooKeeper: Session: 0x284958aa550014 closed
2010-04-29 22:06:02,012 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Closed connection with ZooKeeper

Clearly the reinitializeZooKeeper() method was called for some reason.

Unfortunately:
hbase(main):005:0> zk 'get /hbase/rs/1272540873161'
10.1.3.102:60020
cZxid = 0x5f0000002b
ctime = Thu Apr 29 13:34:33 CEST 2010
mZxid = 0x5f0000003e
mtime = Thu Apr 29 13:34:33 CEST 2010
pZxid = 0x5f0000002b
cversion = 0
dataVersion = 1
aclVersion = 0
ephemeralOwner = 0x284958aa550001
dataLength = 16
numChildren = 0

The owner of the zookeeper node is the first session which was never closed.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2477,"Memstore flushes are triggered today if a memstore exceeds a certain size or there is memory pressure.  However, there is no timer based flush for a memstore. This means a single column family or table getting a very slow rate of writes could hold up old HLogs from getting reclaimed for long periods of time-- which in turn increases recovery time for a failed region server since there are a lot more logs to process.

META is an example of a table which is likely to get very few writes. But even if we special cased META somehow, it wouldn't be good enough, since an application could genuinely have a mix of slow and fast changing tables or column families.

What about also triggering flushes on a timer (in addition to the current mechanism) to bound recovery times?
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2050,"What do people think of making ""."" a valid path in HDFS? The motivation is to allow users to create symlinks to the current directory in HDFS-245, eg see the following test for the current behavior:
{code}
  @Test
  /** Test create symlink to . */
  public void testCreateLinkToDot() throws IOException {
    Path dir  = new Path(""/test"");
    Path link = new Path(""/test/linkToDot"");
    fc.mkdir(dir, FileContext.DEFAULT_PERM, true);        
    fc.setWorkingDirectory(dir);
    try {
      fc.createSymlink(new Path("".""), link);
      fail(""Created symlink to dot"");
      readFile(new Path(""/test/linkToDot/file""));
    } catch (IOException x) {
      // Expected. Path(""."") resolves to """" because URI normalizes
      // the dot away and AbstractFileSystem considers """" invalid.  
    }
    fc.delete(dir, true);
  }
{code}

This involves trade offs since Hadoop Paths represent URIs (rather than the path component of a URI) and in URIs dot normalizes away. Some options:
# Make symlinks to ""."" an exception per the above, though it seems odd to consider ""."", "".."", ""/"" etc invalid paths (and the latter two happen to work based on how the Path constructor initializes the URI even though isValidName in AbstractFileSystem would consider them invalid names.
# Making ""."" immediately parse to an absolute path would be poor symlink semantics (eg a link to ""."" should not break if you rename the link's parent directory). 
# Making Path special case this so ""."" doesn't normalize away would be a weird one off case where Path and URIs differ.

Other alternatives? Of the above I'd prefer the last one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1044,"From IRC (with some improving text added -- finishes on a good point made by jgray):

{code}
18:53 < St^Ack> The coupling in a MR cluster is looser than it is in hbase cluster
18:53 < St^Ack> TTs only need report in every ten minutes and a task can fail and be restarted
18:54 < St^Ack> Whereas with hbase, it must report in at least every two minutes (IIRC) and cannot 'redo' lost edit -- no chance of a redo
18:54 < St^Ack> So, your MR job can be rougher about getting to the finish line; messier.
18:55 < tim_s> yeah. 
18:55 < St^Ack> If MR is running on same nodes as those hosting hbase, then it can rob resources from hbase in a way that damages hbase but not TT
18:56 < St^Ack> So, maybe we need to look at the hbase config; make it more tolerant when its running beside a hogging TT job
18:57 < tim_s> hmm, that would be lovely
18:57 < St^Ack> Need to look at HDFS; see how 'fragile' it is too; hbase should be at least that 'fragile'
18:57 < jgray> yeah, most issues we see come from resource issues on shared hdfs/tt/rs nodes
18:57 < tim_s> so is it common to host hbase elsewhere?
18:57 < St^Ack> Let me make an issue on it because this is common failure case for hbase (Setup hbase then run your old MR job as though nothing has changed -- then surprise when the little hbase lady faints)
18:57 < jgray> tim_s: currently, no.  common practice is shared
18:58 < St^Ack> ... and its better if shared -- locality benefits
18:58 < tim_s> would that be a good idea though? cause I don't really need to have hadoop local I guess.
18:58 < tim_s> ahh
18:58 < apurtell> we share also
...
18:59 < jgray> beyond locality, sharing makes sense as hdfs and hbase nodes have different requirements... hdfs being heaviest on io (where hbase has no use), hbase heavy in memory, TTs vary greatly but most often heavy in cpu/io
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1752,"When a regionserver aborts, there is a window where clients are continuing to try to write to it, but the writes are failing:

{noformat}
Aug 4, 2009 6:47:25 AM net.iridiant.heritrix.writer.HBaseWriterProcessor innerProcessResult
SEVERE: Failed write of Record: http://www.rdc.udel.edu/reports/development/profdev.pdf (in thread 'ToeThread #3: http://www.rdc.udel.edu/reports/development/profdev.pdf'; in processor 'Archiver')
java.io.IOException: org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 172.20.3.229:60020 for region content,23d6b92bc7eb100fc1294e6b124b7e75,1249198098627, row '23d6b92bc7eb100fc1294e6b124b7e75', but failed after 10 attempts.
Exceptions:
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
java.net.ConnectException: Call to /172.20.3.229:60020 failed on connection exception: java.net.ConnectException: Connection refused
	at net.iridiant.heritrix.writer.HBaseWriter.write(Unknown Source)
	at net.iridiant.heritrix.writer.HBaseWriterProcessor.write(Unknown Source)
	at net.iridiant.heritrix.writer.HBaseWriterProcessor.innerProcessResult(Unknown Source)
	at org.archive.modules.Processor.process(Unknown Source)
	at org.archive.crawler.framework.ToeThread.processCrawlUri(Unknown Source)
	at org.archive.crawler.framework.ToeThread.run(Unknown Source)
{noformat}

The client does not retry, so the data is lost. Maybe we can get this in for RC2?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1631,"{noformat}
HTTP ERROR: 500

Expected static method org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.getQuorumServers()Ljava/lang/String;

RequestURI=/master.jsp
Caused by:

java.lang.IncompatibleClassChangeError: Expected static method org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.getQuorumServers()Ljava/lang/String;
	at org.apache.hadoop.hbase.generated.master.master_jsp._jspService(master_jsp.java:103)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:324)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)
{noformat}

This method is no longer static now that each ZooKeeperWrapper maintains their own quorum so that it can be programatically changed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1533,I see this during bulk upload into TRUNK.  Happens often enough.  Odd is that its INFO level and the compaction seems to succeed.  Figure out whats going on here.  The log is disturbing.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1519,"Running on a hacked up TRUNK -- none of my patches touched hfile -- I got below (I have the original 1513 patch in place):

{code}
2009-06-14 02:42:28,853 [regionserver/0:0:0:0:0:0:0:0:60021.compactor] DEBUG org.apache.hadoop.hbase.regionserver.Store: Completed compaction of historian; store size is 47.2k
2009-06-14 02:42:28,855 [IPC Server handler 7 on 60021] INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 7 on 60021, call get([B@6a8bfc4f, row=TestTable,0006569959,1244947258659, maxVersions=1, timeRange=[0,9223372036854775807), families={(family=historian, columns=ALL), (family=info, columns=ALL}) from 208.76.44.139:47644: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
    at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:832)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:822)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1723)
    at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
    at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.lang.NullPointerException
    at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:97)
    at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)
    at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:950)
    at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:906)
    at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.loadBlock(HFile.java:1222)
    at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1105)
    at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:80)
    at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)
    at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1485)
    at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2251)
    at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2240)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1721)
    ... 5 more

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1426,"From Clint Morgan: ""Rather that adding new methods to the existing interface and deprecating the old ones, I'd propose creating a new interface, deprecating the old one, and using a wrapper that takes a deprecated filter and makes it implement the new interface. That way the regionserver logic would only have to honor the new interface.""

If we're going to make changes to filters for 0.20.0, lets entertain Clints idea.  We might do as Clint suggests anyways.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1378,"HBASE-1318, svn checkin 771087, included the following bad change:

{code}
diff --git a/conf/hbase-env.sh b/conf/hbase-env.sh
index 64fa4c5..b260c6c 100644
--- a/conf/hbase-env.sh
+++ b/conf/hbase-env.sh
@@ -23,6 +23,7 @@
 
 # The java implementation to use.  Java 1.6 required.
 # export JAVA_HOME=/usr/java/jdk1.6.0/
+export JAVA_HOME=/usr/lib/jvm/java-6-sun-1.6.0.07/
 
 # Extra Java CLASSPATH elements.  Optional.
 # export HBASE_CLASSPATH=
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1326,"I get this in the logfile:

2009-04-16 23:49:20,518 INFO org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Forced flushing of <table redacted>,1239954535262 because global memcache limit of 3.2m exceeded; currently 3.2m and flushing till 2.0m

With the experimental G1 GC, the heap size is created differently, and the way we calculate the size of memcache is flawed under this GC.  This affects performance and makes things reallll slow.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1208,"On irc this evening, another victim of too few xceivers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1047,"The patch for HBASE-1039 allows regions to continue to be served even after a bloomfilter related exception/failure happens during compaction. Over time, eventually all regions containing column families with bloomfilters enabled will accumulate these errors. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1724,"I have a 3 node cluster setup each running hadoop and hbase. I have created 'accounts' table and loaded some data into it (about 3000 rows).
Some days later one of the region servers died and after i restarted it there were no records in the table at all. I saw HLOG file with my records
in HDFS but as I understand the file was not used by HBase to recover the table.

I tried to emulate the situation and uploaded another 2000 records into my table and killed the region server holding 'accounts' table region.
In the HDFS I found file with my records but some time later it was replaced by another empty directory. As i suspected after killed region 
server startup the data was not recovered.

Everything is lost again and there is no any exceptions in the logs...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-616,"Just saw the below in a log... all in a row on the one server.

{code}
   4493 2008-05-05 18:08:17,512 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 34557ms, ten times longer than scheduled: 3000
   4494 2008-05-05 18:11:08,879 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 30576ms, ten times longer than scheduled: 3000
   4495 2008-05-05 18:30:45,056 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 1091720ms, ten times longer than scheduled: 3000
   4496 2008-05-05 18:30:45,056 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 1094209ms, ten times longer than scheduled: 10000
   4497 2008-05-05 18:30:45,429 FATAL org.apache.hadoop.hbase.HRegionServer: unable to report to master for 1092093 milliseconds - aborting server
{code}

We're seeing these kinda outages pretty frequently.  In the case above, it was small cluster that was using TableReduce to insert.  The MR, HDFS and HBase were all running on same nodes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1570,"[Sorry, pressed Ctrl-Enter accidentally. Please remove this issue]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1571,"Suppose that two threads are concurrently calling HBaseClient.getConnection() to an address to which no connection has been made yet, or one existed but has been dropped due to an error.
One of the threads creates a Connection object, puts it into the 'connections' map, and there, starts doing setupIOStreams, and there goes a context switch.
The second thread also calls getConnection and gets a connection from the 'connections' map, whose 'out' stream is only going to be initialized by the second thread, but has not yet been. There, at synchronized(this.out), goes an NPE.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1135,"{code}
2009-01-18 22:16:35,740 [regionserver/0:0:0:0:0:0:0:0:60020] INFO org.apache.hadoop.hbase.regionserver.HRegionServer: MSG_REGION_OPEN: TestTable,0037764196,1232260341993
2009-01-18 22:16:35,741 [regionserver/0:0:0:0:0:0:0:0:60020.worker] INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_OPEN: TestTable,0037764196,1232260341993
2009-01-18 22:16:35,749 [regionserver/0:0:0:0:0:0:0:0:60020.worker] INFO org.apache.hadoop.hbase.regionserver.HStore: HSTORE_LOGINFOFILE 308435520/info/1230499821085743170-1612503414/6361963498845991946/bottom does not contain a sequence number - ignoring
2009-01-18 22:16:35,757 [regionserver/0:0:0:0:0:0:0:0:60020.worker] ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Error opening TestTable,0037764196,1232260341993
java.io.FileNotFoundException: File does not exist: hdfs://aa0-000-12.u.powerset.com:9000/hbasetrunk2/TestTable/1612503414/info/mapfiles/6361963498845991946/data
    at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
    at org.apache.hadoop.hbase.regionserver.HStoreFile.length(HStoreFile.java:477)
    at org.apache.hadoop.hbase.regionserver.HStore.loadHStoreFiles(HStore.java:487)
    at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:230)
    at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:1764)
    at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:276)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1367)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:1338)
    at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:1253)
    at java.lang.Thread.run(Thread.java:619)
{code}

Above happens over and over again.

HBase should heal itself.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1071,"From Andrew Purtell note up on list:

""Later, maybe it would make sense to dynamically set the index
interval based on the distribution of cell sizes in the 
mapfile at some future time, according to some parameterized
formula that could be adjusted with config variable(s). This
could be done during compaction. Would make sense to also
consider the distribution of key lengths. Or there could be
other similar tricks implemented to keep index sizes down. """,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1376,I get NPEs when no LRU block cache enabled,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1312,"Does the master watch its own znode? Right around the time of regionserver problems described in HBASE-1311, clients could no longer find the master, but according to its log it was up and functionling normally. I think the master and regionserver sessions expired at the same time, as they were started within seconds of each other.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-911,"This issue is about looking into how much space in filesystem hbases uses.  Daniel Ploeg suggests that hbase is profligate in its use of space in hdfs.   Given that block sizes by default are 64MB, and that every time hbase writes a store file that its accompanied by an index file and a very small metadata file, thats 3*64MB even if the file is empty (TODO: Prove this).  The situation is aggrevated by the fact that hbase does a flush of whatever is in memory every 30 minutes to minimize loss in the absence of appends; this latter action makes for lots of small files.

The solution to the above is implement append so optional flush is not necessary and a file format that aggregates info, index and data all in the one file.   Short-term, we should set block size on the info/metadata file down to 4k or some such small size and look into doing likewise for the mapfile index.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-827,"Background introduction :
I was intent to implement a large queue-liked structure based on HBase.
Different from normal queue structure, in my structure, a pop action means 'randomly' pick one elements(which is key/value pair from a row) in queue, and decrease the queueSize of that queue.

For performance consideration, I implemented pop action by following steps :
1.get the queue size
2.random a number between 0~queueSize
3.take step2 as a qualifier, get the value of that element, and put the last element's value to the original qualifier.
4.decrease the queue size. (I didn't delete the last elements since storage space is not my primary consideration)

When the queueSize and number of pop action become large, hbase failed to open a scanner. (Even the data of database is correct)

My program can be split into few steps:
1.create a large queue.
2.pop until the queue empty
3.keep popping the queue 
4.delete the queue ( delete a row with deleteAll )
5.create a small queue with same name (i.e: same row)

After create a small queue, I checked every key/value in the hbase and found it is correct. But when I tried to open a scanner, it got Unknown Exception as follows:

In shell :
NativeException: org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 127.0.0.1:54141 for region pleaseCrash,,1218621377152, row '', but failed after 3 attempts.
Exceptions:
java.net.SocketTimeoutException: timed out waiting for rpc response
java.net.SocketTimeoutException: timed out waiting for rpc response
java.net.SocketTimeoutException: timed out waiting for rpc response

        from org/apache/hadoop/hbase/client/HConnectionManager.java:873:in `getRegionServerWithRetries'
        from org/apache/hadoop/hbase/client/HTable.java:1415:in `nextScanner'
        from org/apache/hadoop/hbase/client/HTable.java:1360:in `<init>'
        from org/apache/hadoop/hbase/client/HTable.java:985:in `getScanner'
        from org/apache/hadoop/hbase/client/HTable.java:779:in `getScanner'
        from org/apache/hadoop/hbase/client/HTable.java:706:in `getScanner'
        from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0'
        from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke'
        from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke'
        from java/lang/reflect/Method.java:597:in `invoke'
        from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling'
        from org/jruby/javasupport/JavaMethod.java:219:in `invoke'
        from org/jruby/javasupport/JavaClass.java:416:in `execute'
        from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call'
        from org/jruby/internal/runtime/methods/DynamicMethod.java:78:in `call'
        from org/jruby/runtime/CallSite.java:155:in `cacheAndCall'
... 128 levels...
        from ruby.home.itspeter.hbase_minus_0_dot_3_dot_0_minus_dev.bin.hirbInvokermethod__23$RUBY$startOpt:-1:in `call'
        from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call'
        from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call'
        from org/jruby/runtime/CallSite.java:123:in `cacheAndCall'
        from org/jruby/runtime/CallSite.java:298:in `call'
        from ruby/home/itspeter/hbase_minus_0_dot_3_dot_0_minus_dev/bin//home/itspeter/hbase-0.3.0-dev/bin/../bin/hirb.rb:350:in `__file__'
        from ruby/home/itspeter/hbase_minus_0_dot_3_dot_0_minus_dev/bin//home/itspeter/hbase-0.3.0-dev/bin/../bin/hirb.rb:-1:in `__file__'
        from ruby/home/itspeter/hbase_minus_0_dot_3_dot_0_minus_dev/bin//home/itspeter/hbase-0.3.0-dev/bin/../bin/hirb.rb:-1:in `load'
        from org/jruby/Ruby.java:512:in `runScript'
        from org/jruby/Ruby.java:432:in `runNormally'
        from org/jruby/Ruby.java:312:in `runFromMain'
        from org/jruby/Main.java:144:in `run'
        from org/jruby/Main.java:89:in `run'
        from org/jruby/Main.java:80:in `main'
        from /home/itspeter/hbase-0.3.0-dev/bin/../bin/hirb.rb:271:in `scan'
        from (hbase):3:in `binding'

Side effects :
	After scan got time out, I discovered that I also failed to disable the table (But not every time), somehow more strange is that table will be dropped successfully even disable failed (but not every time).

System Resources:
	Hbase will rob the cpu...
	In my platform(4-core), cpu usage will raise from 10% -> 50% ..100% -> 200% -> 300% ..

Procedure to reproduce :
Run the attached java file. 
Try to type ""scan 'pleaseCrash'"" in hbase shell after program finished.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-804,"In many failed map tasks we see things like this:
{code}
INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 64020, call next(-8330618580557781998) from 192.168.1.84:59678: error: org.apache.hadoop.hbase.UnknownScannerException: Name: -8330618580557781998
{code}

Here is an excerpt of the regionserver log:
{code}
2008-08-08 10:49:13,276 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting split of region entities,North_America-United_States-Missouri-Oran-b9c7e44a-4a2b-11dd-abd4-1231390079f2,1218205066272
2008-08-08 10:49:13,310 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Compactions and cache flushes disabled for region entities,North_America-United_States-Missouri-Oran-b9c7e44a-4a2b-11dd-abd4-1231390079f2,1218205066272
2008-08-08 10:49:13,310 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates and scanners disabled for region entities,North_America-United_States-Missouri-Oran-b9c7e44a-4a2b-11dd-abd4-1231390079f2,1218205066272
2008-08-08 10:49:13,310 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: waiting for 1 scanners to finish
2008-08-08 10:50:13,306 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -8330618580557781998 lease expired
2008-08-08 10:50:13,307 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region entities,North_America-United_States-Missouri-Oran-b9c7e44a-4a2b-11dd-abd4-1231390079f2,1218205066272
2008-08-08 10:50:13,307 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region entities,North_America-United_States-Missouri-Oran-b9c7e44a-4a2b-11dd-abd4-1231390079f2,1218205066272
2008-08-08 10:50:13,307 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region entities,North_America-United_States-Missouri-Oran-b9c7e44a-4a2b-11dd-abd4-1231390079f2,1218205066272. Current region memcache size 3.7m
2008-08-08 10:50:13,821 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Added /hbase/amsterdam_migration/entities/858230020/attribute/mapfiles/5987693228942080783 with 54576 entries, sequence id 9333266, data size 3.7m, file size 4.5m
2008-08-08 10:50:13,821 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memcache flush for region entities,North_America-United_States-Missouri-Oran-b9c7e44a-4a2b-11dd-abd4-1231390079f2,1218205066272 in 514ms, sequence id=9333266, compaction requested=true
2008-08-08 10:50:13,821 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 858230020/attribute
2008-08-08 10:50:13,822 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 858230020/context
2008-08-08 10:50:13,822 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 858230020/view
2008-08-08 10:50:13,822 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed entities,North_America-United_States-Missouri-Oran-b9c7e44a-4a2b-11dd-abd4-1231390079f2,1218205066272
...
2008-08-08 10:50:23,437 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 64020, call next(-8330618580557781998) from 192.168.1.84:59678: error: org.apache.hadoop.hbase.UnknownScannerException: Name: -8330618580557781998
org.apache.hadoop.hbase.UnknownScannerException: Name: -8330618580557781998
  at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1115)
  at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
  at java.lang.reflect.Method.invoke(Method.java:597)
  at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
  at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)
{code} 

We have to have some way of telling the client code that it's scanner lease was canceled because of a split so that it stays hidden from the user.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-778,Renaud Delbri up on the list and Jon Gray just now ran into issue where getting length of an HSF inside in the HStore constructor failed with FNFE.   Test of length is done after supposed tests that file exists so odd.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-508,"When I look in the log of XX.XX.XX.92, it shows only log rolling activity of following form:

{code}
...
2008-03-13 07:04:17,596 DEBUG org.apache.hadoop.hbase.HLog: Closing current log writer hdfs://coral-dfs.cluster.powerset.com:10000/hbase/XX.XX.XX-2.u.powerset.com/log_XX.XX.XX.92_1205384328364_60020/hlog.dat.022 to get a new one
2008-03-13 07:04:17,599 INFO org.apache.hadoop.hbase.HLog: new log writer created at hdfs://coral-dfs.cluster.powerset.com:10000/hbase/XX.XX.XX-2.u.powerset.com/log_XX.XX.XX.92_1205384328364_60020/hlog.dat.023
2008-03-13 07:08:48,425 INFO org.apache.hadoop.hbase.HRegionServer: Rolling hlog. Number of entries: 30004
2008-03-13 07:08:48,472 DEBUG org.apache.hadoop.hbase.HLog: Closing current log writer hdfs://coral-dfs.cluster.powerset.com:10000/hbase/XX.XX.XX-2.u.powerset.com/log_XX.XX.XX.92_1205384328364_60020/hlog.dat.023 to get a new one
2008-03-13 07:08:48,484 INFO org.apache.hadoop.hbase.HLog: new log writer created at hdfs://coral-dfs.cluster.powerset.com:10000/hbase/XX.XX.XX-2.u.powerset.com/log_XX.XX.XX.92_1205384328364_60020/hlog.dat.024
~        
...                                                                                                                                                                                                           
{code}

.. which is odd because if we're taking on this many edits, you'd think there'd be flushing and compacting going on.  There's none.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-96,"Using a patched version of 0.15.0, my regionserver freezes up, saying repeatedly:

2008-01-22 23:10:12,617 WARN org.apache.hadoop.ipc.Server: IPC Server handler 1 on 60020, call getProtocolVersion(org.
apache.hadoop.hbase.HRegionInterface, 1) from xxx.xxx.xxx.178:55116: discarded for being too old (46464)

Then I get:

2008-01-22 23:11:12,644 WARN org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call openScanner(-ROOT-,,0, [Lorg.apache.hadoop.io.Text;@19958bf9, .META., 1201043326058, null) from xxx.xxx.45.192:44993: output error
java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(Unknown Source)
        at sun.nio.ch.SocketChannelImpl.write(Unknown Source)
        at org.apache.hadoop.ipc.SocketChannelOutputStream.flushBuffer(SocketChannelOutputStream.java:108)
        at org.apache.hadoop.ipc.SocketChannelOutputStream.write(SocketChannelOutputStream.java:89)
        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)
        at java.io.BufferedOutputStream.flush(Unknown Source)
        at java.io.DataOutputStream.flush(Unknown Source)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:615)
2008-01-22 23:11:12,660 INFO org.apache.hadoop.ipc.Server: Process Thread Dump: Discarding call getProtocolVersion(org.apache.hadoop.hbase.HRegionInterface, 1) from xxx.xxx.45.224:34506

29 active threads
Thread 4329 (IPC Client connection to xxx.xxx.44.135:10000):
  State: WAITING
  Blocked count: 1
  Waited count: 4
  Waiting on org.apache.hadoop.ipc.Client$Connection@21e1962d
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Unknown Source)
    org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:216)
    org.apache.hadoop.ipc.Client$Connection.run(Client.java:255)
Thread 37 (IPC Server handler 9 on 60020):
  State: BLOCKED
  Blocked count: 1
  Waited count: 202
  Blocked on org.apache.hadoop.hbase.HStoreFile@72e8a021
  Blocked by 29 (IPC Server handler 1 on 60020)
  Stack:
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
    org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2025)
    org.apache.hadoop.hbase.HRegion$HScanner.<init>(HRegion.java:1699)
    org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1271)
    org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1499)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
    java.lang.reflect.Method.invoke(Unknown Source)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
Thread 36 (IPC Server handler 8 on 60020):
  State: BLOCKED
  Blocked count: 1
  Waited count: 201
  Blocked on org.apache.hadoop.hbase.HStoreFile@72e8a021
  Blocked by 29 (IPC Server handler 1 on 60020)
  Stack:
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
    org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2025)
    org.apache.hadoop.hbase.HRegion$HScanner.<init>(HRegion.java:1699)
    org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1271)
    org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1499)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
    java.lang.reflect.Method.invoke(Unknown Source)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
Thread 35 (IPC Server handler 7 on 60020):
  State: RUNNABLE
  Blocked count: 4
  Waited count: 240
  Stack:
    sun.management.ThreadImpl.getThreadInfo0(Native Method)
    sun.management.ThreadImpl.getThreadInfo(Unknown Source)
    sun.management.ThreadImpl.getThreadInfo(Unknown Source)
    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:114)
    org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:162)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:579)
Thread 34 (IPC Server handler 6 on 60020):
  State: BLOCKED
  Blocked count: 1
  Waited count: 203
  Blocked on org.apache.hadoop.hbase.HStoreFile@72e8a021
  Blocked by 29 (IPC Server handler 1 on 60020)
  Stack:
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
    org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2025)
    org.apache.hadoop.hbase.HRegion$HScanner.<init>(HRegion.java:1699)
    org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1271)
    org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1499)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
    java.lang.reflect.Method.invoke(Unknown Source)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
Thread 33 (IPC Server handler 5 on 60020):
  State: BLOCKED
  Blocked count: 1
  Waited count: 212
  Blocked on org.apache.hadoop.hbase.HStoreFile@72e8a021
  Blocked by 29 (IPC Server handler 1 on 60020)
  Stack:
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
    org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2025)
    org.apache.hadoop.hbase.HRegion$HScanner.<init>(HRegion.java:1699)
    org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1271)
    org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1499)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
    java.lang.reflect.Method.invoke(Unknown Source)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
Thread 32 (IPC Server handler 4 on 60020):
  State: BLOCKED
  Blocked count: 1
  Waited count: 202
  Blocked on org.apache.hadoop.hbase.HStoreFile@72e8a021
  Blocked by 29 (IPC Server handler 1 on 60020)
  Stack:
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
    org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2025)
    org.apache.hadoop.hbase.HRegion$HScanner.<init>(HRegion.java:1699)
    org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1271)
    org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1499)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
    java.lang.reflect.Method.invoke(Unknown Source)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
Thread 31 (IPC Server handler 3 on 60020):
  State: BLOCKED
  Blocked count: 1
  Waited count: 210
  Blocked on org.apache.hadoop.hbase.HStoreFile@72e8a021
  Blocked by 29 (IPC Server handler 1 on 60020)
  Stack:
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
    org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2025)
    org.apache.hadoop.hbase.HRegion$HScanner.<init>(HRegion.java:1699)
    org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1271)
    org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1499)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
    java.lang.reflect.Method.invoke(Unknown Source)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
Thread 30 (IPC Server handler 2 on 60020):
  State: BLOCKED
  Blocked count: 1
  Waited count: 216
  Blocked on org.apache.hadoop.hbase.HStoreFile@72e8a021
  Blocked by 29 (IPC Server handler 1 on 60020)
  Stack:
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
    org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2025)
    org.apache.hadoop.hbase.HRegion$HScanner.<init>(HRegion.java:1699)
    org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1271)
    org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1499)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
    java.lang.reflect.Method.invoke(Unknown Source)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
Thread 29 (IPC Server handler 1 on 60020):
  State: RUNNABLE
  Blocked count: 3
  Waited count: 229
  Stack:
    java.net.SocketInputStream.socketRead0(Native Method)
    java.net.SocketInputStream.read(Unknown Source)
    java.io.BufferedInputStream.fill(Unknown Source)
    java.io.BufferedInputStream.read(Unknown Source)
    java.io.DataInputStream.readShort(Unknown Source)
    org.apache.hadoop.dfs.DFSClient$BlockReader.newBlockReader(DFSClient.java:773)
    org.apache.hadoop.dfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1000)
    org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:1096)
    java.io.DataInputStream.readFully(Unknown Source)
    java.io.DataInputStream.readFully(Unknown Source)
    org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1383)
    org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1360)
    org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1349)
    org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1344)
    org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:263)
    org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:242)
    org.apache.hadoop.hbase.HStoreFile$BloomFilterMapFile$Reader.<init>(HStoreFile.java:816)
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
Thread 28 (IPC Server handler 0 on 60020):
  State: BLOCKED
  Blocked count: 1
  Waited count: 200
  Blocked on org.apache.hadoop.hbase.HStoreFile@72e8a021
  Blocked by 29 (IPC Server handler 1 on 60020)
  Stack:
    org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:936)
    org.apache.hadoop.hbase.HStore$StoreFileScanner.<init>(HStore.java:2057)
    org.apache.hadoop.hbase.HStore$HStoreScanner.<init>(HStore.java:2203)
    org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2025)
    org.apache.hadoop.hbase.HRegion$HScanner.<init>(HRegion.java:1699)
    org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1271)
    org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1499)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
    java.lang.reflect.Method.invoke(Unknown Source)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
Thread 14 (IPC Server listener on 60020):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.PollArrayWrapper.poll0(Native Method)
    sun.nio.ch.PollArrayWrapper.poll(Unknown Source)
    sun.nio.ch.PollSelectorImpl.doSelect(Unknown Source)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
    sun.nio.ch.SelectorImpl.select(Unknown Source)
    sun.nio.ch.SelectorImpl.select(Unknown Source)
    org.apache.hadoop.ipc.Server$Listener.run(Server.java:285)

... etc.

Note that most of the threads are blocked on thread 29, which is in turn blocked on a socket read.  This node was hosting the ROOT region, so when it got wedged it made hbase unusable (since the master won't reassign ROOT until the server actually goes down).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4,"We're running a high load of random reads through a single hbase rest server.  When I look at the 60010 master servlet, there are a very high number of hits to the server hosting .META.,,1.  That server has 4000 requests in the last ""3 seconds"", the server hosting ROOT (and two other regions which shouldn't be getting reads) has 80 requests, and all the other regionservers have less.  

This doesn't seem right: shouldn't the single hbase client be caching table lookups?

This appears to be a hurdle for scaling our random read rate.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-540,HBase trunk region server gets an out of memory exception in the Performance Evaluation (sequential write) test at map 37% reduce 12%,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21,I don't think it'll be found at this location.  Verify.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-179,"I am uploading logs for this

webdata has more then one region loaded that have the same starting row key but different end row keys

This happens after a split sometimes they both had null as the starting row key

PE1750-3 started with the table then once split the new splits went to PE1750-1
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-160,"TestTable fails in Hudson build

    [junit] Running org.apache.hadoop.hbase.TestTable
    ....
    [junit] Tests run: 1, Failures: 0, Errors: 1, Time elapsed: 0 sec
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21506,"{code:java}
[WARNING] Expected all dependencies to require Scala version: 2.11.8
[WARNING] org.apache.phoenix:phoenix-spark:5.1.0-HBase-2.0-SNAPSHOT requires scala version: 2.11.8
[WARNING] com.twitter:chill_2.11:0.8.4 requires scala version: 2.11.8
[WARNING] org.apache.spark:spark-core_2.11:2.3.0 requires scala version: 2.11.8
[WARNING] org.json4s:json4s-jackson_2.11:3.2.11 requires scala version: 2.11.0
[WARNING] Multiple versions of scala libraries detected!{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21332,"When using scan with pagefilter to get data from hbase, the scanner will skip{color:#ff0000} 'non-edge'{color} regions.The code i use comes from the book _HBase: Definitive Guide, Example 4.8, PageFilter example._聽Difference is i use scan with startRow and stopRow.

Say i have regions with start and end聽keys like \{'111', '222', '333', '444'}, which means i have 3 regions \{111, 222}, \{222, 333}, \{333, 444} and they are in different region servers. When scan with startRow '111' and stopRow '444' , most data in region \{222, 333} will be skiped and won't be returned by ResultScanner.Region \{111,222} or \{333,444} works just fine and because region \{222,333} doesn't contain startRowkey or stopRowkey i call it non-edge region.

Below is some explanation聽with log:

聽
{code:java}
// Here scanner works just fine in region {111,222}, it gets exactly {pageSize} rows each time, which is 1000
...
2018-10-17 21:25:57.810 INFO 213872 [ main] c.p.s.c.HBaseTest : Test: results from [2139718600001069] to [2179067497952422], sum [1000 : 64000], cost: [77ms]
2018-10-17 21:25:57.885 INFO 213872 [ main] c.p.s.c.HBaseTest : Test: results from [2179098921079755] to [21c2879280113661], sum [1000 : 65000], cost: [75ms]
2018-10-17 21:25:57.962 INFO 213872 [ main] c.p.s.c.HBaseTest : Test: results from [21c2899018774688] to [2203180876471552], sum [1000 : 66000], cost: [77ms]

// Here scanner goes from region {111,222} to {222,333}. As you can see, the scanner gets 2405 rows with stopRow '3373621463365126'.The scanner moves to regin {333,444} too early and most data in {222,333} are skiped.
2018-10-17 21:25:58.321 INFO 213872 [ main] c.p.s.c.HBaseTest : Test: results from [2203223414254308] to [3373621463365126], sum [2405 : 68405], cost: [359ms]

// Now the scanner is in region {333,444}, everything works just fine
2018-10-17 21:25:58.396 INFO 213872 [ main] c.p.s.c.HBaseTest : Test: results from [3373764408525604] to [33b3849714659525], sum [1000 : 69405], cost: [74ms]
2018-10-17 21:25:58.467 INFO 213872 [ main] c.p.s.c.HBaseTest : Test: results from [33b3882378177107] to [33f5221377695765], sum [1000 : 70405], cost: [71ms]
...{code}
聽",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20473,"{code}
  // Disable verbose INFO logging from org.apache.hadoop.io.compress.CodecPool
  static {
    System.setProperty(""org.apache.commons.logging.Log"",
      ""org.apache.commons.logging.impl.SimpleLog"");
{code}
The above code has no effect since we're migrating away from commons-logging.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18827,"I'm trying to make a release. I'm in a tizzy as is usual around these times*. 1.5 hours seems totally over-the-top. I think [~misty]'s lovely automation has hidden this fact from us but needs digging on why we are taking so long. The cycle seems to be provoked by hbase-archetypes module.... but I got 'mvn log glaze disease' as soon as I tried digging in.

Filing issue in case someone else wants to have a go at this before I. Also filing if only to note that the thing does eventually finish in case I forget....


* I go to build the doc/site and the build never seems to end. First there is the issue HBASE-18821 where we were NPE'ing after a bunch of time had passed. My fix for HBASE-18821 then got me further but after what seemed hours, it failed with a cryptic message (Thanks [~Apache9] for figuring that I'd made an incorrect fix over in HBASE-18821).  Next up I'm looking at a cycle that never seems to end... only it eventually does after 90minutes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18650,"When I use HBase replication with Master-Master  model, install like  below:
1>  with cluster 1  I create table ""repliTest"",  and put some data on it .

2>  after about 6 month, I have cluster 2 ,and install master-master model with two cluster.

3> I put  cluster 1 some data and It replication  to cluster 2, it's correct.

4>  I put  cluster 2 some data and it replication to cluster 1, It's correct also.

5> The issue is : when I run     command 
 ""hbase org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication  clusterID  repliTest  ""    on each cluster.

the result  is different :
on cluster 1  the result is 
	org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$Counters
		BADROWS=33
		GOODROWS=20
		ONLY_IN_PEER_TABLE_ROWS=4
		ONLY_IN_SOURCE_TABLE_ROWS=29

on cluster 2 the result is:

	org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$Counters
		BADROWS=32
		GOODROWS=20
		ONLY_IN_PEER_TABLE_ROWS=28
		ONLY_IN_SOURCE_TABLE_ROWS=4

It means one record is lost on cluster 2  verifierreplication .  I check the table and get the recode  is one recode I have put it  6 month ago.  
I delete this record like this:

hbase(main):017:0> delete 'repliTest','3','score:english'

and after that,   when I run hbase verifyreplication  is also correct on every cluster. 



environment :

HBase 1.16  
hdfs  2.7.1 

ps: I am not good at english  ,sorry about that. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18613,"Noticed the following in some internal testing (line numbers likely are skewed)

{noformat}
2017-08-16 21:20:25,557| 2017-08-16 21:20:25,553 WARN  [main] client.ConnectionManager$HConnectionImplementation: Checking master connection
2017-08-16 21:20:25,557| com.google.protobuf.ServiceException: org.apache.hadoop.hbase.exceptions.ConnectionClosingException: Call to master1.domain.com/10.0.2.131:16000 failed on local exception: org.apache.hadoop.hbase.exceptions.ConnectionClosingException: Connection to master1.domain.com/10.0.2.131:16000 is closing. Call id=581, waitTime=1
2017-08-16 21:20:25,557| at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:223)
2017-08-16 21:20:25,558| at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
2017-08-16 21:20:25,560| at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$BlockingStub.isMasterRunning(MasterProtos.java:62739)
2017-08-16 21:20:25,560| at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation$MasterServiceState.isMasterRunning(ConnectionManager.java:1448)
2017-08-16 21:20:25,561| at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.isKeepAliveMasterConnectedAndRunning(ConnectionManag
er.java:2124)
2017-08-16 21:20:25,561| at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getKeepAliveMasterService(ConnectionManager.java:1712)
2017-08-16 21:20:25,562| at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getMaster(ConnectionManager.java:1701)
2017-08-16 21:20:25,562| at org.apache.hadoop.hbase.DistributedHBaseCluster.getMasterAdminService(DistributedHBaseCluster.java:153)
2017-08-16 21:20:25,563| at org.apache.hadoop.hbase.DistributedHBaseCluster.waitForActiveAndReadyMaster(DistributedHBaseCluster.java:184)
2017-08-16 21:20:25,563| at org.apache.hadoop.hbase.HBaseCluster.waitForActiveAndReadyMaster(HBaseCluster.java:204)
2017-08-16 21:20:25,563| at org.apache.hadoop.hbase.DistributedHBaseCluster.restoreMasters(DistributedHBaseCluster.java:278)
2017-08-16 21:20:25,563| at org.apache.hadoop.hbase.DistributedHBaseCluster.restoreClusterStatus(DistributedHBaseCluster.java:239)
2017-08-16 21:20:25,563| at org.apache.hadoop.hbase.HBaseCluster.restoreInitialStatus(HBaseCluster.java:235)
2017-08-16 21:20:25,564| at org.apache.hadoop.hbase.IntegrationTestingUtility.restoreCluster(IntegrationTestingUtility.java:99)
2017-08-16 21:20:25,564| at org.apache.hadoop.hbase.IntegrationTestBase.cleanUpCluster(IntegrationTestBase.java:200)
2017-08-16 21:20:25,564| at org.apache.hadoop.hbase.IntegrationTestDDLMasterFailover.cleanUpCluster(IntegrationTestDDLMasterFailover.java:146)
2017-08-16 21:20:25,564| at org.apache.hadoop.hbase.IntegrationTestBase.cleanUp(IntegrationTestBase.java:140)
2017-08-16 21:20:25,564| at org.apache.hadoop.hbase.IntegrationTestBase.doWork(IntegrationTestBase.java:125)
2017-08-16 21:20:25,565| at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112)
2017-08-16 21:20:25,565| at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
2017-08-16 21:20:25,565| at org.apache.hadoop.hbase.IntegrationTestDDLMasterFailover.main(IntegrationTestDDLMasterFailover.java:832)
2017-08-16 21:20:25,566| Caused by: org.apache.hadoop.hbase.exceptions.ConnectionClosingException: Call to master1.domain.com/10.0.2.131:16000 failed on local exception: org.apache.hadoop.hbase.exceptions.ConnectionClosingException: Connection to master1.domain.com/10.0.2.131:16000 is closing. Call id=581, waitTime=1
2017-08-16 21:20:25,566| at org.apache.hadoop.hbase.ipc.RpcClientImpl.wrapException(RpcClientImpl.java:1258)
2017-08-16 21:20:25,566| at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1229)
2017-08-16 21:20:25,566| at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
2017-08-16 21:20:25,566| ... 20 more
2017-08-16 21:20:25,566| Caused by: org.apache.hadoop.hbase.exceptions.ConnectionClosingException: Connection to master1.domain.com/10.0.2.131:16000 is closing. Call id=581, waitTime=1
2017-08-16 21:20:25,567| at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.cleanupCalls(RpcClientImpl.java:1047)
2017-08-16 21:20:25,567| at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.close(RpcClientImpl.java:846)
2017-08-16 21:20:25,567| at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.run(RpcClientImpl.java:574)
{noformat}

This is when the IntegrationTest harness is resetting the state of the distributed cluster. When dealing with ""slow"" nodes, the restart of the previously active master could be delayed which cause the test code to see a ConnectionClosingException (wrapped in a ServiceException).

I think we want to just consume this Exception, same as MasterNotRunningException and ZooKeeperConnectionException, in {{DistributedHBaseCluster#waitForActiveAndReadyMaster(long)}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18363,"We run into cases that with read replica, after split, sometimes, the parent replica region is left in  master's in memory onlineRegion list. This results in the region got assigned to a region server. Though the root cause will be fixed by HBASE-18025. We need to enhance hbck tool to fix this in-memory state. Currently, hbck only allows the fix for primary region (in this case, the primary region is gone) with fixAssignment option, please see the following line of code. We will enhance it so it can be applied to replica region as well.

https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java#L2216",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20291,"receiving message
{code:java}
The POM for net.minidev:json-smart:jar:2.3-SNAPSHOT is missing, no dependency information available{code}
when running with
{code:java}
mvn clean install -DHBasePatchProcess -Dhadoop-three.version=3.0.0 -Dhadoop.profile=3.0 -DskipTests{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19192,"{code}
  public int getRegionServerInfoPort(final ServerName sn) {
    RegionServerInfo info = this.regionServerTracker.getRegionServerInfo(sn);
    if (info == null || info.getInfoPort() == 0) {
      return conf.getInt(HConstants.REGIONSERVER_INFO_PORT,
        HConstants.DEFAULT_REGIONSERVER_INFOPORT);
    }
    return info.getInfoPort();
{code}
hbase.regionserver.info.port config is only checked when regionServerTracker doesn't have info port.
When hbase.regionserver.info.port is set to -1 by user, we should respect the config value and disable UI.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12630,"Chatting with Manukranth, online config update feature should handle the case where certain ConfigurationObserver(s) constantly produce exception when notified of config update.

We can handle such ConfigurationObserver by sidelining it after configurable number of exceptions seen from the ConfigurationObserver.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12656,"TestVisibilityLabelsWithDeletes.testVisibilityLabelsWithDeleteFamilyWithMultipleVersionsNoTimestamp is flaky.  I fear if Visibility delete is broken some where. I have some idea on the reason but will provide a patch for it tomorrow after complete analysis. If the bug is only a test case bug will lower the priority of the bug - but I don't think so.
testVisibilityLabelsWithDeleteFamilyWithMultipleVersionsNoTimestamp does not fail in any of the jenkins build but fails in local randomly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12203,"With patch HBASE-7767 we moved table statuses from ZK to HDFS. That was a good cleanup, but we put additional (substantial) load on master. Some client requests use checks for table state (for example HBASE-12035). 
Thats is why patch was not back ported to branch1 (HBASE-11978)

Lets replicate state back to zk, but as a mirror of table states.

What can be done:
1. TableStateManager would push table state changes to zk
2. Return back ZKTableStateClientSideReader.

Alternative way:
1. Move table statuses to separate table like namespaces
2. Issue statuses requests against this table

Alternative way2:
1. Extend RS api with getTableState() call
2. Each RS will be able to cache table states
3. Clients will call RS instead of master or zk",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5224,"HFile's midkey() is implemented as the first key of the middle index block both HFile v1 and HFile v2 (the middle leaf index block is used in v2). However, in HFile v2 midkey() currently grabs 12 more bytes from the next leaf index entry, representing the offset and compressed size of the data block pointed to by that entry. While this probably does not affect the interpretation of the returned buffer as an HBase key (the last 12 bytes are simply discarded), this has to be cleaned up. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3737,"I just realized that htable.delete(List<Delete>) doesn't use the writebuffer and processes the list immediately, but htable.put(List<Put>) does use the writebuffer (i.e., send when filled). Likewise, htable.delete(Delete) sends immediately.
 
Out of sheer curiosity, why?  With the 'batch' methods now in place, it seems like it would be consistent for 'delete' and 'put' to use the writebuffer (assuming it is expanded to hold more than Puts), whereas 'batch' methods process immediately.

This isn't a huge issue, but it does seem a little inconsistent. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11249,"At line 4883:
{code}
            Store store = getStore(kv);
            if (store == null) {
              checkFamily(CellUtil.cloneFamily(kv));
              // unreachable
            }
{code}
Exception would be thrown from checkFamily() if store is null.
In the finally block:
{code}
      } finally {
        if (!mutations.isEmpty() && !walSyncSuccessful) {
          LOG.warn(""Wal sync failed. Roll back "" + mutations.size() +
              "" memstore keyvalues for row(s):"" + StringUtils.byteToHexString(
              processor.getRowsToLock().iterator().next()) + ""..."");
          for (KeyValue kv : mutations) {
            getStore(kv).rollback(kv);
          }
{code}
There is no corresponding null check for return value of getStore() above, potentially leading to partially rolled back state in memstore.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12211,"In the hbase-daemon.sh file line 199, it has the content:
{quote}echo ""`ulimit -a`"" >> $loglog 2>&1{quote}
The variable loglog is defined as:
{quote}
logout=$HBASE_LOG_DIR/$HBASE_LOG_PREFIX.out
loggc=$HBASE_LOG_DIR/$HBASE_LOG_PREFIX.gc
loglog=""${HBASE_LOG_DIR}/${HBASE_LOGFILE}""
{quote}
For my understanding, this information should be printed to the ""logout"" variable; we should not mix this ""ulimit"" information with the actual log printed by hbase java program.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15737,"HBASE-14963 removed reference to Guava Stopwatch from hbase-client module.

However, there're still 3 classes referring to Guava Stopwatch :

hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java:import com.google.common.base.Stopwatch;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JvmPauseMonitor.java:import com.google.common.base.Stopwatch;
hbase-server/src/test/java/org/apache/hadoop/hbase/ScanPerformanceEvaluation.java:import com.google.common.base.Stopwatch;

We should remove reference to Guava Stopwatch.

hadoop is no longer referencing Guava Stopwatch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17393,"In the code,

https://github.com/apache/hbase/blob/master/hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java#L181
 
return getMin() < tr.getMax() && getMax() >= tr.getMin();

Given that TimeRange is defined as [minStamp,maxStamp), 

Assume that TimeRange(4, 5). includesTimeRange(TimeRange(5,6)).
So it will be (4 < 6) && (5 >=5), the result is true.

Same for TimeRangeTracker#includesTimeRange",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17034,"{code:title=HTable.java|borderStyle=solid}
private Result get(Get get, final boolean checkExistenceOnly) throws IOException {
    if (get.isCheckExistenceOnly() != checkExistenceOnly || get.getConsistency() == null) {
      get = ReflectionUtils.newInstance(get.getClass(), get);
      get.setCheckExistenceOnly(checkExistenceOnly);
      if (get.getConsistency() == null){
        get.setConsistency(defaultConsistency);
      }
    }
  ...
}
{code}
Can the passed Get be modified? If so, we can just change the passed Get. If not, we can record the values returned by isCheckExistenceOnly() and getConsistency() for avoiding the Get copy.

It seems to me that it is ok to modify the passed Get.

Any comment? Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16575,"It seems to me that RRCI#callWithRetries and RRCI#callWithoutRetries should have the same logic if the maxAttempts is configured to one. But there are some difference are shown below:
1) timeout
2) failure handle
The quick solution is that we always call the RRCI#callWithRetries in the RRCI#callWithoutRetries when the maxAttempts is configured to one.
Any comment? Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17670,When VictimHandler is used we use the bucket cache to cache those blocks that are evicted. So in case of where we close the hfile and call evictBlocksByHfileName - I think it still makes sense to call evict on the vicitmHandler also. Else the victimHandler is going to just occupy the space till the eviction thread in that vicitm handler clears it. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17431,"Here is related code:
{code}
    public R get() {
      if (super.size() < maxSize) {
        return null;
      }
      nextResource %= super.size();
{code}
Since super.size() is involved in modulo operation after the check, it seems the check should compare against 0 instead of maxSize.

Looks like a copy-paste error from put() method.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17394,"It is supposed to be [minimumTimestamp, maximumTimestamp), the following logic suggests  [minimumTimestamp, maximumTimestamp]

https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java#L81

needs to be modified to set(l, l + 1)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6709,"Current naming convention about QOS is confusing. For first, there is no high or low priority, rather it works based on whether the operation is a root/meta lookup or a pure client side one. 
With addition of ReplicationHandlers, we introduced a new level of QOS. 
I think we should standarized QOS levels that reflects how they actually works.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16717,"Every time to generateChecksums or validateChecksum will create a new DataChecksum, and DataChecksum is not thread safe, so use ThreadLocal to reuse it and keep thread safe.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15829,"The comment of hbase.client.retries.number is:
{code}
  /**  
   * Parameter name for maximum retries, used as maximum for all retryable
   * operations such as fetching of the root region from root region server,
   * getting a cell's value, starting a row update, etc.
   */
  public static final String HBASE_CLIENT_RETRIES_NUMBER = ""hbase.client.retries.number"";
{code}

In branch-1, the max attempts number equals with hbase.client.retries.number. But in master, the max attempts number equals with hbase.client.retries.number + 1.

For RpcRetryingCaller.
{code}
this.retries = retries; // branch-1
{code}
{code}
this.maxAttempts = retries + 1; // master
{code}

For AsyncProcess:
{code}
    this.numTries = conf.getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER,
        HConstants.DEFAULT_HBASE_CLIENT_RETRIES_NUMBER); // branch-1
{code}
{code}
    // how many times we could try in total, one more than retry number
    this.numTries = conf.getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER,
        HConstants.DEFAULT_HBASE_CLIENT_RETRIES_NUMBER) + 1; // master
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16590,TestRestoreSnapshotFromClientWithRegionReplicas uses Consistency.STRONG when doing a scan for counting rows. This is not right as it will not send out scan requests to replicas. It caused issue when read replica logic is corrected in HBASE-16345.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16564,"0.98 compiled with hadoop 2.2.0,   so it has some compatibility issues with hadoop 2.7.2 (it seems 2.5.0+ has the same issue),  some counter has been removed.  

IMO we should catch the exception so our ITBLL could go on.

{code}
16/09/06 15:39:33 INFO hbase.HBaseCluster: Added new HBaseAdmin
16/09/06 15:39:33 INFO hbase.HBaseCluster: Restoring cluster - done
16/09/06 15:39:33 INFO hbase.HBaseCommonTestingUtility: Stopping mini mapreduce cluster...
16/09/06 15:39:33 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
16/09/06 15:39:33 INFO hbase.HBaseCommonTestingUtility: Mini mapreduce cluster stopped
16/09/06 15:39:33 ERROR util.AbstractHBaseTool: Error running command-line tool
java.lang.IllegalArgumentException: No enum constant org.apache.hadoop.mapreduce.JobCounter.MB_MILLIS_MAPS
       	at java.lang.Enum.valueOf(Enum.java:238)
       	at org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.valueOf(FrameworkCounterGroup.java:148)
       	at org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.findCounter(FrameworkCounterGroup.java:182)
       	at org.apache.hadoop.mapreduce.counters.AbstractCounters.findCounter(AbstractCounters.java:154)
       	at org.apache.hadoop.mapreduce.TypeConverter.fromYarn(TypeConverter.java:240)
       	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobCounters(ClientServiceDelegate.java:370)
       	at org.apache.hadoop.mapred.YARNRunner.getJobCounters(YARNRunner.java:511)
       	at org.apache.hadoop.mapreduce.Job$7.run(Job.java:756)
       	at org.apache.hadoop.mapreduce.Job$7.run(Job.java:753)
       	at java.security.AccessController.doPrivileged(Native Method)
       	at javax.security.auth.Subject.doAs(Subject.java:422)
       	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
       	at org.apache.hadoop.mapreduce.Job.getCounters(Job.java:753)
       	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1361)
       	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1289)
       	at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList$Generator.jobCompletion(IntegrationTestBigLinkedList.java:543)
       	at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList$Generator.runRandomInputGenerator(IntegrationTestBigLinkedList.java:505)
       	at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList$Generator.run(IntegrationTestBigLinkedList.java:553)
       	at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList$Loop.runGenerator(IntegrationTestBigLinkedList.java:842)
       	at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList$Loop.run(IntegrationTestBigLinkedList.java:892)
       	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
       	at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.runTestFromCommandLine(IntegrationTestBigLinkedList.java:1237)
       	at org.apache.hadoop.hbase.IntegrationTestBase.doWork(IntegrationTestBase.java:115)
       	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112)
       	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
       	at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.main(IntegrationTestBigLinkedList.java:1272)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16504,"The Replication procedure in ReplicationSink.replicateEntries() method is not preserving the timestamp of the cell. 

Pointer to the code:
m = CellUtil.isDelete(cell) ? new Delete(cell.getRowArray(), cell.getRowOffset(),cell.getRowLength()) : new Put(cell.getRowArray(), cell.getRowOffset(),cell.getRowLength());

The Put and Delete constructors called here assign the timestamp with HConstants.LATEST_TIMESTAMP. Instead we need to keep the timestamp of the cell here.

Also there doesn't seem to be a test which checks if replication is preserving the timestamp. 


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16383,"I was recently trying to set up an MR job initialized with TableMapReduceUtil to be ran by Oozie. Oozie offers a way to configure the job by providing an implementation of org.apache.oozie.action.hadoop.OozieActionConfigurator. Unfortunately, this interface is using org.apache.hadoop.mapred.JobConf, not Job. I may be wrong but I believe that everything TableMapReduceUtil does actually maps to the job configuration so it does not really need the Job itself. If this is true, probably it would be more appropriate to use JobConf in TableMapReduceUtil instead of Job? Or provide the methods for both.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15660,"In debugging an ITBLL job which has numerous failures, I saw that instead of the Verify job completing and reporting that there were a large number of UNDEF nodes, the reducers in the Verify were failing due to lack of progress.

The reducer's syslog file was filled with information from the {{dumpExtraInfoOnRefs()}} method. I believe that when a reducer is repeatedly doing these lookups, the MR framework doesn't realize that any progress is being made (nothing is being written to the context) and eventually kills the reducer task. This ultimately causes the entire Verify job to fail because the reducer fails in the same manner each time.

We should make sure to invoke {{context.progress()}} when we do these lookups to let the framework know that we're still doing ""our thing"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15261,"In the region split process, daughter regions are opened in different threads, Throwable t is set in these threads and it is checked in the calling thread. Need to make it volatile so the checking will not miss any exceptions from opening daughter regions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3521,"We have test a cluster which have more than 30,000 regions, max size of a region is 512MB. At this situation, data no more growing, but remove some old data and insert new, and regions will be more and more. And some regions may be very small or empty. This occupies too much heapsize, and will be more if regions cannot be merged. This will limit hbase running for a long time. 
A script that does a survey to remove empty regions, or pick out adjacent small regions that then does the online merge up seems like it would be useful. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15450,"I have difficulties to start HBase using 'install_local_hadoop' each time I have a new workspace. 
Most of the time, I simply remove the sscc coprocessor from hbase-site.xml and hbase can start well.
Since SSCC has not been maintained for a long time, and need more effort to test it again. So I think we should disable it totally and remove it from hbase-site.xml",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15313,"Getting this error while compiling hbase-0.98.8 using this command *mvn package -DskipTests""* with JAVA8.

{quote} PoolMap.java error: name clash: remove(K,V) in PoolMap and remove(Object,Object) in Map have the same erasure, yet neither overrides the other {quote}

However its working when tried Java7. Sorry If I sound less informative about error. I am a newbie and not very familiar with the issue posting practice :) ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10877,"Example where retries do not make sense:
{noformat}
2014-03-31 20:54:27,765 WARN [InputInitializer [Map 1] #0] org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation: Encountered problems when prefetch hbase:meta table: 
org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=35, exceptions:
Mon Mar 31 20:45:17 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: class com.google.protobuf.HBaseZeroCopyByteString cannot access its superclass com.google.protobuf.LiteralByteString
Mon Mar 31 20:45:17 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:45:17 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:45:18 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:45:20 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:45:24 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:45:34 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:45:45 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:45:55 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:46:05 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:46:25 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:46:45 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:47:05 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:47:25 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:47:45 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:48:05 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:48:25 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:48:46 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:49:06 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:49:26 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:49:46 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:50:06 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:50:26 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:50:46 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:51:06 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:51:26 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:51:46 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:52:06 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:52:27 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:52:47 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:53:07 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:53:27 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:53:47 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:54:07 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString
Mon Mar 31 20:54:27 UTC 2014, org.apache.hadoop.hbase.client.RpcRetryingCaller@343d511e, java.lang.IllegalAccessError: com/google/protobuf/HBaseZeroCopyByteString

	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136)
	at org.apache.hadoop.hbase.client.HTable.getRowOrBefore(HTable.java:751)
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:147)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.prefetchRegionCache(ConnectionManager.java:1167)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegionInMeta(ConnectionManager.java:1232)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1119)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1102)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1061)
	at org.apache.hadoop.hbase.client.HTable.finishSetup(HTable.java:347)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15089,"Previously in 0.98 HTable#flushCommits throws InterruptedIOException and RetriesExhaustedWithDetailsException, but now in 1.1.2 this method signature has been changed to throw IOException, which will force application code changes for exception handling (previous catch on InterruptedIOException and RetriesExhaustedWithDetailsException become invalid). HTable#put has the same problem.

After a check, the compatibility issue was introduced by HBASE-12728. Will recover the compatibility In this JIRA.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2972,"Red Hat's version of Eclipse barfs all over the place on HBase code. The problem is technically inappropriate use of the @Override decorator. See http://download.oracle.com/javase/1.5.0/docs/api/java/lang/Override.html. Should only be used when a method declaration is intended to override a method declaration in a superclass, NOT an interface. 

Attached janitorial patches removes all inappropriate @Override decorators on interface methods on trunk and 0.20 branch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2243,"The Regions on FS metric is almost always bigger than the real number of regions, it means we somehow not always clean region directories and they pile up. I guess it shouldn't be too hard spending some time loading a system until it gets wrong and then see why.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14444,"At home page of Master/RegionServer/Thrift UI, ""Home"" link is redirecting to jsp file. Home link is working fine from other page.
We need to keep it same as ""HBase Logo"" link.

In MasterStatusTmpl.jamon, ""/master-status"" should be configured instead of ""/""
{code}
<li class=""active""><a href=""/"">Home</a></li>
{code}


In RSStatusTmpl.jamon, ""/rs-status"" should be configured instead of ""/""
{code}
<li class=""active""><a href=""/"">Home</a></li>
{code}


In thrift.jsp, ""/thrift.jsp"" should be configured instead of ""/""
{code}
<li class=""active""><a href=""/"">Home</a></li>
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14412,"Created replication peer POB3-HBASE-LL-A750A. By mistake used hyphens in the replication peer name.
- Did {{remove_peer POB3-HBASE-LL-A}}
- Created a new peer POB3_HBASE_LL_A
- Verified zk for entries
{noformat}
ls /hbase/replication/peers 
[POB3_HBASE_LL_A",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14399,"In method run() of class HRegionServer( hbase-server\src\main\java\org\apache\hadoop\hbase\regionserver\HRegionServer.java).

The first dummy catch block catch (KeeperException.NoNodeException nn)
performs no actions to handle its expected exception, which makes itself useless. 

To fix this bug, developers should add more code into the catch block to handle this exception.

public void run() {
...
try {
 deleteMyEphemeralNode();
}catch (KeeperException.NoNodeException nn){
}catch (KeeperException e) {
 LOG.warn(""Failed deleting my ephemeral node"",e);
}
...
}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5249,"After acquiring an explicit row lock, if one attempts to send {{Put}} after the row lock has expired, an NPE is triggered in the RegionServer, instead of throwing an {{UnknownRowLockException}} back to the client.
{code}
2012-01-20 17:09:54,074 ERROR
org.apache.hadoop.hbase.regionserver.HRegionServer: Error obtaining
row lock (fsOk: true)
java.lang.NullPointerException
       at java.util.concurrent.ConcurrentHashMap.put(ConcurrentHashMap.java:881)
       at org.apache.hadoop.hbase.regionserver.HRegionServer.addRowLock(HRegionServer.java:2313)
       at org.apache.hadoop.hbase.regionserver.HRegionServer.lockRow(HRegionServer.java:2299)
       at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
       at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
       at java.lang.reflect.Method.invoke(Method.java:597)
       at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
       at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1327)

It happened only once out of thousands of RPCs that grabbed and
released a row lock.
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6452,HConnectionManager has processSingleMultiPut and processBatchOfMultiPut which are both very similar. Integrating both.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14179,"In method ""markRegionsRecovering()"" of class: hbase-1.1.1\hbase-server\src\main\java\org\apache\hadoop\hbase\coordination\ZKSplitLogManagerCoordination.java
""InterruptedException"" is catched twice.

  public void markRegionsRecovering(final ServerName serverName, Set<HRegionInfo> userRegions)
      throws IOException, InterruptedIOException {
...
   try {
            Thread.sleep(20);
          } catch (InterruptedException e1) {
            throw new InterruptedIOException();
          }
        } catch (InterruptedException e) {
          throw new InterruptedIOException();
        }
...
}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14088,We never close connection in LoadTestTool#applyColumnFamilyOptions,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13785,"We already have metrics for average response time, will be nice to have metrics for average response size. Time might vary a lot depending on the size.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13404,"Bytes has these 4 functions for a lot of data types, might make sense to add missing ones/fix existing ones related to vint and vlong.
1) read X from byte[]
2) read X from offset in byte[]
3) put X in byte[] at a given offset
4) return byte[] for X

Also add tests for these new/changed functions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13521,"Currently, the readRequestsCount records the request count for both get request(random read) and scan#next request(sequential read). However, the cost of get request and scan#next request are different, and usually the get request is much more heavy than the scan#next. Is it reasonable to create a metric getRequestsCount to record the get request count specifically? Then, we can trigger an alert if getRequestsCount grows too fast because large number of random read requests will cause cluster overload more easily(The readRequestsCount will easily grow fast if there is a scan, however, this may not cause the system overload because sequential read is much more fast). Discussions and suggestions are welcomed! Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5110,"The HLog class (method findMemstoresWithEditsEqualOrOlderThan) has unnecessary if check in a loop.

 static byte [][] findMemstoresWithEditsEqualOrOlderThan(final long oldestWALseqid,
      final Map<byte [], Long> regionsToSeqids) {
    //  This method is static so it can be unit tested the easier.
    List<byte []> regions = null;
    for (Map.Entry<byte [], Long> e: regionsToSeqids.entrySet()) {
      if (e.getValue().longValue() <= oldestWALseqid) {
        if (regions == null) regions = new ArrayList<byte []>();
        regions.add(e.getKey());
      }
    }
    return regions == null?
      null: regions.toArray(new byte [][] {HConstants.EMPTY_BYTE_ARRAY});
  }

The following change is suggested

  static byte [][] findMemstoresWithEditsEqualOrOlderThan(final long oldestWALseqid,
      final Map<byte [], Long> regionsToSeqids) {
    //  This method is static so it can be unit tested the easier.
    List<byte []> regions = new ArrayList<byte []>();
    for (Map.Entry<byte [], Long> e: regionsToSeqids.entrySet()) {
      if (e.getValue().longValue() <= oldestWALseqid) {
        regions.add(e.getKey());
      }
    }
    return regions.size() == 0?
      null: regions.toArray(new byte [][] {HConstants.EMPTY_BYTE_ARRAY});
  }",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6072,"We have a MR job that is very memory bound.  It reads a potentially large row from hbase, then deserializes it into an (even larger) object representation, then does a fair amount of computation requiring memory.  After converting the Result into our object representation we want to free the memory holding the Result to be available for the actual computation of output values.

Currently we have our own custom modified copy of TableRecordReaderImpl to be able to set the Result value to null after reading it, but it's almost entirely a duplicate of hbase's TableRecordReaderImpl so we have to manually keep it up to date with changes to the hbase version.  If the value field of TableRecordReaderImpl were protected instead of private we could use a very simple subclass instead.

Are there any philosophical guidelines about what parts of HBase should or should not be easily extensible?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5899,"In 0.92, HBase local cluster won't start because of trying to connect to local HDFS. This error does not happen in 0.90.
We should not need to connect to HDFS to run a local cluster.

Here is my hbase-site.xml
{code:xml}
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <value>file:///usr/local/hbase/var/hbase</value>
  </property>
</configuration>
{code}

This is the error:
{noformat}
2012-04-30 11:32:22,225 ERROR org.apache.hadoop.hbase.master.HMasterCommandLine: Failed to start master
java.net.ConnectException: Call to localhost/127.0.0.1:8020 failed on connection exception: java.net.ConnectException: Connection refused
    at org.apache.hadoop.ipc.Client.wrapException(Client.java:1095)
    at org.apache.hadoop.ipc.Client.call(Client.java:1071)
    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
    at $Proxy11.getProtocolVersion(Unknown Source)
    at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:396)
    at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:379)
    at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:119)
    at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:238)
    at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:203)
    at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:89)
    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1386)
    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1404)
    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:123)
    at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:185)
    at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:418)
    at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:141)
    at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:103)
    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
    at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:76)
    at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1637)
Caused by: java.net.ConnectException: Connection refused
    at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
    at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
    at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
    at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
    at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
    at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
    at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
    at org.apache.hadoop.ipc.Client.getConnection(Client.java:1202)
    at org.apache.hadoop.ipc.Client.call(Client.java:1046)
    ... 20 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5896,hbase.ipc.warn.response.time and hbase.ipc.warn.response.size need documentation,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5859,"There is a graceful_stop script. This algorithm:

{noformat}
for i = 0 to servers.size {
 regionsInServer = servers[i].regions
 move servers[i].regions to random
 stop servers[i]
 start servers[i]
 move regionsInServer to servers[i] //filled back with the same regions
}
{noformat}

It would be possible to optimize it while keeping data locality with

{noformat}
for i = 0 to servers.size {
 start servers[i*2+1] on the computer of servers[i] // Two RS on the same box
 move servers[i].regions to servers[i*2+1]  // The one on the same box
 stop servers[i]
}
{noformat}

There would be an impact with a fixed port configuration. To fix this, we could:
- use a range of port instead of a single port. This could be an issue for the web port.
- start on a port then reuse the fixed ones when they become available. This is not very elegant if a client code is already using the previous code. Moreover the region server code is written in the meta table.
- do a mix of the two solutions: a range for the server itself, while waiting for the web port to be available.


To be discussed...
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5858,"Since HBase tries to find locations of the Hadoop jars from the environment in certain cases it ends up with extra SLF4j jars coming from Hadoop classpath. When that happens ""SLF4j:CLASSPATH contains multiple SLF4j binding"" warning gets displayed.

The good news here is that the warning is just that -- a warning. The bad news is that it seems this issue will be tricky to fix properly. On one hand we would like Hadoop itself to give us transitive closure of the set of jar files required (computing that in the HBase script is a maintenance nightmare). On the other hand that set of jar files could contain some of the very same jars shipped with HBase.

This problem existed for quiet some time. SLF4j is just the first component to complain.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5710,"In the MiniCluster test environment, an NPE occurs while scanning regions
of a pre-split table with multiple column families. Without this working
in the test environment, you cannot write unit tests for these types of
scenarios.

Add the following to TestMetaScanner to repro:

   @Test
   public void testMultiFamilyMultiRegionMetaScanner() throws Exception {
     LOG.info(""Starting testMetaScanner"");
     final byte[] TABLENAME = Bytes.toBytes(""testMetaScanner"");
     final byte[] FAMILY1 = Bytes.toBytes(""family1"");
     final byte[] FAMILY2 = Bytes.toBytes(""family2"");
     TEST_UTIL.createTable(TABLENAME, new byte[][] {FAMILY1,FAMILY2});
     Configuration conf = TEST_UTIL.getConfiguration();
     HTable table = new HTable(conf, TABLENAME);
     TEST_UTIL.createMultiRegions(conf, table, FAMILY1,
         new byte[][]{
           HConstants.EMPTY_START_ROW,
           Bytes.toBytes(""region_a""),
           Bytes.toBytes(""region_b"")});
     TEST_UTIL.createMultiRegions(conf, table, FAMILY2,
             new byte[][]{
               HConstants.EMPTY_START_ROW,
               Bytes.toBytes(""region_a""),
               Bytes.toBytes(""region_b"")});
     // Make sure all the regions are deployed
     TEST_UTIL.countRows(table);

     // This fails with an NPE currently
     MetaScanner.allTableRegions(conf, TABLENAME, false).keySet();
     table.close();
   }


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4151,"I have generated HFiles using importtsv and tried to bulk load them using completebulkload, even though i have specified the ZK quorum ensemble and client port in hbase-site.xml, completebulkload looks for ZK ensemble and client port in zoo.cfg, even after i have specified parameters in zoo.cfg, i was getting NullPointerException at line 167 in ZKConfig.java

{code}
 if (conf.get(HConstants.CLUSTER_DISTRIBUTED).equals(HConstants.CLUSTER_IS_DISTRIBUTED)
            && value.startsWith(""localhost"")) {
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5043,"Easily reproducible:
  (1) Start habse shell
  (2) Press Ctrl-z, to suspend process
  (3) Run ""fg"", to resume

Now when you type nothing shows up.

An irb shell behaves much more gracefully on Suspend/Resume.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5025,"There are two issues with these threads:
 - there should have a better name.  pool-x-thread-y is the default name given by java.util.concurrent.Executors
 - these threads should not survive to a minicluster shutdown

They are created by org.apache.hadoop.ipc.Server$Listener (with version 0.20.205.0; the code was different before), so the first issue is a hadoop common one. It's unclear for the second one, it could be hadoop-common as well. 

Constructor for org.apache.hadoop.ipc.Server$Listener:
{noformat}
    public Listener() throws IOException {
      //...
      readPool = Executors.newFixedThreadPool(readThreads);  // Lack a ThreadFactory to set the names
      //...
    }
{noformat}


Server#stop shutdowns the thread pool.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5023,"If the minicluster is started/stopped multiple time, there is a new LeaseChecker each time. This thread is not created by HBase but by hdfs.

This is likely to be HDFS-1840, solved in 0.23",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4865,"The javadoc states is asynchronous, but we can see in the implementation on HMaster that the implementation does not use executorService but calls directly process(). This is not true for all methods: enableTable, modifyTable, disableTable are truly asynchronous.

The other impact is that the listeners are not called, as this is done by the executorService.


I don't known if we have to change the documentation or the implementation. For consistency; I would change the implementation, but it may breaks existing code.


Two other comments:
1) There is no real naming pattern here, while it would be useful:
HBaseAdmin#createTable is synchrounous and calls the asynchronous HMaster#createTable 
HBaseAdmin#createTableAsync is asynchrounous and calls the asynchronous HMaster#createTable 
HBaseAdmin#modifyTable is asynchrounous and calls the asynchronous HMaster#modifyTable 
HBaseAdmin#modifyColumn is documented as asynchrounous and calls the synchronous HMaster#modifyColumn

2) the coprocessor ""post"" semantic is not consistent across the services.
- when the service is synchronous, post is called after the services execution (ex: addColumn with the current implementation).
- when the service is asynchronous, post is called after the executorService has registered the service to execute, but the service itself is not executed yet.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4427,"It would be extremely helpful to have standalone HBase default to a non-standard port for running its embedded ZK. This would help to run HBase on the same host where a legitimate fully distributed ZK server, etc.

It seems that the following addition to hbase-default.xml would be enough to make it happen:

{noformat}
+  <property>
+    <name>hbase.zookeeper.property.clientPort</name>
+    <value>4181</value>
+  </property>
{noformat}

This will take care of the master/client for HBase and can be overridden in hbase-site if needed.

Thoughts?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4103,"It would be nice, if possible, to get the region-server metrics in another column in the RegionServer table at the bottom of master.jsp.  For instance, seeing the compaction-queues across all the RegionServers, etc., would be useful.

Granted, frameworks like OpenTSDB can probably do this all out of the box, but having a simple cross-cluster view that is built into HBase would be helpful.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4243,"Now that HBASE-3465 has been integrated, perhaps we should try to auto-detect the HADOOP_HOME setting if it is not given explicitly. Something along the lines of:

{noformat}
# check for hadoop in the path
141	HADOOP_IN_PATH=`which hadoop 2>/dev/null`
142	if [ -f ${HADOOP_IN_PATH} ]; then
143	  HADOOP_DIR=`dirname ""$HADOOP_IN_PATH""`/..
144	fi
145	# HADOOP_HOME env variable overrides hadoop in the path
146	HADOOP_HOME=${HADOOP_HOME:-$HADOOP_DIR}
147	if [ ""$HADOOP_HOME"" == """" ]; then
148	  echo ""Cannot find hadoop installation: \$HADOOP_HOME must be set or hadoop must be in the path"";
149	  exit 4;
150	fi
{noformat}

Thoughts?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11599,BloomFilterFactory.IO_STOREFILE_DELETEFAMILY_BLOOM_ENABLED is not used anywhere. I think we should clean it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13403,"We currently wait whatever is the configured value of hbase.server.thread.wakefrequency or the default 10 seconds. We should have a configuration to control how long we wait until the HDFS is no longer in safe mode, since using the existing hbase.server.thread.wakefrequency property to tune that can have adverse side effects. My proposal is to add a new property called hbase.master.waitonsafemode and start with the current default.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8311,Adding an option to output summaries related to each table into a file in json format. The table information would contain the following details total/online/offline (not deployed)/missing/skipped regions. Also each table would contain a list of errors for the regions for that table.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9833,"So far, when we try to insert to HTableMultiplexer, it returns false if the buffer is full. This forces one to write wrapper code to retry inserting into the buffer. If someone is okay with the put getting blocked while the buffer is flushed, we should block.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9000,This is to address the linear reseek in MemStoreScanner. Currently reseek iterates over the kvset and the snapshot linearly by just calling next repeatedly. The new solution is to do this linear seek up to a configurable maximum amount of times then if the seek is not yet complete fall back to logarithmic seek.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11389,"Over time, features people work get buried in the large heap of config parameters that we have. This task is to find and document all the config parameters in hbase and tag them. This should be automated so that we can run it every now and then and find out the lost configs.

Ideas on how these can be found :
1. Look for Configuration objects and identify where we are setting values.
2. Identify constants/strings that are the parameter names.
3. Identify the constants that are default values.
4. Identify where in the code they are present and tag them appropriately, for example if a constant is being read in a bunch of places like HRegionServer.class, HRegion.class, we can tag it with HRegionServer and HRegion. We can go a bit further and subtag them with the functions they are displayed in.
5. Obtain the comments around the parameter name constants when they are defined.

A few pointers to traversing the java source tree :
http://stackoverflow.com/questions/2183488/traversing-through-the-ast-node
http://www.vogella.com/tutorials/EclipseJDT/article.html",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10109,"When a new table is created we place the primary locations for the regions in a round robin fashion. Because we do this for every newly created table it is possible that some regionservers end up with more regions than the others and if there are more tables in the cluster the difference between a min and max #regions per RS can be larger. 
One small optimization is to sort the RS in ascending order before assigning them regions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12105,"Exists does a proper Get, it does not need to get all the KVs for a row to do an existence check. The first KV itself is a good enough indicator. This will speed up exists().",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9704,"Fixing the following unit tests:
TestCompaction",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11138,"HBaseAdmin#checkSplitKeys() doesn't check for empty split keys, which can cause multiple regions with the same start key (i.e., """"). This diff fixes that.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10538,"In current a Scan for Get, which was created by Scan(Get) and isGetScan returns true, is implemented by setting startRow and stopRow the same, which breaks the definition of Scan for general usage. This fix will set stopRow to a value next to startRow, which makes it accord to normal definition.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10869,"Motivation of doing this is two-folded:

1. local file system is more stable than `MiniDFSCluster`, so for cases only testing on HBase logic, using this may avoid unstable problems caused by DFS unstable problem.
1. Starting of local file systme is much faster.

Currently only a few of the testcases is switch to LFS mode for testing. Some other diff may switch more.

Implementaiton

For `FS_TYPE_DFS`, same as before.
For `FS_TYPE_LFS`, use `LocalFileSystem`",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8775,Throttle the open and close of the regions after an online schema change,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7179,Can save up to 30 secs during shutdown. No point waiting for these threads.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10808,This fix simplifies the Leases to use a ConcurrentHashMap instead of a DelayQueue so as to avoid the Synchronization cost. The LeaseChecker now should check the ConcurrentHashMap periodically to check if a scanner has been inactive for atleast the max time. This has a weaker guarantee on when the lease will be expired but is more efficient and decreases the amount of contention.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9143,"In order to achieve online configurable, some of key HBase configuration knobs needed to be updated on the fly. 
Currently, HBase can be configured to flush multiple Region's memstore in parallel.  And this task is to make the number of flush thread be updated in an online fashion (hbase.regionserver.flusher.count).  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8524,"We've seen in a couple of replication use cases that the client thread keeps waiting for a response but waits for ever, as it does not get a response.

The client waits indefintely even if a rpcTimeout is specified.

1) Need to find out what is causing this. 

2) Convert the unconditional wait() in HBaseClient into a timed wait, so that the client can bail out if it waits longer than the rpcTimeout",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11106,"If we don't change the assignment plan accordingly, the moving of the region may be igonred.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8942,"This is a similar issue as discussed in HBASE-8228

1) A scanner holds the Store.ReadLock() while opening the store files ... encounters errors. Thus, takes a long time to finish.

2) A flush is completed, in the mean while. It needs the write lock to commit(), and update scanners. Hence ends up waiting.

3+) All Puts (and also Gets) to the CF, which will need a read lock, will have to wait for 1) and 2) to complete. Thus blocking updates to the system for the DFS timeout.

Fix:
 Open Store files outside the read lock. getScanners() already tries to do this optimisation. However, Store.getScanner() which calls this functions through the StoreScanner constructor, redundantly tries to grab the readLock. Causing the readLock to be held while the storeFiles are being opened, and seeked.

 We should get rid of the readLock() in Store.getScanner(). This is not required. The constructor for StoreScanner calls getScanners(xxx, xxx, xxx). This has the required locking already.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8292,"Currently, any changes to the configuration options: compaction tuning/etc. requires that we restart the regionserver.

Perhaps, some of the configs can be updated on the fly, without having to restart the region server.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11881,With introduction of swift we have to build composite data structures that can represent a list of KeyValues in a more efficient manner. This can be used both in Put and the Result objects.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11712,"isLegalFamilyName might have a zero length string as the argument, but current code does not check its length and directly try to access.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8221,"Currently, the RS stops responding as soon as the stop is requested. We then go in and close all regions in a 2-flush mechanism.

Ensure that RS will first close the regions, and then stop taking client requests. This will reduce the number of errors seen by the client.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11602,"In case the election znode is deleted (manually for example), the active master should kill itself.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11883,ZookeeperWrapper contains a lot of confusing methods. Combine and redefine them.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8194,"The test creates regions in the meta region and waits for the master to allot them to regionservers. When the favored nodes were set, the timout was not completely reliable to say that they will be set. Instead setting the favored nodes while creating the regions directly in the starting would ensure that the master creates the regions assigning selected favored nodes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8245,"When a dead region server comes up, the regions that belonged to the region server are assigned to it very aggressively. This causes a increase in the get latencies over all these regions which are under movement and hurt the performance. Instead spreading out this process over a period of time will be beneficial.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13360,"I'm very interested in the Raft implementation (in particular, whether it can be reused elsewhere, given that this effort seems likely to produce the canonical Raft implementation).

I'd like to try it standalone, but I'm not yet having much success.

I start a cluster of 3 servers (N=0,1,2):

java -cp ""conf:hbase-consensus/target/hbase-consensus-2.0.0-SNAPSHOT.jar:hbase-consensus/target/dependency/*"" org.apache.hadoop.hbase.consensus.server.LocalConsensusServer -region 1 -servers 127.0.0.1:10000,127.0.0.1:10001,127.0.0.1:10002  -debug DEBUG -localIndex ${N}

And then I try running the load-test client:

java -cp ""hbase-consensus/target/hbase-consensus-2.0.0-SNAPSHOT.jar:hbase-consensus/target/dependency/*"" org.apache.hadoop.hbase.consensus.client.QuorumLoadTestClient -region 1 -servers 127.0.0.1:10000,127.0.0.1:10001,127.0.0.1:10002

That gives an immediate NPE at org.apache.hadoop.hbase.consensus.quorum.QuorumInfo.populateInternalMaps(QuorumInfo.java:315).

Are there any docs on how to get started playing with running this branch?  Thanks!",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12803,"http://hbase.apache.org/book/ops_mgt.html#copytable

The page incorrectly shows some text between two unrelated single quotes, in red. See attached picture.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10776,"HConnectionManager is too large to effectively maintain. This Jira records some refactoring jobs:

1. Move TableServers out as a standalone class
2. Move region-locating code as a class",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13180,"Noticing the test failure frequently on internal test rig. 
{code}
FAILED:  org.apache.hadoop.hbase.regionserver.TestRegionReplicas.testGetOnTargetRegionReplicaError Message:
1

Stack Trace:
java.lang.ArrayIndexOutOfBoundsException: 1
        at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas$ResultBoundedCompletionService.submit(RpcRetryingCallerWithReadReplicas.java:420)
        at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.addCallsForReplica(RpcRetryingCallerWithReadReplicas.java:280)
        at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.call(RpcRetryingCallerWithReadReplicas.java:199)
        at org.apache.hadoop.hbase.client.HTable.get(HTable.java:890)
        at org.apache.hadoop.hbase.regionserver.TestRegionReplicas.testGetOnTargetRegionReplica(TestRegionReplicas.java:193)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11967,"Got this testing 0.99.0 RC.

I started it up after unbundling and got this:

{code}
 99 2014-09-12 14:50:42,761 FATAL [ActiveMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
100 org.apache.hadoop.hbase.util.FileSystemVersionException: HBase file layout needs to be upgraded. You have version null and I want version 8. Consult http://hbase.apache.org/book.html for further information about upgrading HBase. Is your hbase.rootdir valid? If so, you may need to run 'hbase hbck -fixVersionFile'.
101   at org.apache.hadoop.hbase.util.FSUtils.checkVersion(FSUtils.java:587)
....
{code}

But now my master is stuck trying to become master in here:

{code}
 46 ""main"" prio=5 tid=0x00007fe825001000 nid=0x1303 waiting on condition [0x0000000107383000]
 47    java.lang.Thread.State: TIMED_WAITING (sleeping)
 48   at java.lang.Thread.sleep(Native Method)
 49   at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:218)
 50   at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:438)
 51   at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:188)
 52   at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:139)
 53   at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
 54   at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
 55   at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1794)
...

{code}

Any ideas [~jxiang]?  Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10603,RegionSplitter is a utility for partitioning a table based on some split algorithm. Those same algorithms are exposed via the shell create command. There's no value in having two ways to access the same functionality. Ensure the main method doesn't provide any functionality absent from the shell and remove it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10846,"Links between active and backup masters are broken for the the blanks before info port in the url.
{code}
href=""//wcc-hadoop-tst-ct01.bj: 12501/master-status""
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11582,"Recent precommit builds shows some javadoc warnings here
{code}
[WARNING] Javadoc Warnings
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase-server/src/main/java/org/apache/hadoop/hbase/io/DataInputInputStream.java:32: warning - Tag @see: reference not found: DataOutputOutputStream
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheConfig.java:99: warning - Tag @link: can't find BUCKET_CACHE_COMBINED_PERCENTAGE_KEY in org.apache.hadoop.hbase.io.hfile.CacheConfig
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13033,Currently in MemstoreFlusher the check for maximum allowed memstore size is set to 90% and it should be 80%,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12977,"If enable multi callQueues , handlers may not be distributed evenly among multi queues, which mean the queue's capacity is not the same. Should we make handler's distribution even? ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3599,"The Result(List<KeyValue>) and Result(KeyValue[]) constructor assume that the input is already sorted (HBASE-3073, HBASE-2753).  This works for normal use cases, but not for hand constructed Result objects (e.g. unit tests).

I encountered this when upgrading to 0.90 that some unit tests now failed due to this.  One fix is to add some documentation on the constructors that says the input MUST be sorted.  The other would be to explicitly sort the items (not so desirable).


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8121,"This doesn't seems to cause any issue, but should not ReplicationSink#batch() take a look at the batch call results?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6121,"We shouldn't clear an ArrayList that might be iterated on by another thread.

Specifically, multiput() calls clear() on ArrayList (to free up some memory) while MultiPut.toMap is iterating over that ArrayList in a different thread (called from MonitorTasks UI)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6760,"The issue seems to exists due to oversight during the rewrite. In line 1289, the variable 'plans' is created as a 'new ArrayList<RegionPlan>()' and then in line 1298, balancerRan is calculated as (plans != null) which for obvious reason, will always return true.

{code:title=HMaster.java (trunk:1383496)}
....
1289        List<RegionPlan> plans = new ArrayList<RegionPlan>();
1290        //Give the balancer the current cluster state.
1291        this.balancer.setClusterStatus(getClusterStatus());
1292        for (Map<ServerName, List<HRegionInfo>> assignments : assignmentsByTable.values()) {
1293          List<RegionPlan> partialPlans = this.balancer.balanceCluster(assignments);
1294          if (partialPlans != null) plans.addAll(partialPlans);
1295        }
1296        int rpCount = 0;  // number of RegionPlans balanced so far
1297        long totalRegPlanExecTime = 0;
1298        balancerRan = plans != null;
1299        if (plans != null && !plans.isEmpty()) {
....
{code}

A simple fix is to initialize 'balancerRan' to 'false', remove ""balancerRan = plans != null"" and add ""balancerRan = true"" after ""if (plans != null && !plans.isEmpty()) {"".

However, a question remains that should we call ""this.cpHost.postBalance();"" if the balancer did not run at this point?

I'll attach the patch shortly if I get a confirmation on this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7275,[89-fb] Fixing some minor bugs in 89-fb branch based on the findBugs report,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4201,Delayed RPC crashes if return value is not delayed and endDelay is called before the actual function returns a value.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6042,"Given the implementation of ScanQueryMatcher, we check 
filter.filterKeyValue()

before determining weather we are going to include the KV in the
result or not. Thus, if the scan/get were to specify columns other
than the very first column in the row, they get nothing because
the filter removes everything else.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5756,This can be a point of concern when on a certain day the logging happens more because of more and more activity. In that case the log file for that day can grow huge. These logs can not be opened for analysis since size is more.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5082,"I was trying to use the ColumnAggregationEndPoint.sum().
 
In my sample is just created a column family but did not use any qualifier and inserted some data.
 
I tried to use  ColumnAggregationEndPoint.sum(qualifier, null).  When i did this inside the ColumnAggregationEndPoint we do 
scan.addColumn().  This is adding the [null] array in the scan object.  Later in the scanQueryMatcher it is throwing nullpointer exception.  
I can understand that addColumn() is to specifiy the qualifier.
Do we need to document somewhere saying qualifier should not be null? I think coprocessors can be used even in places where we don't have qualifiers. If that is the case this sample ColumnAggregationEndPoint may not work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4975,"Hadoop QA generated comments based on patches submitted to JIRAs; for example:

https://issues.apache.org/jira/browse/HBASE-4960?focusedCommentId=13163191&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13163191

There are some spurious -1's given to the patch. The patch only affects documentation, not source code, but Hadoop QA says that:
{noformat}
-1 findbugs. The patch appears to introduce 72 new Findbugs (version 1.3.9)
warnings.
{noformat}

Evidently Hadoop QA is not able to recall the set of Findbugs warnings from the previous build.

(Of course the Findbugs warnings themselves should be addressed, but this patch could not have added to them).

{noformat}
-1 javadoc. The javadoc tool appears to have generated -160 warning
messages.
{noformat}

This should be ""160 warning messages"", not ""-160 warning messages"".

Thanks to NKeywal for suggesting that the relevant file is {{dev-support/test-patch.sh}}.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12805,"When I added hbase-client as a dependency in Nutch's ivy.xml. 

{code}
<dependency org=""org.apache.hbase"" name=""hbase-client"" rev=""0.98.8-hadoop2"" conf=""*->default"">
{code}
Ivy can not resolve hbase-common and hbase-annotations in compile scope rather than hbase-protocol. It sees these dependencies in test scope and map to runtime and master scope. they looks like below in hbase-client resolved ~/.ivy2/cache/org.apache.hbase/hbase-client/ivy-0.98.8-hadoop2.xml file :

{code}
<dependency org=""org.apache.hbase"" name=""hbase-annotations"" rev=""0.98.8-hadoop2"" force=""true"" conf=""test->runtime(*),master(*)""/>
<dependency org=""org.apache.hbase"" name=""hbase-annotations"" rev=""0.98.8-hadoop2"" force=""true"" conf=""test->runtime(*),master(*)"">
  <artifact name=""hbase-annotations"" type=""test-jar"" ext=""jar"" conf="""" m:classifier=""tests""/>
</dependency>
<dependency org=""org.apache.hbase"" name=""hbase-common"" rev=""0.98.8-hadoop2"" force=""true"" conf=""test->runtime(*),master(*)""/>
<dependency org=""org.apache.hbase"" name=""hbase-common"" rev=""0.98.8-hadoop2"" force=""true"" conf=""test->runtime(*),master(*)"">
  <artifact name=""hbase-common"" type=""test-jar"" ext=""jar"" conf="""" m:classifier=""tests""/>
</dependency>
<dependency org=""org.apache.hbase"" name=""hbase-protocol"" rev=""0.98.8-hadoop2"" force=""true"" conf=""compile->compile(*),master(*);runtime->runtime(*)""/>
{code} 

Not only Hbase-client. Other Hbase modules have same problem. Do you have any idea ?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4038,"We should provide a basic way for end users to operationally diagnose hot row problems.  Thinking about a 2-phase approach:

1. Diagnose hot regions
2. Inspect those regions/servers to find the hot rows.

To diagnose hot regions, we could query the master or regionservers for these regions + sort.  To inspect the regions for hot rows, we could write another script to analyze the HLogs on a server and basically do: sort log|uniq -n|sort -n|top",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3761,"Creating hundreds of tables with hundreds of regions I ran into this issue doing mass table delete:

{code}
11/04/09 10:26:06 WARN client.HConnectionManager$HConnectionImplementation: Encountered problems when prefetch META table:
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in .META. for table: bbb_48, row=bbb_48,T锟紻锟斤拷iy%锟斤拷,99999999999999
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:136)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:95)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:648)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:702)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:593)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.relocateRegion(HConnectionManager.java:564)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getRegionLocation(HConnectionManager.java:415)
        at org.apache.hadoop.hbase.client.ServerCallable.instantiateServer(ServerCallable.java:57)
        at org.apache.hadoop.hbase.client.ScannerCallable.instantiateServer(ScannerCallable.java:63)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getRegionServerWithRetries(HConnectionManager.java:1011)
        at org.apache.hadoop.hbase.client.HTable$ClientScanner.nextScanner(HTable.java:1077)
        at org.apache.hadoop.hbase.client.HTable$ClientScanner.initialize(HTable.java:1000)
        at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:533)
{code}

The table was probably removed between start of prefetch scan and next invocation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4615,"In checking our package manifests for BigTop, we found a number of source files are set with incorrect permissions:

hbase-0.90.4-cdh3u2/docs/apidocs/org// are set to +x
hbase-0.90.4-cdh3u2/docs/* are set to +x ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4306,"It is possible for the LoadBalancer to try to assign an offline/split region while it is waiting to be CatalogJanitor'ed. It goes like this:

{quote}
2011-08-25 00:32:07,137 INFO org.apache.hadoop.hbase.master.ServerManager: Received REGION_SPLIT: parent: Daughters; d1, d2 from sv4r22s16,60020,1314211225331
...
(cleaning never happens or whatever)
...
2011-08-29 13:45:14,561 INFO org.apache.hadoop.hbase.master.HMaster: balance hri=parent, src=sv4r22s16,60020,1314211225331, dest=sv4r19s17,60020,1314218170402
2011-08-29 13:45:14,561 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region parent (offlining)
2011-08-29 13:45:14,588 INFO org.apache.hadoop.hbase.master.AssignmentManager: Server serverName=sv4r22s16,60020,1314211225331, load=(requests=0, regions=0, usedHeap=0, maxHeap=0) returned org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Received close for parent but we are not serving it for parent
{quote}

Here it took 4 days of balancing to finally get to try to balance the parent (that was never deleted because of HBASE-4238), but it can also happen if the balancer decides to balance the parent just before it's cleaned. The end effect is that the balancer will be disabled _forever_ until that's fixed.

The culprit here is that the master keeps the region ""online"" until AssignmentManager.regionOffline is called by the CJ, which means it's still treated like any other region although it's offline.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3592,"Running some of the bulk load tools (importtsv, completebulkload, etc.) is a bit awkward from the user perspective. When a user is used to interacting with HBase from the shell, the expectation is kind of set that the shell is the definitive place to be working with their data. However, in order to do bulk load operations, they need to switch gears and submit a MR job. Not a big deal for everyday Hadoop users, but it gets confusing for the HBase-only user.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11962,"This issue is to backport the commands for appending and removing peer table-cfs for replication to 0.98

Two new commands, append_peer_tableCFs and remove_peer_tableCFs, are added to do the operation of adding and removing a table/table-column family.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12132,mvn install -Dtest=<testclass> runs tests in it and they time out. This Jira is intended to fix that behavior. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12177,"TestIPv6NIOServerSocketChannel hangs consistently on Java 8u20. jstack dump attached. This is on a 64-bit Ubuntu 14.04 system kernel ""Linux version 3.13.0-29-generic (buildd@toyol) (gcc version 4.8.2 (Ubuntu 4.8.2-19ubuntu1) ) #53-Ubuntu SMP Wed Jun 4 21:00:20 UTC 2014""

{noformat}
""pool-1-thread-1"" #9 prio=5 os_prio=0 tid=0x00007ff330707000 nid=0x41a8 runnable [0x00007ff309e8f000]
   java.lang.Thread.State: RUNNABLE
	at java.net.PlainSocketImpl.socketBind(Native Method)
	at java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:382)
	- locked <0x00000000e1c004e0> (a java.net.SocksSocketImpl)
	at java.net.ServerSocket.bind(ServerSocket.java:375)
	at java.net.ServerSocket.bind(ServerSocket.java:329)
	at org.apache.hadoop.hbase.TestIPv6NIOServerSocketChannel.bindServerSocket(TestIPv6NIOServerSocketChannel.java:60)
	at org.apache.hadoop.hbase.TestIPv6NIOServerSocketChannel.testServerSocketFromLocalhostResolution(TestIPv6NIOServerSocketChannel.java:149){noformat}

I am going to disable this test in 0.98 branch for now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12179,TestConstraints intermittently hangs on Java 8. There are a few things this test could be doing better. Looking at it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8619,"In our rolling upgrade testing, running ImportTsv failed in the job submission phase when the master was down. This was when the master was failing over to the backup master. In this case, a retry would have been helpful and made sure that the job would get submitted.

A good solution would be to refresh the master information before placing the call to getHTableDescriptor.

Command:
{code} sudo -u hbase hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=HBASE_ROW_KEY,c1,c2,c3 -Dimporttsv.bulk.output=/user/hbase/storeFiles2_2/import2_table1369439156 import2_table1369439156 /user/hbase/tsv2{code}

Here is the stack trace:

{code} 13/05/24 16:55:49 INFO compress.CodecPool: Got brand-new compressor [.deflate]
16:45:44  Exception in thread ""main"" java.lang.reflect.UndeclaredThrowableException
16:45:44  	at $Proxy7.getHTableDescriptors(Unknown Source)
16:45:44  	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getHTableDescriptor(HConnectionManager.java:1861)
16:45:44  	at org.apache.hadoop.hbase.client.HTable.getTableDescriptor(HTable.java:440)
16:45:44  	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.configureCompression(HFileOutputFormat.java:458)
16:45:44  	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.configureIncrementalLoad(HFileOutputFormat.java:375)
16:45:44  	at org.apache.hadoop.hbase.mapreduce.ImportTsv.createSubmittableJob(ImportTsv.java:280)
16:45:44  	at org.apache.hadoop.hbase.mapreduce.ImportTsv.main(ImportTsv.java:424)
16:45:44  Caused by: java.io.IOException: Call to hbase-rolling-6.ent.cloudera.com/10.20.186.99:22001 failed on local exception: java.io.EOFException
16:45:44  	at org.apache.hadoop.hbase.ipc.HBaseClient.wrapException(HBaseClient.java:1030)
16:45:44  	at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:999)
16:45:44  	at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:86)
16:45:44  	... 7 more
16:45:44  Caused by: java.io.EOFException
16:45:44  	at java.io.DataInputStream.readInt(DataInputStream.java:375)
16:45:44  	at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.receiveResponse(HBaseClient.java:646)
16:45:44  	at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.run(HBaseClient.java:580){code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11614,MAX_FILESIZE = 0 doesn't make sense. We should avoid creating such tables.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3558,"Last night we ran into a problem with the times on RSs being out of sync by 1 minute. The times were being reset by ~70s often because we were getting different responses from pool.ntpd.org.

This caused lost ZK sessions and problems writing to datanodes,  so all the RSs kept shutting down.

I think it would be useful to have HBaseFsck check to see if the times on the region servers are out of sync. Or maybe put a warning on the master web ui or something. 

This seems related to HBASE-3168, but applies when region servers become out of sync once they already joined the cluster (due to NTP issues or something else).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11695,"We just ran into a flush storm caused by the PeriodicFlusher.
Many memstore became eligible for flushing at exactly the same time, the effect we've seen is that the exact same region was flushed multiple times, because the flusher wakes up too often (every 10s). The jitter of 20s is larger than that and it takes some time to actually flush the memstore.

Here's one example. We've seen 100's of these, monopolizing the flush queue and preventing ""important"" flushes from happening.

{code}
06-Aug-2014 20:11:56  [regionserver60020.periodicFlusher] INFO  org.apache.hadoop.hbase.regionserver.HRegionServer[1397]-- regionserver60020.periodicFlusher requesting flush for region tsdb,\x00\x00\x0AO\xCF* \x00\x00\x01\x00\x01\x1F\x00\x00\x03\x00\x00\x0C,1340147003629.ef4a680b962592de910d0fdeb376dfc2. after a delay of 13449
06-Aug-2014 20:12:06  [regionserver60020.periodicFlusher] INFO  org.apache.hadoop.hbase.regionserver.HRegionServer[1397]-- regionserver60020.periodicFlusher requesting flush for region tsdb,\x00\x00\x0AO\xCF* \x00\x00\x01\x00\x01\x1F\x00\x00\x03\x00\x00\x0C,1340147003629.ef4a680b962592de910d0fdeb376dfc2. after a delay of 14060
{code}

So we need to increase the period of the PeriodicFlusher to at least the random jitter, also increase the default random jitter (20s does not help with many regions).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6517,"Hadoop common is adding a JUnit run listener which prints full thread dump into System.err when a test is failed due to timeout. See HDFS-3762.

Suggest pulling in their {{TestTimedOutListener}} once it is committed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11638,So single server dev clusters don't inexplicably fail to start. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3442,"We've got our servers running on Amazon EC2 and nodes will go through some shutdown scripts if/when we want to take them out of the mix.  Ended up shutting down one of the nodes, in this case Node98, which cased the immediate crash of the master server.  Upon restarting the master, it would attempt to contact the missing node, and then stop it's startup process.  I believe the node removed itself from the DNS server first, then ran a stop on the datanode, and regionserver.  The missing node was also removed from any slave/regionserver list on the master server.  I finally put in a bogus entry in the /etc/hosts file for the missing node, pointing it back to 127.0.0.1, and the master server finally marked it as a dead node, ignored it, and finished the startup process.

Going to try and replicate it again and save some more logs, the following log is the only thing I saved from the first occurrence;  It's the master failing to start up while checking for the missing node:  http://pastebin.com/ZyQMQm91",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3414,"I have a project assuming dynamic HBase schema and I would like to be able to create tables and families on the fly. For performance reasons, I was going to react to exceptions like NoSuchColumnFamilyException rather than checking for family validity, alter the table appropriately and repeat the put(). However, it turned out that this exception only contains a human-readable message. Please add two more fields to this class: table and family names.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3319,"A useful check to add to HBCK is a way to estimate the max # of files that a cluster should have and raise a warning/error if the file count goes above that threshold.   We ran into an issue this week where our "".oldlogs"" folder filled up to 100k files because 'hbase.master.logcleaner.maxdeletedlogs"" was set too low.  We found this because of faulty region count metric in the HTTP server that actually showed the file count.  Adding an HBCK check would provide an extra layer of detection to find leaks from new features or conservatively configured cleanup thresholds.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11300,"For the checkAndPut operation, the AccessController only checks the read and write permission for the family and qualifier to check, but ignores the write permission for the family map of ""put"". What's more,  we don't need the write permission for the family and qualifier to check.

See the code AccessController.java #1538
{code}
    Map<byte[],? extends Collection<byte[]>> families = makeFamilyMap(family, qualifier);
    User user = getActiveUser();
    AuthResult authResult = permissionGranted(OpType.CHECK_AND_PUT, user, env, families,
      Action.READ, Action.WRITE);
{code}

Same problem for checkAndDelete operation.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3188,"AssignmentManager.regionPlans is currently a ConcurrentSkipListMap so does not require synchronization.  But sometimes we do multiple operations and we synchronize on it.  But other times we don't synchronize on it at all.

Let's review and make sure we're doing the right thing.

Also see if we still need this AssignmentManager.updateTimers().  Don't we disable load balancer / expiration during startup or no?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3078,"It happens very rare (was seen only once yet), but looks like it was caused inside HBase TableOutputFormat class while running periodic mapreduce job on my cluster.

Here is a task log for failed task:

2010-10-04 12:08:00,339 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.lang.IndexOutOfBoundsException: toIndex = 850
	at java.util.SubList.<init>(Unknown Source)
	at java.util.RandomAccessSubList.<init>(Unknown Source)
	at java.util.AbstractList.subList(Unknown Source)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:611)
	at org.apache.hadoop.hbase.mapreduce.TableOutputFormat$TableRecordWriter.close(TableOutputFormat.java:80)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:567)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:408)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)
2010-10-04 12:08:00,343 INFO org.apache.hadoop.mapred.TaskRunner: Runnning cleanup for the task

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3029,"During a scan if the HFile layer throws a unrecoverable IOE, for example, checksum exception, right now we throw the exception, and abort that RPC.  But the scanner is not marked as closed, and the HFileScanner is left in a weird state.  Subsequent calls get weird exceptions about ByteBuffers but this is an artifact of being left pointing at the end of the previous block when we should be into the next block.

If the DFSClient throws an exception we have a choice:
- make some efforts to retry
- assume DFSClient has already tried, and thus this is a fatal type error

The former case might be hard to implement, and the latter case needs to be handled so that subsequent calls to the scanner throw meaningful exceptions.  Right now there is no way to early terminate a scanner from the server-side... HRegion$RegionScanner doesn't have a 'closed' flag nor does it have the ability to realize the scanner is now closed.  The client side takes care of not iterating past the end of a scanner so in the normal case we dont iterate anymore once a scanner returns 'false'.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2877,"When {{HbaseObjectWritable#writeObject}} serializes a {{Writable}} RPC parameter, it writes its ""class code"" twice to the wire.  {{writeClassCode}} is already called once unconditionally at the beginning of the method, and for {{Writable}} arguments, it's called a second time towards the end of the method.  It seems that the code is trying to deal with the ""declared type"" vs. ""actual type"" of a parameter.  The Hadoop RPC code was already doing this before Stack changed it to use codes in r608738 for HADOOP-2519.  It's not documented when this is useful though, and I couldn't find any use case.  Every RPC I've seen so far just ends up with the same byte sent twice to the wire.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2826,"As per users@hbase.apache.org thread: http://mail-archives.apache.org/mod_mbox/hbase-user/201007.mbox/%3CAANLkTimyCtWiuNxWw9P2IFAy6Y4Q7X8oLZSZNdggV3Nn@mail.gmail.com%3E

I setup HBase (and as such, Zookeeper) on Ubuntu Karmic using the Cloudera Karmic CDH3 distribution. Zookeeper has installed fine, however when it comes to starting an hbase master, it falls over with the following exception:

(stack trace summarised to last bit)
Caused by: java.io.EOFException
   at java.io.DataInputStream.readInt(DataInputStream.java:375)
   at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:508)
   at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)

The cause was that the hbase.rootdir was incorrectly set to hdfs://master:50071/hbase, when it should have been set to port 50070. After remedying this hbase master started fine.

I was asked to raise this as a JIRA to investigate the possibility of improving the handling of the EOFException to perhaps indicate more clearly to the user that an incorrect address has been specified for the rootdir, rather than the very unclear statement above.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2778,Seeing a very occasional (maybe one in 40) failure of this unit test.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2773,"I had some failed test due to this last weekend, but can't find the trace now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2637,"If a table is disabled when HBase is started up, then ""HTTP ERROR  500"" will happen when view this table in table.jsp",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2304,"When there is a error given in the UI/JSPs, the HTTP status code is not set accordingly.

For example, if the page output for master.jsp is:

{{HTTP ERROR: 500
Trying to contact region server null for region , row '', but failed after 3
attempts.
Exceptions:
org.apache.hadoop.hbase.NotServingRegionException:
org.apache.hadoop.hbase.NotServingRegionException: -ROOT-,,0}}

The HTTP status code sent with the response is still ""HTTP/1.1 200 OK"".  This is a red herring for some types of monitoring, though it is debatable if an HTTP status code of 4xx/5xx reflect the server state or the state of the system being monitored.  It may well be that HTTP 200 is OK, since the HTTP UI is responsive and correctly indicating a failed HBase cluster.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2292,"I'm grabbing my own {{RowLock}} on a given row and then I want to do an ICV on the row (among other things) while I hold the lock.  Unlike {{Get}}, {{Put}} and whatnot, there's no way to specify your own {{RowLock}} when doing an ICV.  Technically, you can live without this since you can get just a {{Get}} followed by a {{Put}} after having manually incremented the value, which is guaranteed to work as you hold the {{RowLock}} on that row, but it would be nice to be able to just do an ICV.

Right now, {{incrementColumnValue}} attempts to lock the row again (which is normal), thus causing my client to ""deadlock"" itself until its {{RowLock}}'s lease expires.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2071,"When adding columns to a Scan, using ""addColumns"" or ""addColumn"" (with single argument) the order in which they are added matters.  When adding columns as distinct family and qualifier (2 arguments) this is not a problem.  It is only a problem when adding as a single argument.

For example:
user> (scan ""t1"" {:columns [ ""f1:"" ""f1:hello"" ] })
cols are: [f1: f1:hello]
col: f1:  --  
col: f1:hello  --  world

user> (scan ""t1"" {:columns [ ""f1:hello"" ""f1:"" ] })
cols are: [f1:hello f1:]
col: f1:hello  --  world
col: f1:  --  v1

In the first call to ""scan,"" the arguments are in lexicographic order, and this results in the value associated with ""f1"" to be left out.  In the second call to ""scan,"" the arguments are in reverse order, and the results are valid.

Sorry the example is in Clojure.  In essence, this is what's happending:

This doesn't work:
myScan.addColumn(""f1:"")
myScan.addColumn(""f1:hello"")

This works:
myScan.addColumn(""f1:hello"")
myScan.addColumn(""f1:"")

I have omitted the code which creates a scanner with this scan, returns the results, and then prints them.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1565,"Every developer that works with HBase ends up inevitably writing all sorts of rsync and kill scripts. These scripts usually end up failing from time to time as our system changes. I think we should maintain some of these capabilities in our bin/ scripts directly to ease the work of our users/developers.

For the record Hadoop has recently put in similar sort of stuff in bin/hadoop-daemon.sh:

{code}
    if [ ""$HADOOP_MASTER"" != """" ]; then
      echo rsync from $HADOOP_MASTER
      rsync -a -e ssh --delete --exclude=.svn --exclude='logs/*' --exclude='contrib/hod/logs/*' $HADOOP_MASTER/ ""$HADOOP_HOME""
    fi
{code}

Whatever we add can be extra options, like this $HADOOP_MASTER variable above, so that the normal operation of the scripts is not affected.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1452,"From an irc conversation
(12:43:54 PM) posix4e: ok sorry to keep on bothering y'all but I seem to have more than one directory per regionserver in the .logs file. 
(12:44:00 PM) posix4e: but one of them is empty
(12:44:04 PM) posix4e: soo if the node is called foo
(12:44:07 PM) iand left the room (quit: Connection timed out).
(12:44:24 PM) posix4e: foo_1243299289601_60020
(12:44:24 PM) posix4e: foo_1243299289601_60020
(12:44:30 PM) posix4e: would both exist, and one would be empty
(12:59:16 PM) St^Ack: both named the same?
(1:27:42 PM) posix4e: St^Ack: same hostname yea
(1:29:45 PM) St^Ack: posix4e: all is the same?  Even the startcode?
(1:29:50 PM) St^Ack: how can you have to dirnames sam?
(1:30:08 PM) nitay: St^Ack, sounds good :)
(1:30:37 PM) posix4e: so if the the name of the directory looks like
(1:30:37 PM) posix4e: hostname__stuff_port
(1:30:44 PM) posix4e: then stuff would be different and that's it
(1:33:58 PM) St^Ack: the 'stuff' is different in each case?
(1:34:03 PM) posix4e: yea
(1:34:07 PM) ***St^Ack the 'stuff' is the server startcode
(1:34:08 PM) St^Ack: ok...
(1:34:21 PM) St^Ack: well, here is what I speculate....
(1:34:33 PM) St^Ack: The server was restarted
(1:34:37 PM) St^Ack: got a new startcode
(1:34:39 PM) St^Ack: made a new dir
(1:35:10 PM) St^Ack: the old one, if it had logs in it -- i.e. wasn't shutdown clean -- then its logs were replayed by master (or should have been)
(1:35:19 PM) St^Ack: master should have cleaned it up
(1:35:24 PM) St^Ack: when done
(1:35:34 PM) St^Ack: or regionserver on clean shutdown should have cleaned it up when done
(1:35:39 PM) St^Ack: posix4e: please make an issue
(1:35:49 PM) posix4e: St^Ack: kk
(1:35:56 PM) St^Ack: else our logs dir will be flooded w/ empty dirs
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-420,"Region merge functionality exists in HBase today, but merges are triggered manually (in theory only, because there is no admin tool for doing so). Instead of relying on an admin to note and merge regions, the Master should detect adjacent undersized regions and automatically merge them.

Other than the case when a table has exactly one region, region sizes should always be between 1/2x and 1x the split size. For instance, if the max file size is 256MB, steady-state, regions will be between 128 and 256MB. If we find two regions near each other that are less than some threshold when summed together, they are candidates for merging. For instance, we could set the threshold to 1/2x max file size, so if one region was 50MB and the other was 16MB, they would be mergeable. 

The only time that regions small enough to merge should exist is when there have been significant deletions. Otherwise, regions will always stay in the 1/2 to 1x range. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-77,"> Right now the only interface for insertion is via a byte[], which severely limits the flexibility of the system. Added 2007-10-08 by stuhood.

Tell us more Stu why you need this feature? (Because you want to write BLOBs of multiple Gigabytes into an hbase cell?)

Added as part of migrating new feature requests from the obsoleted http://wiki.apache.org/hadoop/Hbase/HbaseFeatureRequests",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-68,"Today, HStoreFiles keep the entire serialized HStoreKey objects around for every cell in the HStore. Since HStores are 1-1 with column families, this is really unnecessary - you can always surmise the column family by looking at the HStore it belongs to. (This information would ostensibly come from the file name or a header section.) This means that we could remove the column family part of the HStoreKeys we put into the HStoreFile, reducing the size of data stored. This would be a space-saving benefit, removing redundant data, and could be a speed benefit, as you have to scan over less data in memory and transfer less data over the network.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10559,"Investigate if it's possible to autogenerate the CHANGES.txt file from the 'release' Maven profile, using the JIRA API.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10063,"In SecureWALCellCodec#EncryptedKvEncoder#write we get the IV for the entry from the secure RNG. This can be a heavyweight operation if not using an accelerated RNG. Consider something lighter weight. One option could be to create a random IV only once, store it in the header, and then increment it per cell. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6221,"As discussed in the HBase BoF today, a patch backporting HBASE-6135 UI improvements to 0.94 may be interesting even if not actually committed to that branch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2055,"There was some advocacy of using Avro for serialization of HBase WAL records up on hbase-dev@. Idea is Hadoop core is getting away from Writables and Avro is the blessed replacement. 

I think we have this criteria for its use:
1) Performance of writing Avro records is no worse than that for writing Writables into a SequenceFile.
2) Space consumed by Avro serialization is no worse than that of Writables
3) File format is amenable to appends (cannot require valid trailers, etc.)

I'll put up a patch so we can try it out. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7395,The security profile in the 0.94 POM shouldn't set hadoop.version. This is done elsewhere. It isn't necessary anymore and I think depending on the order of Maven command line environments may do the wrong thing.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9305,"The assertion failures are like this:

{noformat}
java.lang.AssertionError: expected:<2089> but was:<2109>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.junit.Assert.assertEquals(Assert.java:456)
	at org.apache.hadoop.hbase.client.TestFromClientSide.testCacheOnWriteEvictOnClose(TestFromClientSide.java:4248)
{noformat}

Also:

{noformat}
expected:<2067> but was:<2087>
{noformat}

{noformat}
expected:<2070> but was:<2090>
{noformat}

The test saves off the current block cache stats - block count and hits and misses - then puts a value and gets it back:

{code}
4242: Put put = new Put(ROW);
4243: put.add(FAMILY, QUALIFIER, data);
4244: table.put(put);
4245: assertTrue(Bytes.equals(table.get(new Get(ROW)).value(), data));
{code}

then we have these asserts:

{code}
4246: //data was in memstore so don't expect any changes
4247: assertEquals(startBlockCount, cache.getBlockCount());
4248: assertEquals(startBlockHits, cache.getStats().getHitCount());
4249: assertEquals(startBlockMiss, cache.getStats().getMissCount());
{code}

There are exactly 20 more hits than expected every time. In the log looks like there's a meta scan happening around the same time. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9361,"The error:

{noformat}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:92)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.junit.Assert.assertTrue(Assert.java:54)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.testThreeRSAbort(TestDistributedLogSplitting.java:132)
{noformat}

Here the test has aborted three regionservers but not all of them have terminated after 60 seconds.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9362,"An example failure:

{noformat}
java.lang.AssertionError: expected:<0> but was:<200>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.junit.Assert.assertEquals(Assert.java:456)
	at org.apache.hadoop.hbase.regionserver.TestColumnSeeking.testDuplicateVersions(TestColumnSeeking.java:160)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11065,"mvn site fails
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.2:site (default-site) on project hbase: SiteToolException: ArtifactResolutionException: Unable to find skin: Could not transfer artifact org.apache.maven.skins:maven-stylus-skin:jar:1.5 from/to central (http//repo.maven.apache.org/maven2/): No connector available to access repository central (http//repo.maven.apache.org/maven2/) of type default using the available factories WagonRepositoryConnectorFactory
[ERROR] org.apache.maven.skins:maven-stylus-skin:jar:RELEASE

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6030,"The HBase AccessController can emit a detailed trace of every action, and whether it succeeded or failed, but this is expected to be used only for debugging an application in a staging environment. In production a RegionServer may have thousands of requests per second, logging the audit trace just isn't viable. However, we might want to log the AccessDeniedExceptions which result from access failures in the daemon logs like Hadoop does, e.g. the NameNode log.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11043,"AccessController#preGetTableDescriptors only allow users with admin or create permission to get table's description.
{quote}
        requirePermission(""getTableDescriptors"", nameAsBytes, null, null,
          Permission.Action.ADMIN, Permission.Action.CREATE);
{quote}

I think Users with table's read/write permission should also be able to get table's description. 

Eg: when create a hive table on HBase,  hive will get the table description to check if the mapping is right. Usually the hive users only have the read permission of table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7759,"HADOOP-9252 slightly changes the format of some StringUtils outputs.  It may cause test failures.

Also, some methods were deprecated by HADOOP-9252.  The use of them should be replaced with the new methods.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3530,"Currently we always start the LogSyncer thread, even when not necessary because the ""deferred flush"" is set to false and the sync() is called on every record. We could disable the thread and not have it flush every n secs unnecessarily.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-800,"From Billy Pearson on hbase-users@

Hey Andrew

Do we have plans to include setMaxFileSize for the shell,thrift,rest?
So non java users can change this as needed with out having to learn java.

Billy

""Andrew Purtell"" <apurtell@yahoo.com> wrote in message news:189371.9860.qm@web65516.mail.ac4.yahoo.com...
> Hello David,
>
> Current trunk (upcoming 0.2.0) has support for per-table metadata. See
> https://issues.apache.org/jira/browse/HBASE-42 and
> https://issues.apache.org/jira/browse/HBASE-62.
>
> So maybe you can set the split threshold quite low for the table in
> question?
>
> The default is 256MB (268435456), set globally for all tables in the HBase
> configuration as ""hbase.hregion.max.filesize"". However it's reasonable to
> set it as low as the DFS blocksize. The guidance for a typical HBase
> installation is to set the DFS blocksize to 8MB (8388608), instead of the
> default 64MB.
>
> At create time:
>
>  HTableDescriptor htd = new HTableDescriptor(""foo"");
>  htd.setMaxFileSize(8388608);
>  ...
>  HBaseAdmin admin = new HBaseAdmin(hconf);
>  admin.createTable(htd);
>
> If the table already exists:
>
>  HTable table = new HTable(hconf, ""foo"");
>  admin.disableTable(""foo"");
>  // make a read-write descriptor
>  HTableDescriptor htd =
>    new HTableDescriptor(table.getTableDescriptor());
>  htd.setMaxFileSize(83388608);
>  admin.modifyTableMeta(""foo"", htd);
>  admin.enableTable(""foo"");
>
> Hope this helps,
>
>   - Andy
>
>> From: David Alves
>> <dr-alves@criticalsoftware.com>
>> Subject: Region Splits
>> To: ""hbase-user@hadoop.apache.org""
>> <hbase-user@hadoop.apache.org>
>> Date: Thursday, July 31, 2008, 6:06 AM
> [...]
>> I use hbase (amongst other things) to crawl some repos of infomation
>> and util now I've been using the Nutch segment generation paradigm.
>> I would very much like to skip the segment generation step using
>> hbase as source and sink directly but in order to do that I would
>> need to either allow more that one split to be generated for a
>> single region or make the regions in this particular table split
>> with much less entries than other tables.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10386,"I was doing load test on a 0.98 cluster and saw the following in output:
{code}
2014-01-20 20:44:52,567 [Thread-2] INFO  client.HBaseAdmin (HBaseAdmin.java:enableTable(761)) - Enabled table test
Starting to write data...
Failed to write keys: 0
{code}
The above was from call to System.out.println()

There is LOG field in MultiThreadedWriter which is used in other methods except for waitForFinish()
waitForFinish() should utilize LOG as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7147,"I worked on a MapReduce to archive some old rows from a table to place
them on another one. I think it can be interesting for some other. So
I'm sharing it here.

Feel free to comment if any update is required, or just close the JIRA
if you think it's not useful enough to be integrated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10190,"Rolling restart is giving some words as hosts names. (I have added some output to the trace below),

{code}
hbase@hbasetest1:~$ time ./bin/rolling-restart.sh --graceful
Gracefully restarting: Command
2013-12-17T15:06:08 Disabling load balancer
2013-12-17 15:06:11,817 INFO  [main] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2013-12-17T15:06:15 Previous balancer state was true
2013-12-17T15:06:15 Unloading Command region(s)
2013-12-17 15:06:19,991 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6dabf4b connecting to ZooKeeper ensemble=hbasetest1.domain.com:2181
2013-12-17 15:06:20,301 INFO  [main] region_mover: Looking for Command
2013-12-17 15:06:20,302 INFO  [main] region_mover: Checking hbasetest4,60020,1387308979399
2013-12-17 15:06:20,302 INFO  [main] region_mover: getHostnameFromServerName(server) = hbasetest4
2013-12-17 15:06:20,302 INFO  [main] region_mover: Checking hbasetest3,60020,1387308979395
2013-12-17 15:06:20,303 INFO  [main] region_mover: getHostnameFromServerName(server) = hbasetest3
2013-12-17 15:06:20,303 INFO  [main] region_mover: Checking hbasetest2,60020,1387310715952
2013-12-17 15:06:20,303 INFO  [main] region_mover: getHostnameFromServerName(server) = hbasetest2
RuntimeError: Server Command not online
    stripServer at /home/hbase/bin/region_mover.rb:224
  unloadRegions at /home/hbase/bin/region_mover.rb:330
         (root) at /home/hbase/bin/region_mover.rb:484
2013-12-17T15:06:20 Unloaded Command region(s)
2013-12-17T15:06:20 Stopping regionserver
Command: ssh: Could not resolve hostname Command: Name or service not known
2013-12-17T15:06:20 Restarting regionserver
Command: ssh: Could not resolve hostname Command: Name or service not known
2013-12-17T15:06:21 Reloading Command region(s)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10133,"Noticed in the logs we had lines like this: 

2013-12-11 00:02:00,343 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: currentNbOperations:-1341767084 and seenEntries:0 and size: 0

Maybe this value should be reset after we ship our edits this value should get adjusted.  Either that or convert from an int to a long.  

As this is a jmx metric I feel its important to get this correct.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9787,"See HBASE-9775:

Some comment on the retry time limit, we may need to fix it.
It was introduced for server-specific retry fallback, which I hope is not broken by recent changes to HCM. That is the logic where we go to one server, retry, wait, retry, wait more, retry, wait more, then we learn that region went to different server. Here, we don't need to wait, because we can assume by default the different server is healthy; but the old code would carry on with wait sequence.
However, if region moves around (which is common in aggressive CM IT tests), retry count can quickly be exhausted as we go to each new server a few times and never reach higher multipliers. It was especially pronounced w/10 retries, where some request could fail in just a few seconds in case of double server failure where region is recovered twice; w/31-35 now it's probably less pronounced but still possible.
So, the time limit based on original retries is supposed to prevent these fast failures, by allowing the retries to go on for as long as we would have retried ""as if"" we were just using the multiplier sequence to its ""full potential"".
It should not serve as lower limit, we might want to change code to check that both time AND count are exhaused, in this case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8048,"Does anyone use this? Do we advocate it's use for monitoring? We have a proper metrics infra now, so I don't think the latency statistic is produces should be a primary data source. Maybe move it to hbase-examples? At the very least, put it in util package next to all the other tools.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9878,"AbstractHBaseTool catches any uncaught exceptions, logs them, and explicitly exists. I believe the reason for this is to explicitly set a non-0 exit code for the process. However, this means one cannot attach a debugger and break on uncaught exceptions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8929,"When running the test repeatedly on the same cluster one can sometimes see unexpected reference count, where the number found is (in the observed case) a multiple of the number expected, so instead ok 2.5m nodes it finds 12.5m, for example. It looks like it's reading the data from the old run. Setup should delete that (not cleanup, as the data may be used for debugging after the test)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10068,"Ran the following:
create 'Person' 'Table', 'Demography'

was expecting the shell would throw a syntax error,however, it created the table with the  name  PersonTable. There is a space between 'Person' and 'Table'.

I've pasted the screen text:

hbase(main):002:0> create 'Person' 'Table', 'Demography'
0 row(s) in 1.2050 seconds

hbase(main):003:0> list
TABLE
PersonTable
1 row(s) in 0.0330 seconds

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9935,"Here's an example:
{code}
KeyValue.createLastOnRow(
          kv.getBuffer(), kv.getRowOffset(), kv.getRowLength(),
          kv.getBuffer(), kv.getFamilyOffset(), kv.getFamilyLength(),
           kv.getBuffer(), kv.getQualifierOffset(), kv.getQualifierLength());
{code}

Looks harmless enough, but that actually recalculates the rowlength 5 times. And each time it needs to decode the rowlength again from the bytes of the KV.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9589,"Starting with line 1177:
{code}
          if (diff != 0) {
            if (!littleEndian) {
              return lessThanUnsigned(lw, rw) ? -1 : 1;
            }

            // Use binary search
            int n = 0;
            int y;
            int x = (int) diff;
            if (x == 0) {
              x = (int) (diff >>> 32);
{code}
The value of ""x"" cannot be equal to 0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8589,"Sometimes there's need to write an integration test that only makes sense for large amount of data, cluster, etc. It doesn't make sense to run such test on minicluster on single machine. We need to add an attribute or something like that to indicate that, and make sure mvn verify and IntegrationTestDriver do not run such tests by default, unless name is explicitly specified",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9571,"mvn dependency:analyze is strange on this one. You can remove or add the dependency, it won't complain about ""used but undeclared"" or ""undeclared but used"" dependencies. But it does a difference in dependency:tree or for the client application.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6657,"After HBASE-6477, Filter is an abstract class, as is FilterBase.  It probably doesn't make much sense to keep both.

See Review Request for more info:
https://reviews.apache.org/r/6670/",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9357,"When there's no ZK available, running `bin/hbase rest` must timeout before printing usage information. Initiating a connection should happen after parsing CLI options, not before.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6687,"If a clusterkey for a replication peer cluster can not be deserialized, we log a warning and continue. This should probably be a stop the world event, because we can no longer connect to the peer cluster.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8793,"hbase-regionserver startup script always returns 0 (exit 0 at the end of the script) this is wrong behaviour which causes issues when trying to recognise true status of the service.
Replacing it with 'exit $?' seems to fix the problem, looking at hbase master return codes are assigned to RETVAL variable which is used with exit.

Not sure if the problem exist in other versions.

> /etc/init.d/hbase-regionserver.orig status
hbase-regionserver is not running.
> echo $?

After fix:

> /etc/init.d/hbase-regionserver status
hbase-regionserver is not running.
> echo $?
1
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8759,"On table with VERSIONS => '1', KEEP_DELETED_CELLS => 'true'. Family Delete Markers does not get purged after put > delete > major compaction (they keep on incrementing after every put > delete > major compaction)

Following is the raw scan output after 10 iterations of put > delete > major compaction.

ROW                                       COLUMN+CELL                                                                                                             
A                                        column=CF:, timestamp=1371512706683, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512706394, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512706054, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512705763, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512705457, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512705149, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512704836, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512704518, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512704162, type=DeleteFamily                                                                  
A                                        column=CF:, timestamp=1371512703779, type=DeleteFamily                                                                  
A                                        column=CF:COL, timestamp=1371512706682, value=X 


[~lhofhansl]

Code to repro this issue:
http://phoenix-bin.github.io/client/code/delete.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2883,"Now that the region servers can heartbeat back to the master as soon as they have a message (region open, close, etc), they also recompute their metrics. I see two problems:

 - The metrics are recomputed way too often, and by the looks of that code it seems quite intense.
 - Our UIs are expecting that the value returned by the metrics computation is per second, but when regions are moving a RS can ping back a few times within a single second. This gives a very wrong view of the load.

I think it's time we move metrics computation in it's own separate thread.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2317,"HRS.lockRow doesn't manage exceptions like all the other methods: 

{code}
    try {
      HRegion region = getRegion(regionName);
      Integer r = region.obtainRowLock(row);
      long lockId = addRowLock(r,region);
      LOG.debug(""Row lock "" + lockId + "" explicitly acquired by client"");
      return lockId;
    } catch (Throwable t) {
      throw convertThrowableToIOE(cleanup(t,
        ""Error obtaining row lock (fsOk: "" + this.fsOk + "")""));
    }
{code}

Also it throws a special message and shows if fs is ok, although it already calls checkOpen() at the beginning of that method.

Fix by making it behaving like all the other calls.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2188,"In the same spirit as group commit down in HLog, incrementColumnValue should be grouping all requests waiting on the row lock into one in HRegion. This means that 10 clients waiting on the lock should be all summed up and then applied only once.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3021,"We've been running replication for a little while now and the tool I wrote to verify replicated data (will be posted in HBASE-3013) works great, unless that data is counters. The reason is that in HRegion.incrementColumnValue we append to the WAL a KV with a timestamp that we're not reusing for the MemStore (since we do some processing on it in updateColumnValue), so the replicated KV is different and comparing sets of rows using time ranges usually fails because one row will almost surely be cut in half on the edges (at least this is what my testing shows).

I guess this is also an issue on the slave cluster since if we don't want values on the same ts on the master cluster, why would we want it elsewhere?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7831,"There are times in the life of many a region server when it realizes that it cannot go on any longer in the hostile, inhospitable environment. Or it might realize that there's something inherently wrong with it on the inside (probably because a developer screwed up). The only way out is killing itself.
There's code in some places currently that does Runtime halt in such cases, and there may be code that calls HRegionServer method to do this.
I think we need some easy-to-access (lightweight interface, or static) way to trigger reliable (no catching exceptions on the upper levels, etc.) RS death in such cases.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8499,"{code}
    if (this.in.available() <= 0) {
      this.hasNext = false;
      return this.hasNext;
    }
{code}

Javadoc for available:
{quote}
Returns an estimate of the number of bytes that can be read (or skipped over) from this input stream without blocking by the next invocation of a method for this input stream. The next invocation might be the same thread or another thread. A single read or skip of this many bytes will not block, but may read or skip fewer bytes.

Note that while some implementations of InputStream will return the total number of bytes in the stream, many will not.
{quote}

Not a big deal if we always use it with correct streams now, but rather dangerous.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-553,"Hadoop is incorporating the bloom filter code that is in HBase to make a BloomFilterMapFile (HADOOP-3063). Once this is committed to Hadoop trunk, the bloom filter code can be removed from HBase.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8418,"Looking at the profile seems that Bytes.toShort() is called a lot.
the calls are in ScanQueryMatcher.match() and KeyValue.KeyComparator.compare()

getKeyLength() is already cached, but getRowLength() is not.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8037,"RegionMovedException is currently thrown on global level, and due to how ProtobufUtil does things, it fails the entire multi-request, see HBASE-8036. RME also doesn't specify the region.
Thus, if it's thrown for one region and there are multiple regions in the request, HCM applies it to all of them, which causes clients to become confused temporarily. We should either fix HBASE-8036 or add region encoded name in the description. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8087,"Pls refer to the comments

https://issues.apache.org/jira/browse/HBASE-7992?focusedCommentId=13600513&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13600513

https://issues.apache.org/jira/browse/HBASE-7992?focusedCommentId=13600780&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13600780

Raised this issue to solve that comments.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8046,"HBaseConfTool looks like it could be handy for people who don't feel comfortable digging into ruby/shell and don't have a configuration manager like CM/Ambari.

If no one uses it, we should just delete it.

If we want to keep it around, clean it up to use the Tool interface, GenericOptionParser, etc; change the interface audience to Public, maybe add support for wild-card matching, or at least dumping the entire config; document it in the book.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7500,"From https://builds.apache.org/job/HBase-TRUNK/3702/testReport/org.apache.hadoop.hbase/TestNodeHealthCheckChore/testHealthChecker/:
{code}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:92)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.junit.Assert.assertTrue(Assert.java:54)
	at org.apache.hadoop.hbase.TestNodeHealthCheckChore.testHealthChecker(TestNodeHealthCheckChore.java:71)
...
2013-01-06 04:29:23,889 INFO  [pool-1-thread-1] hbase.HealthCheckChore(68): Health status at 377068hrs, 29mins, 23sec : ERROR
Server not healthy
{code}
Here is related code:
{code}
    assertTrue(report.getStatus() == HealthCheckerExitStatus.SUCCESS);
    LOG.info(""Health Status:"" + checker);
{code}
The health status log should be moved before the assertion. I think report should be in the log instead of checker.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7805,"If multiple scans to different parts of the same region are executed in parallel, they are processed serially if the table has a region observer coprocessor.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7792,I don't see any judicial use of these two parameters in the code base. Why not remove them?,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6776,"For opened region of disabled table, it should be added to online region list, and then closed.  We should not just ignore them.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1648,"Getting some early experience with the G1 GC.

Running with -Xmx1000m and HBASE_OPTS set to ""-XX:+UnlockExperimentalVMOpts -XX:+UseG1GC"".  Regionserver heap use reports are not of much use:

{noformat}
hbase(main):001:0> status 'simple'
3 live servers
    test3:60020 1247389283042
        requests=0, regions=1, usedHeap=0, maxHeap=41
    test2:60020 1247389219994
        requests=0, regions=1, usedHeap=0, maxHeap=41
    test4:60020 1247389324563
        requests=0, regions=2, usedHeap=0, maxHeap=41
0 dead servers
{noformat}

top is about right:

{noformat}
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
23988 hadoop    24   0 1492m  98m  10m S  0.0  2.5   0:02.65 java
{noformat}

Incidentally, don't try -XX:+UseG1GC and -XX:+DoEscapeAnalysis together or the JVM will rapidly segfault.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7131,"For a table that is re-enabled shortly after it is disabled, regions that are reported to be online are not. This is manifested by a flush attempt throwing a NotServingRegion exception despite all regions from the original table reporting that they are online.

I have a test in place that verifies this flaky behavior. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7090,"This has been there for some time. It is a surprise to find it is reversed actually.  Did I missing anything?

I think it really means to do it if the server is online.

{noformat}
  private void splitLogAndExpireIfOnline(final ServerName sn)
      throws IOException {
    if (sn == null || !serverManager.isServerOnline(sn)) {
      return;
    }
    LOG.info(""Forcing splitLog and expire of "" + sn);
    fileSystemManager.splitLog(sn);
    serverManager.expireServer(sn);
  }
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2444,"If a region server that has already been declared dead reports to the master, the master throws LeaseStillHeldException. This is not a very descriptive exception for this case - we should either add a new exception for this purpose, or make a general exception like RegionServerStateException and use a descriptive message.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4522,"The motivation for diff is that we want to override some config change for any specific cluster easily by just adding the config entries in the hbase-site-custom.xml for that cluster. This change adds the hbase-site-custom.xml configuration file into HBaseConfiguration.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4046,"We can add the following statistics to the master. Some stats that can be added are: 
1. number of logs split 
2. size of logs split
3. number of region servers online 
4. number of region servers opened
5. number of region servers expired 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5691,"I was trying to run importtsv from a servlet. Everytime after the completion of job, the tomcat server was shutdown.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4858,"Under Linux with OpenJDK 1.6, using a file:///XX URL in the config file creates a directory called 'file:' in the hbase root directory. If I use a standard Unix absolute path, it works as expected. This may work on other platforms, but it would be good to add a note in the example:

{code}
<?xml version=""1.0""?>
<?xml-stylesheet type=""text/xsl"" href=""configuration.xsl""?>
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <!-- Depending on your platform, this may create a 'file:' directory
         in hbase home instead of the desired behavior. Try using a standard
         platform specific absolute path instead. -->
    <value>file:///DIRECTORY/hbase</value>
  </property>
</configuration>
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5999,AggregationClient throws an exception when the startRow is set and stopRow is not set in scan object. AggregationClient should not throw the exception in this case because the user might want to scan the entire table starting from the startRow.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5236,"I can't start HMaster :( 
Please help me.. second day about this error
Exception in thread ""main"" java.lang.RuntimeException: Failed construction of Regionserver: class org.apache.hadoop.hbase.regionserver.HRegionServer

Unable to start master
Has already worked well hadoop cluster installation. Wait 30 sec before start hbase.

I followed this tutorial http://hbase.apache.org/book/example_config.html#d0e2432
Change system configuration in required section ulimit and nproc

Have: 1 master, 4 slaves

Here all diagnostic information

Java java version ""1.6.0_26""
Java(TM) SE Runtime Environment (build 1.6.0_26-b03)
Java HotSpot(TM) 64-Bit Server VM (build 20.1-b02, mixed mode)
Debian 6.03 Linux slave1 2.6.32-5-amd64

Copy hadoop-core to hbase/lib on each machine
hduser@slave1:/usr/local/hbase$ ls lib/hadoo*
lib/hadoop-core-1.0.0.jar

Hbase: hbase-0.90.5

LOG
http://pastie.org/private/s9hjy3hsfebzfltvxee6qa

LOG FROM SLAVE1
http://pastie.org/private/ebzulfseaotfcehz0cqua

LOG FROM ZOOKEPER ON SLAVE1
http://pastie.org/private/y7j11uuhzpebrottsx3ug

HBASE 
hbase-site.xml
http://pastie.org/private/6giqrpeeysidqnjsyimg

hbase-env.xml
http://pastie.org/private/9q0abbvmtsgi4kava8zm9w

regionservers
http://pastie.org/private/eic5waqafmsm73j9h0nra


HADOOP
hadoop-env.sh
http://pastie.org/private/6lmz3xhmcovwag7vmpecjg


core-site.xml
http://pastie.org/private/udskadmow3khd3jqavawww

hdfs-site.xml
http://pastie.org/private/b7g1tkpzukkivhjiwgmsfw


masters and slaves
http://pastie.org/private/l8o0luukig6jnnba6mpryg
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1911,"There are a number of instances of ad hoc versioning of Writables: HTD, HCD, etc. We should convert our classes to inherit VersionedWritable. See http://hadoop.apache.org/common/docs/r0.19.1/api/org/apache/hadoop/io/VersionedWritable.html",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4146,"HBase doesn't shut down using hbase-stop.sh on OS X 10.7 (""Lion"") most of the time, though it did work for me once.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2240,"I'm running a mapreduce job.  I see a region split and its daughters come on line and then 8 seconds later, master judges the regionserver overloaded and so closes the just-opened region.  This messes up clients.   They may have just picked up the new location for their row query and now its moved again and client has to go hunting anew. 

We need to assign the vintage regions first.

I'm going to change balancer slop.  Its not sloppy enough and balancing cuts in too early.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1967,"Testcase: testPutPutScan took 15.822 sec FAILED
expected:<299> but was:<199>

Not sure exactly how the test is supposed to work but it seems that sometimes the two Put are on the same timestamp so the value returned is 199. I will commit a temporary fix to branch in order to release 0.20.2",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1313,"2009-04-06 17:34:13,357 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: MSG_REGION_OPEN: urls,,1239039250933
2009-04-06 17:34:13,357 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_OPEN: urls,,1239039250933
2009-04-06 17:34:13,358 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region urls,,1239039250933/39686773
2009-04-06 17:34:13,360 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Next sequence id for region urls,,1239039250933 is 0
2009-04-06 17:34:13,360 INFO org.apache.hadoop.hbase.regionserver.HRegion: region urls,,1239039250933/39686773 available
2009-04-06 17:34:13,360 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for region urls,,1239039250933/39686773 because: Region open check
2009-04-06 17:34:13,360 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting  compaction on region urls,,1239039250933
2009-04-06 17:34:13,360 DEBUG org.apache.hadoop.hbase.regionserver.Store: 39686773/info: no store files to compact
2009-04-06 17:34:13,361 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region urls,,1239039250933 in 0sec
2009-04-06 17:34:16,368 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: Processing message (Retry: 0)
java.io.IOException: java.io.IOException: java.lang.IllegalStateException: Cannot set a region as open if it has not been pending. State: name=urls,,1239039250933, unassigned=true, pendingOpen=false, open=false, closing=false, pendingClose=false, closed=false, offlined=false
	at org.apache.hadoop.hbase.master.RegionManager$RegionState.setOpen(RegionManager.java:1236)
	at org.apache.hadoop.hbase.master.RegionManager.setOpen(RegionManager.java:805)
	at org.apache.hadoop.hbase.master.ServerManager.processRegionOpen(ServerManager.java:524)
	at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:390)
	at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:361)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:269)
	at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:601)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:909)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.checkThrowable(RemoteExceptionHandler.java:48)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:66)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:493)
	at java.lang.Thread.run(Thread.java:619)
2009-04-06 17:34:16,376 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: MSG_REGION_OPEN: urls,,1239039250933
2009-04-06 17:34:16,376 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_OPEN: urls,,1239039250933
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-767,HBASE-646 and HBASE-766 are about handlers for the case where store file 'data' goes missing.  This issue is about figuring why/how they disappear,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-29,"Ok, this one is a little tricky. Let's say that you write a row with some value without a timestamp, thus meaning right now. Then, the memcache gets flushed out to a MapFile. Then, you write another value to the same row, this time with a timestamp that is in the past, ie, before the ""now"" timestamp of the first put. 

Some time later, but before there is a compaction, if you do a get for this row, and only ask for a single version, you will logically be expecting the latest version of the cell, which you would assume would be the one written at ""now"" time. Instead, you will get the value written into the ""past"" cell, because even though it is tagged as having happened in the past, it actually *was written* after the ""now"" cell, and thus when #get searches for satisfying values, it runs into the one most recently written first. 

The result of this problem is inconsistent data results. Note that this problem only ever exists when there's an uncompacted HStore, because during compaction, these cells will all get sorted into the correct order by timestamp and such. In a way, this actually makes the problem worse, because then you could easily get inconsistent results from HBase about the same (unchanged) row depending on whether there's been a flush/compaction.

The only solution I can think of for this problem at the moment is to scan all the MapFiles and Memcache for possible results, sort them, and then select the desired number of versions off of the top. This is unfortunate because it means you never get the snazzy shortcircuit logic except within a single mapfile or memcache. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-58,"Currently, the only way to tell what is really going on with an HBase cluster is to enable DEBUG level logging. Unfortunately, this also generates a lot of 'noise' messages. We need to review log messages and see which DEBUG messages should be promoted to INFO and if any current INFO messages should be demoted to debug.

In addition, some messages are very verbose and don't really need to be. This should be fixed too.

A good starting point for review would be to look at the output from test-contrib. Although that is not everything, it is a place to start working from.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2005,"The hbase shell has 'delete' and 'deleteall' for deleting a cell/cells for a given row.

I don't see any equivalent of the RDBMS equivalent of 'truncate' that would delete all the rows in a table, however (i.e., based on my understanding of the shell, 'deleteall' applies horizontally, but not vertically).

At the very least, this could be useful for development purposes when you want to quickly remove test data from a table.  

Nice to have - something like:

truncate mytable    (no column families specified...  so it removes all the rows from every column family)

truncate mytable family1    (remove all rows from table 'mytable' but only for column family 'family1').

Something like that...  just a suggestion.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-509,"A couple of times during an upload, hdfs complains it is corrupt.  Complaint is as following:

{code}
/hbase/XX.XX.XX-2.u.powerset.com/log_XX.XX.XX.92_1205384328364_60020/hlog.dat.025:  Replica placement policy is violated for blk_2712323855504360379. Block should be additionally replicated on 2 more rack(s).
/hbase/XX.XX.XX-2.u.powerset.com/log_XX.XX.XX.92_1205384328364_60020/hlog.dat.025: MISSING 1 blocks of total size 0 B.
{code}

Now the odd thing is that the next time I do a fsck, I see that log number its complaining about for the above server has increased inline with a new file just rolled as in:

{code}
......92_1205384328364_60020/hlog.dat.026:  Replica placement policy is violated for blk_4062204433046618058. Block should be additionally replicated on 2 more rack(s).
/hbase/aa0-005-2.u.powerset.com/log_XX.XX.XX.92_1205384328364_60020/hlog.dat.026: MISSING 1 blocks of total size 0 B.
{code}

Its no longer complaining about hlog.dat.025.  If I do an fsck on the file hlog.dat.020, it says its healthy, replicated 7M file.

Likely an hdfs issue.  Or its the way we're doing our logging? Restart reports cluster HEALTHY (didn't run fsck with remove 'bad' blocks or files).



",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-968,"I get a java.lang.ArrayIndexOutOfBoundsException from cell iterator()
It has a logic error on the count

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-866,"I've been testing running biggish MR jobs uploading into hbase.  My jobs consistently fail with child task timing out its ten minute period.  Adding logging, was able to see that we're actual stuck in a commit.  Following the thread of the row we're committing, I see this in the log:

{code}
...
2008-09-03 18:37:03,446 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Flush requested on TestTable,0029377106,1220466998108
2008-09-03 18:37:03,446 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region TestTable,0029377106,1220466998108. Current region memcache size 64.0m
2008-09-03 18:37:03,446 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 1 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:13,450 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 1 on 60020'
2008-09-03 18:37:16,089 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 16 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:16,090 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 1 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:16,090 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 4 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:16,090 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 6 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:16,090 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 2 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:16,090 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 12 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:16,090 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 9 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:16,091 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for 'IPC Server handler 7 on 60020' on region TestTable,0029377106,1220466998108: Memcache size 64.0m is >= than blocking 64.0m size
2008-09-03 18:37:21,984 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memcache flush for region TestTable,0029377106,1220466998108 in 18538ms, sequence id=2852547, compaction requested=false
2008-09-03 18:47:06,241 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region TestTable,0029377106,1220466998108. Current region memcache size 64.0m
2008-09-03 18:47:10,031 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memcache flush for region TestTable,0029377106,1220466998108 in 3790ms, sequence id=2919208, compaction requested=true
2008-09-03 18:47:10,031 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 9 on 60020'
2008-09-03 18:47:10,031 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for region: TestTable,0029377106,1220466998108
2008-09-03 18:47:10,031 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 12 on 60020'
2008-09-03 18:47:10,032 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting compaction on region TestTable,0029377106,1220466998108
2008-09-03 18:47:10,032 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 7 on 60020'
2008-09-03 18:47:10,035 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 6 on 60020'
2008-09-03 18:47:10,035 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 4 on 60020'
2008-09-03 18:47:10,035 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 2 on 60020'
2008-09-03 18:47:10,037 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 16 on 60020'
2008-09-03 18:47:10,043 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region TestTable,0029377106,1220466998108 'IPC Server handler 1 on 60020'
2008-09-03 18:47:18,403 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region TestTable,0029377106,1220466998108 in 8sec
...
{code}

Notice how we're blocked for ten minutes until new flush runs.  My guess is that the flush that is going on concurrent with the blocking is clearing the flag ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-828,"Process:

One the 1st run of the application, i use tableExists( new Text(""TestTable5"")) & tableCreate to create the table.

On the 2nd run, I call tableExists(new Text(""TestTable5"")), which returns false, then i call disableTable, deleteTable, and finally createTable.


Workaround for now is to avoid using Text.   tableExists(byte[]) works when i tested it.

To test this, you have to run the program 2 times.  Once to create the table that doesnt exist, then the 2nd time to see the error.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-777,"Using the old shell I was able to use CREATE TABLE to create a table named 'RelatedAlbums' and then access it from Java using new HTable(conf, new Text(""RelatedAlbums"")).

Using the new shell, trying to use 'create' from the irb shell and then that same constructor results in the table not being found.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-760,"HCD creation in HBase.rb was brittle and nonfunctional. 

[hadoop@sjdc-atr-dns tmp]$ hbase shell --master=10.30.94.1:60000
(eval):1 warning: already initialized constant MEMCACHE_FLUSHSIZE
(eval):1 warning: already initialized constant IN_MEMORY
(eval):1 warning: already initialized constant VERSIONS
HBase Shell; enter 'help<RETURN>' for list of supported commands.
Version: 0.2.0-dev, r678650, Tue Jul 22 06:15:47 UTC 2008
hbase(main):001:0> create 'content', {NAME => 'url', VERSIONS => 1, TTL => 2592000}, {NAME => 'info', VERSIONS => 1, TTL => 2592000, BLOCKCACHE => 'true'}, {NAME => 'content', VERSIONS => 1, COMPRESSION => 'RECORD', TTL => 2592000,BLOCKCACHE => 'true' }
NameError: no constructor with arguments matching [class [B, class java.lang.Long, class org.apache.hadoop.hbase.HColumnDescriptor$CompressionType, class java.l
ang.Boolean, class java.lang.String, class java.lang.Long, class java.lang.Long,
 class java.lang.Boolean] on object JavaUtilities
        from file:/opt/hadoop-0.17.1/contrib/hbase/lib/jruby-complete-1.1.2.jar!
/builtin/javasupport/proxy/concrete.rb:23:in `__jcreate!'
        from file:/opt/hadoop-0.17.1/contrib/hbase/lib/jruby-complete-1.1.2.jar!
/builtin/javasupport/proxy/concrete.rb:23:in `initialize'
        from file:/opt/hadoop-0.17.1/contrib/hbase/lib/jruby-complete-1.1.2.jar!
/builtin/javasupport/proxy/concrete.rb:6:in `new'
        from file:/opt/hadoop-0.17.1/contrib/hbase/lib/jruby-complete-1.1.2.jar!
/builtin/javasupport/proxy/concrete.rb:6:in `new'
        from /opt/hadoop/contrib/hbase/bin/../bin/HBase.rb:156:in `hcd'
        from /opt/hadoop/contrib/hbase/bin/../bin/HBase.rb:112:in `create'
        from /opt/hadoop/contrib/hbase/bin/../bin/HBase.rb:106:in `each'
        from /opt/hadoop/contrib/hbase/bin/../bin/HBase.rb:106:in `create'
        from /opt/hadoop/contrib/hbase/bin/../bin/hirb.rb:223:in `create'
        from wtp.create.rb:3:in `binding'
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-657,"If an invalid column name is passed to the Thrift server, the InvalidColumnNameException is not caught and turned into a Thrift exception. Debug output:

08/05/29 20:34:30 DEBUG thrift.ThriftServer$HBaseHandler: get: table=test_table, row=todd, col=foobar
08/05/29 20:34:30 DEBUG hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.InvalidColumnNameException: foobar is missing the colon family/qualifier separator
        at org.apache.hadoop.hbase.HStoreKey.getColonOffset(HStoreKey.java:335)
        at org.apache.hadoop.hbase.HStoreKey.extractFamily(HStoreKey.java:295)
        at org.apache.hadoop.hbase.HRegion.checkColumn(HRegion.java:1676)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1191)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1154)
        at org.apache.hadoop.hbase.HRegionServer.get(HRegionServer.java:1402)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

08/05/29 20:34:40 DEBUG hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.InvalidColumnNameException: foobar is missing the colon family/qualifier separator
        at org.apache.hadoop.hbase.HStoreKey.getColonOffset(HStoreKey.java:335)
        at org.apache.hadoop.hbase.HStoreKey.extractFamily(HStoreKey.java:295)
        at org.apache.hadoop.hbase.HRegion.checkColumn(HRegion.java:1676)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1191)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1154)
        at org.apache.hadoop.hbase.HRegionServer.get(HRegionServer.java:1402)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

08/05/29 20:34:50 DEBUG hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.InvalidColumnNameException: foobar is missing the colon family/qualifier separator
        at org.apache.hadoop.hbase.HStoreKey.getColonOffset(HStoreKey.java:335)
        at org.apache.hadoop.hbase.HStoreKey.extractFamily(HStoreKey.java:295)
        at org.apache.hadoop.hbase.HRegion.checkColumn(HRegion.java:1676)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1191)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1154)
        at org.apache.hadoop.hbase.HRegionServer.get(HRegionServer.java:1402)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

08/05/29 20:35:00 DEBUG hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.InvalidColumnNameException: foobar is missing the colon family/qualifier separator
        at org.apache.hadoop.hbase.HStoreKey.getColonOffset(HStoreKey.java:335)
        at org.apache.hadoop.hbase.HStoreKey.extractFamily(HStoreKey.java:295)
        at org.apache.hadoop.hbase.HRegion.checkColumn(HRegion.java:1676)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1191)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1154)
        at org.apache.hadoop.hbase.HRegionServer.get(HRegionServer.java:1402)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

08/05/29 20:35:10 DEBUG hbase.HTable: Trying to contact region server for row 'todd', but failed after 5 attempts.
Exception 1:
org.apache.hadoop.hbase.InvalidColumnNameException: org.apache.hadoop.hbase.InvalidColumnNameException: foobar is missing the colon family/qualifier separator
        at org.apache.hadoop.hbase.HStoreKey.getColonOffset(HStoreKey.java:335)
        at org.apache.hadoop.hbase.HStoreKey.extractFamily(HStoreKey.java:295)
        at org.apache.hadoop.hbase.HRegion.checkColumn(HRegion.java:1676)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1191)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1154)
        at org.apache.hadoop.hbase.HRegionServer.get(HRegionServer.java:1402)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)
Exception 1:
org.apache.hadoop.hbase.InvalidColumnNameException: org.apache.hadoop.hbase.InvalidColumnNameException: foobar is missing the colon family/qualifier separator
        at org.apache.hadoop.hbase.HStoreKey.getColonOffset(HStoreKey.java:335)
        at org.apache.hadoop.hbase.HStoreKey.extractFamily(HStoreKey.java:295)
        at org.apache.hadoop.hbase.HRegion.checkColumn(HRegion.java:1676)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1191)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1154)
        at org.apache.hadoop.hbase.HRegionServer.get(HRegionServer.java:1402)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)
Exception 1:
org.apache.hadoop.hbase.InvalidColumnNameException: org.apache.hadoop.hbase.InvalidColumnNameException: foobar is missing the colon family/qualifier separator
        at org.apache.hadoop.hbase.HStoreKey.getColonOffset(HStoreKey.java:335)
        at org.apache.hadoop.hbase.HStoreKey.extractFamily(HStoreKey.java:295)
        at org.apache.hadoop.hbase.HRegion.checkColumn(HRegion.java:1676)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1191)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1154)
        at org.apache.hadoop.hbase.HRegionServer.get(HRegionServer.java:1402)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)
Exception 1:
org.apache.hadoop.hbase.InvalidColumnNameException: org.apache.hadoop.hbase.InvalidColumnNameException: foobar is missing the colon family/qualifier separator
        at org.apache.hadoop.hbase.HStoreKey.getColonOffset(HStoreKey.java:335)
        at org.apache.hadoop.hbase.HStoreKey.extractFamily(HStoreKey.java:295)
        at org.apache.hadoop.hbase.HRegion.checkColumn(HRegion.java:1676)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1191)
        at org.apache.hadoop.hbase.HRegion.get(HRegion.java:1154)
        at org.apache.hadoop.hbase.HRegionServer.get(HRegionServer.java:1402)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-591,"My timezone is in UTC+8, but HBase's log uses PST time. It makes me a little annoying when reading the logs. i think it should either use UTC or localtime in log which makes reading logs more easy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-432,"no matter where I tell the scanner to start it always starts with this key
%20%20.gr.counseling.www/greekatalog/index.php-c=481.htm:http
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-55,"We would like the master's region assignment function to take into account more factors when choosing where to assign regions.
 
- More advanced accounting of load on regionserver - memory, # requests, etc
- Don't deploy both daughter regions to the same regionserver
- Assign regions where the underlying DFS blocks are hosted if possible

Please add additional ideas in comments as they come up.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-253,"I get this on my region servers logs sometimes when I shutdown the cluster it repeats several times sometimes trying to find the master
I thank we need to look at the master and make sure we do not stop the master on exit before all region servers report down.

I am not sure if there could be data loss or not but we should not leave region servers looking for the master unless it has failed on it own.

{code}
2008-01-18 17:40:42,009 WARN org.apache.hadoop.hbase.HRegionServer: Failed to send exiting message to master:
java.net.ConnectException: Connection refused
        at java.net.PlainSocketImpl.socketConnect(Native Method)
        at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
        at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
        at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
        at java.net.Socket.connect(Socket.java:519)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:159)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:575)
        at org.apache.hadoop.ipc.Client.call(Client.java:498)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Invoker.invoke(HbaseRPC.java:210)
        at $Proxy0.regionServerReport(Unknown Source)
        at org.apache.hadoop.hbase.HRegionServer.run(HRegionServer.java:898)
        at java.lang.Thread.run(Thread.java:595)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-213,"From the command-line, list all tables:

{code}
./src/contrib/hbase/bin/hbase client listTables
{code}

Delete a table:

{code}
./src/contrib/hbase/bin/hbase client deleteTable testStringCursor
{code}

List tables again. Notice how the 'deleted' table still shows.  Even after restart, its still present.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-149,"After the JAR command runs successfully, it kills the shell, but any exceptions cause the shell to remain open.

Instead the shell should remain open in all cases so that it is not necessary to relaunch the shell to rerun the JAR.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-106,"below shows a memcache size of 64M but when you add up the regions I get
149.3K =  152883.2B
153B = 153B
153B = 153B
3.8M = 3984588.8B
2.6M = 2726297.6B
153B = 153B
129K = 132096B
2.6M = 2726297.6B
153B = 153B

total  = 9569891.4B = 9.12M not 64M

{code}
2008-01-21 23:51:30,812 DEBUG org.apache.hadoop.hbase.HRegion: Started memcache flush for region webdata,,1200970130265. Size 64.0m
2008-01-21 23:51:31,694 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/size/2337100008775916241 with 11004 entries, sequence id 32535827, and size 149.3k for 540402979/size
2008-01-21 23:51:31,956 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/rank_total/6511354828803004572 with 0 entries, sequence id 32535827, and size 153.0 for 540402979/rank_total
2008-01-21 23:51:32,210 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/first_seen/116626538562002170 with 0 entries, sequence id 32535827, and size 153.0 for 540402979/first_seen
2008-01-21 23:51:40,084 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/anchor/5635668875929221096 with 189726 entries, sequence id 32535827, and size 3.8m for 540402979/anchor
2008-01-21 23:51:48,134 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/last_seen/5152520466951569025 with 189726 entries, sequence id 32535827, and size 2.6m for 540402979/last_seen
2008-01-21 23:51:48,400 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/source/7366562139108336733 with 0 entries, sequence id 32535827, and size 153.0 for 540402979/source
2008-01-21 23:51:49,075 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/stime/5227996581170475543 with 11004 entries, sequence id 32535827, and size 129.6k for 540402979/stime
2008-01-21 23:51:55,944 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/in_rank/7235419568042410782 with 189726 entries, sequence id 32535827, and size 2.6m for 540402979/in_rank
2008-01-21 23:51:56,217 DEBUG org.apache.hadoop.hbase.HStore: Added 540402979/rank_visual/5975562391477267376 with 0 entries, sequence id 32535827, and size 153.0 for 540402979/rank_visual
2008-01-21 23:51:56,217 DEBUG org.apache.hadoop.hbase.HRegion: Finished memcache flush for region webdata,,1200970130265 in 25405ms, sequenceid=32535827
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18088,"I just noticed the following warns.
{code}
[WARNING] Some problems were encountered while building the effective model for org.apache.hbase:hbase-resource-bundle:jar:2.0.0-SNAPSHOT
[WARNING] 'reporting.plugins.plugin.version' for org.scala-tools:maven-scala-plugin is missing. @ org.apache.hbase:hbase:2.0.0-SNAPSHOT, /home/chia7712/apache/hbase/pom.xml, line 3212, column 15
[WARNING]
[WARNING] Some problems were encountered while building the effective model for org.apache.hbase:hbase-server:jar:2.0.0-SNAPSHOT
[WARNING] 'reporting.plugins.plugin.version' for org.scala-tools:maven-scala-plugin is missing. @ org.apache.hbase:hbase:2.0.0-SNAPSHOT, /home/chia7712/apache/hbase/pom.xml, line 3212, column 15
[WARNING]
[WARNING] Some problems were encountered while building the effective model for org.apache.hbase:hbase-thrift:jar:2.0.0-SNAPSHOT
[WARNING] 'reporting.plugins.plugin.version' for org.scala-tools:maven-scala-plugin is missing. @ org.apache.hbase:hbase:2.0.0-SNAPSHOT, /home/chia7712/apache/hbase/pom.xml, line 3212, column 15
[WARNING]
[WARNING] Some problems were encountered while building the effective model for org.apache.hbase:hbase-shell:jar:2.0.0-SNAPSHOT
[WARNING] 'reporting.plugins.plugin.version' for org.scala-tools:maven-scala-plugin is missing. @ org.apache.hbase:hbase:2.0.0-SNAPSHOT, /home/chia7712/apache/hbase/pom.xml, line 3212, column 15
[WARNING]
[WARNING] Some problems were encountered while building the effective model for org.apache.hbase:hbase-protocol-shaded:jar:2.0.0-SNAPSHOT
[WARNING] 'reporting.plugins.plugin.version' for org.scala-tools:maven-scala-plugin is missing. @ org.apache.hbase:hbase:2.0.0-SNAPSHOT, /home/chia7712/apache/hbase/pom.xml, line 3212, column 15
{code}
We should add the version of the plugin to eliminate the warning.
{code:title=pom.xml#3212|borderStyle=solid}
      <plugin>
        <groupId>org.scala-tools</groupId>
        <artifactId>maven-scala-plugin</artifactId>
      </plugin>
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17591,"As consequence of HBASE-12577, `hbase.master.distributed.log.replay` is no longer default true. But in the documentation, it is still noted as default true as follows:

{quote}
To enable distributed log replay, set hbase.master.distributed.log.replay to true. This will be the default for HBase 0.99 (HBASE-10888).
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17843,"Junit test sometimes failed in TestRegionReplicaFailover.java, so I changed the testPrimaryRegionKill method  test timeout  to 240000ms, and add sleep 5000ms for verify result. 
error logs:
Tests run: 6, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 285.221 sec <<< FAILURE! - in org.apache.hadoop.hbase.regionserver.TestRegionReplicaFailover
testPrimaryRegionKill[0](org.apache.hadoop.hbase.regionserver.TestRegionReplicaFailover)  Time elapsed: 125.963 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 120000 milliseconds
at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:460)
	at java.util.concurrent.TimeUnit.timedWait(TimeUnit.java:348)
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService.pollForSpecificCompletedTask(ResultBoundedCompletionService.java:258)
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService.pollForFirstSuccessfullyCompletedTask(ResultBoundedCompletionService.java:214)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.call(RpcRetryingCallerWithReadReplicas.java:209)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:428)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:392)
	at org.apache.hadoop.hbase.HBaseTestingUtility.verifyNumericRows(HBaseTestingUtility.java:2197)
	at org.apache.hadoop.hbase.regionserver.TestRegionReplicaFailover.verifyNumericRowsWithTimeout(TestRegionReplicaFailover.java:227)
	at org.apache.hadoop.hbase.regionserver.TestRegionReplicaFailover.testPrimaryRegionKill(TestRegionReplicaFailover.java:200)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16113,"Step 1: put a cell
Step 2: delete the cell
Step 3: Scan#setRaw(true).setMaxVersions(0)
Step 4: Result result = table.getScanner(scan).next()
Step 5: The result will contain a Cell of DELETE type
Is it a correct result ? The critical code is shown below:
{code:title=ScanWildcardColumnTracker.java|borderStyle=solid}
// May be we should check the verion first
  private MatchCode checkVersion(byte type, long timestamp) {
    if (!CellUtil.isDelete(type)) {
      currentCount++;
    }
    if (currentCount > maxVersions) {
      return ScanQueryMatcher.MatchCode.SEEK_NEXT_COL; // skip to next col
    }
    // keep the KV if required by minversions or it is not expired, yet
    if (currentCount <= minVersions || !isExpired(timestamp)) {
      setTSAndType(timestamp, type);
      return ScanQueryMatcher.MatchCode.INCLUDE;
    } else {
      return MatchCode.SEEK_NEXT_COL;
    }

  }
{code}
Comments?
Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2010,"In hadoop projects the jar-test task is used to compile the test jars. 
In hbase this task is called compile-core-test. 

Shouldn't we have a jar-test task that depends on the compile-core-test?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10777,"Sometimes the embedded thrift server dies, but the regionserver is still alive. This make the regions living on that regionserver available via the thrift client. This JIRA is to restart the embedded thrift in such scenarios.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11840,"Formally the HRegionServer's address was printed in the constructor even though the port was actually set only in initialize(). For example when the port supplied in the conf is 0, then a random open one is allocated upon socket initialization, and that's the one which needs to be printed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11931,Avoid copy/paste in RegionServerCoprocessorHost methods like we did with HBASE-11733  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3926,The count help for example shows the call with no curly braces. We should make them all look like the one recommended on the main help screen. Just to keep it coherent.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8095,"Failed for me while my machine was under load: Failed tests:   testBackoffLogic(org.apache.hadoop.hbase.client.TestSnapshotFromAdmin): Elapsed time:4119 is more than expected max:4050

Looks like it uses system time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8268,HBASE-4894 removed sbin from tarball for 0.92 release. I think the 'mess' Stack referred to in jira hasn't been taken care of in 0.94. So we should have HBASE-4894 fix in 0.94,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8562,"StoreFileScanners open readers to read the store file. However, these readers are not closed upon StoreFileScanner.close().

This should be closed at the end of the compaction.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8623,"Got this running Jeffrey's fancy new IntegrationTestDataIngestWithChaosMonkey

{code}
2013-05-25 14:12:07,972 WARN  [Thread-4] util.ChaosMonkey: Exception occured during performing action: java.lang.IllegalArgumentException: n must be positive
	at java.util.Random.nextInt(Random.java:250)
	at org.apache.hadoop.hbase.util.ChaosMonkey.selectRandomItem(ChaosMonkey.java:595)
	at org.apache.hadoop.hbase.util.ChaosMonkey$RestartRandomRs.perform(ChaosMonkey.java:275)
	at org.apache.hadoop.hbase.util.ChaosMonkey$PeriodicRandomActionPolicy.runOneIteration(ChaosMonkey.java:576)
	at org.apache.hadoop.hbase.util.ChaosMonkey$PeriodicPolicy.run(ChaosMonkey.java:488)
	at java.lang.Thread.run(Thread.java:662)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5339,"Add support that you can combine some columns from the TSV with either a given separator, no separator, or with a custom row key generator class. Syntax could be:

{code}
-Dimporttsv.columns=HBASE_ROW_KEY_1,HBASE_ROW_KEY_2,cf1:col1,cf2:col3,HBASE_ROW_KEY_3
-Dimporttsv.rowkey.separator=""-""
{code}

Another option of course is using the custom mapper class and handle this there, but this also seems like a nice to have option, probably often covering the 80% this sort of thing is needed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8679," boolean shouldFlush = true;
      if (request.hasIfOlderThanTs()) {
        shouldFlush = region.getLastFlushTime() < request.getIfOlderThanTs();
      }
If shouldFlush is false should add a log to say that flush did not happen for what reason. Better for debugging.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10626,"since the hadoop-2.2.0 need a reverse look up about hostname and our dns doesn't support the reverse look up,  we configured the ""/etc/hosts"" of namenode, This lead a bug when we started hbase master in the same machine of namenode:
the ""HMaster"" would get a ""ServerName"" which consisted of hostname,port,ts and get another ""ServerName"" from zookeeper consisted of ip,port,ts, One regionserver will be recorded twice.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11269,"Currently RegionPlacement use LOG.info to output the results of""print"" command. The results will be sent to stderr. This is not a common design for linux command because then it's hard to redirect the results to e.g. grep or less.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11213,"At line 175:
{code}
    RestoreMetaChanges metaChanges = new RestoreMetaChanges(parentsMap);
{code}
Access to parentsMap should be synchronized.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11184,"when i read Store close() method i found  the thread pool for closing store files  with only one Thread.
why initialize the thread pool with only one thread for closing store files?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8926,"Exporting default GC options in HBASE_OPTS from hbase-env.sh by default can interfere with some deployment scenarios. We probably shouldn't be doing that.

Noticed this when using scripts to set up EC2 test clusters for G1 GC. Having ""-XX:+UseConcMarkSweepGC"" on the command line in that case will cause the JVMs to fail to launch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11141,"{code}
      globalCache = newCache;
      mtime++;
{code}
mtime is a long. The above increment doesn't have protection against intervening update in another thread.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9881,"Currently, there seems two call paths to determine the value of _hbase.root.logger_ in log4j.properties file.

1. hbase -> hbase-config.sh -> hbase-env.sh (set _HBASE_ROOT_LOGGER_ if any) -> hbase (set default value to HBASE_ROOT_LOGGER if no variable declared)

2. hbase-daemon.sh -> hbase-config.sh -> hbase-env.sh (set _HBASE_ROOT_LOGGER_ if any) -> hbase-daemon.sh (set default value to HBASE_ROOT_LOGGER if no variable declared)

We found an issue at call path#1, while using 'bin/hbase' the original +console output will redirect to the log file+ if the _HBASE_ROOT_LOGGER_ enabled in hbase-env.sh

for example
1. we use 'bin/hbase zkcli' to connect to zookeeper, will see following log output to the console...
{noformat}
# bin/hbase zkcli
Connecting to scottm-hbase-1.lab:2181
2013-11-04 08:33:39,855 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2013-11-04 08:33:39,855 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=scottm-hbase-1.lab
2013-11-04 08:33:39,856 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_26
2013-11-04 08:33:39,856 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2013-11-04 08:33:39,856 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/java/jdk1.6.0_26/jre
2013-11-04 08:33:39,856 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/usr/java/jdk1.6.0_26/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.7.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.1.1.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-net-1.4.1.jar:/opt/hbase/bin/../lib/core-3.1.1.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/hadoop-core-1.2.1.jar:/opt/hbase/bin/../lib/hamcrest-core-1.3.jar:/opt/hbase/bin/../lib/hbase-client-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-common-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-common-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT-tests.jar:/opt/hbase/bin/../lib/hbase-examples-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-hadoop1-compat-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-it-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-it-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-protocol-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-server-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-server-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT-tests.jar:/opt/hbase/bin/../lib/hbase-shell-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-testing-util-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/hbase-thrift-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT.jar:/opt/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/opt/hbase/bin/../lib/htrace-core-2.01.jar:/opt/hbase/bin/../lib/httpclient-4.1.3.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/opt/hbase/bin/../lib/jackson-xc-1.8.8.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jersey-core-1.8.jar:/opt/hbase/bin/../lib/jersey-json-1.8.jar:/opt/hbase/bin/../lib/jersey-server-1.8.jar:/opt/hbase/bin/../lib/jettison-1.3.1.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.1.2.jar:/opt/hbase/bin/../lib/netty-3.6.6.Final.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/slf4j-api-1.6.4.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/opt/hbase/bin/../lib/stax-api-1.0.1.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/zookeeper-3.4.5.jar:2013-11-04 08:33:39,858 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/java/jdk1.6.0_26/jre/lib/amd64/server:/usr/java/jdk1.6.0_26/jre/lib/amd64:/usr/java/jdk1.6.0_26/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2013-11-04 08:33:39,858 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2013-11-04 08:33:39,858 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2013-11-04 08:33:39,858 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2013-11-04 08:33:39,859 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2013-11-04 08:33:39,859 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.18-164.el5xen
2013-11-04 08:33:39,859 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2013-11-04 08:33:39,859 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2013-11-04 08:33:39,859 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase-0.97.0-hadoop1-SNAPSHOT-SNAPSHOT
2013-11-04 08:33:39,861 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=scottm-hbase-1.lab:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@2efb56b1
2013-11-04 08:33:40,026 INFO  [main-SendThread(scottm-hbase-1.lab:2181)] zookeeper.ClientCnxn: Opening socket connection to server scottm-hbase-1.lab/10.1.145.175:2181. Will not attempt to authenticate using SASL (Unable to locate a login configuration)
2013-11-04 08:33:40,034 INFO  [main-SendThread(scottm-hbase-1.lab:2181)] zookeeper.ClientCnxn: Socket connection established to scottm-hbase-1.lab/10.1.145.175:2181, initiating session
Welcome to ZooKeeper!
JLine support is enabled
2013-11-04 08:33:40,310 INFO  [main-SendThread(scottm-hbase-1.lab:2181)] zookeeper.ClientCnxn: Session establishment complete on server scottm-hbase-1.lab/10.1.145.175:2181, sessionid = 0x14221eebeb70017, negotiated timeout = 30000

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[zk: scottm-hbase-1.lab:2181(CONNECTED) 0]
{noformat}

2. then we enable the _HBASE_ROOT_LOGGER_ in hbase-env.sh
{noformat}
129 # HBASE_ROOT_LOGGER=INFO,DRFA
{noformat}
remove pound sign to enable the _HBASE_ROOT_LOGGER_
{noformat}
129 HBASE_ROOT_LOGGER=INFO,DRFA
{noformat}

3. and re-issue the 'bin/hbase zkcli' again, we will see the logging msg disappear in console output
{noformat}
bin/hbase zkcli
Connecting to scottm-hbase-1.lab:2181
Welcome to ZooKeeper!
JLine support is enabled

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[zk: scottm-hbase-1.lab:2181(CONNECTED) 0]
{noformat}

The reason is that the _HBASE_ROOT_LOGGER_ in hbase-env.sh over-writes the _HBASE_ROOT_LOGGER_ in hbase shell file

put the _egrep_ results for _HBASE_ROOT_LOGGER_ for reference.
{code}
$ egrep -in --color ""HBASE_[a-zA-Z]+_LOGGER"" conf/*
conf/hbase-env.sh:127:# HBASE_ROOT_LOGGER to ""<DESIRED_LOG LEVEL>,DRFA"".
conf/hbase-env.sh:129:# HBASE_ROOT_LOGGER=INFO,DRFA

$ egrep -in --color ""HBASE_[a-zA-Z]+_LOGGER"" bin/*
bin/hbase:47:#   HBASE_ROOT_LOGGER The root appender. Default is INFO,console
bin/hbase:345:HBASE_OPTS=""$HBASE_OPTS -Dhbase.root.logger=${HBASE_ROOT_LOGGER:-INFO,console}""
bin/hbase:353:  HBASE_OPTS=""$HBASE_OPTS -Dhbase.security.logger=${HBASE_SECURITY_LOGGER:-INFO,RFAS}""
bin/hbase:355:  HBASE_OPTS=""$HBASE_OPTS -Dhbase.security.logger=${HBASE_SECURITY_LOGGER:-INFO,NullAppender}""
鈥?bin/hbase-daemon.sh:147:export HBASE_ROOT_LOGGER=${HBASE_ROOT_LOGGER:-""INFO,RFA""}
bin/hbase-daemon.sh:148:export HBASE_SECURITY_LOGGER=${HBASE_SECURITY_LOGGER:-""INFO,RFAS""}
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-474,"Instead of just compressing when we write to disk, maybe we should consider compressing any cell data that would be over a few KB so that it would mean less is going out over the wire. 

Additionally, if we were using record compression, possibly we could even leave it compressed and write it directly to disk. It'd be a way to distribute the compression overhead to clients.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8047,Does anyone use this? Delete it or document it in book.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4467,"When using an Hadoop tarball that has a library naming of ""hadoop-x.y.z-core"" as opposed to ""hadoop-core-x.y.z"" then the hbase script throws errors.

{noformat}
$ bin/start-hbase.sh 
ls: /projects/opensource/hadoop-0.20.2-append/hadoop-core*.jar: No such file or directory
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/util/PlatformName
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.util.PlatformName
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
ls: /projects/opensource/hadoop-0.20.2-append/hadoop-core*.jar: No such file or directory
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/util/PlatformName
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.util.PlatformName
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
localhost: starting zookeeper, logging to /projects/opensource/hbase-trunk-rw//logs/hbase-larsgeorge-zookeeper-de1-app-mbp-2.out
localhost: /projects/opensource/hadoop-0.20.2-append
localhost: ls: /projects/opensource/hadoop-0.20.2-append/hadoop-core*.jar: No such file or directory
localhost: Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/util/PlatformName
localhost: Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.util.PlatformName
localhost: 	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
localhost: 	at java.security.AccessController.doPrivileged(Native Method)
localhost: 	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
localhost: 	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
localhost: 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
localhost: 	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
starting master, logging to /projects/opensource/hbase-trunk-rw/bin/../logs/hbase-larsgeorge-master-de1-app-mbp-2.out
/projects/opensource/hadoop-0.20.2-append
ls: /projects/opensource/hadoop-0.20.2-append/hadoop-core*.jar: No such file or directory
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/util/PlatformName
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.util.PlatformName
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
localhost: starting regionserver, logging to /projects/opensource/hbase-trunk-rw//logs/hbase-larsgeorge-regionserver-de1-app-mbp-2.out
localhost: /projects/opensource/hadoop-0.20.2-append
localhost: ls: /projects/opensource/hadoop-0.20.2-append/hadoop-core*.jar: No such file or directory
localhost: Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/util/PlatformName
localhost: Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.util.PlatformName
localhost: 	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
localhost: 	at java.security.AccessController.doPrivileged(Native Method)
localhost: 	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
localhost: 	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
localhost: 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
localhost: 	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
{noformat}

The naming in this case:

{noformat}
$ ll /projects/opensource/hadoop-0.20.2-append/
total 14960
drwxr-xr-x@  26 larsgeorge  staff      884 Apr 13 09:09 .
drwxr-xr-x  114 larsgeorge  staff     3876 Sep 22 19:42 ..
-rw-r--r--@   1 larsgeorge  staff   348624 Apr 13 08:58 CHANGES.txt
-rw-r--r--@   1 larsgeorge  staff    13366 Apr 13 08:58 LICENSE.txt
-rw-r--r--@   1 larsgeorge  staff      101 Apr 13 08:58 NOTICE.txt
-rw-r--r--@   1 larsgeorge  staff     1366 Apr 13 08:58 README.txt
drwxr-xr-x@  17 larsgeorge  staff      578 Apr 13 08:58 bin
-rw-r--r--@   1 larsgeorge  staff    74035 Apr 13 08:58 build.xml
drwxr-xr-x@   4 larsgeorge  staff      136 Apr 13 08:58 c++
drwxr-xr-x   18 larsgeorge  staff      612 Aug  9 15:11 conf
drwxr-xr-x@  15 larsgeorge  staff      510 Apr 13 08:58 conf.original
drwxr-xr-x@  13 larsgeorge  staff      442 Apr 13 08:58 contrib
drwxr-xr-x@  63 larsgeorge  staff     2142 Apr 13 08:58 docs
-rw-r--r--@   1 larsgeorge  staff     6839 Apr 13 08:58 hadoop-0.20.2-ant.jar
-rw-r--r--    1 larsgeorge  staff  2707920 Apr 13 09:06 hadoop-0.20.2-core.jar
-rw-r--r--@   1 larsgeorge  staff  2689741 Apr 13 08:58 hadoop-0.20.2-core.jar.original
-rw-r--r--@   1 larsgeorge  staff   142466 Apr 13 08:58 hadoop-0.20.2-examples.jar
-rw-r--r--@   1 larsgeorge  staff  1563859 Apr 13 08:58 hadoop-0.20.2-test.jar
-rw-r--r--@   1 larsgeorge  staff    69940 Apr 13 08:58 hadoop-0.20.2-tools.jar
drwxr-xr-x@   6 larsgeorge  staff      204 Apr 13 08:58 ivy
-rw-r--r--@   1 larsgeorge  staff     8852 Apr 13 08:58 ivy.xml
drwxr-xr-x@  30 larsgeorge  staff     1020 Jul 13 10:20 lib
drwxr-xr-x@   3 larsgeorge  staff      102 Apr 13 08:58 librecordio
drwxr-xr-x    3 larsgeorge  staff      102 May 16 09:56 logs
drwxr-xr-x@  17 larsgeorge  staff      578 Apr 13 08:58 src
drwxr-xr-x@   8 larsgeorge  staff      272 Apr 13 08:58 webapps
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8440,"As per Stack and J-D's comments:
ReplicationStateInterface should drop the interface part and ReplicationStateImpl should indicate that it is the Zookeeper implementation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3009,"We had an internal need for a method to update a single cell thousands of times per second without having a ""versions explosion"" problem, and found that the code can be somewhat easily modified for that by reusing Store.updateColumnValue and making it accept byte[]. I'm putting the patch here in case someone else finds it useful, and maybe it can eventually make its way into the source.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7746,"Small nit. These jobs are examples, no used directly by any part of the system, nor exposed explicitly to the user. Move them to the examples module.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4782,Adding a script to check if table descriptors for each region in META for a given table are consistent.  The script compares the table descriptors in META for all regions of a particular table to the table's descriptor (which is just the descriptor for the first region).,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5065,"When trying to build an 'HServerAddress' object with an unresolvable hostname:

e.g. new HServerAddress(""www.IAMUNREACHABLE.com:80"")

a call to 'getResolvedAddress' would cause the 'InetSocketAddress' c'tor to throw an IllegalArgumentException because it is called with a null 'hostname' parameter.
This happens because there is no null-check after the static 'getBindAddressInternal' method returns a null value when the hostname is unresolved.

This is a trivial bug because the code HServerAddress is expected to throw this kind of exception when this error occurs, but it is thrown ""for the wrong reason"". The method 'checkBindAddressCanBeResolved' should be the one throwing the exception (and give a slightly different reason). Because of this reason the method call itself becomes redundent as it will always succeed in the current flow, because the case it checks is already ""checked"" for by the previous ""getResolvedAddress"" method.

In short:
an IllegalArgumentException is thrown with reason: ""hostname can't be null"" from the InetSocketAddress c'tor
INSTEAD OF
an IllegalArgumentException with reason: ""Could not resolve the DNS name of [BADHOSTNAME]:[PORT]"" from HServerAddress's checkBindCanBeResolved method.

Stack trace:
java.lang.IllegalArgumentException: hostname can't be null
	at java.net.InetSocketAddress.<init>(InetSocketAddress.java:139) ~[na:1.7.0_02]
	at org.apache.hadoop.hbase.HServerAddress.getResolvedAddress(HServerAddress.java:108) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.HServerAddress.<init>(HServerAddress.java:64) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.zookeeper.RootRegionTracker.dataToHServerAddress(RootRegionTracker.java:82) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.zookeeper.RootRegionTracker.waitRootRegionLocation(RootRegionTracker.java:73) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:579) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:559) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:688) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:590) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:559) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:688) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:594) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:559) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:173) ~[hbase-0.90.4.jar:0.90.4]
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:147) ~[hbase-0.90.4.jar:0.90.4]

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4226,Just a simple style cleanup of HFileBlock.java.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2813,"It seems we require SSH even for non-distributed mode.  Is it possible to not use SSH and thus not require it, just for the simple local box environment?  (rburton up on irc brought this up)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-398,"This is a comparison table between a SQL and HQL.
IMO, i don't think these features(SQL) are perfectly fit with HQL and Hbase, but If you want for anything from here, please let me know using comment.

Thanks.

|| *SQL* || *HQL* ||
| *Select Statement* \\
SELECT ""column_name"" FROM ""table_name"" \\ | O \\
\\ |
| *Distinct* \\
SELECT DISTINCT ""column_name"" \\
FROM ""table_name"" \\ | {color:#cc0000}{*}X{*}{color} |
| *Where* \\
SELECT ""column_name"" \\
FROM ""table_name"" \\
WHERE ""condition"" \\ | {color:#cc0000}{*}X{*}{color} |
| *And / Or* \\
SELECT ""column_name"" \\
FROM ""table_name"" \\
WHERE ""simple condition"" \\
\{\[AND\|OR\] ""simple condition""\}\+ \\ | {color:#cc0000}{*}X{*}{color}\\ |
| *In* \\
SELECT ""column_name"" \\
FROM ""table_name"" \\
WHERE ""column_name"" IN ('value1', 'value2', ...) \\ | {color:#cc0000}{*}X{*}{color} |
| *Between* \\
SELECT ""column_name"" \\
FROM ""table_name"" \\
WHERE ""column_name"" BETWEEN 'value1' AND 'value2' \\ | {color:#cc0000}{*}X{*}{color} |
| *Like* \\
SELECT ""column_name"" \\
FROM ""table_name"" \\
WHERE ""column_name"" LIKE \{PATTERN\} \\ | {color:#cc0000}{*}X{*}{color}\\ |
| *Order By* \\
SELECT ""column_name"" \\
FROM ""table_name"" \\
\[WHERE ""condition""\] \\
ORDER BY ""column_name"" \[ASC, DESC\] \\ | {color:#cc0000}{*}X{*}{color} |
| *Count / Sum / Min / Max / Avg* \\
SELECT COUNT(""column_name"") \\
FROM ""table_name"" \\ | {color:#cc0000}{*}X{*}{color}\\ |
| *Group By* \\
SELECT ""column_name1"", SUM(""column_name2"") \\
FROM ""table_name"" \\
GROUP BY ""column_name1"" \\ | {color:#cc0000}{*}X{*}{color} |
| *Having* \\
SELECT ""column_name1"", SUM(""column_name2"") \\
FROM ""table_name"" \\
GROUP BY ""column_name1"" \\
HAVING (arithematic function condition) \\ | {color:#cc0000}{*}X{*}{color} \\ |
| *Create Table Statement* \\
CREATE TABLE ""table_name"" \\
(""column 1"" ""data_type_for_column_1"", \\
""column 2"" ""data_type_for_column_2"", \\
... ) \\ | O \\ |
| *Drop Table Statement* \\
DROP TABLE ""table_name"" \\ | O \\ |
| *Truncate Table Statement* \\
TRUNCATE TABLE ""table_name"" \\ | O \\ |
| *Insert Into Statement* \\
INSERT INTO ""table_name"" (""column1"", ""column2"", ...) \\
VALUES (""value1"", ""value2"", ...) \\ | O \\ |
| *Update Statement* \\
UPDATE ""table_name"" \\
SET ""column_1"" = \[new value\] \\
WHERE \{condition\} \\ | {color:#cc0000}{*}X{*}{color} \\ |
| *Delete From Statement* \\
DELETE FROM ""table_name"" \\
WHERE \{condition\} \\ | O \\ |

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1701,Set some status on rowcounter.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-429,"Can we get the hbase-site.xml out of there. Seems it should not be there. 

In particular this causes a problem with maven, as we have little control over classpath ordering, so our hbase-site.xml is behind the hbase jar.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-25,"Looking in logs, a regionserver went down because it could not contact the master after 60 seconds.  Watching logging, the HRS is repeatedly checking all 150 loaded regions over and over again w/ a pause of about 5 seconds between runs... then there is a suspicious 60+ second gap with no logging as though the regionserver had hung up on something:

{code}
2007-12-03 13:14:54,178 DEBUG hbase.HRegionServer - flushing region postlog,img151/60/plakatlepperduzy1hh7.jpg,1196614355635
2007-12-03 13:14:54,178 DEBUG hbase.HRegion - Not flushing cache for region postlog,img151/60/plakatlepperduzy1hh7.jpg,1196614355635: snapshotMemcaches() determined that there was nothing to do
2007-12-03 13:14:54,205 DEBUG hbase.HRegionServer - flushing region postlog,img247/230/seanpaul4li.jpg,1196615889965
2007-12-03 13:14:54,205 DEBUG hbase.HRegion - Not flushing cache for region postlog,img247/230/seanpaul4li.jpg,1196615889965: snapshotMemcaches() determined that there was nothing to do
2007-12-03 13:16:04,305 FATAL hbase.HRegionServer - unable to report to master for 67467 milliseconds - aborting server
2007-12-03 13:16:04,455 INFO  hbase.Leases - regionserver/0:0:0:0:0:0:0:0:60020 closing leases
2007-12-03 13:16:04,455 INFO  hbase.Leases$LeaseMonitor - regionserver/0:0:0:0:0:0:0:0:60020.leaseChecker exiting
{code}

Master seems to be running fine scanning its ~700 regions.  Then you see this in log, before the HRS shuts itself down.

{code}
2007-12-03 13:14:31,416 INFO  hbase.Leases - HMaster.leaseChecker lease expired 153260899/1532608992007-12-03 13:14:31,417 INFO  hbase.HMaster - XX.XX.XX.102:60020 lease expired
{code}

... and we go on to process shutdown.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15309,"I'd memory leak issue in regionserver process, VM and RSS memory continiously increasing 64MB.
I'm using hbase-0.94.6 , MALLOC_ARENA_MAX=4 was set in hbase-env.sh
I've huge write load and frequent minor compaction, We've used GZip hfile compression.
Max java regionserver heap size is 32GB.


{noformat}
top - 14:28:30 up 201 days, 21:06,  3 users,  load average: 5.67, 3.72, 3.31
Tasks: 803 total,   1 running, 802 sleeping,   0 stopped,   0 zombie
Cpu(s):  8.3%us,  2.1%sy,  0.0%ni, 85.9%id,  3.5%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:  65932340k total, 63961912k used,  1970428k free,  2394528k buffers
Swap: 29659132k total,    63532k used, 29595600k free,  1095268k cached

 PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 57335 hbase     20   0 46.4g  44g 9296 S 98.2 70.9  13319:10 java
{noformat}

{noformat}
 [hbase@xxxxxx-hslave ~]$  pmap -x 57335 | sort -k 3 -nr | more
total kB        48695984 46765792 46756512
00007ff312460000 33171072 33169464 33169464 rwx--    [ anon ]
000000004010a000 1448552 1448552 1448552 rwx--    [ anon ]
00007ff2d1810000  612120  603124  603124 rwx--    [ anon ]
00007ff2fadff000  383364  383364  383364 rwx--    [ anon ]
00007ff0e8000000  131072  131072  131072 rwx--    [ anon ]
00007ff218000000  131048  131048  131048 rwx--    [ anon ]
00007ff128000000  131068  131048  131048 rwx--    [ anon ]
00007ff230000000  131044  131044  131044 rwx--    [ anon ]
00007ff000000000  131036  131036  131036 rwx--    [ anon ]
00007fefe0000000  131060  131036  131036 rwx--    [ anon ]
00007ff23c000000   65536   65536   65536 rwx--    [ anon ]
00007ff0a4000000   65536   65536   65536 rwx--    [ anon ]
00007ff054000000   65536   65536   65536 rwx--    [ anon ]
00007ff01c000000   65536   65536   65536 rwx--    [ anon ]
00007fefb4000000   65536   65536   65536 rwx--    [ anon ]
00007ff22c000000   65532   65532   65532 rwx--    [ anon ]
00007ff110000000   65532   65532   65532 rwx--    [ anon ]
00007ff10c000000   65532   65532   65532 rwx--    [ anon ]
00007ff0b8000000   65532   65532   65532 rwx--    [ anon ]
00007ff09c000000   65532   65532   65532 rwx--    [ anon ]
00007feff8000000   65532   65532   65532 rwx--    [ anon ]
00007ff250000000   65528   65528   65528 rwx--    [ anon ]
--More--
{noformat}

{noformat}
$pmap -x 57335 | awk '{print $3}' | awk '{ if($i<65536 && $i>64000) print $i}' | wc -l
146
{noformat}

Regionserver process has many anon pages, size varying from 64000 to 65536 KB that shown above.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21176,"Faced with several inconsistency issues in HBase 2.0.1:
{code}
ERROR: Region \{ meta => null, hdfs => hdfs://master:50001/hbase/data/default/some_table/0646d0bee757d0fb0de1529475b5426f, deployed => hbase-region,16020,1536493017073;some_table,,1534195327532.0646d0bee757d0fb0de1529475b5426f., replicaId => 0 } not in META, but deployed on hbase-region,16020,1536493017073
...
ERROR: hbase:namespace has no state in meta
ERROR: table1 has no state in meta
ERROR: table2 has no state in meta
2018-09-09 21:40:04,155 INFO [main] util.HBaseFsck: Handling overlap merges in parallel. set hbasefsck.overlap.merge.parallel to false to run serially.
ERROR: There is a hole in the region chain between and . You need to create a new .regioninfo and region dir in hdfs to plug the hole.
ERROR: Found inconsistency in table test3
{code}

BUT in 2.0.x HBAse version options _-repair, -fix, -fixHdfsHoles, etc_ was deprecated.
How I can fix it without these options?

Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21049,"Power off and restart(Hadoop and HBase), Master is initializing -聽Hbase ServerManager: but crash processing already in progress

command jps, HMaster聽and HRegionServer is live

聽

LOG:

core file size (blocks, -c) 0
data seg size (kbytes, -d) unlimited
scheduling priority (-e) 0
file size (blocks, -f) unlimited
pending signals (-i) 64091
max locked memory (kbytes, -l) 64
max memory size (kbytes, -m) unlimited
open files (-n) 1024
pipe size (512 bytes, -p) 8
POSIX message queues (bytes, -q) 819200
real-time priority (-r) 0
stack size (kbytes, -s) 8192
cpu time (seconds, -t) unlimited
max user processes (-u) 64091
virtual memory (kbytes, -v) unlimited
file locks (-x) unlimited
2018-08-14 17:25:00,173 INFO [main] master.HMaster: STARTING service HMaster
2018-08-14 17:25:00,174 INFO [main] util.VersionInfo: HBase 2.1.0
2018-08-14 17:25:00,174 INFO [main] util.VersionInfo: Source code repository revision=4531d1c947a25b28a9a994b60c791a112c12a2b4
2018-08-14 17:25:00,174 INFO [main] util.VersionInfo: Compiled by hbase on Wed Aug 1 11:25:59 2018
2018-08-14 17:25:00,174 INFO [main] util.VersionInfo: From source with checksum fc32566f7e030ff71458fbf6dc77bce9
2018-08-14 17:25:00,516 INFO [main] util.ServerCommandLine: hbase.tmp.dir: /tmp/hbase-root
2018-08-14 17:25:00,516 INFO [main] util.ServerCommandLine: hbase.rootdir: hdfs://192.168.101.114:9000/hbase
2018-08-14 17:25:00,516 INFO [main] util.ServerCommandLine: hbase.cluster.distributed: true
2018-08-14 17:25:00,516 INFO [main] util.ServerCommandLine: hbase.zookeeper.quorum: 192.168.101.114:2181
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:PATH=/opt/apache-phoenix-5.0.0-HBase-2.0-bin/bin:/opt/hbase-2.1.0/bin:/opt/hadoop-2.8.4/bin:/opt/jdk1.8.0_172/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/opt/hadoop-2.8.4/etc/hadoop
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop-2.8.4/lib/native::/opt/hadoop-2.8.4/lib/native:
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8071
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:HBASE_CONF_DIR=/opt/hbase-2.1.0/conf
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:HDFS_DATANODE_SECURE_USER=root
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/root
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:PHOENIX_HOME=/opt/apache-phoenix-5.0.0-HBase-2.0-bin
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop-2.8.4/lib/native::/opt/hadoop-2.8.4/lib/native:
2018-08-14 17:25:00,517 INFO [main] util.ServerCommandLine: env:LOGNAME=root
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:PWD=/opt/hbase-2.1.0/bin
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HADOOP_PREFIX=/opt/hadoop-2.8.4
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HADOOP_INSTALL=/opt/hadoop-2.8.4
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:SHELL=/bin/bash
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:SELINUX_USE_CURRENT_RANGE=
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:YARN_CONF_DIR=/opt/hadoop-2.8.4/etc/hadoop
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/opt/hadoop-2.8.4
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8070
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop-2.8.4
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_OPTS= -XX:+UseConcMarkSweepGC -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8070 -Dhbase.log.dir=/opt/hbase-2.1.0/logs -Dhbase.log.file=hbase-root-master-hbase-114.log -Dhbase.home.dir=/opt/hbase-2.1.0 -Dhbase.id.str=root -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop-2.8.4/lib/native::/opt/hadoop-2.8.4/lib/native: -Dhbase.security.logger=INFO,RFAS
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HDFS_DATANODE_USER=root
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: 1:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:SHLVL=4
2018-08-14 17:25:00,518 INFO [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-root-master-hbase-114.log
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HISTSIZE=1000
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:JAVA_HOME=/opt/jdk1.8.0_172
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:TERM=xterm
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:LANG=zh_CN.UTF-8
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:XDG_SESSION_ID=1
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:SELINUX_LEVEL_REQUESTED=
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/opt/hadoop-2.8.4/libexec
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:SELINUX_ROLE_REQUESTED=
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/opt/hadoop-2.8.4
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/opt/hadoop-2.8.4
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/opt/hadoop-2.8.4
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop-2.8.4/lib:/opt/hadoop-2.8.4/lib/native
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=root
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-root-master.znode
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:SSH_TTY=/dev/pts/0
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:SSH_CLIENT=192.168.98.129 35604 22
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-root-master-hbase-114
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase-2.1.0/logs
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:USER=root
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: dparty/commons-logging-1.2.jar:/opt/hbase-2.1.0/lib/client-facing-thirdparty/findbugs-annotations-1.3.9-1.jar:/opt/hbase-2.1.0/lib/client-facing-thirdparty/htrace-core4-4.2.0-incubating.jar:/opt/hbase-2.1.0/lib/client-facing-thirdparty/log4j-1.2.17.jar:/opt/hbase-2.1.0/lib/client-facing-thirdparty/phoenix-5.0.0-HBase-2.0-server.jar:/opt/hbase-2.1.0/lib/client-facing-thirdparty/phoenix-core-5.0.0-HBase-2.0.jar:/opt/hbase-2.1.0/lib/client-facing-thirdparty/slf4j-api-1.7.25.jar:/opt/hadoop-2.8.4/etc/hadoop:/opt/hadoop-2.8.4/share/hadoop/common/lib/*:/opt/hadoop-2.8.4/share/hadoop/common/*:/opt/hadoop-2.8.4/share/hadoop/hdfs:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/*:/opt/hadoop-2.8.4/share/hadoop/hdfs/*:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/*:/opt/hadoop-2.8.4/share/hadoop/yarn/*:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/*:/opt/hadoop-2.8.4/share/hadoop/mapreduce/*:/opt/hadoop-2.8.4/contrib/capacity-scheduler/*.jar:/opt/hbase-2.1.0/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HDFS_NAMENODE_USER=root
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:SSH_CONNECTION=192.168.98.129 35604 192.168.101.114 22
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HBASE_AUTOSTART_FILE=/tmp/hbase-root-master.autostart
2018-08-14 17:25:00,519 INFO [main] util.ServerCommandLine: env:HOSTNAME=hbase-114
2018-08-14 17:25:00,520 INFO [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop-2.8.4/lib/native
2018-08-14 17:25:00,520 INFO [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2018-08-14 17:25:00,520 INFO [main] util.ServerCommandLine: env:HDFS_SECONDARYNAMENODE_USER=root
2018-08-14 17:25:00,520 INFO [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2018-08-14 17:25:00,520 INFO [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase-2.1.0
2018-08-14 17:25:00,520 INFO [main] util.ServerCommandLine: env:HOME=/root
2018-08-14 17:25:00,520 INFO [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2018-08-14 17:25:00,521 INFO [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.172-b11
2018-08-14 17:25:00,521 INFO [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -Xdebug, -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8070, -Dhbase.log.dir=/opt/hbase-2.1.0/logs, -Dhbase.log.file=hbase-root-master-hbase-114.log, -Dhbase.home.dir=/opt/hbase-2.1.0, -Dhbase.id.str=root, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop-2.8.4/lib/native::/opt/hadoop-2.8.4/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2018-08-14 17:25:00,886 INFO [main] metrics.MetricRegistries: Loaded MetricRegistries class org.apache.hadoop.hbase.metrics.impl.MetricRegistriesImpl
2018-08-14 17:25:01,258 INFO [main] regionserver.RSRpcServices: master/hbase-114:16000 server-side Connection retries=3
2018-08-14 17:25:01,278 INFO [main] ipc.RpcExecutor: Instantiated default.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=3, maxQueueLength=300, handlerCount=30
2018-08-14 17:25:01,280 INFO [main] ipc.RpcExecutor: Instantiated priority.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=2, maxQueueLength=300, handlerCount=20
2018-08-14 17:25:01,280 INFO [main] ipc.RpcExecutor: Instantiated replication.FPBQ.Fifo with queueClass=class java.util.concurrent.LinkedBlockingQueue; numCallQueues=1, maxQueueLength=300, handlerCount=3
2018-08-14 17:25:01,418 INFO [main] ipc.RpcServerFactory: Creating org.apache.hadoop.hbase.ipc.NettyRpcServer hosting hbase.pb.MasterService, hbase.pb.RegionServerStatusService, hbase.pb.LockService, hbase.pb.ClientService, hbase.pb.AdminService
2018-08-14 17:25:01,632 INFO [main] ipc.NettyRpcServer: Bind to /192.168.101.114:16000
2018-08-14 17:25:01,688 INFO [main] hfile.CacheConfig: Allocating onheap LruBlockCache size=1.55 GB, blockSize=64 KB
2018-08-14 17:25:01,694 INFO [main] hfile.CacheConfig: Created cacheConfig: blockCache=LruBlockCache\{blockCount=0, currentSize=1.16 MB, freeSize=1.55 GB, maxSize=1.55 GB, heapSize=1.16 MB, minSize=1.47 GB, minFactor=0.95, multiSize=752.80 MB, multiFactor=0.5, singleSize=376.40 MB, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
2018-08-14 17:25:01,695 INFO [main] hfile.CacheConfig: Created cacheConfig: blockCache=LruBlockCache\{blockCount=0, currentSize=1.16 MB, freeSize=1.55 GB, maxSize=1.55 GB, heapSize=1.16 MB, minSize=1.47 GB, minFactor=0.95, multiSize=752.80 MB, multiFactor=0.5, singleSize=376.40 MB, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
2018-08-14 17:25:02,160 INFO [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2018-08-14 17:25:02,163 INFO [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2018-08-14 17:25:02,233 INFO [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=192.168.101.114:2181
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:host.name=hbase-114
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_172
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/jdk1.8.0_172/jre
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: o-2.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.4-tests.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.4.jar:/opt/hadoop-2.8.4/contrib/capacity-scheduler/*.jar:/opt/hbase-2.1.0/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop-2.8.4/lib/native::/opt/hadoop-2.8.4/lib/native:
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:os.version=3.10.0-862.el7.x86_64
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:user.name=root
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2018-08-14 17:25:02,239 INFO [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase-2.1.0/bin
2018-08-14 17:25:02,240 INFO [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.101.114:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@4ae2e781
2018-08-14 17:25:02,256 INFO [main-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.101.114/192.168.101.114:2181. Will not attempt to authenticate using SASL (unknown error)
2018-08-14 17:25:02,264 INFO [main-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.101.114/192.168.101.114:2181, initiating session
2018-08-14 17:25:02,282 INFO [main-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.101.114/192.168.101.114:2181, sessionid = 0x10004dac1970000, negotiated timeout = 40000
2018-08-14 17:25:02,352 INFO [main] util.log: Logging initialized @2552ms
2018-08-14 17:25:02,413 INFO [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2018-08-14 17:25:02,426 INFO [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2018-08-14 17:25:02,426 INFO [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
2018-08-14 17:25:02,428 INFO [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2018-08-14 17:25:02,428 INFO [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-08-14 17:25:02,428 INFO [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-08-14 17:25:02,455 INFO [main] http.HttpServer: Jetty bound to port 16010
2018-08-14 17:25:02,456 INFO [main] server.Server: jetty-9.3.19.v20170502
2018-08-14 17:25:02,489 INFO [main] handler.ContextHandler: Started o.e.j.s.ServletContextHandler@49232c6f\{/logs,file:///opt/hbase-2.1.0/logs/,AVAILABLE}
2018-08-14 17:25:02,490 INFO [main] handler.ContextHandler: Started o.e.j.s.ServletContextHandler@279126f5\{/static,file:///opt/hbase-2.1.0/hbase-webapps/static/,AVAILABLE}
2018-08-14 17:25:02,582 INFO [main] handler.ContextHandler: Started o.e.j.w.WebAppContext@537b3b2e\{/,file:///opt/hbase-2.1.0/hbase-webapps/master/,AVAILABLE}{file:/opt/hbase-2.1.0/hbase-webapps/master}
2018-08-14 17:25:02,587 INFO [main] server.AbstractConnector: Started ServerConnector@550c973e\{HTTP/1.1,[http/1.1]}{0.0.0.0:16010}
2018-08-14 17:25:02,587 INFO [main] server.Server: Started @2787ms
2018-08-14 17:25:02,590 INFO [main] master.HMaster: hbase.rootdir=hdfs://192.168.101.114:9000/hbase, hbase.cluster.distributed=true
2018-08-14 17:25:02,606 INFO [Thread-14] master.HMaster: Adding backup master ZNode /hbase/backup-masters/hbase-114,16000,1534238700547
2018-08-14 17:25:02,685 INFO [Thread-14] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/hbase-114,16000,1534238700547 from backup master directory
2018-08-14 17:25:02,691 INFO [Thread-14] master.ActiveMasterManager: Registered as active master=hbase-114,16000,1534238700547
2018-08-14 17:25:02,697 INFO [Thread-14] regionserver.ChunkCreator: Allocating data MemStoreChunkPool with chunk size 2 MB, max count 713, initial count 0
2018-08-14 17:25:02,698 INFO [Thread-14] regionserver.ChunkCreator: Allocating index MemStoreChunkPool with chunk size 204.80 KB, max count 792, initial count 0
2018-08-14 17:25:02,992 INFO [Thread-14] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2018-08-14 17:25:03,001 INFO [Thread-14] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2018-08-14 17:25:03,094 INFO [Thread-14] zookeeper.ReadOnlyZKClient: Connect 0x66461af1 to 192.168.101.114:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
2018-08-14 17:25:03,100 INFO [ReadOnlyZKClient-192.168.101.114:2181@0x66461af1] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.101.114:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$52/1619197561@6e451c19
2018-08-14 17:25:03,101 INFO [ReadOnlyZKClient-192.168.101.114:2181@0x66461af1-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.101.114/192.168.101.114:2181. Will not attempt to authenticate using SASL (unknown error)
2018-08-14 17:25:03,101 INFO [ReadOnlyZKClient-192.168.101.114:2181@0x66461af1-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.101.114/192.168.101.114:2181, initiating session
2018-08-14 17:25:03,104 INFO [ReadOnlyZKClient-192.168.101.114:2181@0x66461af1-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.101.114/192.168.101.114:2181, sessionid = 0x10004dac1970001, negotiated timeout = 40000
2018-08-14 17:25:03,145 INFO [Thread-14] procedure2.ProcedureExecutor: Starting 16 core workers (bigger of cpus/4 or 16) with max (burst) worker count=160
2018-08-14 17:25:03,149 INFO [Thread-14] util.FSHDFSUtils: Recover lease on dfs file hdfs://192.168.101.114:9000/hbase/MasterProcWALs/pv2-00000000000000000004.log
2018-08-14 17:25:03,153 INFO [Thread-14] util.FSHDFSUtils: Recovered lease, attempt=0 on file=hdfs://192.168.101.114:9000/hbase/MasterProcWALs/pv2-00000000000000000004.log after 4ms
2018-08-14 17:25:03,188 WARN [Thread-14] util.CommonFSUtils: Your Hadoop installation does not include the StreamCapabilities class from HDFS-11644, so we will skip checking if any FSDataOutputStreams actually support hflush/hsync. If you are running on top of HDFS this probably just means you have an older version and this can be ignored. If you are running on top of an alternate FileSystem implementation you should manually verify that hflush and hsync are implemented; otherwise you risk data loss and hard to diagnose errors when our assumptions are violated.
2018-08-14 17:25:03,189 INFO [Thread-14] wal.WALProcedureStore: Rolled new Procedure Store WAL, id=5
2018-08-14 17:25:03,190 INFO [Thread-14] procedure2.ProcedureExecutor: Recovered WALProcedureStore lease in 42msec
2018-08-14 17:25:03,224 INFO [Thread-14] procedure2.ProcedureExecutor: Loaded WALProcedureStore in 33msec
2018-08-14 17:25:03,224 INFO [Thread-14] procedure2.RemoteProcedureDispatcher: Instantiated, coreThreads=128 (allowCoreThreadTimeOut=true), queueMaxSize=32, operationDelay=150
2018-08-14 17:25:03,261 WARN [Thread-14] master.ServerManager: Expiration of hbase-116,16020,1534237430655 but server not online
2018-08-14 17:25:03,261 INFO [Thread-14] master.ServerManager: Processing expiration of hbase-116,16020,1534237430655 on hbase-114,16000,1534238700547
2018-08-14 17:25:03,481 WARN [Thread-14] master.ServerManager: Expiration of hbase-115,16020,1534237425729 but server not online
2018-08-14 17:25:03,481 INFO [Thread-14] master.ServerManager: Processing expiration of hbase-115,16020,1534237425729 on hbase-114,16000,1534238700547
2018-08-14 17:25:03,622 INFO [Thread-14] balancer.BaseLoadBalancer: slop=0.001, tablesOnMaster=false, systemTablesOnMaster=false
2018-08-14 17:25:03,629 INFO [Thread-14] balancer.StochasticLoadBalancer: Loaded config; maxSteps=1000000, stepsPerRegion=800, maxRunningTime=30000, isByTable=false, etc.
2018-08-14 17:25:03,669 INFO [Thread-14] master.HMaster: Active/primary master=hbase-114,16000,1534238700547, sessionid=0x10004dac1970000, setting cluster-up flag (Was=false)
2018-08-14 17:25:03,771 INFO [PEWorker-4] procedure.ServerCrashProcedure: Start pid=12, state=RUNNABLE:SERVER_CRASH_START; ServerCrashProcedure server=hbase-115,16020,1534237425729, splitWal=true, meta=false
2018-08-14 17:25:03,772 INFO [Thread-14] procedure2.TimeoutExecutorThread: ADDED pid=-1, state=WAITING_TIMEOUT; org.apache.hadoop.hbase.procedure2.ProcedureExecutor$CompletedProcedureCleaner; timeout=30000, timestamp=1534238733772
2018-08-14 17:25:03,774 INFO [PEWorker-3] procedure.ServerCrashProcedure: Start pid=11, state=RUNNABLE:SERVER_CRASH_START; ServerCrashProcedure server=hbase-116,16020,1534237430655, splitWal=true, meta=false
2018-08-14 17:25:03,775 INFO [Thread-14] cleaner.CleanerChore: Cleaner pool size is 1
2018-08-14 17:25:03,776 INFO [Thread-14] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=192.168.101.114:2181
2018-08-14 17:25:03,776 INFO [Thread-14] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.101.114:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@46bb7405
2018-08-14 17:25:03,777 INFO [Thread-14-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.101.114/192.168.101.114:2181. Will not attempt to authenticate using SASL (unknown error)
2018-08-14 17:25:03,777 INFO [Thread-14-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.101.114/192.168.101.114:2181, initiating session
2018-08-14 17:25:03,777 INFO [Thread-14] cleaner.LogCleaner: Creating OldWALs cleaners with size=2
2018-08-14 17:25:03,780 INFO [Thread-14-SendThread(192.168.101.114:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.101.114/192.168.101.114:2181, sessionid = 0x10004dac1970006, negotiated timeout = 40000
2018-08-14 17:25:03,967 INFO [RpcServer.default.FPBQ.Fifo.handler=28,queue=1,port=16000] master.ServerManager: Registering regionserver=hbase-116,16020,1534238701517
2018-08-14 17:25:03,967 INFO [RpcServer.default.FPBQ.Fifo.handler=29,queue=2,port=16000] master.ServerManager: Registering regionserver=hbase-115,16020,1534238702258
2018-08-14 17:25:04,022 INFO [RegionServerTracker-0] master.RegionServerTracker: RegionServer ephemeral node created, adding [hbase-116,16020,1534238701517]
2018-08-14 17:25:04,023 INFO [RegionServerTracker-0] master.RegionServerTracker: RegionServer ephemeral node created, adding [hbase-115,16020,1534238702258]
2018-08-14 17:25:33,877 INFO [WALProcedureStoreSyncThread] wal.ProcedureWALFile: Archiving hdfs://192.168.101.114:9000/hbase/MasterProcWALs/pv2-00000000000000000004.log to hdfs://192.168.101.114:9000/hbase/oldWALs/pv2-00000000000000000004.log
2018-08-14 17:26:59,875 WARN [qtp1304765785-87] servlet.ServletHandler: /master-status
org.apache.hadoop.hbase.PleaseHoldException: Master is initializing
 at org.apache.hadoop.hbase.master.HMaster.isInMaintenanceMode(HMaster.java:2890)
 at org.apache.hadoop.hbase.tmpl.master.MasterStatusTmplImpl.renderNoFlush(MasterStatusTmplImpl.java:277)
 at org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.renderNoFlush(MasterStatusTmpl.java:395)
 at org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl.render(MasterStatusTmpl.java:386)
 at org.apache.hadoop.hbase.master.MasterStatusServlet.doGet(MasterStatusServlet.java:81)
 at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
 at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
 at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
 at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
 at org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:112)
 at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
 at org.apache.hadoop.hbase.http.ClickjackingPreventionFilter.doFilter(ClickjackingPreventionFilter.java:48)
 at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
 at org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1374)
 at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
 at org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:49)
 at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
 at org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:49)
 at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
 at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
 at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
 at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
 at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
 at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
 at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
 at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
 at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
 at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
 at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
 at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
 at org.eclipse.jetty.server.Server.handle(Server.java:534)
 at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)
 at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
 at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
 at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
 at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
 at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
 at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
 at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
 at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
 at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
 at java.lang.Thread.run(Thread.java:748)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17966,"tableExists can return false for cases where createTable fails. Obviously the logic implemented in these two methods are different. 
This is to make this implementation consistent",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19499,"Probably this is the first of few issues found during some tests with RegionMover. After HBASE-13014 we ship the new RegionMover tool but it currently assumes that master will be hosting regions so it attempts to remove master from the list and that causes an issue similar to this:

{code}
17/12/12 11:01:06 WARN util.RegionMover: Could not remove master from list of RS
java.lang.Exception: Server host1.example.com:22001 is not in list of online servers(Offline/Incorrect)
	at org.apache.hadoop.hbase.util.RegionMover.stripServer(RegionMover.java:818)
	at org.apache.hadoop.hbase.util.RegionMover.stripMaster(RegionMover.java:757)
	at org.apache.hadoop.hbase.util.RegionMover.access$1800(RegionMover.java:78)
	at org.apache.hadoop.hbase.util.RegionMover$Unload.call(RegionMover.java:339)
	at org.apache.hadoop.hbase.util.RegionMover$Unload.call(RegionMover.java:314)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}

Basicaly",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19507,"1銆?
create   'abc',{NAME => 'cf', MOB_THRESHOLD => '10', IS_MOB => 'true'}
put 'abc','1','cf:a','xxxx1'
put 'abc','2','cf:a','xxxx2'
put 'abc','3','cf:a','xxxx3'
put 'abc','4','cf:a','yyyyyyyyyyyyy1'
put 'abc','5','cf:a','yyyyyyyyyyyyy2'
put 'abc','6','cf:a','yyyyyyyyyyyyy3'
  
hbase(main):011:0> scan 'abc'
ROW                                        COLUMN+CELL                                                                                                                 
 1                                         column=cf:a, timestamp=1513171753098, value=xxxx1                                                                           
 2                                         column=cf:a, timestamp=1513171753208, value=xxxx2                                                                           
 3                                         column=cf:a, timestamp=1513171753246, value=xxxx3                                                                           
 4                                         column=cf:a, timestamp=1513171753273, value=yyyyyyyyyyyyy1                                                                  
 5                                         column=cf:a, timestamp=1513171753301, value=yyyyyyyyyyyyy2                                                                  
 6                                         column=cf:a, timestamp=1513171754282, value=yyyyyyyyyyyyy3                                                                  

hbase(main):012:0> flush 'abc'
hbase(main):012:0> major_compact 'abc'
hbase(main):012:0> major_compact_mob 'abc'

2銆?
[See Hfile]:
hbase org.apache.hadoop.hbase.io.hfile.HFile -f /hbase/data/default/abc/a31b3146cba0d4569a7bf44e70e299c9/cf/22a432ba5c2c4802bedd947b99626f10 -p
K: 1/cf:a/1513172294864/Put/vlen=5/seqid=4 V: xxxx1
K: 2/cf:a/1513172294892/Put/vlen=5/seqid=5 V: xxxx2
K: 3/cf:a/1513172294914/Put/vlen=5/seqid=6 V: xxxx3
K: 4/cf:a/1513172294954/Put/vlen=76/seqid=7 V: \x00\x00\x00\x0Ed41d8cd98f00b204e9800998ecf8427e20171213ce022548c4c3498e864fda289b81e711 T[0]:  T[1]: abc
K: 5/cf:a/1513172294982/Put/vlen=76/seqid=8 V: \x00\x00\x00\x0Ed41d8cd98f00b204e9800998ecf8427e20171213ce022548c4c3498e864fda289b81e711 T[0]:  T[1]: abc
K: 6/cf:a/1513172296455/Put/vlen=76/seqid=9 V: \x00\x00\x00\x0Ed41d8cd98f00b204e9800998ecf8427e20171213ce022548c4c3498e864fda289b81e711 T[0]:  T[1]: abc
Scanned kv count -> 6

[See Mobfile]:
hbase org.apache.hadoop.hbase.io.hfile.HFile -f /hbase/mobdir/data/default/abc/07aab825b62dd9111831839cc9039df9/cf/d41d8cd98f00b204e9800998ecf8427e20171213bd8cfaf146684d4096ebf7994f050e96 -p
K: 4/cf:a/1513172924196/Put/vlen=14/seqid=7 V: yyyyyyyyyyyyy1
K: 5/cf:a/1513172924214/Put/vlen=14/seqid=8 V: yyyyyyyyyyyyy2
K: 6/cf:a/1513172925768/Put/vlen=14/seqid=9 V: yyyyyyyyyyyyy3

3銆?
alter 'abc',{NAME => 'cf', MOB_THRESHOLD => '10240' }
put 'abc','7','cf:a','zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz'
ROW                                        COLUMN+CELL                                                                                                                 
 1                                         column=cf:a, timestamp=1513172294864, value=xxxx1                                                                           
 2                                         column=cf:a, timestamp=1513172294892, value=xxxx2                                                                           
 3                                         column=cf:a, timestamp=1513172294914, value=xxxx3                                                                           
 4                                         column=cf:a, timestamp=1513172294954, value=yyyyyyyyyyyyy1                                                                  
 5                                         column=cf:a, timestamp=1513172294982, value=yyyyyyyyyyyyy2                                                                  
 6                                         column=cf:a, timestamp=1513172296455, value=yyyyyyyyyyyyy3                                                                  
 7                                         column=cf:a, timestamp=1513172691250, value=zzzzzzzzzzzzzzzzzzzzzz .....'(10304 Byte) 

hbase(main):012:0> flush 'abc'
hbase(main):013:0> major_compact_mob 'abc'

hbase(main):070:0> scan 'abc'
ROW                                        COLUMN+CELL                                                                                                                 
 1                                         column=cf:a, timestamp=1513172294864, value=xxxx1                                                                           
 2                                         column=cf:a, timestamp=1513172294892, value=xxxx2                                                                           
 3                                         column=cf:a, timestamp=1513172294914, value=xxxx3                                                                           
 4                                         column=cf:a, timestamp=1513172294954, value=\x00\x00\x00\x0Ed41d8cd98f00b204e9800998ecf8427e2017121320a7c40681254d6a8a396e9d
                                           b34529af                                                                                                                    
 5                                         column=cf:a, timestamp=1513172294982, value=\x00\x00\x00\x0Ed41d8cd98f00b204e9800998ecf8427e2017121320a7c40681254d6a8a396e9d
                                           b34529af                                                                                                                    
 6                                         column=cf:a, timestamp=1513172296455, value=\x00\x00\x00\x0Ed41d8cd98f00b204e9800998ecf8427e2017121320a7c40681254d6a8a396e9d
                                           b34529af                                                                                                                    
 7                                         column=cf:a, timestamp=1513172691250, value=\x00\x00(@d41d8cd98f00b204e9800998ecf8427e2017121320a7c40681254d6a8a396e9db34529
                                           af                                                                                                                          
7 row(s) in 0.0280 seconds

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17714,"We have a test in Phoenix where we introduce an artificial sleep of 2 times the RPC timeout in preScannerNext() hook of a co-processor. 

{code}
 public static class SleepingRegionObserver extends SimpleRegionObserver {
        public SleepingRegionObserver() {}
        
        @Override
        public boolean preScannerNext(final ObserverContext<RegionCoprocessorEnvironment> c,
                final InternalScanner s, final List<Result> results,
                final int limit, final boolean hasMore) throws IOException {
            try {
                if (SLEEP_NOW && c.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString().equals(TABLE_NAME)) {
                    Thread.sleep(RPC_TIMEOUT * 2);
                }
            } catch (InterruptedException e) {
                throw new IOException(e);
            }
            return super.preScannerNext(c, s, results, limit, hasMore);
        }
    }
{code}

This test was passing fine till 1.1.3 but started failing sometime before 1.1.9 with an OutOfOrderScannerException. See PHOENIX-3702. [~lhofhansl] mentioned that we have client heartbeats enabled and that should prevent us from running into issues like this. FYI, this test fails with 1.2.3 version of HBase too.

CC [~apurtell], [~jamestaylor]

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12433,"When modifying the coprocessor priority through the HBase shell, the order of the firing of the coprocessors wasn't changing. It probably would have with a cluster bounce, but if we can make it dynamic easily, that would be preferable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16212,"As described in https://issues.apache.org/jira/browse/HDFS-8659, the datanode is suffering from logging the same repeatedly. Adding log to DFSInputStream, it outputs as follows:

2016-07-10 21:31:42,147 INFO  [B.defaultRpcServer.handler=22,queue=1,port=16020] hdfs.DFSClient: DFSClient_NONMAPREDUCE_1984924661_1 seek DatanodeInfoWithStorage[10.130.1.29:50010,DS-086bc494-d862-470c-86e8-9cb7929985c6,DISK] for BP-360285305-10.130.1.11-1444619256876:blk_1109360829_35627143. pos: 111506876, targetPos: 111506843
 ...
As the pos of this input stream is larger than targetPos(the pos trying to seek), A new connection to the datanode will be created, the older one will be closed as a consequence. When the wrong seeking ops are large, the datanode's block scanner info message is spamming logs, as well as many connections to the same datanode will be created.

hadoop version: 2.7.1

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14442,"I created a Scan whose startRow and stopRow are the same with a region's startRow, then I found no map was built. 
The following is the source code of this condtion:
(startRow.length == 0 || keys.getSecond()[i].length == 0 ||
                    Bytes.compareTo(startRow, keys.getSecond()[i]) < 0) &&
                    (stopRow.length == 0 || Bytes.compareTo(stopRow,
                            keys.getFirst()[i]) > 0)

I think  a ""="" should be added.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15483,"After setting hbase.security.authorization to be false, hbase does NOT do authority check for any operations by any users. Thus, any user, including read only user, has the authority to grant <user> <any permission>. The change to ACL record is lasted and will take effective after next authorization enabling. 

The conseqence is,
A readonly user can change an admin user to be a ""readonly"" user after a round of ""disable authorization"" and ""enable authorization""
Also,
A readonly user can change a ""readonly"" user to be an Admin after such a round of disable/enable.

It is expected that 
after authorization is disabled, the authorization related file, the ACL record, should not be open to users and not be changed. Otherwise, after the authorization next enablement, the changed ACL takes action and users get unexpected authority.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19153,"The latest version of LruBolckCache, I found the code logic of cache too big bolcks is inconsistent with annotation.
If follow the notes, the code should look like this:

if (buf.heapSize() > maxBlockSize) {
      // If there are a lot of blocks that are too
      // big this can make the logs way too noisy.
      // So we log 2%
      if (stats.failInsert() % 50 != 0) {
        return;
      }
      LOG.warn(""Trying to cache too large a block ""
            + cacheKey.getHfileName() + "" @ ""
            + cacheKey.getOffset()
            + "" is "" + buf.heapSize()
            + "" which is larger than "" + maxBlockSize);
      
    }

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20345,"I am running HBase in a docker container. Version is 1.2.4 (Also tried 1.2.6)

Basically based on
{quote}[https://github.com/dajobe/hbase-docker]
{quote}
When i do the following:

1) Build the image: *docker build -t hbase-docker .*

2) Start the container: *./start-hbase.sh*

3) Go in the container: *docker exec -it hbase bash*

4) Open HBase shell: *hbase shell*

5) and then if i type something and press backspace, it crashes with following:
{code:java}
hbase(main):001:0> li ConsoleReader.java:1414:in `backspace': java.lang.ArithmeticException: / by zero
聽聽 聽from ConsoleReader.java:1436:in `backspace'
聽聽 聽from ConsoleReader.java:628:in `readLine'
聽聽 聽from ConsoleReader.java:457:in `readLine'
聽聽 聽from Readline.java:237:in `s_readline'
聽聽 聽from Readline$s$s_readline.gen:65535:in `call'
聽聽 聽from CachingCallSite.java:332:in `cacheAndCall'
聽聽 聽from CachingCallSite.java:203:in `call'
聽聽 聽from FCallTwoArgNode.java:38:in `interpret'
聽聽 聽from LocalAsgnNode.java:123:in `interpret'
聽聽 聽from IfNode.java:111:in `interpret'
聽聽 聽from NewlineNode.java:104:in `interpret'
聽聽 聽from ASTInterpreter.java:74:in `INTERPRET_METHOD'
聽聽 聽from InterpretedMethod.java:147:in `call'
聽聽 聽from DefaultMethod.java:183:in `call'
    ...
    ...{code}
聽

Any idea how to make backspace work and prevent this from happening?! Thank you",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19221,"Copying the mail from the dev@
{code}
I tried running some IT test cases using the alpha-4 RC. I found this issue
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/hamcrest/SelfDescribing
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:760)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
        at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:361)

...
       at org.apache.hadoop.hbase.IntegrationTestsDriver.doWork(IntegrationTestsDriver.java:111)
        at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:154)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
        at org.apache.hadoop.hbase.IntegrationTestsDriver.main(IntegrationTestsDriver.java:47)

The same when run against latest master it runs without any issues
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18896,"HADOOP-14267 change methods on DistCpOptions and introduced a new Builder class which doesn't exist on any previous releases.

We'll have to shim/reflect around this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20336,"running {{mvn verify}} for the spark integration tests against current master fails

{code}
$ mvn -DskipTests install
11:37:26,815 [INFO] Scanning for projects...
...
11:43:36,711 [INFO] ------------------------------------------------------------------------
11:43:36,711 [INFO] Reactor Summary:
11:43:36,711 [INFO] 
11:43:36,712 [INFO] Apache HBase ....................................... SUCCESS [  6.294 s]
11:43:36,712 [INFO] Apache HBase - Checkstyle .......................... SUCCESS [  1.742 s]
11:43:36,712 [INFO] Apache HBase - Build Support ....................... SUCCESS [  0.070 s]
11:43:36,712 [INFO] Apache HBase - Error Prone Rules ................... SUCCESS [  2.206 s]
11:43:36,712 [INFO] Apache HBase - Annotations ......................... SUCCESS [  1.413 s]
11:43:36,712 [INFO] Apache HBase - Build Configuration ................. SUCCESS [  0.254 s]
11:43:36,712 [INFO] Apache HBase - Shaded Protocol ..................... SUCCESS [ 37.870 s]
11:43:36,712 [INFO] Apache HBase - Common .............................. SUCCESS [ 12.526 s]
11:43:36,712 [INFO] Apache HBase - Metrics API ......................... SUCCESS [  2.412 s]
11:43:36,712 [INFO] Apache HBase - Hadoop Compatibility ................ SUCCESS [  3.260 s]
11:43:36,712 [INFO] Apache HBase - Metrics Implementation .............. SUCCESS [  2.756 s]
11:43:36,713 [INFO] Apache HBase - Hadoop Two Compatibility ............ SUCCESS [  3.959 s]
11:43:36,713 [INFO] Apache HBase - Protocol ............................ SUCCESS [ 11.295 s]
11:43:36,713 [INFO] Apache HBase - Client .............................. SUCCESS [ 15.360 s]
11:43:36,713 [INFO] Apache HBase - Zookeeper ........................... SUCCESS [  4.389 s]
11:43:36,713 [INFO] Apache HBase - Replication ......................... SUCCESS [  4.202 s]
11:43:36,713 [INFO] Apache HBase - Resource Bundle ..................... SUCCESS [  0.206 s]
11:43:36,713 [INFO] Apache HBase - HTTP ................................ SUCCESS [  8.530 s]
11:43:36,713 [INFO] Apache HBase - Procedure ........................... SUCCESS [  4.196 s]
11:43:36,713 [INFO] Apache HBase - Server .............................. SUCCESS [ 44.604 s]
11:43:36,713 [INFO] Apache HBase - MapReduce ........................... SUCCESS [ 11.122 s]
11:43:36,713 [INFO] Apache HBase - Testing Util ........................ SUCCESS [  6.633 s]
11:43:36,713 [INFO] Apache HBase - Thrift .............................. SUCCESS [  9.771 s]
11:43:36,713 [INFO] Apache HBase - RSGroup ............................. SUCCESS [  6.703 s]
11:43:36,713 [INFO] Apache HBase - Shell ............................... SUCCESS [  7.094 s]
11:43:36,713 [INFO] Apache HBase - Coprocessor Endpoint ................ SUCCESS [  7.542 s]
11:43:36,713 [INFO] Apache HBase - Backup .............................. SUCCESS [  6.246 s]
11:43:36,713 [INFO] Apache HBase - Integration Tests ................... SUCCESS [  7.461 s]
11:43:36,713 [INFO] Apache HBase - Examples ............................ SUCCESS [  9.054 s]
11:43:36,713 [INFO] Apache HBase - Rest ................................ SUCCESS [  8.972 s]
11:43:36,713 [INFO] Apache HBase - External Block Cache ................ SUCCESS [  5.180 s]
11:43:36,713 [INFO] Apache HBase - Spark ............................... SUCCESS [01:10 min]
11:43:36,713 [INFO] Apache HBase - Spark Integration Tests ............. SUCCESS [  7.774 s]
11:43:36,713 [INFO] Apache HBase - Assembly ............................ SUCCESS [ 15.075 s]
11:43:36,713 [INFO] Apache HBase - Shaded .............................. SUCCESS [  0.323 s]
11:43:36,713 [INFO] Apache HBase - Shaded - Client ..................... SUCCESS [  3.004 s]
11:43:36,713 [INFO] Apache HBase - Shaded - MapReduce .................. SUCCESS [  3.542 s]
11:43:36,714 [INFO] Apache HBase Shaded Packaging Invariants ........... SUCCESS [  3.105 s]
11:43:36,714 [INFO] Apache HBase - Archetypes .......................... SUCCESS [  0.063 s]
11:43:36,714 [INFO] Apache HBase - Exemplar for hbase-client archetype . SUCCESS [  4.843 s]
11:43:36,714 [INFO] Apache HBase - Exemplar for hbase-shaded-client archetype SUCCESS [  4.523 s]
11:43:36,714 [INFO] Apache HBase - Archetype builder ................... SUCCESS [  0.739 s]
11:43:36,714 [INFO] ------------------------------------------------------------------------
11:43:36,714 [INFO] BUILD SUCCESS
11:43:36,714 [INFO] ------------------------------------------------------------------------
11:43:36,714 [INFO] Total time: 06:09 min
11:43:36,714 [INFO] Finished at: 2018-04-03T11:43:36-05:00
11:43:38,408 [INFO] Final Memory: 305M/1087M
11:43:38,408 [INFO] ------------------------------------------------------------------------
$ mvn -pl hbase-spark -pl hbase-spark-it verify
11:45:14,664 [INFO] Scanning for projects...
...

11:49:27,439 [INFO] --- maven-failsafe-plugin:2.21.0:integration-test (integration-test) @ hbase-spark-it ---
11:49:27,576 [WARNING] The parameter forkMode is deprecated since version 2.14. Use forkCount and reuseForks instead.
11:49:27,641 [INFO] 
11:49:27,641 [INFO] -------------------------------------------------------
11:49:27,641 [INFO]  T E S T S
11:49:27,641 [INFO] -------------------------------------------------------
11:49:27,866 [WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /Users/busbey/tmp_projects/hbase/hbase-spark-it/target/failsafe-reports/2018-04-03T11-49-27_574-jvmRun1.dumpstream
11:49:28,752 [INFO] Running org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad
11:49:36,776 [ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 7.995 s <<< FAILURE! - in org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad
11:49:36,776 [ERROR] testBulkLoad(org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad)  Time elapsed: 7.699 s  <<< ERROR!
java.io.IOException: Shutting down
	at org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad.setUpCluster(IntegrationTestSparkBulkLoad.java:613)
Caused by: java.lang.RuntimeException: Failed construction of RegionServer: class org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer
	at org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad.setUpCluster(IntegrationTestSparkBulkLoad.java:613)
Caused by: java.lang.IllegalArgumentException: port out of range:-1
	at org.apache.hadoop.hbase.spark.IntegrationTestSparkBulkLoad.setUpCluster(IntegrationTestSparkBulkLoad.java:613)

11:49:37,190 [INFO] 
11:49:37,190 [INFO] Results:
11:49:37,191 [INFO] 
11:49:37,191 [ERROR] Errors: 
11:49:37,191 [ERROR]   IntegrationTestSparkBulkLoad>IntegrationTestBase.setUp:170->setUpCluster:613 禄 IO
11:49:37,191 [INFO] 
11:49:37,191 [ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0
11:49:37,191 [INFO] 
11:49:37,199 [INFO] 
11:49:37,199 [INFO] --- maven-failsafe-plugin:2.21.0:verify (verify) @ hbase-spark-it ---
11:49:37,848 [INFO] ------------------------------------------------------------------------
11:49:37,848 [INFO] Reactor Summary:
11:49:37,848 [INFO] 
11:49:37,848 [INFO] Apache HBase - Spark ............................... SUCCESS [03:57 min]
11:49:37,848 [INFO] Apache HBase - Spark Integration Tests ............. FAILURE [ 22.686 s]
11:49:37,849 [INFO] ------------------------------------------------------------------------
11:49:37,849 [INFO] BUILD FAILURE
11:49:37,849 [INFO] ------------------------------------------------------------------------
11:49:37,849 [INFO] Total time: 04:23 min
11:49:37,849 [INFO] Finished at: 2018-04-03T11:49:37-05:00
11:49:38,093 [INFO] Final Memory: 75M/762M
11:49:38,094 [INFO] ------------------------------------------------------------------------
11:49:38,096 [ERROR] Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.21.0:verify (verify) on project hbase-spark-it: There are test failures.
11:49:38,096 [ERROR] 
11:49:38,096 [ERROR] Please refer to /Users/busbey/tmp_projects/hbase/hbase-spark-it/target/failsafe-reports for the individual test results.
11:49:38,096 [ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
11:49:38,096 [ERROR] -> [Help 1]
11:49:38,096 [ERROR] 
11:49:38,096 [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
11:49:38,096 [ERROR] Re-run Maven using the -X switch to enable full debug logging.
11:49:38,096 [ERROR] 
11:49:38,096 [ERROR] For more information about the errors and possible solutions, please read the following articles:
11:49:38,096 [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
11:49:38,096 [ERROR] 
11:49:38,096 [ERROR] After correcting the problems, you can resume the build with the command
11:49:38,096 [ERROR]   mvn <goals> -rf :hbase-spark-it
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20381,see HBASE-20219 and related builds.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2042,"Below is from Stefan Will:

{code}
I just ran into another case where a Regionserver wouldn't properly shut down (this is on my development cluster, so not too critical). In this case, it is also holding over 27000 datanode sockets (port 50010) in CLOSE_WAIT state. I was actually using so many that the SSH daemon wouldn't let me log in to the machine due to too many open file handles (I can probably figure out how to increase that limit). So I shut down the Master and the other regionservers, which might have been the cause for it to be in ""handleConnectionFailure()"". The last few lines of the log were:

009-12-06 10:30:12,609 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: aborting server at: 10.1.20.144:60020 <http://10.1.20.144:60020>
- Hide quoted text -
2009-12-06 10:30:12,646 INFO org.apache.hadoop.hbase.regionserver.LogFlusher: regionserver/10.1.20.144:60020.logFlusher exiting
2009-12-06 10:30:12,646 INFO org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker: regionserver/10.1.20.144:60020.majorCompactionChecker exiting
2009-12-06 10:30:14,871 INFO org.apache.hadoop.hbase.Leases: regionserver/10.1.20.144:60020.leaseChecker closing leases
2009-12-06 10:30:14,871 INFO org.apache.hadoop.hbase.Leases: regionserver/10.1.20.144:60020.leaseChecker closed leases
2009-12-06 10:30:17,366 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting
2009-12-06 10:30:17,366 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x2255b24f9f1003a
2009-12-06 10:30:17,366 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn for session: 0x2255b24f9f1003a
2009-12-06 10:30:17,387 INFO org.apache.zookeeper.ClientCnxn: Exception while closing send thread for session 0x2255b24f9f1003a : Read error rc = -1 java.nio.DirectByteBuffer[
pos=0 lim=4 cap=4]
2009-12-06 10:30:17,489 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn for session: 0x2255b24f9f1003a
2009-12-06 10:30:17,489 INFO org.apache.zookeeper.ZooKeeper: Session: 0x2255b24f9f1003a closed
2009-12-06 10:30:17,548 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-12-06 20:35:25,725 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Starting shutdown thread.

And here is the stacktrace taken after I was able to log back into the machine and send a kill to the process (at the last timestamp). It is now 15 minutes later, and the process is still running with no further log output.

Between midnight and 10:30, there are also over 6700 checksum errors in the log, always with the same log file name:

org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_4234778497757442733:of:/hbase/post/1926133619/oldlogfile.log at 62521344
        at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
        at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)

Here is the stack dump:

Exception in thread ""LeaseChecker"" java.lang.NullPointerException
    at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:351)
    at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:313)
    at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:176)
    at org.apache.hadoop.ipc.Client.getConnection(Client.java:859)
    at org.apache.hadoop.ipc.Client.call(Client.java:719)
    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
    at $Proxy1.renewLease(Unknown Source)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
    at $Proxy1.renewLease(Unknown Source)
    at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1046)
    at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1058)
    at java.lang.Thread.run(Thread.java:619)
2009-12-06 20:43:32
Full thread dump Java HotSpot(TM) 64-Bit Server VM (14.0-b16 mixed mode):

""Thread-28"" prio=10 tid=0x00000000539e5800 nid=0x742e in Object.wait() [0x0000000040a45000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab7803738> (a java.lang.Thread)
    at java.lang.Thread.join(Thread.java:1143)
    - locked <0x00002aaab7803738> (a java.lang.Thread)
    at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:77)
    at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:66)
    at org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread.run(HRegionServer.java:992)

""SIGTERM handler"" daemon prio=10 tid=0x0000000053ca6000 nid=0x742d in Object.wait() [0x0000000043b02000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab7941978> (a org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread)
    at java.lang.Thread.join(Thread.java:1143)
    - locked <0x00002aaab7941978> (a org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread)
    at java.lang.Thread.join(Thread.java:1196)
    at java.lang.ApplicationShutdownHooks.runHooks(ApplicationShutdownHooks.java:79)
    at java.lang.ApplicationShutdownHooks$1.run(ApplicationShutdownHooks.java:24)
    at java.lang.Shutdown.runHooks(Shutdown.java:79)
    at java.lang.Shutdown.sequence(Shutdown.java:123)
    at java.lang.Shutdown.exit(Shutdown.java:168)
    - locked <0x00002aaaed6f2ef0> (a java.lang.Class for java.lang.Shutdown)
    at java.lang.Terminator$1.handle(Terminator.java:35)
    at sun.misc.Signal$1.run(Signal.java:195)
    at java.lang.Thread.run(Thread.java:619)

""Thread-23"" prio=10 tid=0x00002aab08019800 nid=0x2036 sleeping[0x00000000413de000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
    at java.lang.Thread.sleep(Native Method)
    at org.apache.hadoop.ipc.Client.stop(Client.java:679)
    at org.apache.hadoop.ipc.RPC$ClientCache.stopClient(RPC.java:192)
    at org.apache.hadoop.ipc.RPC$ClientCache.access$400(RPC.java:141)
    at org.apache.hadoop.ipc.RPC$Invoker.close(RPC.java:234)
    - locked <0x00002aaab7955f10> (a org.apache.hadoop.ipc.RPC$Invoker)
    at org.apache.hadoop.ipc.RPC$Invoker.access$500(RPC.java:199)
    at org.apache.hadoop.ipc.RPC.stopProxy(RPC.java:393)
    at org.apache.hadoop.hdfs.DFSClient.close(DFSClient.java:241)
    - locked <0x00002aaab78e5078> (a org.apache.hadoop.hdfs.DFSClient)
    at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:269)
    at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:1419)
    - locked <0x00002aaab79563f0> (a org.apache.hadoop.fs.FileSystem$Cache)
    at org.apache.hadoop.fs.FileSystem.closeAll(FileSystem.java:212)
    at org.apache.hadoop.fs.FileSystem$ClientFinalizer.run(FileSystem.java:197)
    - locked <0x00002aaab78037e0> (a org.apache.hadoop.fs.FileSystem$ClientFinalizer)

""LruBlockCache.EvictionThread"" daemon prio=10 tid=0x0000000053920800 nid=0x31a4 in Object.wait() [0x0000000043900000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab7a56160> (a org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread)
    at java.lang.Object.wait(Object.java:485)
    at org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread.run(LruBlockCache.java:512)
    - locked <0x00002aaab7a56160> (a org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread)

""DestroyJavaVM"" prio=10 tid=0x00002aaaf800f000 nid=0x2f53 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""regionserver/10.1.20.144:60020 <http://10.1.20.144:60020> "" prio=10 tid=0x00002aaaf800e000 nid=0x2f6c waiting for monitor entry [0x00000000415e2000]
- Hide quoted text -

   java.lang.Thread.State: BLOCKED (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab78037e0> (a org.apache.hadoop.fs.FileSystem$ClientFinalizer)
    at java.lang.Thread.join(Thread.java:1151)
    - locked <0x00002aaab78037e0> (a org.apache.hadoop.fs.FileSystem$ClientFinalizer)
    at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:77)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.runThread(HRegionServer.java:722)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:677)
    at java.lang.Thread.run(Thread.java:619)

""Low Memory Detector"" daemon prio=10 tid=0x00000000536b5000 nid=0x2f66 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""CompilerThread1"" daemon prio=10 tid=0x00000000536b2800 nid=0x2f65 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""CompilerThread0"" daemon prio=10 tid=0x00000000536ae000 nid=0x2f64 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Signal Dispatcher"" daemon prio=10 tid=0x00000000536ac000 nid=0x2f63 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Surrogate Locker Thread (CMS)"" daemon prio=10 tid=0x00000000536aa000 nid=0x2f62 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Finalizer"" daemon prio=10 tid=0x0000000053687800 nid=0x2f61 in Object.wait() [0x00000000421e9000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab77f0108> (a java.lang.ref.ReferenceQueue$Lock)
    at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)
    - locked <0x00002aaab77f0108> (a java.lang.ref.ReferenceQueue$Lock)
    at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:134)
    at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)

""Reference Handler"" daemon prio=10 tid=0x0000000053685800 nid=0x2f60 in Object.wait() [0x00000000420e8000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00002aaab77f32b8> (a java.lang.ref.Reference$Lock)
    at java.lang.Object.wait(Object.java:485)
    at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)
    - locked <0x00002aaab77f32b8> (a java.lang.ref.Reference$Lock)

""VM Thread"" prio=10 tid=0x000000005367e800 nid=0x2f5f runnable

""Gang worker#0 (Parallel GC Threads)"" prio=10 tid=0x00000000534c1800 nid=0x2f54 runnable

""Gang worker#1 (Parallel GC Threads)"" prio=10 tid=0x00000000534c3800 nid=0x2f55 runnable

""Gang worker#2 (Parallel GC Threads)"" prio=10 tid=0x00000000534c5800 nid=0x2f56 runnable

""Gang worker#3 (Parallel GC Threads)"" prio=10 tid=0x00000000534c7000 nid=0x2f57 runnable

""Gang worker#4 (Parallel GC Threads)"" prio=10 tid=0x00000000534c9000 nid=0x2f58 runnable

""Gang worker#5 (Parallel GC Threads)"" prio=10 tid=0x00000000534cb000 nid=0x2f59 runnable

""Gang worker#6 (Parallel GC Threads)"" prio=10 tid=0x00000000534cc800 nid=0x2f5a runnable

""Gang worker#7 (Parallel GC Threads)"" prio=10 tid=0x00000000534ce800 nid=0x2f5b runnable

""Concurrent Mark-Sweep GC Thread"" prio=10 tid=0x000000005359e800 nid=0x2f5e runnable
""Gang worker#0 (Parallel CMS Threads)"" prio=10 tid=0x000000005359b000 nid=0x2f5c runnable

""Gang worker#1 (Parallel CMS Threads)"" prio=10 tid=0x000000005359c800 nid=0x2f5d runnable

""VM Periodic Task Thread"" prio=10 tid=0x00000000536b7800 nid=0x2f67 waiting on condition

JNI global references: 960

Heap
 par new generation   total 115200K, used 67320K [0x00002aaaae6f0000, 0x00002aaab63f0000, 0x00002aaab63f0000)
  eden space 102400K,  65% used [0x00002aaaae6f0000, 0x00002aaab28a6130, 0x00002aaab4af0000)
  from space 12800K,   0% used [0x00002aaab5770000, 0x00002aaab5777f10, 0x00002aaab63f0000)
  to   space 12800K,   0% used [0x00002aaab4af0000, 0x00002aaab4af0000, 0x00002aaab5770000)
 concurrent mark-sweep generation total 896000K, used 705982K [0x00002aaab63f0000, 0x00002aaaecef0000, 0x00002aaaecef0000)
 concurrent-mark-sweep perm gen total 27204K, used 16361K [0x00002aaaecef0000, 0x00002aaaee981000, 0x00002aaaf22f0000)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13088,"[~busbey] noticed that the module hbase-native-client was not part of the release candidate 1.0.0RC5 in the src tarball (and neither in binary arifacts). 

I think we have added that as a part of C-API, but without implementation it just sits there. 

We should decide: 
1. Remove it
2. Add it to the release artifacts (src tarball from maven)

Does anybody have a plan around it? A reference implementation? I do not want to release it as official C API, without anything to back it up. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5608,"Many of the MR testcases are failing in PreCommit builds (triggered by Hadoop QA).
Failing testcases are
a) TestImportTsv
b) TestHFileOutputFormat
c) TestTableMapReduce",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-24,"We've been here before (HADOOP-2341).

Today the rapleaf gave me an lsof listing from a regionserver.  Had thousands of open sockets to datanodes all in ESTABLISHED and CLOSE_WAIT state.  On average they seem to have about ten file descriptors/sockets open per region (They have 3 column families IIRC.  Per family, can have between 1-5 or so mapfiles open per family -- 3 is max... but compacting we open a new one, etc.).

They have thousands of regions.   400 regions -- ~100G, which is not that much -- takes about 4k open file handles.

If they want a regionserver to server a decent disk worths -- 300-400G -- then thats maybe 1600 regions... 16k file handles.  If more than just 3 column families..... then we are in danger of blowing out limits if they are 32k.

We've been here before with HADOOP-2341.

A dfsclient that used non-blocking i/o would help applications like hbase (The datanode doesn't have this problem as bad -- CLOSE_WAIT on regionserver side, the bulk of the open fds in the rapleaf log, don't have a corresponding open resource on datanode end).

Could also just open mapfiles as needed, but that'd kill our random read performance and its bad enough already.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11419,"After increasing and decreasing the TTL value of a Hbase Table , table gets inaccessible. Scan table not working.

Scan in hbase shell throws

java.lang.IllegalStateException: Block index not loaded
at com.google.common.base.Preconditions.checkState(Preconditions.java:145)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV1.blockContainingKey(HFileReaderV1.java:181)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV1$AbstractScannerV1.seekTo(HFileReaderV1.java:426)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:226)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:145)
at org.apache.hadoop.hbase.regionserver.StoreScanner.<init>(StoreScanner.java:131)
at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:2015)
at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.<init>(HRegion.java:3706)
at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1761)
at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1753)
at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1730)
at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:2409)
at sun.reflect.GeneratedMethodAccessor56.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:320)
at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1426)

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1972,"As part of a split, we go to close the region.  The close fails because flush failed -- a DN was down and HDFS refuses to move past it -- so we jump up out of the close with an IOE.  But the region has been closed yet its still in the .META. as online.

Here is where the hole is:

1. CompactSplitThread calls split.
2. This calls HRegion splitRegion.
3. splitRegion calls close(false).
4. Down the end of the close, we get as far as the LOG.info(""Closed "" + this)..... but a DFSClient running thread throws an exception because it can't allocate block for the flush made as part of the close (Ain't sure how... we should add more try/catch in here):


{code}
2009-11-12 00:47:17,865 [regionserver/208.76.44.142:60020.compactor] DEBUG org.apache.hadoop.hbase.regionserver.Store: Added hdfs://aa0-000-12.u.powerset.com:9002/hbase/TestTable/868626151/info/5071349140567656566, entries=46975, sequenceid=2350017, memsize=52.0m, filesize=46.5m to TestTable,,1257986664542
2009-11-12 00:47:17,866 [regionserver/208.76.44.142:60020.compactor] DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~52.0m for region TestTable,,1257986664542 in 7985ms, sequence id=2350017, compaction requested=false
2009-11-12 00:47:17,866 [regionserver/208.76.44.142:60020.compactor] DEBUG org.apache.hadoop.hbase.regionserver.Store: closed info
2009-11-12 00:47:17,866 [regionserver/208.76.44.142:60020.compactor] INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed TestTable,,1257986664542
2009-11-12 00:47:17,906 [Thread-315] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:17,906 [Thread-315] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_1351692500502810095_1391
2009-11-12 00:47:23,918 [Thread-315] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:23,918 [Thread-315] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-3310646336307339512_1391
2009-11-12 00:47:29,982 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:29,982 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_3070440586900692765_1393
2009-11-12 00:47:35,997 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:35,997 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-5656011219762164043_1393
2009-11-12 00:47:42,007 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:42,007 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-2359634393837722978_1393
2009-11-12 00:47:48,017 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 00:47:48,017 [Thread-318] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-1626727145091780831_1393
2009-11-12 00:47:54,022 [Thread-318] WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSClient.java:3100)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2681)

2009-11-12 00:47:54,022 [Thread-318] WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file ""/hbase/TestTable/868626151/splits/1211221550/info/5071349140567656566.868626151"" - Aborting...
2009-11-12 00:47:54,029 [regionserver/208.76.44.142:60020.compactor] ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction/Split failed for region TestTable,,1257986664542
java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.createBlockOutputStream(DFSClient.java:3160)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSClient.java:3080)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2681)
{code}

Marking this as blocker.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1750,"This is so broke, its hard to know where to start.

In the below, node 14 expires, we continue to take on messages from it queueing open region todos for us to work on later.  Then we start to process shutdown of server 14.  Meantime we are assigning it regions.

Later, not reported here.  The open of a particular region is queued on the todo list > 1 time.  Processing the 2nd and 3rd times we call the assignment a duplicate and tell remote server close its region (it'll be same region as was in the first todo message).  It dutifully closes without report.  Now we NSRE till the end of time trying to find this closed region.

{code}
2009-08-05 04:39:12,007 [main-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got notification sessionid:0x22e734176a0001
2009-08-05 04:39:12,007 [main-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got WatchedEvent: Znode change. Path: /hbase/rs/1249419499242 Type: NodeDeleted for sessionid 0x22e734176a0001
2009-08-05 04:39:12,007 [main-EventThread] INFO org.apache.hadoop.hbase.master.ServerManager: 14.powerset.com,60020,1249419499242 znode expired
2009-08-05 04:39:12,137 [IPC Server handler 22 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.142:60020, startcode: 1249419499272, load: (requests=5, regions=243,  
usedHeap=732, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:13,028 [main-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got ping response for sessionid:0x22e734176a0001 after 0ms
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0707104931,1249439925123 from 14.powerset.com,60
020,1249447142944; 1 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0807477918,1249435417405 from 14.powerset.com,60
020,1249447142944; 2 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0239771780,1249436471662 from 14.powerset.com,60
020,1249447142944; 3 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0295087929,1249438529628 from 14.powerset.com,60
020,1249447142944; 4 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0344538034,1249438625837 from 14.powerset.com,60
020,1249447142944; 5 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0067977092,1249431465797 from 14.powerset.com,60
020,1249447142944; 6 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0521945645,1249426826597 from 14.powerset.com,60
020,1249447142944; 7 of 19
2009-08-05 04:39:13,554 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0221136504,1249447128488 from 14.powerset.com,60
020,1249447142944; 8 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0272411446,1249433459428 from 14.powerset.com,60
020,1249447142944; 9 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0284541889,1249434580130 from 14.powerset.com,60020,1249
447142944; 10 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0707104931,1249439925123 from 14.powerset.com,60020,1249
447142944; 11 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0807477918,1249435417405 from 14.powerset.com,60020,1249
447142944; 12 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0239771780,1249436471662 from 14.powerset.com,60020,1249
447142944; 13 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0295087929,1249438529628 from 14.powerset.com,60020,1249
447142944; 14 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0344538034,1249438625837 from 14.powerset.com,60020,1249
447142944; 15 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0067977092,1249431465797 from 14.powerset.com,60020,1249
447142944; 16 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0521945645,1249426826597 from 14.powerset.com,60020,1249
447142944; 17 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0221136504,1249447128488 from 14.powerset.com,60020,1249
447142944; 18 of 19
2009-08-05 04:39:13,555 [IPC Server handler 4 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0272411446,1249433459428 from 14.powerset.com,60020,1249
447142944; 19 of 19
2009-08-05 04:39:14,260 [IPC Server handler 24 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.140:60020, startcode: 1249419499240, load: (requests=0, regions=236,  
usedHeap=644, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:14,994 [IPC Server handler 3 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.139:60020, startcode: 1249419499241, load: (requests=0, regions=242, u
sedHeap=715, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:15,196 [IPC Server handler 2 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.142:60020, startcode: 1249419499272, load: (requests=0, regions=243, u
sedHeap=733, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:15,289 [HMaster-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got ping response for sessionid:0x22e734176a0002 after 1ms
2009-08-05 04:39:15,319 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,321 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,321 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,322 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,323 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,325 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:14,260 [IPC Server handler 24 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.140:60020, startcode: 1249419499240, load: (requests=0, regions=236, 
usedHeap=644, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:14,994 [IPC Server handler 3 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.139:60020, startcode: 1249419499241, load: (requests=0, regions=242, u
sedHeap=715, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:15,196 [IPC Server handler 2 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.142:60020, startcode: 1249419499272, load: (requests=0, regions=243, u
sedHeap=733, maxHeap=1391): total nregions to assign=7, nregions to reach balance=7, isMetaAssign=false
2009-08-05 04:39:15,289 [HMaster-SendThread] DEBUG org.apache.zookeeper.ClientCnxn: Got ping response for sessionid:0x22e734176a0002 after 1ms
2009-08-05 04:39:15,319 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,321 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,321 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,322 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,323 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,325 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,327 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,328 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,330 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: RegionAssignmentHistorian from 14.powerset.com,60020,1249447142944
2009-08-05 04:39:15,331 [HMaster] DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: ProcessServerShutdown of 14.powerset.com,60020,1249419499242
2009-08-05 04:39:15,331 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: process shutdown of server 14.powerset.com,60020,1249419499242: logSplit: false, rootRescanned: false, numbe
rOfMetaRegions: 1, onlineMetaRegions.size(): 1
2009-08-05 04:39:15,340 [HMaster] INFO org.apache.hadoop.hbase.regionserver.HLog: Splitting 34 hlog(s) in hdfs://12.powerset.com:9002/hbase/.logs/14.powerset.com,60020,1249419499242
2009-08-05 04:39:15,341 [HMaster] DEBUG org.apache.hadoop.hbase.regionserver.HLog: Splitting hlog 1 of 34: hdfs://12.powerset.com:9002/hbase/.logs/14.powerset.com,60020,1249419499242/hlog.dat
.1249446428006, length=58628658
2009-08-05 04:39:15,412 [HMaster] DEBUG org.apache.hadoop.hbase.regionserver.HLog: Adding queue for TestTable,0855568194,1249436793311
2009-08-05 04:39:15,989 [HMaster] DEBUG org.apache.hadoop.hbase.regionserver.HLog: Adding queue for TestTable,0839835862,1249431318932
2009-08-05 04:39:16,030 [HMaster] DEBUG org.apache.hadoop.hbase.regionserver.HLog: Adding queue for TestTable,0470769394,1249439783171
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Assigning for address: XX.XX.XX.141:60020, startcode: 1249447142944, load: (requests=0, regions=10, us
edHeap=51, maxHeap=1391): total nregions to assign=7, nregions to reach balance=0, isMetaAssign=false
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] DEBUG org.apache.hadoop.hbase.master.RegionManager: Doing for address: XX.XX.XX.141:60020, startcode: 1249447142944, load: (requests=0, regions=10, usedHe
ap=51, maxHeap=1391) nregions: 7 and nRegionsToAssign: 7
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0196260871,1249434878197 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0831634449,1249445668584 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0621687088,1249440865643 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0046898120,1249435993439 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0706868362,1249439909374 to 14.powerset.com,60020,1249447142944
2009-08-05 04:39:16,566 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,0226534644,1249438950155 to 14.powerset.com,60020,1249447142944
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3322,"Testing HBASE-2467 and HDFS-895 on 100 node cluster w/ a heavy increment workload we experienced significant slowdown.

Stack traces show that most threads are on HLog.updateLock.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3032,"Saw this message:

2010-09-22 13:10:03,547 FATAL org.apache.hadoop.hbase.master.MetaScanner: Caught error. Starting shutdown.
java.lang.OutOfMemoryError: unable to create new native thread
        at java.lang.Thread.start0(Native Method)
        at java.lang.Thread.start(Thread.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.setupIOstreams(HBaseClient.java:328)
        at org.apache.hadoop.hbase.ipc.HBaseClient.getConnection(HBaseClient.java:857)
        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:725)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:252)
        at $Proxy1.openScanner(Unknown Source)
        at org.apache.hadoop.hbase.master.BaseScanner.scanRegion(BaseScanner.java:182)
        at org.apache.hadoop.hbase.master.MetaScanner.scanOneMetaRegion(MetaScanner.java:73)
        at org.apache.hadoop.hbase.master.MetaScanner.maintenanceScan(MetaScanner.java:129)
        at org.apache.hadoop.hbase.master.BaseScanner.chore(BaseScanner.java:156)
        at org.apache.hadoop.hbase.Chore.run(Chore.java:68)

At this point the regionservers were instructed to exit, which caused more problems than if the master just terminated itself.  

This would prevent a backup master from picking up since the cluster is terminating!",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3020,"From Ryan:

Log recovery didn't seem to run during META open, here is my hadoop lsr:

{code}

drwxr-xr-x   - hadoop supergroup          0 2010-09-20 19:20 /hbase-206/.META.
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 19:20
/hbase-206/.META./.META.,,1
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 19:20
/hbase-206/.META./.META.,,1/recovered.edits
-rw-r--r--   3 hadoop supergroup      35544 2010-09-20 19:20
/hbase-206/.META./.META.,,1/recovered.edits/0000000000000000008
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 13:36
/hbase-206/.META./1028785192
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 13:36
/hbase-206/.META./1028785192/.oldlogs
-rw-r--r--   3 hadoop supergroup        124 2010-09-20 13:36
/hbase-206/.META./1028785192/.oldlogs/hlog.1285015016913
-rw-r--r--   3 hadoop supergroup       1018 2010-09-20 13:36
/hbase-206/.META./1028785192/.regioninfo
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 13:36
/hbase-206/.META./1028785192/historian
drwxr-xr-x   - hadoop supergroup          0 2010-09-20 13:36
/hbase-206/.META./1028785192/info
{code}

Notice how above recovered.edits is under a dir which is not the encoded name?

This is my fault I'd guess.  I tried to put in place actual region names of -ROOT- and .META. rather than the anonymous encodings.  Looks like I broke something split of .META. when I committed new master.  Will fix in morning.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12612,"The namespace upgrade code from pre-0.96 requires a clean shutdown prior to run. Right now the NamespaceUpgrade code does the following

# instantiate wal factory
# ask for a meta-wal
# online meta and make changes
# clean up meta-wal

That last bit is done instead of closing the factory itself. Since the factory initializes a non-meta-wal as a part of its constructor, not closing it leaves behind an empty wal. The rest of hte upgrade process sees that empty wal as an indicator that there's been a failure and goes into recovery.

The recovery process skips the loading of the hbase:acl table, which then causes the upgrade after master initialization to fail.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11538,"See thread on dev@ titled ""Comparing the performance of 0.98.4 RC0 and 0.98.0 using YCSB - 23% perf regression in workload E""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1076,"Running latest trunk plus jimk's patch for HBASE-543: 

2008-12-21 12:47:31,741 DEBUG org.apache.hadoop.hbase.regionserver.HStoreScanner
: Added a StoreFileScanner to outstanding HStoreScanner
2008-12-21 12:47:31,741 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: urls,http|playvideogame.net|,1229725620550
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:880)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:773)
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:228)
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushSomeRegions(MemcacheFlusher.java:292)
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.reclaimMemcacheMemory(MemcacheFlusher.java:262)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdates(HRegionServer.java:1594)
        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:894)
Caused by: java.util.ConcurrentModificationException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)
        at java.util.HashMap$KeyIterator.next(HashMap.java:828)
        at org.apache.hadoop.hbase.regionserver.HStore.notifyChangedReadersObservers(HStore.java:736)
        at org.apache.hadoop.hbase.regionserver.HStore.updateReaders(HStore.java:724)
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:693)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:629)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:865)
        ... 10 more
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7233,"Undo KeyValue being a Writable.

This issue wandered and became general discussion of KeyValue serialization, in particular, how to pass lots of KeyValues across rpc.  It was noticed that what we were passing over the wire for KeyValues was not protobuf'd KeyValues but the old serialization which assumes the KeyValue version 1 format.  After a bunch of good discussion working out rpc formats, was decided to close this issue in favor of more specific issues: see summary at https://issues.apache.org/jira/browse/HBASE-7233?focusedCommentId=13573259&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13573259",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7981,"https://builds.apache.org/job/hbase-0.95/11/testReport/junit/org.apache.hadoop.hbase.regionserver/TestSplitTransactionOnCluster/testShutdownFixupWhenDaughterHasSplit/

Hard to tell which region is missing post crash.  Not logged.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3346,"After the abort in HBASE-3345, I restarted the master, and it crashed again during startup

2010-12-13 12:57:00,367 DEBUG org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED event for c5005ca650c7e3bdbab4c8d3e9b7c618
2010-12-13 12:57:00,367 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region usertable
2010-12-13 12:57:00,367 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c780205200116 Deleting existing unassigned node for c5005ca650c7e3bdbab4c8d3e9b7c618 that is in expected state
2010-12-13 12:57:00,367 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: master:60000-0x12c780205200116 Retrieved 127 byte(s) of data from znode /hbase/unassigned/c5005ca650c7e3bdbab4c8d3e9b7c618; data=
2010-12-13 12:57:00,373 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher: master:60000-0x12c780205200116 Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/unassigned/
2010-12-13 12:57:00,374 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher: master:60000-0x12c780205200116 Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/una
2010-12-13 12:57:00,374 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c780205200116 Successfully deleted unassigned node for region c5005ca650c7e3bdbab4c8d3e9b7c618 in expected sta
2010-12-13 12:57:00,374 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: master:60000-0x12c780205200116 Retrieved 114 byte(s) of data from znode /hbase/unassigned/3dc9df76f111271c150c853716ce1f07 and se
2010-12-13 12:57:00,376 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
java.lang.NullPointerException
        at org.apache.hadoop.hbase.master.AssignmentManager.processRegionInTransition(AssignmentManager.java:263)
        at org.apache.hadoop.hbase.master.AssignmentManager.processFailover(AssignmentManager.java:222)
        at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:392)
        at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:274)
2010-12-13 12:57:00,377 INFO org.apache.hadoop.hbase.master.HMaster: Aborting
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5831,"No test failures but build complains it has failed.  trunk build seems to have the same affliction:

{code}
Results :

Tests run: 909, Failures: 0, Errors: 0, Skipped: 9

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 41:19.273s
[INFO] Finished at: Wed Apr 18 21:54:31 UTC 2012
[INFO] Final Memory: 59M/451M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.12-TRUNK-HBASE-2:test (secondPartTestsExecution) on project hbase: Failure or timeout -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException




-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12523250/5811+%281%29.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 findbugs.  The patch appears to introduce 6 new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

     -1 core tests.  The patch failed these unit tests:
{code}

Its not apparent that any particular test is not finishing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3345,"Running on a config that triggers lots of splits, I attempted to disable a table while it was getting a lot of load and injected failures. Got the following NPE in master, followed by an abort:

2010-12-13 12:52:27,323 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region usertable,user1182862181,1292273503885.d223f1dc4d9003508f2db7566518b05d. (offlining)
2010-12-13 12:52:27,323 FATAL org.apache.hadoop.hbase.master.HMaster: Remote unexpected exception
java.lang.NullPointerException: Passed server is null
        at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:581)
        at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1085)
        at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1032)
        at org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler$1.run(DisableTableHandler.java:132)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-475,Add enable/disable to hql help.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-459,"Jim was just running a loading test.  It failed because of a WrongRegionException.  At first I thought it HBASE-428 -- because we were making regions w/ same start and end key -- but looking closer, it looks like the client is getting a WRE thought its making a legitimate request; it just happens to be asking for a row from the top-half of a region just as it split.  I would think that on WRE, the client would at least retry in same manner in which it does when it gets a NSRE?

Here is the split detail:

{code}
2008-02-21 19:15:11,747 INFO  [regionserver/0:0:0:0:0:0:0:0:8020.compactor] hbase.HRegionServer$CompactSplitThread(345): region split, META updated, and report to master all successful. Old region=regionname: TestTable,0018951818,1203620807290, startKey: <0018951818>, endKey: <0022085183>, encodedName: 1601381187, offline: true, split: true, tableDesc: {name: TestTable, families: {info:={name: info, max versions: 3, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}, new regions: TestTable,0018951818,1203621311590, TestTable,0020990296,1203621311590. Split took 0sec
{code}

Here is the WRE:

{code}
org.apache.hadoop.hbase.WrongRegionException: org.apache.hadoop.hbase.WrongRegionException: Requested row out of range for HRegion TestTable,0018951818,1203620807290, startKey='0018951818', getEndKey()='0022085183', row='0062914560'
	at org.apache.hadoop.hbase.HRegion.checkRow(HRegion.java:1496)
	at org.apache.hadoop.hbase.HRegion.obtainRowLock(HRegion.java:1541)
	at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1236)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1450)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
	at java.lang.reflect.Constructor.newInstance(Unknown Source)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
	at org.apache.hadoop.hbase.client.HTable.getRegionServerWithRetries(HTable.java:1008)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:751)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:740)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:721)
	at org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest.testRow(PerformanceEvaluation.java:463)
	at org.apache.hadoop.hbase.PerformanceEvaluation$Test.test(PerformanceEvaluation.java:331)
	at org.apache.hadoop.hbase.PerformanceEvaluation.runOneClient(PerformanceEvaluation.java:527)
	at org.apache.hadoop.hbase.PerformanceEvaluation$EvaluationMapTask.map(PerformanceEvaluation.java:176)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:208)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2071)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-463,"I attempted to try out HBASE-458, and discovered that I couldn't create a table in shell at all on a fresh trunk. 

{code}
hql > show tables;
error msg : org.apache.hadoop.hbase.TableNotFoundException: Table '.META.' does not exist.
{code}

I tried wiping out my dfs to see if that made a difference, and it didn't.

This is a big problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-265,"The MiniDFSCluster used in many test cases is failing to start which causes test cases to fail.

    [junit] 07/07/18 09:56:30 INFO dfs.Storage: Storage directory /home/jim/Documents/workspace/hadoop-commit/build/contrib/hbase/test/data/dfs/name1 has been successfully formatted.
    [junit] 07/07/18 09:56:30 INFO dfs.Storage: Storage directory /home/jim/Documents/workspace/hadoop-commit/build/contrib/hbase/test/data/dfs/name2 has been successfully formatted.
    [junit] 07/07/18 09:56:30 INFO dfs.NameNode: Namenode up at: vermin.localdomain/127.0.0.1:46160
    [junit] 07/07/18 09:56:30 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=NameNode, sessionId=null
    [junit] 07/07/18 09:56:30 INFO ipc.Server: Stopping server on 46160
    [junit] 07/07/18 09:56:30 ERROR hbase.MiniHBaseCluster: Failed setup of mini dfs cluster
    [junit] java.io.IOException: 
    [junit]    Distributed upgrade for NameNode version -6 to current LV -6 is required.
    [junit]    Please restart NameNode with -upgrade option.
    [junit] 	at org.apache.hadoop.dfs.FSImage.verifyDistributedUpgradeProgress(FSImage.java:1059)
    [junit] 	at org.apache.hadoop.dfs.FSImage.recoverTransitionRead(FSImage.java:193)
    [junit] 	at org.apache.hadoop.dfs.FSDirectory.loadFSImage(FSDirectory.java:393)
    [junit] 	at org.apache.hadoop.dfs.FSNamesystem.<init>(FSNamesystem.java:248)
    [junit] 	at org.apache.hadoop.dfs.NameNode.init(NameNode.java:181)
    [junit] 	at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:219)
    [junit] 	at org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:839)
    [junit] 	at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:133)
    [junit] 	at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:77)
    [junit] 	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:116)
    [junit] 	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:73)
    [junit] 	at org.apache.hadoop.hbase.HBaseClusterTestCase.setUp(HBaseClusterTestCase.java:59)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17229,Backport HBASE-17072 and HBASE-16146. The former needs to be backported to 1.3 ([~mantonov]) and 1.2 ([~busbey]). The latter is already in 1.3.  Needs to be backported to 1.2.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17801,"In Apache 1.x, there is a Assignment Manager bug when SSH and drop table happens at the same time.  Here is the sequence:

(1). The Region Server hosting the target region is dead, SSH (server shutdown handler) offlined all regions hosted by the RS: 
{noformat}
2017-02-20 20:39:25,022 ERROR org.apache.hadoop.hbase.master.MasterRpcServices: Region server rs01.foo.com,60020,1486760911253 reported a fatal error:
ABORTING region server rs01.foo.com,60020,1486760911253: regionserver:60020-0x55a076071923f5f, quorum=zk01.foo.com:2181,zk02.foo.com:2181,zk3.foo.com:2181, baseZNode=/hbase regionserver:60020-0x1234567890abcdf received expired from ZooKeeper, aborting
Cause:
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:613)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:524)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:534)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:510)
2017-02-20 20:42:43,775 INFO org.apache.hadoop.hbase.master.handler.ServerShutdownHandler: Splitting logs for rs01.foo.com,60020,1486760911253 before assignment; region count=999
2017-02-20 20:43:31,784 INFO org.apache.hadoop.hbase.master.RegionStates: Transition {783a4814b862a6e23a3265a874c3048b state=OPEN, ts=1487568368296, server=rs01.foo.com,60020,1486760911253} to {783a4814b862a6e23a3265a874c3048b state=OFFLINE, ts=1487648611784, server=rs01.foo.com,60020,1486760911253}
{noformat}

(2). Now SSH goes through each region and check whether it should be re-assigned (at this time, SSH do check whether a table is disabled/deleted).  If a region needs to be re-assigned, it would put into a list.  Since at this time, the troubled region is still on the table that is enabled, it will be in the list.

{noformat}
2017-02-20 20:43:31,795 INFO org.apache.hadoop.hbase.master.handler.ServerShutdownHandler: Reassigning 999 region(s) that rs01.foo.com,60020,1486760911253 was carrying (and 0 regions(s) that were opening on this server)
{noformat}

(3). Now, disable and delete table come in and also try to offline the region; since the region is already offlined, the deleted table just removes the region from meta and in-memory.
{noformat}
2017-02-20 20:43:32,429 INFO org.apache.hadoop.hbase.master.HMaster: Client=b_kylin/null disable t1
2017-02-20 20:43:34,275 INFO org.apache.hadoop.hbase.zookeeper.ZKTableStateManager: Moving table t1 state from DISABLING to DISABLED
2017-02-20 20:43:34,276 INFO org.apache.hadoop.hbase.master.procedure.DisableTableProcedure: Disabled table, t1, is completed.
2017-02-20 20:43:35,624 INFO org.apache.hadoop.hbase.master.HMaster: Client=b_kylin/null delete t1
2017-02-20 20:43:36,011 INFO org.apache.hadoop.hbase.MetaTableAccessor: Deleted [{ENCODED => fbf9fda1381636aa5b3cd6e3fe0f6c1e, NAME => 't1,,1487568367030.fbf9fda1381636aa5b3cd6e3fe0f6c1e.', STARTKEY => '', ENDKEY => '\x00\x01'}, {ENCODED => 783a4814b862a6e23a3265a874c3048b, NAME => 't1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b.', STARTKEY => '\x00\x01', ENDKEY => ''}]
{noformat}

(4). However, SSH calls Assignment Manager to reassign the dead region (note that the dead region is in the re-assign list SSH collected and we don't re-check again)
{noformat}

2017-02-20 20:43:52,725 WARN org.apache.hadoop.hbase.master.AssignmentManager: Assigning but not in region states: {ENCODED => 783a4814b862a6e23a3265a874c3048b, NAME => 't1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b.', STARTKEY => '\x00\x01', ENDKEY => ''}

{noformat}

(5).  In the region server that the dead region tries to land, because the table is dropped, we could not open region and now the dead region is in FAILED_OPEN, which is in permanent RIT state. 

{noformat}
2017-02-20 20:43:52,861 INFO org.apache.hadoop.hbase.regionserver.RSRpcServices: Open t1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b.
2017-02-20 20:43:52,865 ERROR org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Failed open of region=t1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b., starting to roll back the global memstore size.
java.lang.IllegalStateException: Could not instantiate a region instance.
        at org.apache.hadoop.hbase.regionserver.HRegion.newHRegion(HRegion.java:5981)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6288)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6260)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6216)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:6167)
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:362)
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:129)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.GeneratedConstructorAccessor340.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.hbase.regionserver.HRegion.newHRegion(HRegion.java:5978)
        ... 10 more
Caused by: java.lang.IllegalArgumentException: Need table descriptor
        at org.apache.hadoop.hbase.regionserver.HRegion.<init>(HRegion.java:654)
        at org.apache.hadoop.hbase.regionserver.HRegion.<init>(HRegion.java:631)
        ... 14 more
2017-02-20 20:43:52,866 INFO org.apache.hadoop.hbase.coordination.ZkOpenRegionCoordination: Opening of region {ENCODED => 783a4814b862a6e23a3265a874c3048b, NAME => 't1,\x00\x01,1487568367030.783a4814b862a6e23a3265a874c3048b.', STARTKEY => '\x00\x01', ENDKEY => ''} failed, transitioning from OPENING to FAILED_OPEN in ZK, expecting version 1
{noformat}

Even no one would access this dead region, the dead region in RIT would prevent balancer to run; and warnings fired that regions stuck in RIT.

The issue could be resolved by restarting master, which is a good workaround, but undesirable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18152,"I've seen corruption from time-to-time testing.  Its rare enough. Often we can get over it but sometimes we can't. It took me a while to capture an instance of corruption. Turns out we are write to the WAL out-of-order which undoes a basic tenet; that WAL content is ordered in line w/ execution.

Below I'll post a corrupt WAL.

Looking at the write-side, there is a lot going on. I'm not clear on how we could write out of order. Will try and get more insight. Meantime parking this issue here to fill data into.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14950,"Scenario:
1. Set hbase.quota.enabled to true
2. As per the [ACL matrix | http://hbase.apache.org/book.html#appendix_acl_matrix] for create table, grant '@group1', 'C', '@ns1'
3. From a user of group1, create 't1', 'd'  -- *Failed*
{noformat}
ERROR: java.io.IOException: Namespace Descriptor found null for ns1 This is unexpected.
	at org.apache.hadoop.hbase.namespace.NamespaceStateManager.checkAndUpdateNamespaceTableCount(NamespaceStateManager.java:170)
	at org.apache.hadoop.hbase.namespace.NamespaceAuditor.checkQuotaToCreateTable(NamespaceAuditor.java:76)
	at org.apache.hadoop.hbase.quotas.MasterQuotaManager.checkNamespaceTableAndRegionQuota(MasterQuotaManager.java:312)
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1445)
	at org.apache.hadoop.hbase.master.MasterRpcServices.createTable(MasterRpcServices.java:428)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:49404)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2136)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)
{noformat}
When quota is enabled, then as part of createTable we internally also call getNamespaceDescriptor which needs 'A' privilege.

So when quota is enabled we need both C and A permission to create a table. ACL Matrix needs to be updated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18144,Description to follow.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19713,Make sure TestInterfaceAudienceAnnotations pass before 2.0 release.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20203,"This is an odd one. Causes ITBLL to fail because region is offline.

Two seconds after reporting Finished, successful assign, another thread tries to finish the Procedure. The second run messes us up.

{code}
2018-03-14 11:04:07,987 INFO  [PEWorker-1] procedure2.ProcedureExecutor: Finished pid=3600, ppid=3591, state=SUCCESS; AssignProcedure table=IntegrationTestBigLinkedList, region=b58e6e7c3b2e449f80533ea999707319 in 4.4100sec
....
2018-03-14 11:04:10,600 INFO  [PEWorker-2] procedure.MasterProcedureScheduler: pid=3600, ppid=3591, state=SUCCESS; AssignProcedure table=IntegrationTestBigLinkedList, region=b58e6e7c3b2e449f80533ea999707319, IntegrationTestBigLinkedList,\x9Ey\xE7\x9Ey\xE7\x9Ep,1521050540660.b58e6e7c3b2e449f80533ea999707319.
2018-03-14 11:04:10,606 ERROR [PEWorker-2] procedure2.ProcedureExecutor: CODE-BUG: Uncaught runtime exception for pid=3600, ppid=3591, state=SUCCESS; AssignProcedure table=IntegrationTestBigLinkedList, region=b58e6e7c3b2e449f80533ea999707319                                                                                        java.lang.UnsupportedOperationException: Unhandled state REGION_TRANSITION_FINISH; there is no rollback for assignment unless we cancel the operation by dropping/disabling the table
  at org.apache.hadoop.hbase.master.assignment.RegionTransitionProcedure.rollback(RegionTransitionProcedure.java:345)                                                                                                                                                                                                                      at org.apache.hadoop.hbase.master.assignment.RegionTransitionProcedure.rollback(RegionTransitionProcedure.java:86)                                                                                                                                                                                                                       at org.apache.hadoop.hbase.procedure2.Procedure.doRollback(Procedure.java:859)
  at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeRollback(ProcedureExecutor.java:1353)
  at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeRollback(ProcedureExecutor.java:1309)                                                                                                                                                                                                                                     at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1178)
  at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$800(ProcedureExecutor.java:75)                                                                                                                                                                                                                                            at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1740)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19193,"This is a good one turned up by that really great unit test facility where we do double execution of procedures with kills in between.

The scenario in this case is interesting. It was brought on by the fix to ""HBASE-19165 TODO Handle stuck in transition: rit=OPENING, location=ve0538...."" HBASE-19165 removed the presumption that an empty region state in hbase:meta meant OPENING.

The test that started failing was #testRecoveryAndDoubleExecution in TestRestoreSnapshotProcedure. A table is being deleted with kills and double execution of procedures enabled. The Table delete has mostly completed the delete of all regions and then the Master is killed. The new Master comes up, sees a few regions left in the hbase:meta but at least for a few, the state field is empty.

AMv2 tries to do the wrong thing which is reassign the region. It needs to do some probing to figure what to do with a region it doesn't know state on... e..g see if table is enabled or not.

Filing this issue to fix. Its part of a broader problem of what to do when state is empty in meta.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18919,"branch-1.1 nightly builds have been timing out in hbase-server on jdk7:

https://builds.apache.org/job/HBase%20Nightly/job/branch-1.1/

all recent runs look the same to me. yetus doesn't detect any hanging tests, so I'm not sure what's hanging exactly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12959,"I upgraded the hbase from 0.96.1.1 to 0.98.7 and hadoop from 2.2.0 to 2.5.1,some table encoding using prefix-tree was abnormal for compacting,  the gui shows the table's Compaction status is MAJOR_AND_MINOR(MAJOR) all the time.

in the regionserver dump , there are some logs as below:


Tasks:
===========================================================
Task: Compacting info in PREFIX_NOT_COMPACT,,1421954285670.41ef60e2c221772626e141d5080296c5.
Status: RUNNING:Compacting store info
Running for 1097s  (on the  site running more than 3 days)
............................

Thread 197 (regionserver60020-smallCompactions-1421954341530):
  State: RUNNABLE
  Blocked count: 7
  Waited count: 3
  Stack:
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.followFan(PrefixTreeArrayScanner.java:329)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:149)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)
    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)
    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)
    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)
    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)
    org.apache.hadoop.hbase.regionserver.compactions.Compactor.performCompaction(Compactor.java:222)
    org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:77)
    org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:110)
    org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1099)
    org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1482)

Thread 177 (regionserver60020-smallCompactions-1421954314809):
  State: RUNNABLE
  Blocked count: 40
  Waited count: 60
  Stack:
    org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnReader.populateBuffer(ColumnReader.java:81)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.populateQualifier(PrefixTreeArrayScanner.java:471)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.populateNonRowFields(PrefixTreeArrayScanner.java:452)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRow(PrefixTreeArrayScanner.java:226)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.advance(PrefixTreeArrayScanner.java:208)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtQualifierTimestamp(PrefixTreeArraySearcher.java:244)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:123)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)
    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)
    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)
    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)
    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)

Thread 170 (regionserver60020-smallCompactions-1421954306575):
  State: RUNNABLE
  Blocked count: 40
  Waited count: 46
  Stack:
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRowInternal(PrefixTreeArrayScanner.java:259)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRow(PrefixTreeArrayScanner.java:222)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.advance(PrefixTreeArrayScanner.java:208)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtQualifierTimestamp(PrefixTreeArraySearcher.java:244)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:123)
    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)
    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)
    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)
    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)
    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)
    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)
    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)
    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)
    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)
    org.apache.hadoop.hbase.regionserver.compactions.Compactor.performCompaction(Compactor.java:222)
    org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:77)



I also reproduce the appearance in the test env,actually the logs was fetch in my test env. 

schema :
create 'PREFIX_NOT_COMPACT', {NAME=>'info',VERSIONS=>1,BLOCKCACHE => true,DATA_BLOCK_ENCODING => 'PREFIX_TREE', BLOOMFILTER => 'ROW', IN_MEMORY => 'false', REPLICATION_SCOPE => '0', COMPRESSION => 'LZ4',MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', TTL => '600'},SPLITS =>['20150202']

data :
     see the attachments , load from the text data or storefiles.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14319,"org.apache.hadoop.hbase.regionserver.TestAtomicOperation.testMultiRowMutationMultiThreads has been failing sporadically for a while on at least trunk. This might also be reproducible on other branches, but it's hard to tell the state since our b.a.o Jenkins matrix for different Java versions that we test against hasn't been set up to display test results in a pretty way (separate JIRA forthcoming).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13605,"As mentioned in https://issues.apache.org/jira/browse/HBASE-9514?focusedCommentId=13769761&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13769761 and HBASE-12844 we should have only 1 source of cluster membership. 

The list of dead server and RegionStates doing it's own liveliness check (ServerManager.isServerReachable()) has caused an assignment problem again in a test cluster where the region states ""thinks"" that the server is dead and SSH will handle the region assignment. However the RS is not dead at all, living happily, and never gets zk expiry or YouAreDeadException or anything. This leaves the list of regions unassigned in OFFLINE state. 

master assigning the region:
{code}
15-04-20 09:02:25,780 DEBUG [AM.ZK.Worker-pool3-t330] master.RegionStates: Onlined 77dddcd50c22e56bfff133c0e1f9165b on os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268 {ENCODED => 77dddcd50c
{code}

Master then disabled the table, and unassigned the region:
{code}
2015-04-20 09:02:27,158 WARN  [ProcedureExecutorThread-1] zookeeper.ZKTableStateManager: Moving table loadtest_d1 state from DISABLING to DISABLING
 Starting unassign of loadtest_d1,,1429520544378.77dddcd50c22e56bfff133c0e1f9165b. (offlining), current state: {77dddcd50c22e56bfff133c0e1f9165b state=OPEN, ts=1429520545780,   server=os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268}
bleProcedure$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268 for region loadtest_d1,,1429520544378.77dddcd50c22e56bfff133c0e1f9165b.
2015-04-20 09:02:27,414 INFO  [AM.ZK.Worker-pool3-t316] master.RegionStates: Offlined 77dddcd50c22e56bfff133c0e1f9165b from os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268
{code}

On table re-enable, AM does not assign the region: 
{code}
2015-04-20 09:02:30,415 INFO  [ProcedureExecutorThread-3] balancer.BaseLoadBalancer: Reassigned 25 regions. 25 retained the pre-restart assignment.路
2015-04-20 09:02:30,415 INFO  [ProcedureExecutorThread-3] procedure.EnableTableProcedure: Bulk assigning 25 region(s) across 5 server(s), retainAssignment=true

l,16000,1429515659726-GeneralBulkAssigner-4] master.RegionStates: Couldn't reach online server os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268

l,16000,1429515659726-GeneralBulkAssigner-4] master.AssignmentManager: Updating the state to OFFLINE to allow to be reassigned by SSH
nmentManager: Skip assigning loadtest_d1,,1429520544378.77dddcd50c22e56bfff133c0e1f9165b., it is on a dead but not processed yet server: os-amb-r6-us-1429512014-hbase4-6.novalocal,16020,1429520535268
{code}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14506,See attached log. Flakey up on jenkins and down locally.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12542,"Using alter command to delete a family of table online will make the regionsevers that serve the regions of the table crash.
{code}
alter 't', NAME => 'f', METHOD => 'delete'
{code}

The reason is that TableDeleteFamilyHandler in HMaster delete the family dir firstly and then reopen all the regions of table.
When the regionserver reopen the region, it will crash for the exception in flushing memstore to hfile of the deleted family during closing the region, because the parent dir of the hfile has been deleted in TableDeleteFamilyHandler.
See: TableDeleteFamilyHandler.java #57

A simple solution is change the order of operations in TableDeleteFamilyHandler.
- update table descriptor first, 
- reopen all the regions,
- delete the the family dir at last.

Suggestions are welcomed.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6461,"Spun up a new dfs on hadoop-0.20.2-cdh3u3
Started hbase
started running loadtest tool.
killed rs and dn holding root with killall -9 java on server sv4r27s44 at about 2012-07-25 22:40:00

After things stabilize Root is in a bad state. Ran hbck and got:
Exception in thread ""main"" org.apache.hadoop.hbase.client.NoServerForRegionException: No server address listed in -ROOT- for region .META.,,1.1028785192 containing row 
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1016)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:841)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:810)
at org.apache.hadoop.hbase.client.HTable.finishSetup(HTable.java:232)
at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:172)
at org.apache.hadoop.hbase.util.HBaseFsck.connect(HBaseFsck.java:241)
at org.apache.hadoop.hbase.util.HBaseFsck.main(HBaseFsck.java:3236)



hbase(main):001:0> scan '-ROOT-'
ROW                                           COLUMN+CELL                                                                                                                       
12/07/25 22:43:18 INFO security.UserGroupInformation: JAAS Configuration already set up for Hadoop, not re-installing.
 .META.,,1                                    column=info:regioninfo, timestamp=1343255838525, value={NAME => '.META.,,1', STARTKEY => '', ENDKEY => '', ENCODED => 1028785192,}
 .META.,,1                                    column=info:v, timestamp=1343255838525, value=\x00\x00                                                                            
1 row(s) in 0.5930 seconds


Here's the master log: https://gist.github.com/3179194

I tried the same thing with 0.92.1 and I was able to get into a similar situation, so I don't think this is anything new. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5578,"The regeionserver log:
2012-03-11 11:55:37,808 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: ABORTING region server data3,60020,1331286604591: Unhandled exception: null
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.Store.getTotalStaticIndexSize(Store.java:1788)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.createRegionLoad(HRegionServer.java:994)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.buildServerLoad(HRegionServer.java:800)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:776)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:678)
	at java.lang.Thread.run(Thread.java:662)
2012-03-11 11:55:37,808 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: []
2012-03-11 11:55:37,808 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics: requestsPerSecond=1687, numberOfOnlineRegions=37, numberOfStores=37, numberOfStorefiles=144, storefileIndexSizeMB=2, rootIndexSizeKB=2362, totalStaticIndexSizeKB=229808, totalStaticBloomSizeKB=2166296, memstoreSizeMB=2854, readRequestsCount=1352673, writeRequestsCount=113137586, compactionQueueSize=8, flushQueueSize=3, usedHeapMB=7359, maxHeapMB=12999, blockCacheSizeMB=32.31, blockCacheFreeMB=3867.52, blockCacheCount=38, blockCacheHitCount=87713, blockCacheMissCount=22144560, blockCacheEvictedCount=122, blockCacheHitRatio=0%, blockCacheHitCachingRatio=99%, hdfsBlocksLocalityIndex=100
2012-03-11 11:55:37,992 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: STOPPED: Unhandled exception: null",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4216,"Received one of these while doing a YCSB test on 26 nodes on trunk:
java.io.IOException: java.lang.IllegalArgumentException: hostname can't be null
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14177,"After adding a large row, scanning back that row winds up being empty. After a few attempts it will succeed (all attempts over the same data on an hbase getting no other writes).

Looking at logs, it seems this happens when there is memory pressure on the client and there are several Full GCs that happen. Then messages that indicate that region locations are being removed from the local client cache:

2015-07-31 12:50:24,647 [main] DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation  - Removed 192.168.1.131:50981 as a location of big_row_1438368609944,,1438368610048.880c849594807bdc7412f4f982337d6c. for tableName=big_row_1438368609944 from cache

Blaming the GC may sound fanciful, but if the test is run with -Xms4g -Xmx4g then it always passes on the first scan attempt. Maybe the pause is enough to remove something from the cache, or the client is using weak references somewhere?

More info http://mail-archives.apache.org/mod_mbox/hbase-user/201507.mbox/%3CCAE8tVdnFf%3Dob569%3DfJkpw1ndVWOVTkihYj9eo6qt0FrzihYHgw%40mail.gmail.com%3E

Test used to reproduce:
https://github.com/housejester/hbase-debugging#fullgctest


I tested and had failures in:

0.98.12 client/server
0.98.13 client 0.98.12 server
0.98.13 client/server
1.1.0 client 0.98.13 server
0.98.13 client and 1.1.0 server
0.98.12 client and 1.1.0 server

I tested without failure in:

1.1.0 client/server",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14233,"{code}
15/08/17 14:10:50 INFO master.RegionStates: Transition null to {6486b9b9409b25f10eb806ec3bad442d state=MERGING_NEW, ts=1439845850422, server=hbase508.ash1.facebook.com,16020,1439844470302}
15/08/17 14:10:57 INFO master.AssignmentManager: Failed to record merged region 6486b9b9409b25f10eb806ec3bad442d
15/08/17 14:10:57 ERROR master.AssignmentManager: Failed to transtion region from {6486b9b9409b25f10eb806ec3bad442d state=MERGING_NEW, ts=1439845850422, server=hbase508.ash1.facebook.com,16020,1439844470302} to MERGE_PONR by hbase508.ash1.facebook.com,16020,1439844470302: Failed to record the merging in meta
15/08/17 14:11:08 WARN master.RegionStates: THIS SHOULD NOT HAPPEN: unexpected {6486b9b9409b25f10eb806ec3bad442d state=MERGING_NEW, ts=1439845857580, server=hbase508.ash1.facebook.com,16020,1439844470302}
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3622,"On Dmitriy's cluster:

{code}

""IPC Reader 0 on port 60020"" prio=10 tid=0x00002aacb4a82800 nid=0x3a72 waiting on condition [0x00000000429ba000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00002aaabf5fa6d0> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:747)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:778)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1114)
        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:186)
        at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:262)
        at java.util.concurrent.LinkedBlockingQueue.signalNotEmpty(LinkedBlockingQueue.java:103)
        at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:267)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.processData(HBaseServer.java:985)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.readAndProcess(HBaseServer.java:946)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.doRead(HBaseServer.java:522)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener$Reader.run(HBaseServer.java:316)
        - locked <0x00002aaabf580fb0> (a org.apache.hadoop.hbase.ipc.HBaseServer$Listener$Reader)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
...
""IPC Server handler 29 on 60020"" daemon prio=10 tid=0x00002aacbc163800 nid=0x3acc waiting on condition [0x00000000462f3000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00002aaabf5e3800> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025)
""IPC Server handler 28 on 60020"" daemon prio=10 tid=0x00002aacbc161800 nid=0x3acb waiting on condition [0x00000000461f2000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00002aaabf5e3800> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025
...
{code}

This region server stayed in this state for hours. The reader is waiting to put and the handlers are waiting to take, and they wait on different lock ids. It reminds me of the UseMembar thing about the JVM sometime missing to notify waiters. In any case, that RS needed to be closed in order to get out of that state. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3331,"If you find the server hosting META and kill -STOP its region server, it will eventually lose its ZK session and the master will split its logs and try to reassign. However, at some point along here it tries to access the old META, and gets SocketTimeoutExceptions, which cause it to keep retrying forever. Once I kill -9ed the stopped server, things came back to life.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2880,"I just ran into this testing 0.89 RC candidate.

So, Master is hung up because all threads are locked out because one thread is stuck inside a block that is synchronized on RegionManager (0x00007fe1f94777d0 in the below):

{code}
3277 ""IPC Server handler 9 on 60000"" daemon prio=10 tid=0x00007fe1dc00f000 nid=0x409d in Object.wait() [0x00007fe1e9200000]
3278    java.lang.Thread.State: WAITING (on object monitor)
3279         at java.lang.Object.wait(Native Method)
3280         at java.lang.Object.wait(Object.java:485)
3281         at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:732)
3282         - locked <0x00007fe1f8672818> (a org.apache.hadoop.hbase.ipc.HBaseClient$Call)
3283         at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:252)
3284         at $Proxy1.get(Unknown Source)
3285         at org.apache.hadoop.hbase.master.ServerManager.assignSplitDaughter(ServerManager.java:550)
3286         at org.apache.hadoop.hbase.master.ServerManager.processSplitRegion(ServerManager.java:525)
3287         - locked <0x00007fe1f94777d0> (a org.apache.hadoop.hbase.master.RegionManager)
3288         at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:476)
3289         at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:425)
3290         at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:335)
3291         at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:738)
3292         at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
3293         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
3294         at java.lang.reflect.Method.invoke(Method.java:597)
3295         at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:576)
3296         at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:919)
{code}

The above code is not returning because Call#callComplete is never going to be called on the outstanding Get.  The target RS OOME'd.  Something in the way an OOME is being processed made it so this connection is not ever going to be cleaned up/notified.

We're stuck here.

I'm trying to figure why the clean up is not happening.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3637,"I don't 100% understand how this happened, but the following was observed:

- META is in OPENED state in ZK, for a server which no longer exists
- Handler sees that server is dead, and figures that the RIT timeout will handle it
- RIT timeout sees that it's already in OPENED state, and assumes that the OPENED handler will handle it
- loops in timeout state forever, never actually getting reassigned",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4954,"On Tue, Nov 29, 2011 at 10:20 PM, Stack <stack@duboce.net> wrote:
> The first hbase 0.92.0 release candidate is available for download:
>
>  http://people.apache.org/~stack/hbase-0.92.0-candidate-0/

Here's another persistent issues that I'd appreciate somebody taking
a quick look at:
    http://bigtop01.cloudera.org:8080/view/Hadoop%200.22/job/Bigtop-hadoop22-smoketest/28/testReport/org.apache.bigtop.itest.hbase.smoke/TestHFileOutputFormat/testMRIncrementalLoadWithSplit/

Caused by: java.lang.IllegalArgumentException
       at java.nio.Buffer.position(Buffer.java:218)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.blockSeek(HFileReaderV2.java:632)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:545)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:503)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:511)
       at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:475)
       at org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(HalfStoreFileReader.java:157)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.copyHFileHalf(LoadIncrementalHFiles.java:544)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.splitStoreFile(LoadIncrementalHFiles.java:516)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.splitStoreFile(LoadIncrementalHFiles.java:377)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.groupOrSplit(LoadIncrementalHFiles.java:441)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call(LoadIncrementalHFiles.java:325)
       at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$2.call(LoadIncrementalHFiles.java:323)
       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
       at java.util.concurrent.FutureTask.run(FutureTask.java:138)
       at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
       at java.lang.Thread.run(Thread.java:619)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6636,"The test class TestMasterZKSessionRecovery has been removed in trunk.  Its master tests were moved elsewhere or removed because useless (See nkeywal reasoning over in HBASE-5572 ""KeeperException.SessionExpiredException management could be improved in Master""; it was actually removed by HBASE-5549 ""Master can fail if ZooKeeper session expires"").

TestMasterZKSessionRecovery in 0.92 and 0.94 has an extra test that was not in trunk, the sporadically failing testRegionAssignmentAfterMasterRecoveryDueToZKExpiry.  This was added by ""HBASE-6046
Master retry on ZK session expiry causes inconsistent region assignments"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13782,"hbaes version: 1.0.0-cdh5.4.0
hadoop version: 2.6.0-cdh5.4.0 


Environment: 40-node hadoop cluster shared with a 10-node hbase cluster and a 30-node yarn.

We started to see that one RS stopped to serve any client request since 2015-05-26 01:05:33, while all other RS were okay. I checked RS log and found that there are some FATAL logs when org.apache.hadoop.hbase.regionserver.wal.FSHLog tried to append() and sync{}:

{code}

2015-05-26 01:05:33,700 FATAL org.apache.hadoop.hbase.regionserver.wal.FSHLog: Could not append. Requesting close of wal
java.io.IOException: Bad connect ack with firstBadLink as 10.28.1.17:50010
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1472)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1373)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:600)
2015-05-26 01:05:33,700 FATAL org.apache.hadoop.hbase.regionserver.wal.FSHLog: Could not append. Requesting close of wal
java.io.IOException: Bad connect ack with firstBadLink as 10.28.1.17:50010
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1472)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1373)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:600)
2015-05-26 01:05:33,700 FATAL org.apache.hadoop.hbase.regionserver.wal.FSHLog: Could not append. Requesting close of wal
java.io.IOException: Bad connect ack with firstBadLink as 10.28.1.17:50010
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1472)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1373)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:600)
2015-05-26 01:05:33,700 INFO org.apache.hadoop.hbase.regionserver.wal.FSHLog: Archiving hdfs://nameservice1/hbase/WALs/hbase08.company.com,60020,1431985722474/hbase08.company.com%2C60020%2C1431985722474.default.1432602140966 to hdfs://nameservice1/hbase/oldWALs/hbase08.company.com%2C60020%2C1431985722474.default.1432602140966
2015-05-26 01:05:33,701 ERROR org.apache.hadoop.hbase.regionserver.wal.FSHLog: Error syncing, request close of wal 

{code}

Since the HDFS cluster is shared with a YARN cluster, at the time, there were some io heavy jobs running, and exhausted xciever at some of the DNs at the exact same time. I think it's the reason why the RS got ``java.io.IOException: Bad connect ack with firstBadLink''

The problem is, the RS got stuck without any response since then. flushQueueLength grew to the ceiling and stayed there. The only log entries are from periodicFlusher:

{code}
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,3992+80bb1,1432526964367.c4906e519c1f8206a284c66a8eda2159. after a delay of 11000
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,0814+0416,1432541066864.cf42d5ab47e051d69e516971e82e84be. after a delay of 7874
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,2022+7a571,1432528246524.299c1d4bb28fda2a4d9f248c6c22153c. after a delay of 22740
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,2635+b9b677,1432540367215.749efc885317a2679e2ea39bb0845fbe. after a delay of 3162
2015-05-26 02:06:26,742 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/hbase08.company.com/10.28.1.6:60020.periodicFlusher requesting flush for region myns:mytable,0401+985e,1432527151473.eb97576381fce10a9616efd471103920. after a delay of 9142
{code}

Looks like there is a RS level deadlock triggered by the FATAL append exception handling. In the end, I had to restart the RS service to rescue the regions from the stuck RS.

{code}
      } catch (Exception e) {
        LOG.fatal(""Could not append. Requesting close of wal"", e);
        requestLogRoll();
        throw e;
      }
      numEntries.incrementAndGet();
    }
{code}

Maybe the RS can just suicide after the FATAL exception since it cannot append WAL to hdfs? ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6289,"The ROOT RS has some network problem and its ZK node expires first, which kicks off the ServerShutdownHandler. it calls verifyAndAssignRoot() to try to re-assign ROOT. At that time, the RS is actually still working and passes the verifyRootRegionLocation() check, so the ROOT region is skipped from re-assignment.
{code}
  private void verifyAndAssignRoot()
  throws InterruptedException, IOException, KeeperException {
    long timeout = this.server.getConfiguration().
      getLong(""hbase.catalog.verification.timeout"", 1000);
    if (!this.server.getCatalogTracker().verifyRootRegionLocation(timeout)) {
      this.services.getAssignmentManager().assignRoot();
    }
  }
{code}
After a few moments, this RS encounters DFS write problem and decides to abort. The RS then soon gets restarted from commandline, and constantly report:
{code}
2012-06-27 23:13:08,627 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
2012-06-27 23:13:08,627 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
2012-06-27 23:13:08,628 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
2012-06-27 23:13:08,628 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
2012-06-27 23:13:08,630 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: NotServingRegionException; Region is not online: -ROOT-,,0
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2818,"I have a region that's open on a server, but META thinks it's not deployed anywhere. I get the following when trying to close it:

hbase(main):002:0> close_region 'usertable,user302806495,1278457018956.c4ad0681f7be3995490c745861af66ea.', '192.168.42.41:60020'

ERROR: java.io.IOException: java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.util.Bytes.toLong(Bytes.java:479)
        at org.apache.hadoop.hbase.util.Bytes.toLong(Bytes.java:453)
        at org.apache.hadoop.hbase.master.HMaster.modifyTable(HMaster.java:1021)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11401,"After HBASE-8763, we have combined KV mvcc and HLog seqNo. This is implemented in a tricky way now.
In HRegion on write path, we first write to memstore and then write to HLog finally sync log. So at the time of write to memstore we dont know the WAL seqNo.  To overcome this, we hold the ref to the KV objects just added to memstore and pass those also to write to wal call. Once the seqNo is obtained, we will reset the mvcc is those KVs with this seqNo.  (While write to memstore we wrote kvs with a very high temp value for mvcc so that concurrent readers wont see them)
This model works well with the DefaultMemstore.  During the write there wont be any concurrent call to snapshot(). 
But now we have memstore as a pluggable interface. The above model of late binding assumes that the memstore internal datastructure continue to refer to same java objects. This might not be true always.  Like in HBASE-10713, in btw the kvs can be converted into a CellBlock. If we discontinue to refer to same KV java objects, we will fail in getting the seqNo assigned as kv mvcc.

If we were doing write and sync to wal and then write to memstore, this would have get solved. But this model we changed (in 94 I believe) for better perf. Under HRegion level lock, we write to memstore and then to wal. Finally out of lock we do the the log sync.  So we can not change it now

I tried changing the order of ops within the lock (ie. write to log and then to memstore) so that we can get the seqNo when write to memstore. But because of the new HLog write model, we are not guarenteed to get the write to done immediately. 

One possible way can be add a new API in Log level, to get a next seqNo alone. Call this first and then using which write to memstore and then to wal (using this seqNo).  Just a random thought. Not tried.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4951,"It is easy to reproduce by following step:
step1:start master process.(do not start regionserver process in the cluster).
the master will wait the regionserver to check in:
org.apache.hadoop.hbase.master.ServerManager: Waiting on regionserver(s) to checkin

step2:stop the master by sh command bin/hbase master stop

result:the master process will never die because catalogTracker.waitForRoot() method will block unitl the root region assigned.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3350,"With my ""crazy conf"" that causes tons of splits, I had a 2000 region table, which I disabled while inserting data (similar to HBASE-3345). This time I didn't get NPE, but I ended up with 68 regions stuck in transition (disable never finished)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2575,"We performed a fault test where we physically pulled the root drive out of a machine while it was on. The regionserver continued to run fine with existing clients. But any new clients that tried to connect to it for RPC would not work correctly. So when I started a new client, that client made no progress. Despite this, the RS continued to happily heartbeat to the master, so the master did not remove it from the cluster. Note that in this case, we were logging to NFS, and the logs continued to write, but no exceptions shown.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2176,"We ran some tests on our cluster, and getting back reports about WrongRegionException, on some rows. After looking at the data, we see that we have ""gaps"" between regions, like this:

{noformat}
demo__users,user_8949795897,1264089193398  l2:60030  736660864  user_8949795897  user_8950697145 <- end key
demo__users,user_8953502603,1263992844343  l5:60030  593335873  user_8953502603 <- should be star key here   user_8956071605
{noformat}

Fact: we had 28 regions that were reported with empty HRegionInfo, and deleted from .META.. 

Fact: we recovered our data entirely, without any issues, by running the .META. restore script from table contents (bin/add_table.rb)

Fact: on our regionservers, we have three days with no logs. To the best of our knowledge, the machines were not rebooted, the processes were running. During these three days, on the master, the only entry in the logs (repeated), every second, is a .META. scan:

{noformat}
2010-01-23 00:01:27,816 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scan of 1 row(s) of meta region {server: 10.72.135.7:60020, regionname: -ROOT-,,0, startKey: <>} complete
2010-01-23 00:01:34,413 INFO org.apache.hadoop.hbase.master.ServerManager: 6 region servers, 0 dead, average load 1113.6666666666667
2010-01-23 00:02:23,645 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {server: 10.72.135.10:60020, regionname: .META.,,1, startKey: <>}
2010-01-23 00:02:26,002 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of 6679 row(s) of meta region {server: 10.72.135.10:60020, regionname: .META.,,1, startKey: <>} complete
2010-01-23 00:02:26,002 INFO org.apache.hadoop.hbase.master.BaseScanner: All 1 .META. region(s) scanned
2010-01-23 00:02:27,821 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {server: 10.72.135.7:60020, regionname: -ROOT-,,0, startKey: <>}
.......................................................
{noformat}

In the master logs, we see a pretty normal evolution: region r0 is split into r1 and r2. Now, r1 exists and is good, r2 does not exist in .META. anymore, because it was reported as having empty HRegionInfo. The only thing in the master logs that is weird is that the message about updating the region in meta comes up twice:

{noformat}
2010-01-27 22:46:45,007 INFO org.apache.hadoop.hbase.master.RegionServerOperation: demo__users,user_8950697145,1264089193398 open on 10.72.135.7:60020
2010-01-27 22:46:45,010 INFO org.apache.hadoop.hbase.master.RegionServerOperation: Updated row demo__users,user_8950697145,1264089193398 in region .META.,,1 with startcode=1264661019484, server=10.72.135.7:60020
2010-01-27 22:46:45,010 INFO org.apache.hadoop.hbase.master.RegionServerOperation: demo__users,user_8950697145,1264089193398 open on 10.72.135.7:60020
2010-01-27 22:46:45,012 INFO org.apache.hadoop.hbase.master.RegionServerOperation: Updated row demo__users,user_8950697145,1264089193398 in region .META.,,1 with startcode=1264661019484, server=10.72.135.7:60020
{noformat}

Attached you will find the entire forensics work, with explanations, in a text file. 

Suppositions:

Our entire cluster was in a really weird state. All the regionservers are missing logs for three days, and to the best of our knowledge they were running, and in this time the master has ONLY .META. scan messages, every second, reporting 6 regionservers live, out of 7 total. 

Also, during this time, we get filesystem closed messages on a regionservers with one of the missing regions. This is after the gap in the logs. 

How we suppose the data in .META. was lost

1. Race conditions in ServerManager / RegionManager. In our logs, we have about 3 or 4 CME, in these classes (see the attached file)
2. Data loss in HDFS. On a regionserver, we get filesystem closed messages
3. Data could not be read fro HDFS ( highly unlikely, there are no weird data read messages)
4. Race condition leading to loss of the HRegionInfo from memory, and then persisted as empty. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1214,"One of my region server falls in a long GC time that get it unresponsive during about 10 minutes.
As I can see in the log, it seems that its DFSClient component was sending a file to hdfs, the sending times out when it recovers from GC:

h5. 1. Region server log after recovering from GC
{noformat}
2009-02-21 01:22:26,454 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  
    for block blk_7545556036225037274_1820952java.io.IOException: Bad response 1 for block 
    blk_7545556036225037274_1820952 from datanode 192.168.1.10:50010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2342)
{noformat}

h5. 2. corresponding error in receiving datanode
{noformat}
2009-02-21 01:23:56,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block 
    blk_7545556036225037274_1820952 java.io.EOFException: while trying to read 65557 bytes
[...]
2009-02-21 01:23:59,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block 
    blk_7545556036225037274_1820952 Interrupted.
2009-02-21 01:24:01,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block 
    blk_7545556036225037274_1820952 terminating
2009-02-21 01:24:01,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock 
   blk_7545556036225037274_1820952 received exception java.io.EOFException: while trying to read 65557 bytes
{noformat}

Since region server misses its lease to report to the master, it has to close all its regions before recover, and reopens them when the master asks for.
From this time, it tries to _recover_ this block, as seen in the regionserver log:

h5. 3. Region server log in an endless loop to recover
{noformat}
009-02-21 01:22:29,327 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block 
    blk_7545556036225037274_1820952 bad datanode[1] 192.168.1.10:50010
2009-02-21 01:22:29,327 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block 
    blk_7545556036225037274_1820952 in pipeline 192.168.1.13:50010, 
   192.168.1.10:50010: bad datanode 192.168.1.10:50010
2009-02-21 01:22:29,689 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block 
    blk_7545556036225037274_1820952 failed  because recovery from primary datanode 192.168.1.13:50010 failed 2 times. Will retry...
{noformat}

To this _recover_ request, all datanodes fail with this Exception

h5. 4.
{noformat}
2009-02-21 01:24:18,650 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020, call 
   recoverBlock(blk_7545556036225037274_1820952, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@311c4f) from 
   192.168.1.13:56968: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: 
   blk_7545556036225037274_1820952 is already commited, storedBlock == null.
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:4536)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:402)
        at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_7545556036225037274_1820952 is already commited, 
   storedBlock == null.
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:4536)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:402)
        at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)

        at org.apache.hadoop.ipc.Client.call(Client.java:696)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
        at $Proxy4.nextGenerationStamp(Unknown Source)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1466)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1440)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1506)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:892)
{noformat}

The problem is that, in this case, the RegionServer and therefore the master fails to stop when I launch the stop-hbase script.
A kill (-TERM) on the region server launches the SIGTERM handler thread, but the loop which try to reach the block does not stop.
here is a thread dump of the region server at this time:

h5. 5. Thread dump of the region server
{noformat}
Full thread dump Java HotSpot(TM) Server VM (10.0-b23 mixed mode):

""Thread-16"" prio=10 tid=0x081c3c00 nid=0x6e81 in Object.wait() [0x8f74f000..0x8f74fec0]
   java.lang.Thread.State: WAITING (on object monitor)                                
        at java.lang.Object.wait(Native Method)                                        
        at java.lang.Thread.join(Thread.java:1143)                                    
        - locked <0x93d0d060> (a java.lang.Thread)                                    
        at java.lang.Thread.join(Thread.java:1196)                                    
        at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:78)              
        at org.apache.hadoop.hbase.util.Threads.shutdown(Threads.java:66)              
        at org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread.run(HRegionServer.java:814)

""SIGTERM handler"" daemon prio=10 tid=0x08dbcc00 nid=0x6e80 in Object.wait() [0x8edaf000..0x8edaff40]
   java.lang.Thread.State: WAITING (on object monitor)                                              
        at java.lang.Object.wait(Native Method)                                                    
        at java.lang.Thread.join(Thread.java:1143)                                                  
        - locked <0x93d0f3c0> (a org.apache.hadoop.hbase.regionserver.HRegionServer$ShutdownThread)
        at java.lang.Thread.join(Thread.java:1196)                                                  
        at java.lang.ApplicationShutdownHooks.run(ApplicationShutdownHooks.java:79)                
        at java.lang.Shutdown.runHooks(Shutdown.java:89)                                            
        at java.lang.Shutdown.sequence(Shutdown.java:133)                                          
        at java.lang.Shutdown.exit(Shutdown.java:178)                                              
        - locked <0xb0d3ed60> (a java.lang.Class for java.lang.Shutdown)                            
        at java.lang.Terminator$1.handle(Terminator.java:35)                                        
        at sun.misc.Signal$1.run(Signal.java:195)                                                  
        at java.lang.Thread.run(Thread.java:619)                                                    

""Attach Listener"" daemon prio=10 tid=0x081e8800 nid=0x6e50 waiting on condition [0x00000000..0x00000000]
   java.lang.Thread.State: RUNNABLE                                                                    

""IPC Client (47) connection to /192.168.1.13:50020 from an unknown user"" daemon prio=10 tid=0x8e97a400 nid=0x39d1 in Object.wait() [0x8ec81000..0x8ec81fc0]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                                                                              
        at java.lang.Object.wait(Native Method)                                                                                                            
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:395)                                                                            
        - locked <0xa44a36a0> (a org.apache.hadoop.ipc.Client$Connection)                                                                                  
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:437)                                                                                    

""IPC Client (47) connection to /192.168.1.10:50020 from an unknown user"" daemon prio=10 tid=0x8e5f1c00 nid=0x523f in Object.wait() [0x8ecd3000..0x8ecd3140]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                                                                              
        at java.lang.Object.wait(Native Method)                                                                                                            
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:395)                                                                            
        - locked <0xa448ca50> (a org.apache.hadoop.ipc.Client$Connection)                                                                                  
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:437)                                                                                    

""BlockFSInputStreamReferenceQueueChecker"" daemon prio=10 tid=0x085a9400 nid=0x8c8 waiting on condition [0x8ee6c000..0x8ee6cdc0]
   java.lang.Thread.State: WAITING (parking)                                                                                  
        at sun.misc.Unsafe.park(Native Method)                                                                                
        - parking to wait for  <0x93e76068> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)          
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                                  
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)  
        at java.util.concurrent.DelayQueue.take(DelayQueue.java:160)                                                          
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:582)        
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:575)        
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:946)                                        
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:906)                                    
        at java.lang.Thread.run(Thread.java:619)                                                                              

""IPC Server handler 9 on 60020"" daemon prio=10 tid=0x0882e000 nid=0x889 waiting on condition [0x8eebd000..0x8eebdfc0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 8 on 60020"" daemon prio=10 tid=0x0882cc00 nid=0x888 waiting on condition [0x8ef0e000..0x8ef0f040]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 7 on 60020"" daemon prio=10 tid=0x0882b800 nid=0x887 waiting on condition [0x8ef5f000..0x8ef5fec0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 6 on 60020"" daemon prio=10 tid=0x0882a400 nid=0x886 waiting on condition [0x8efb0000..0x8efb0f40]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 5 on 60020"" daemon prio=10 tid=0x08829000 nid=0x885 waiting on condition [0x8f001000..0x8f001dc0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 4 on 60020"" daemon prio=10 tid=0x083bcc00 nid=0x884 waiting on condition [0x8f052000..0x8f052e40]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 3 on 60020"" daemon prio=10 tid=0x083bb800 nid=0x883 waiting on condition [0x8f0a3000..0x8f0a40c0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 2 on 60020"" daemon prio=10 tid=0x083ba400 nid=0x882 waiting on condition [0x8f0f4000..0x8f0f5140]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 1 on 60020"" daemon prio=10 tid=0x083b9400 nid=0x881 waiting on condition [0x8f145000..0x8f145fc0]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server handler 0 on 60020"" daemon prio=10 tid=0x083b8400 nid=0x880 waiting on condition [0x8f196000..0x8f197040]
   java.lang.Thread.State: WAITING (parking)                                                                        
        at sun.misc.Unsafe.park(Native Method)                                                                      
        - parking to wait for  <0x93d0e9c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)                                        
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)                                      
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:881)                                        

""IPC Server listener on 60020"" daemon prio=10 tid=0x083bfc00 nid=0x87f runnable [0x8f1e7000..0x8f1e7ec0]
   java.lang.Thread.State: RUNNABLE                                                                    
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)                                        
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)                                
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)                            
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)                                
        - locked <0x93d0c090> (a sun.nio.ch.Util$1)                                                    
        - locked <0x93d0c120> (a java.util.Collections$UnmodifiableSet)                                
        - locked <0x93d0c0b0> (a sun.nio.ch.EPollSelectorImpl)                                          
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)                                        
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:84)                                        
        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.run(HBaseServer.java:299)                  

""IPC Server Responder"" daemon prio=10 tid=0x083bec00 nid=0x87e runnable [0x8f238000..0x8f238f40]
   java.lang.Thread.State: RUNNABLE                                                            
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)                                
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)                        
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)                    
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)                        
        - locked <0x93d0c0f0> (a sun.nio.ch.Util$1)                                            
        - locked <0x93d0c100> (a java.util.Collections$UnmodifiableSet)                        
        - locked <0x93d0be30> (a sun.nio.ch.EPollSelectorImpl)                                  
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)                                
        at org.apache.hadoop.hbase.ipc.HBaseServer$Responder.run(HBaseServer.java:458)          

""SocketListener0-1"" prio=10 tid=0x088d5000 nid=0x87c in Object.wait() [0x8f2da000..0x8f2dae40]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                  
        at java.lang.Object.wait(Native Method)                                              
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:522)                    
        - locked <0x93e39bc8> (a org.mortbay.util.ThreadPool$PoolThread)                      

""SocketListener0-0"" prio=10 tid=0x08ab5000 nid=0x87b in Object.wait() [0x8f32b000..0x8f32c0c0]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                  
        at java.lang.Object.wait(Native Method)                                              
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:522)                    
        - locked <0x93e39920> (a org.mortbay.util.ThreadPool$PoolThread)                      

""Acceptor ServerSocket[addr=0.0.0.0/0.0.0.0,port=0,localport=60030]"" prio=10 tid=0x084f6800 nid=0x87a 
   runnable [0x8f37c000..0x8f37d140]
   java.lang.Thread.State: RUNNABLE                                                                                                    
        at java.net.PlainSocketImpl.socketAccept(Native Method)                                                                        
        at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:384)                                                                  
        - locked <0x93e382a8> (a java.net.SocksSocketImpl)                                                                            
        at java.net.ServerSocket.implAccept(ServerSocket.java:453)                                                                    
        at java.net.ServerSocket.accept(ServerSocket.java:421)                                                                        
        at org.mortbay.util.ThreadedServer.acceptSocket(ThreadedServer.java:432)                                                      
        at org.mortbay.util.ThreadedServer$Acceptor.run(ThreadedServer.java:631)                                                      

""SessionScavenger"" daemon prio=10 tid=0x088f1400 nid=0x879 waiting on condition [0x8f3cd000..0x8f3cdfc0]
   java.lang.Thread.State: TIMED_WAITING (sleeping)                                                    
        at java.lang.Thread.sleep(Native Method)                                                        
        at org.mortbay.jetty.servlet.AbstractSessionManager$SessionScavenger.run(AbstractSessionManager.java:587)

""SessionScavenger"" daemon prio=10 tid=0x08ab5c00 nid=0x878 waiting on condition [0x8f41e000..0x8f41f040]
   java.lang.Thread.State: TIMED_WAITING (sleeping)                                                    
        at java.lang.Thread.sleep(Native Method)                                                        
        at org.mortbay.jetty.servlet.AbstractSessionManager$SessionScavenger.run(AbstractSessionManager.java:587)

""regionserver/0.0.0.0:60020.leaseChecker"" prio=10 tid=0x086d5800 nid=0x877 waiting on condition [0x8f476000..0x8f476ec0]
   java.lang.Thread.State: TIMED_WAITING (parking)                                                                      
        at sun.misc.Unsafe.park(Native Method)                                                                          
        - parking to wait for  <0x93d0e980> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)  
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)                                      
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1963)
        at java.util.concurrent.DelayQueue.poll(DelayQueue.java:201)                                                            
        at org.apache.hadoop.hbase.Leases.run(Leases.java:78)                                                                    

""regionserver/0.0.0.0:60020.majorCompactionChecker"" daemon prio=10 tid=0x086d4000 nid=0x876 waiting on 
   condition [0x8f4c7000..0x8f4c7f40]
   java.lang.Thread.State: TIMED_WAITING (sleeping)                                                                                      
        at java.lang.Thread.sleep(Native Method)                                                                                        
        at org.apache.hadoop.hbase.util.Sleeper.sleep(Sleeper.java:74)                                                                  
        at org.apache.hadoop.hbase.Chore.run(Chore.java:72)                                                                              

""LeaseChecker"" daemon prio=10 tid=0x0837cc00 nid=0x870 waiting on condition [0x8f6ad000..0x8f6ae040]
   java.lang.Thread.State: TIMED_WAITING (sleeping)                                                
        at java.lang.Thread.sleep(Native Method)                                                    
        at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:979)                    
        at java.lang.Thread.run(Thread.java:619)                                                    

""DataStreamer for file /hbase/log_192.168.1.13_1235129194745_60020/hlog.dat.1235129195649 block blk_7545556036225037274_1820952"" 
   daemon prio=10 tid=0x08375400 nid=0x86f in Object.wait() [0x8f6fe000..0x8f6feec0]                                                                                                      
   java.lang.Thread.State: TIMED_WAITING (on object monitor)                                                                                                
        at java.lang.Object.wait(Native Method)                                                                                                            
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2166)                                                          
        - locked <0x93d0ea10> (a java.util.LinkedList)                                                                                                      

""DestroyJavaVM"" prio=10 tid=0x0805a000 nid=0x855 waiting on condition [0x00000000..0xb7dd2090]
   java.lang.Thread.State: RUNNABLE                                                          

""regionserver/0.0.0.0:60020"" prio=10 tid=0x085b2400 nid=0x863 in Object.wait() [0x8f7f7000..0x8f7f7f40]
   java.lang.Thread.State: WAITING (on object monitor)                                                
        at java.lang.Object.wait(Native Method)                                                        
        at java.lang.Object.wait(Object.java:485)                                                      
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.flushInternal(DFSClient.java:3015)        
        - locked <0x93d0ea10> (a java.util.LinkedList)                                                
        - locked <0x93d0ec58> (a org.apache.hadoop.hdfs.DFSClient$DFSOutputStream)                    
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3104)        
        - locked <0x93d0ec58> (a org.apache.hadoop.hdfs.DFSClient$DFSOutputStream)                    
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3053)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:59)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:79)
        at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:959)
        - locked <0x93d50d20> (a org.apache.hadoop.io.SequenceFile$Writer)
        at org.apache.hadoop.hbase.regionserver.HLog.close(HLog.java:421)
        - locked <0x93d4ce00> (a java.lang.Integer)
        at org.apache.hadoop.hbase.regionserver.HLog.closeAndDelete(HLog.java:404)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:373)
        at java.lang.Thread.run(Thread.java:619)

""Low Memory Detector"" daemon prio=10 tid=0x080dd800 nid=0x85e runnable [0x00000000..0x00000000]
   java.lang.Thread.State: RUNNABLE

""CompilerThread1"" daemon prio=10 tid=0x080dc400 nid=0x85d waiting on condition [0x00000000..0x8fbc1588]
   java.lang.Thread.State: RUNNABLE

""CompilerThread0"" daemon prio=10 tid=0x080d9c00 nid=0x85c waiting on condition [0x00000000..0x8fc42608]
   java.lang.Thread.State: RUNNABLE

""Signal Dispatcher"" daemon prio=10 tid=0x080d8800 nid=0x85b runnable [0x00000000..0x8fc93e80]
   java.lang.Thread.State: RUNNABLE

""Surrogate Locker Thread (CMS)"" daemon prio=10 tid=0x080d7800 nid=0x85a waiting on condition [0x00000000..0x8fce522c]
   java.lang.Thread.State: RUNNABLE

""Finalizer"" daemon prio=10 tid=0x080bbc00 nid=0x859 in Object.wait() [0x8fd7b000..0x8fd7bec0]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116)
        - locked <0x93d0bdc0> (a java.lang.ref.ReferenceQueue$Lock)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)

""Reference Handler"" daemon prio=10 tid=0x080ba800 nid=0x858 in Object.wait() [0x8fdcc000..0x8fdccf40]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object",,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6737,"Real cluster, scenario in HBASE-5843.
There are two exceptions, I create a single JIRA with both of them.

2012-09-04 18:14:49,264 FATAL org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: WriterThread-1 Got while writing log entry to log
java.io.IOException: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.append(SequenceFileLogWriter.java:229)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:949)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:919)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:891)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.SequenceFile$Writer.checkAndWriteSync(SequenceFile.java:1026)
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1068)
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1035)
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.append(SequenceFileLogWriter.java:226)
	... 3 more


2012-09-04 18:15:52,546 ERROR org.apache.hadoop.hbase.regionserver.wal.HLogSplitter: Error in log splitting write thread
java.lang.reflect.UndeclaredThrowableException
	at $Proxy7.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:875)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:513)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:768)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getRegionSplitEditsPath(HLogSplitter.java:559)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.createWAP(HLogSplitter.java:974)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.access$800(HLogSplitter.java:82)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$OutputSink.getWriterAndPath(HLogSplitter.java:1309)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.writeBuffer(HLogSplitter.java:942)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.doRun(HLogSplitter.java:919)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$WriterThread.run(HLogSplitter.java:891)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:261)
	... 11 more
Caused by: java.io.IOException: Call to BOX1/192.168.15.5:9000 failed on local exception: java.nio.channels.ClosedByInterruptException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1107)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy7.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy7.getFileInfo(Unknown Source)
	... 15 more
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:783)
	at org.apache.hadoop.ipc.Client.call(Client.java:1051)
	... 23 more

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8416,"This morning one our region servers (we have 44) stopped responding to
the '/jmx' request. (It's working for regular activity.)  Additionally,
the region server is now using all the CPU on the host, running all 8
cores at 100%.

A full jstack is at:
http://pastebin.com/dGTmTEN7


Right now, there are 37 threads stuck here:
""38565532@qtp-228776471-196"" prio=10 tid=0x00002aaacc4f2800 nid=0x7f57 runnable [0x0000000054a48000]
   java.lang.Thread.State: RUNNABLE
        at java.util.HashMap.get(HashMap.java:303)
        at org.apache.hadoop.metrics.util.MetricsDynamicMBeanBase.getAttribute(MetricsDynamicMBeanBase.java:137)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:666)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:638)
        at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:315)
        at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:293)
        at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:193)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:734)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:847)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1056)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1774,"HTable$ClientScanner modifies the Scan that is passed to it on construction.

I would consider this to be bad programming practice because if I wanted to use the same Scan object to scan multiple tables, I would not expect one table scan to effect the other, but it does.

If input parameters are going to be modified either now or later it should be called out *loudly* in the javadoc. The only way I found this behavior was by creating an application that did scan multiple tables using the same Scan object and having 'wierd stuff' happen.

In my opinion, if you want to modify a field in an input parameter, you should:
- make a copy of the original object
- optionally return a reference to the copy.

There is no javadoc about this behavior. The only thing I found was a comment in HTable$ClientScanner:
{code}
    // HEADSUP: The scan internal start row can change as we move through table.
{code}

Is there a use case that requires this behavior? If so, I would recommend that ResultScanner  (and the classes that implement it) provide an accessor to the mutable copy of the input Scan and leave the input argument alone.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6401,"This comes from a hdfs bug, fixed in some hdfs versions. I haven't found the hdfs jira for this.

Context: HBase Write Ahead Log features. This is using hdfs append. If the node crashes, the file that was written is read by other processes to replay the action.
- So we have in hdfs one (dead) process writing with another process reading.
- But, despite the call to syncFs, we don't always see the data when we have a dead node. It seems to be because the call in DFSClient#updateBlockInfo ignores the ipc errors and set the length to 0.
- So we may miss all the writes to the last block if we try to connect to the dead DN.

hdfs 1.0.3, branch-1 or branch-1-win: we have the issue
http://svn.apache.org/viewvc/hadoop/common/branches/branch-1/src/hdfs/org/apache/hadoop/hdfs/DFSClient.java?revision=1359853&view=markup

hdfs branch-2 or trunk: we should not have the issue (but not tested)
http://svn.apache.org/viewvc/hadoop/common/branches/branch-2/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java?view=markup


The attached test will fail ~50 of the time.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4481,"TestMergeTool failed due to the following exception:
{code}
java.lang.StringIndexOutOfBoundsException: String index out of range: -1
	at java.lang.String.substring(String.java:1937)
	at org.apache.hadoop.hbase.ServerName.parseHostname(ServerName.java:81)
	at org.apache.hadoop.hbase.ServerName.<init>(ServerName.java:63)
	at org.apache.hadoop.hbase.MasterAddressTracker.getMasterAddress(MasterAddressTracker.java:62)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getMaster(HConnectionManager.java:583)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:108)
	at org.apache.hadoop.hbase.client.HBaseAdmin.checkHBaseAvailable(HBaseAdmin.java:1588)
	at org.apache.hadoop.hbase.util.Merge.run(Merge.java:94)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.TestMergeTool.mergeAndVerify(TestMergeTool.java:186)
	at org.apache.hadoop.hbase.util.TestMergeTool.testMergeTool(TestMergeTool.java:264)
{code}
Log can be found at:
https://builds.apache.org/view/G-L/view/HBase/job/HBase-0.92/20/testReport/junit/org.apache.hadoop.hbase.util/TestMergeTool/testMergeTool/",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-907,"I have a table with 8 byte binary row keys.  There are a a few hundred thousands rows, each with two families and between 1k and 50k of total data across about 15 columns.

When attempting to get a scanner using a specified startRow, my client freezes on the HT.getScanner(cols,row) with no exception ever thrown and no debug output in any server logs.

If I get a scanner with HT.getScanner(cols) and then iterate through, I will eventually reach the row I was seeking before successfully.

Some rows can be found, some cannot.  At this point I'm not able to distinguish anything special about the ones that cause the client the hang.

At first I thought this was only a problem with 0.19 trunk as a downgrade to 0.18 resolved the issue for a particular key.  However other keys still have this issue on 0.18 branch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3466,"Happened while running ycsb against a single RS.  BlockSize was set to 64M to tickle more splits. No compression, and replication factor set to 1.
 
I noticed that  https://issues.apache.org/jira/browse/HBASE-2455 applied to 0.20.4, so opened this new one (didn't check to see if the code was the same in 0.20.4 and 0.90.0)

YCSB was run as follows:

java -mx3000m -cp conf/:build/ycsb.jar:db/hbase/lib/* com.yahoo.ycsb.Client -t -db com.yahoo.ycsb.db.HBaseClient -P workloads/workloada -p columnfamily=family -p operationcount=10000000 -s -threads 30 -target 30000

workloada was modified to do 1 billion records:
----------
recordcount=1000000000
operationcount=1000
workload=com.yahoo.ycsb.workloads.CoreWorkload
readallfields=true
readproportion=0.5
updateproportion=0.4
scanproportion=0
insertproportion=0.1
requestdistribution=zipfian
---------------

Relevant portions from the RS's log:

2011-01-23 10:48:20,719 INFO  org.apache.hadoop.hbase.regionserver.SplitTransaction [regionserver60020.compactor]: Starting split of region usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c.
2011-01-23 10:48:20,788 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Renaming flushed file at maprfs:/hbase/usertable/44386ab6079bd5b497a6de3ab95e850c/.tmp/3202441284831392385 to maprfs:/hbase/usertable/44386ab6079bd5b497a6de3ab95e850c/family/1800354539520698957
2011-01-23 10:48:20,791 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Added maprfs:/hbase/usertable/44386ab6079bd5b497a6de3ab95e850c/family/1800354539520698957, entries=10943, sequenceid=128924, memsize=3.4m, filesize=1.5m
2011-01-23 10:48:20,792 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: Closed usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c.
2011-01-23 10:48:20,828 INFO  org.apache.hadoop.hbase.catalog.MetaEditor [regionserver60020.compactor]: Offlined parent region usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c. in META
2011-01-23 10:48:20,856 INFO  org.apache.hadoop.hbase.regionserver.HRegion [perfnode15.perf.lab,60020,1295807975391-daughterOpener=89e0f70da1e5ce2d5c4024ca6cc1addb]: Onlined usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb.; next sequenceid=128925
2011-01-23 10:48:20,791 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Added maprfs:/hbase/usertable/44386ab6079bd5b497a6de3ab95e850c/family/1800354539520698957, entries=10943, sequenceid=128924, memsize=3.4m, filesize=1.5m
2011-01-23 10:48:20,792 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: Closed usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c.
2011-01-23 10:48:20,828 INFO  org.apache.hadoop.hbase.catalog.MetaEditor [regionserver60020.compactor]: Offlined parent region usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c. in META
2011-01-23 10:48:20,856 INFO  org.apache.hadoop.hbase.regionserver.HRegion [perfnode15.perf.lab,60020,1295807975391-daughterOpener=89e0f70da1e5ce2d5c4024ca6cc1addb]: Onlined usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb.; next sequenceid=128925
2011-01-23 10:48:20,863 INFO  org.apache.hadoop.hbase.catalog.MetaEditor [perfnode15.perf.lab,60020,1295807975391-daughterOpener=89e0f70da1e5ce2d5c4024ca6cc1addb]: Added daughter usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb. in region .META.,,1, serverInfo=perfnode15.perf.lab,60020,1295807975391
2011-01-23 10:48:20,868 INFO  org.apache.hadoop.hbase.regionserver.HRegion [perfnode15.perf.lab,60020,1295807975391-daughterOpener=fd1d4e71c9a7e262a6e26adc0742414e]: Onlined usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e.; next sequenceid=128926
2011-01-23 10:48:20,869 INFO  org.apache.hadoop.hbase.catalog.MetaEditor [perfnode15.perf.lab,60020,1295807975391-daughterOpener=fd1d4e71c9a7e262a6e26adc0742414e]: Added daughter usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e. in region .META.,,1, serverInfo=perfnode15.perf.lab,60020,1295807975391
2011-01-23 10:48:20,870 INFO  org.apache.hadoop.hbase.regionserver.CompactSplitThread [regionserver60020.compactor]: Region split, META updated, and report to master. Parent=usertable,,1295808232386.44386ab6079bd5b497a6de3ab95e850c., new regions: usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb., usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e.. Split took 0sec
2011-01-23 10:48:20,871 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: Starting compaction on region usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb.
2011-01-23 10:48:20,873 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Started compaction of 4 file(s) in cf=family, hasReferences=true, into maprfs:/hbase/usertable/89e0f70da1e5ce2d5c4024ca6cc1addb/.tmp, seqid=128924, totalSize=271.3m
2011-01-23 10:48:21,822 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer [IPC Server handler 1 on 60020]: 
java.lang.RuntimeException: Cached an already cached block
        at org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(LruBlockCache.java:252)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:1056)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1433)
        at org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(HalfStoreFileReader.java:160)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:139)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:96)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.<init>(StoreScanner.java:77)
        at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1338)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.<init>(HRegion.java:2229)
        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateInternalScanner(HRegion.java:1119)
        at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1111)
        at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1095)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2951)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2853)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1623)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:570)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1036)
2011-01-23 10:48:28,877 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Completed compaction of 4 file(s), new file=maprfs:/hbase/usertable/89e0f70da1e5ce2d5c4024ca6cc1addb/family/1639385306246002272, size=125.9m; total size for store is 125.9m
2011-01-23 10:48:28,877 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: completed compaction on region usertable,,1295808500713.89e0f70da1e5ce2d5c4024ca6cc1addb. after 8sec
2011-01-23 10:48:28,879 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: Starting compaction on region usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e.
2011-01-23 10:48:28,881 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Started compaction of 4 file(s) in cf=family, hasReferences=true, into maprfs:/hbase/usertable/fd1d4e71c9a7e262a6e26adc0742414e/.tmp, seqid=128925, totalSize=271.3m
2011-01-23 10:48:33,880 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.compactor]: Completed compaction of 4 file(s), new file=maprfs:/hbase/usertable/fd1d4e71c9a7e262a6e26adc0742414e/family/7964093352375224080, size=141.2m; total size for store is 141.2m
2011-01-23 10:48:33,880 INFO  org.apache.hadoop.hbase.regionserver.HRegion [regionserver60020.compactor]: completed compaction on region usertable,user1907848630,1295808500713.fd1d4e71c9a7e262a6e26adc0742414e. after 5sec
2011-01-23 10:48:44,117 INFO  org.apache.hadoop.hbase.regionserver.Store [regionserver60020.cacheFlusher]: Renaming flushed file at maprfs:/hbase/usertable/fd1d4e71c9a7e262a6e26adc0742414e/.tmp/8006640041641015018 to maprfs:/hbase/usertable/fd1d4e
71c9a7e262a6e26adc0742414e/family/2931765299907917041
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4722,I'm digging in.  It fails occasionally for me locally to.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-485,"Two runs of the PerformanceEvaluation job on our test cluster running HBase trunk failed with region offline error.

The following is an excerpt from the failed task's log:
{code}
2008-03-01 19:30:42,184 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:30:42,186 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.
2008-03-01 19:30:42,186 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999
2008-03-01 19:30:42,188 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:30:52,196 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:30:52,200 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.
2008-03-01 19:30:52,200 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999
2008-03-01 19:30:52,203 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:31:02,219 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:31:02,236 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.
2008-03-01 19:31:02,237 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999
2008-03-01 19:31:02,240 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:31:12,261 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}
2008-03-01 19:31:12,270 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.lang.RuntimeException: java.lang.IllegalStateException: region offline: TestTable,0012639235,1204398750147
	at org.apache.hadoop.hbase.client.HTable.getRegionServerWithRetries(HTable.java:1019)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:753)
	at org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest.testRow(PerformanceEvaluation.java:465)
	at org.apache.hadoop.hbase.PerformanceEvaluation$Test.test(PerformanceEvaluation.java:333)
	at org.apache.hadoop.hbase.PerformanceEvaluation.runOneClient(PerformanceEvaluation.java:529)
	at org.apache.hadoop.hbase.PerformanceEvaluation$EvaluationMapTask.map(PerformanceEvaluation.java:178)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:208)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2071)
Caused by: java.lang.IllegalStateException: region offline: TestTable,0012639235,1204398750147
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:447)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:352)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:314)
	at org.apache.hadoop.hbase.client.HTable.getRegionLocation(HTable.java:109)
	at org.apache.hadoop.hbase.client.HTable$ServerCallable.instantiateServer(HTable.java:992)
	at org.apache.hadoop.hbase.client.HTable.getRegionServerWithRetries(HTable.java:1006)
	... 8 more
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17384,"From https://builds.apache.org/job/PreCommit-HBASE-Build/5072/testReport/org.apache.hadoop.hbase.regionserver/TestHRegionWithInMemoryFlush/org_apache_hadoop_hbase_regionserver_TestHRegionWithInMemoryFlush/ :
{code}
org.junit.runners.model.TestTimedOutException: test timed out after 10 minutes
	at java.lang.Object.wait(Native Method)
	at org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.waitForRead(MultiVersionConcurrencyControl.java:218)
	at org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.completeAndWait(MultiVersionConcurrencyControl.java:149)
	at org.apache.hadoop.hbase.regionserver.HRegion.getNextSequenceId(HRegion.java:2732)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2447)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2343)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2314)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2304)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1601)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1506)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1456)
	at org.apache.hadoop.hbase.HBaseTestingUtility.closeRegionAndWAL(HBaseTestingUtility.java:374)
	at org.apache.hadoop.hbase.regionserver.TestHRegion.testFlushCacheWhileScanning(TestHRegion.java:3839)
{code}
As can be seen from test output:
{code}
2016-12-28 13:43:28,379 INFO  [Time-limited test] regionserver.HStore(1431): Completed major compaction of 1 (all) file(s) in family1 of testWritesWhileScanning,,1482932605883.2e46061b97a54d7f8434c4a705b3c4a2. into 255e7eb61cfc4945ac5887957d39b1fe(size=98.0 K), total size for store is 98.0 K
...[truncated 4062267 bytes]...
TUCK: MultiVersionConcurrencyControl{readPoint=1090, writePoint=1093}
2016-12-28 13:48:29,396 WARN  [Time-limited test] regionserver.MultiVersionConcurrencyControl(214): STUCK: MultiVersionConcurrencyControl{readPoint=1090, writePoint=1093}
2016-12-28 13:48:30,406 WARN  [Time-limited test] regionserver.MultiVersionConcurrencyControl(214): STUCK: MultiVersionConcurrencyControl{readPoint=1090, writePoint=1093}
2016-12-28 13:48:31,416 WARN  [Time-limited test] regionserver.MultiVersionConcurrencyControl(214): STUCK: MultiVersionConcurrencyControl{readPoint=1090, writePoint=1093}
{code}
At least 5 minutes passed with the above log showing waitForRead() stuck.

Since the flush is blocked, we should consider aborting region server when waitForRead() gets stuck for extended period of time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21379,"聽log as follow:
{code:java}
//浠ｇ爜鍗犱綅绗?
2018-10-24 09:22:42,381 INFO聽 [regionserver/11-3-19-10:16020] wal.AbstractFSWAL: New WAL /hbase/WALs/11-3-19-10.jd.local,16020,1540344155469/11-3-19-10.jd.local%2C16020%2C1540344155469.1540344162124聽 聽 聽 聽 聽鈹?

2018-10-24 09:23:05,151 ERROR [regionserver/11-3-19-10:16020.replicationSource.11-3-19-10.jd.local%2C16020%2C1540344155469,2.replicationSource.wal-reader.11-3-19-10.jd.local%2C16020%2C1540344155469,2] region鈹?
server.ReplicationSource: Unexpected exception in regionserver/11-3-19-10:16020.replicationSource.11-3-19-10.jd.local%2C16020%2C1540344155469,2.replicationSource.wal-reader.11-3-19-10.jd.local%2C16020%2C1540鈹?
344155469,2 currentPath=hdfs://11-3-18-67.JD.LOCAL:9000/hbase/WALs/11-3-19-10.jd.local,16020,1540344155469/11-3-19-10.jd.local%2C16020%2C1540344155469.1540344162124 鈹?
java.lang.ArrayIndexOutOfBoundsException: 8830 鈹?
at org.apache.hadoop.hbase.KeyValue.getFamilyLength(KeyValue.java:1365) 鈹?
at org.apache.hadoop.hbase.KeyValue.getFamilyLength(KeyValue.java:1358) 鈹?
at org.apache.hadoop.hbase.CellUtil.cloneFamily(CellUtil.java:114) 鈹?
at org.apache.hadoop.hbase.replication.ScopeWALEntryFilter.filterCell(ScopeWALEntryFilter.java:54) 鈹?
at org.apache.hadoop.hbase.replication.ChainWALEntryFilter.filterCells(ChainWALEntryFilter.java:90) 鈹?
at org.apache.hadoop.hbase.replication.ChainWALEntryFilter.filter(ChainWALEntryFilter.java:77) 鈹?
at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.filterEntry(ReplicationSourceWALReader.java:234) 鈹?
at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.readWALEntries(ReplicationSourceWALReader.java:170) 鈹?at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReader.run(ReplicationSourceWALReader.java:133) 鈹?
2018-10-24 09:23:05,153 INFO [regionserver/11-3-19-10:16020.replicationSource.11-3-19-10.jd.local%2C16020%2C1540344155469,2.replicationSource.wal-reader.11-3-19-10.jd.local%2C16020%2C1540344155469,2] region鈹?
server.HRegionServer: ***** STOPPING region server '11-3-19-10.jd.local,16020,1540344155469' *****
{code}
hbase wal -p output
{code:java}
//浠ｇ爜鍗犱綅绗?
writer Classes: ProtobufLogWriter AsyncProtobufLogWriter
Cell Codec Class: org.apache.hadoop.hbase.regionserver.wal.WALCellCodec
Sequence=15 , region=fee7a9465ced6ce9e319d37e9d71c63c at write timestamp=Wed Oct 24 09:22:49 CST 2018
row=80000000, column=METAFAMILY:HBASE::REGION_EVENT
value: \x08\x00\x12\x1Cmlaas:ump_host_second_181029\x1A fee7a9465ced6ce9e319d37e9d71c63c \x0E*\x06\x0A\x01f\x12\x01f2\x1F\x0A\x1311-3-19-10.JD.LOCAL\x10\x94}\x18\xCD\x9A\xAA\x9D\xEA,:Umlaas:ump_host_second_181029,80000000,1540271129253.fee7a9465ced6ce9e319d37e9d71c63c.
Sequence=9 , region=ba6684888d826328a6373435124dc1cd at write timestamp=Wed Oct 24 09:22:49 CST 2018
row=91000000, column=METAFAMILY:HBASE::REGION_EVENT
...
row=34975#00, column=f:\x09,
value: {""tp50"":1,""avg"":2,""min"":0,""tp90"":1,""max"":3,""count"":13,""tp99"":2,""tp999"":2,""error"":0}
row=349824#00, column=f:\x08\xFA
value: {""tp50"":2,""avg"":2,""min"":0,""tp90"":2,""max"":98,""count"":957,""tp99"":3,""tp999"":34,""error"":0}
row=349824#00, column=f:\x08\xD2
value: {""tp50"":2,""avg"":2,""min"":0,""tp90"":2,""max"":43,""count"":1842,""tp99"":2,""tp999"":31,""error"":0}
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 8830
at org.apache.hadoop.hbase.KeyValue.getFamilyLength(KeyValue.java:1365)
at org.apache.hadoop.hbase.KeyValue.getFamilyLength(KeyValue.java:1358)
at org.apache.hadoop.hbase.wal.WALPrettyPrinter.toStringMap(WALPrettyPrinter.java:336)
at org.apache.hadoop.hbase.wal.WALPrettyPrinter.processFile(WALPrettyPrinter.java:290)
at org.apache.hadoop.hbase.wal.WALPrettyPrinter.run(WALPrettyPrinter.java:421)
at org.apache.hadoop.hbase.wal.WALPrettyPrinter.main(WALPrettyPrinter.java:356)
{code}
聽",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20671,"Another bug coming out of a master restart and replay of the pv2 logs.

The master merged two regions into one successfully, was restarted, but then ended up assigning the children region back out to the cluster. There is a log message which appears to indicate that RegionStates acknowledges that it doesn't know what this region is as it's replaying the pv2 WAL; however, it incorrectly assumes that the region is just OFFLINE and needs to be assigned.
{noformat}
2018-05-30 04:26:00,055 INFO聽 [RpcServer.default.FPBQ.Fifo.handler=29,queue=2,port=20000] master.HMaster: Client=hrt_qa//172.27.85.11 Merge regions a7dd6606dcacc9daf085fc9fa2aecc0c and 4017a3c778551d4d258c785d455f9c0b
2018-05-30 04:28:27,525 DEBUG [master/ctr-e138-1518143905142-336066-01-000003:20000] procedure2.ProcedureExecutor: Completed pid=4368, state=SUCCESS; MergeTableRegionsProcedure table=tabletwo_merge, regions=[a7dd6606dcacc9daf085fc9fa2aecc0c, 4017a3c778551d4d258c785d455f9c0b], forcibly=false
{noformat}
{noformat}
2018-05-30 04:29:20,263 INFO聽 [master/ctr-e138-1518143905142-336066-01-000003:20000] assignment.AssignmentManager: a7dd6606dcacc9daf085fc9fa2aecc0c regionState=null; presuming OFFLINE
2018-05-30 04:29:20,263 INFO聽 [master/ctr-e138-1518143905142-336066-01-000003:20000] assignment.RegionStates: Added to offline, CURRENTLY NEVER CLEARED!!! rit=OFFLINE, location=null, table=tabletwo_merge, region=a7dd6606dcacc9daf085fc9fa2aecc0c
2018-05-30 04:29:20,266 INFO聽 [master/ctr-e138-1518143905142-336066-01-000003:20000] assignment.AssignmentManager: 4017a3c778551d4d258c785d455f9c0b regionState=null; presuming OFFLINE
2018-05-30 04:29:20,266 INFO聽 [master/ctr-e138-1518143905142-336066-01-000003:20000] assignment.RegionStates: Added to offline, CURRENTLY NEVER CLEARED!!! rit=OFFLINE, location=null, table=tabletwo_merge, region=4017a3c778551d4d258c785d455f9c0b
{noformat}
Eventually, the RS reports in its online regions, and the master tells it to kill itself:
{noformat}
2018-05-30 04:29:24,272 WARN聽 [RpcServer.default.FPBQ.Fifo.handler=26,queue=2,port=20000] assignment.AssignmentManager: Killing ctr-e138-1518143905142-336066-01-000002.hwx.site,16020,1527654546619: Not online: tabletwo_merge,,1527652130538.a7dd6606dcacc9daf085fc9fa2aecc0c.
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7044,"at the beginning there is 1 whole hbase cluster, then I decide to split is into 2 cluster, one is for offline mining, one is for online service, and the online one is striped, the offline one contains the original master.
unfortunately, the META of the original cluster is assigned to the machine stripped, and as there is a cache policy for META, the offline cluster is still access the META of the stripped one.
after inspected the code, I found that in verifyRegionLocation of CatalogTracker.java, although it checks if the region server still contains the region, but it didn't check if the regions erver is still in the cluster which is very easy, just inspect if it is registered int zk.
all in all, I have to shutdown the online cluster and restart the offline one, then the META is re-assgined. then everything is back to normal.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7959,"While lots of region splits going on, HBCK incorrectly reports inconsistencies since it skips recently modified, but does not take those into account for computing the region chain. 

{code}
13/02/28 03:33:16 WARN util.HBaseFsck: Region { meta => cluster_test,,1362021481742.69639761fdf693ab1e2bf33f523cd1ae., hdfs => NN:8020/apps/hbase-trunk/data/cluster_test/69639761fdf693ab1e2bf33f523cd1ae, deployed =>  } was recently modified -- skipping
13/02/28 03:33:16 DEBUG util.HBaseFsck: There are 23 region info entries
ERROR: (region cluster_test,0ccccccc,1362021481742.ec3ba583b4ea01393591572bf1f31e07.) First region should start with an empty key.  You need to  create a new region and regioninfo in HDFS to plug the hole.
ERROR: Found inconsistency in table cluster_test
Summary:
  -ROOT- is okay.
    Number of regions: 1
    Deployed on:  RSs
  .META. is okay.
    Number of regions: 1
    Deployed on:  RSs
Table cluster_test is inconsistent.
    Number of regions: 19
    Deployed on:  RSs
1 inconsistencies detected.
Status: INCONSISTENT

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6184,"insert data

hadoop-0.23.2 + hbase-0.94.0

2012-06-07 13:09:38,573 WARN  [org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation] Encountered problems when prefetch META table: 
java.io.IOException: HRegionInfo was null or empty in Meta for hbase_one_col, row=hbase_one_col,09115303780247449149,99999999999999
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:160)
        at org.apache.hadoop.hbase.client.MetaScanner.access$000(MetaScanner.java:48)
        at org.apache.hadoop.hbase.client.MetaScanner$1.connect(MetaScanner.java:126)
        at org.apache.hadoop.hbase.client.MetaScanner$1.connect(MetaScanner.java:123)
        at org.apache.hadoop.hbase.client.HConnectionManager.execute(HConnectionManager.java:359)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:123)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:99)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:894)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:948)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:836)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:1482)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1367)
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:945)
        at org.apache.hadoop.hbase.client.HTable.doPut(HTable.java:801)
        at org.apache.hadoop.hbase.client.HTable.put(HTable.java:776)
        at org.apache.hadoop.hbase.client.HTablePool$PooledHTable.put(HTablePool.java:397)
        at com.dinglicom.hbase.HbaseImport.insertData(HbaseImport.java:177)
        at com.dinglicom.hbase.HbaseImport.run(HbaseImport.java:210)
        at java.lang.Thread.run(Thread.java:662)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16674,"This test shows up on flaky dashboard here:
https://builds.apache.org/job/HBASE-Find-Flaky-Tests/lastSuccessfulBuild/artifact/dashboard.html

{code}
java.lang.AssertionError: expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.hadoop.hbase.regionserver.wal.TestAsyncLogRolling.testLogRollOnDatanodeDeath(TestAsyncLogRolling.java:63)
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10710,"This case ever failed in last month for HBASE-10648 / HBASE-10615 / HBASE-9990 / HBASE-10582 / HBASE-10527 / HBASE-10575 / HBASE-10570 / HBASE-10532 / HBASE-10537 / HBASE-10534 / HBASE-6642 / HBASE-3909 / HBASE-10169 and so on and on..., but seems it can't reproduce in local run.

This issue is created for any further tracking.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9712,"Opening this issue to keep account of failures.  It failed for me locally just now.

Failed tests:   testTaskResigned(org.apache.hadoop.hbase.master.TestSplitLogManager): version1=2, version=2

{code}
durruti:hbase stack$ more hbase-server/target/surefire-reports/org.apache.hadoop.hbase.master.TestSplitLogManager.txt
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.hbase.master.TestSplitLogManager
-------------------------------------------------------------------------------
Tests run: 14, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 86.697 sec <<< FAILURE!
testTaskResigned(org.apache.hadoop.hbase.master.TestSplitLogManager)  Time elapsed: 0.004 sec  <<< FAILURE!
java.lang.AssertionError: version1=2, version=2
        at org.junit.Assert.fail(Assert.java:88)
        at org.junit.Assert.assertTrue(Assert.java:41)
        at org.apache.hadoop.hbase.master.TestSplitLogManager.testTaskResigned(TestSplitLogManager.java:387)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.junit.runners.Suite.runChild(Suite.java:127)
        at org.junit.runners.Suite.runChild(Suite.java:26)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
        at java.lang.Thread.run(Thread.java:680)
{code}

Let me attach the log",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9014,"http://54.241.6.143/job/HBase-0.95/665/org.apache.hbase$hbase-server/testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLog/testAppendClose/

{code}
Error Message

Problem binding to localhost/127.0.0.1:37036 : Address already in use
Stacktrace

java.net.BindException: Problem binding to localhost/127.0.0.1:37036 : Address already in use
	at org.apache.hadoop.ipc.Server.bind(Server.java:228)
	at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:302)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:1488)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:560)
	at org.apache.hadoop.ipc.RPC.getServer(RPC.java:521)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:302)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:536)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1410)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSClusterForTestHLog(HBaseTestingUtility.java:525)
...
{code}


This testAppendClose stops hdfs and starts it again.  It looks problematic.  Has waits of 7 seconds for the hdfs cluster to go down but in this test it seems like it needs even more time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8999,"[~sershe] Is this your test boss?  Mind taking a looksee.  Here is the fail:

https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/624/consoleFull

Go to the end for the stack trace.

Otherwise I'll just disable for now.  Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8922,"Started today as far as I can tell.  Doesn't always happen.  Looking at it, we are splitting region not where we are supposed to -- at the 1/4 mark rather than 1/2 mark which then throws off all calculations.  Let me commit some debug to help elicit where we are going wrong.  Here is a sample:

https://builds.apache.org/job/PreCommit-HBASE-Build/6294//testReport/org.apache.hadoop.hbase.client/TestAdmin/testForceSplitMultiFamily/",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7896,"The rename_table function is very useful for our customers. However, rename_table.rb does not work for 92/94. It has several bugs. It will be useful to fix them so that users can solve their problems. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14707,"See this in branch-1 tip:

{code}
2015-10-27 08:01:08,954 INFO  [main-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/e1101.halxg.cloudera.com,16020,1445958006576 znode expired, triggering replicatorRemoved event
2015-10-27 08:01:20,645 ERROR [685943200@qtp-893835279-134] util.JSONBean: getting attribute Value of ""org.apache.hadoop.hbase.client"":type=""MetricsConnection"",scope=""hconnection-0x33abd9d3"",name=""executorPoolActiveThreads"" threw an exception
javax.management.RuntimeMBeanException: java.lang.NullPointerException
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:839)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:852)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:651)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)
        at org.apache.hadoop.hbase.util.JSONBean.writeAttribute(JSONBean.java:235)
        at org.apache.hadoop.hbase.util.JSONBean.write(JSONBean.java:209)
        at org.apache.hadoop.hbase.util.JSONBean.access$000(JSONBean.java:53)
        at org.apache.hadoop.hbase.util.JSONBean$1.write(JSONBean.java:96)
        at org.apache.hadoop.hbase.http.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:202)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:113)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.ClickjackingPreventionFilter.doFilter(ClickjackingPreventionFilter.java:48)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1354)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:49)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:49)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Caused by: java.lang.NullPointerException
{code}

TSDB is trying to get metrics on a period",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21193,"This makes it hard to change retry count on a read of meta for instance.

I noticed this when trying to change the defaults for a meta read. I made a customer Connection inside in the master with a new Configuration that had rpc retries and timings upped radically. My reads nonetheless were finishing at the usual retry point (31 tries after 60 seconds or so) because it looked like the Retrying Callable that does the read was taking  max retries from defaults rather than reading the passed in Configuration.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18910,HBASE-18900 will backport HBASE-17290 to branch-1.3.But  HBASE-17290 is dependent on HBASE-17292.so this issue will backport HBASE-17292 to branch-1.3.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14163,It would appear that there is an infinite loop in the zk client connection code when performing a master stop when no external zk servers are configured.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21109,"HBASE won't start and gives a Java error when I try in Java 9 but seems to start in Java 8

The error is:

~/Downloads/hbase-2.1.0$ export JAVA_HOME=/usr
~/Downloads/hbase-2.1.0$ bin/start-hbase.sh script
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
 at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
 at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/JarFile.java:1017)
 at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.java:399)
 at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
 at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:480)
 at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIndex.java:114)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:640)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:632)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.URLClassPath$JarLoader.ensureOpen(java.base@9-internal/URLClassPath.java:631)
 at jdk.internal.loader.URLClassPath$JarLoader.<init>(java.base@9-internal/URLClassPath.java:606)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassPath.java:386)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassPath.java:376)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLClassPath.java:375)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLClassPath.java:352)
 at jdk.internal.loader.URLClassPath.getResource(java.base@9-internal/URLClassPath.java:218)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/BuiltinClassLoader.java:463)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/BuiltinClassLoader.java:460)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(java.base@9-internal/BuiltinClassLoader.java:459)
 at jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(java.base@9-internal/BuiltinClassLoader.java:406)
 at jdk.internal.loader.BuiltinClassLoader.loadClass(java.base@9-internal/BuiltinClassLoader.java:364)
 at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(java.base@9-internal/ClassLoaders.java:184)
 at java.lang.ClassLoader.loadClass(java.base@9-internal/ClassLoader.java:419)
 at sun.launcher.LauncherHelper.loadMainClass(java.base@9-internal/LauncherHelper.java:585)
 at sun.launcher.LauncherHelper.checkAndLoadMain(java.base@9-internal/LauncherHelper.java:497)
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
 at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
 at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/JarFile.java:1017)
 at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.java:399)
 at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
 at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:480)
 at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIndex.java:114)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:640)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:632)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.URLClassPath$JarLoader.ensureOpen(java.base@9-internal/URLClassPath.java:631)
 at jdk.internal.loader.URLClassPath$JarLoader.<init>(java.base@9-internal/URLClassPath.java:606)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassPath.java:386)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassPath.java:376)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLClassPath.java:375)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLClassPath.java:352)
 at jdk.internal.loader.URLClassPath.getResource(java.base@9-internal/URLClassPath.java:218)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/BuiltinClassLoader.java:463)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/BuiltinClassLoader.java:460)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Native Method)
 at jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(java.base@9-internal/BuiltinClassLoader.java:459)
 at jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(java.base@9-internal/BuiltinClassLoader.java:406)
 at jdk.internal.loader.BuiltinClassLoader.loadClass(java.base@9-internal/BuiltinClassLoader.java:364)
 at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(java.base@9-internal/ClassLoaders.java:184)
 at java.lang.ClassLoader.loadClass(java.base@9-internal/ClassLoader.java:419)
 at sun.launcher.LauncherHelper.loadMainClass(java.base@9-internal/LauncherHelper.java:585)
 at sun.launcher.LauncherHelper.checkAndLoadMain(java.base@9-internal/LauncherHelper.java:497)
running master, logging to /opr/Downloads/hbase-2.1.0/bin/../logs/hbase-opr-master-nagios.out
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
 at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
 at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/JarFile.java:1017)
 at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.java:399)
 at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
 at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:480)
 at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIndex.java:114)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:640)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:632)
: running regionserver, logging to /opr/Downloads/hbase-2.1.0/bin/../logs/hbase-opr-regionserver-nagios.out
: Error: A JNI error has occurred, please check your installation and try again
: Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
: at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
: at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/JarFile.java:1017)
: at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.java:399)
: at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
: at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:480)
: at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIndex.java:114)
: at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:640)
: at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal/URLClassPath.java:632)
opr@nagios:~/Downloads/hbase-2.1.0$ more /opr/Downloads/hbase-2.1.0/bin/../logs/hbase-opr-regionserver-nagios.out
Error: A JNI error has occurred, please check your installation and try again
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 64
 at java.util.jar.JarFile.match(java.base@9-internal/JarFile.java:983)
 at java.util.jar.JarFile.checkForSpecialAttributes(java.base@9-internal/
JarFile.java:1017)
 at java.util.jar.JarFile.isMultiRelease(java.base@9-internal/JarFile.jav
a:399)
 at java.util.jar.JarFile.getEntry(java.base@9-internal/JarFile.java:524)
 at java.util.jar.JarFile.getJarEntry(java.base@9-internal/JarFile.java:4
80)
 at jdk.internal.util.jar.JarIndex.getJarIndex(java.base@9-internal/JarIn
dex.java:114)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal
/URLClassPath.java:640)
 at jdk.internal.loader.URLClassPath$JarLoader$1.run(java.base@9-internal
/URLClassPath.java:632)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Nati
ve Method)
 at jdk.internal.loader.URLClassPath$JarLoader.ensureOpen(java.base@9-int
ernal/URLClassPath.java:631)
 at jdk.internal.loader.URLClassPath$JarLoader.<init>(java.base@9-interna
l/URLClassPath.java:606)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassP
ath.java:386)
 at jdk.internal.loader.URLClassPath$3.run(java.base@9-internal/URLClassP
ath.java:376)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Nati
ve Method)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLCl
assPath.java:375)
 at jdk.internal.loader.URLClassPath.getLoader(java.base@9-internal/URLCl
assPath.java:352)
 at jdk.internal.loader.URLClassPath.getResource(java.base@9-internal/URL
ClassPath.java:218)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/Bui
ltinClassLoader.java:463)
 at jdk.internal.loader.BuiltinClassLoader$3.run(java.base@9-internal/Bui
ltinClassLoader.java:460)
 at java.security.AccessController.doPrivileged(java.base@9-internal/Nati
ve Method)
 at jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(jav
a.base@9-internal/BuiltinClassLoader.java:459)
 at jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(java.base@9-in
ternal/BuiltinClassLoader.java:406)
 at jdk.internal.loader.BuiltinClassLoader.loadClass(java.base@9-internal
/BuiltinClassLoader.java:364)
 at jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(java.base@9
-internal/ClassLoaders.java:184)
 at java.lang.ClassLoader.loadClass(java.base@9-internal/ClassLoader.java
:419)
 at sun.launcher.LauncherHelper.loadMainClass(java.base@9-internal/Launch
erHelper.java:585)
 at sun.launcher.LauncherHelper.checkAndLoadMain(java.base@9-internal/Lau
ncherHelper.java:497)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16374,"While testing the 0.98.21 RC found these failures
{code}
IntegrationTestIngestWithACL
IntegrationTestMTTR.testKillRsHoldingMeta
IntegrationTestMTTR.testRestartRsHoldingTable
{code}
The first one was a failure and the last 2 are errors.
{code}
java.util.concurrent.ExecutionException: java.io.IOException: did timeout 60000ms waiting for region server to start: stobdtserver5
        at java.util.concurrent.FutureTask.report(FutureTask.java:122)
        at java.util.concurrent.FutureTask.get(FutureTask.java:192)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.run(IntegrationTestMTTR.java:317)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.testKillRsHoldingMeta(IntegrationTestMTTR.java:276)
Caused by: java.io.IOException: did timeout 60000ms waiting for region server to start: stobdtserver5
        at org.apache.hadoop.hbase.HBaseCluster.waitForRegionServerToStart(HBaseCluster.java:173)
        at org.apache.hadoop.hbase.chaos.actions.Action.startRs(Action.java:142)
        at org.apache.hadoop.hbase.chaos.actions.RestartActionBaseAction.restartRs(RestartActionBaseAction.java:52)
        at org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingMetaAction.perform(RestartRsHoldingMetaAction.java:38)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR$ActionCallable.call(IntegrationTestMTTR.java:585)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR$ActionCallable.call(IntegrationTestMTTR.java:576)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

testRestartRsHoldingTable(org.apache.hadoop.hbase.mttr.IntegrationTestMTTR)  Time elapsed: 120.533 sec  <<< ERROR!
java.util.concurrent.ExecutionException: java.io.IOException: did timeout 60000ms waiting for region server to start: stobdtserver5
        at java.util.concurrent.FutureTask.report(FutureTask.java:122)
        at java.util.concurrent.FutureTask.get(FutureTask.java:192)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.run(IntegrationTestMTTR.java:317)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR.testRestartRsHoldingTable(IntegrationTestMTTR.java:271)
Caused by: java.io.IOException: did timeout 60000ms waiting for region server to start: stobdtserver5
        at org.apache.hadoop.hbase.HBaseCluster.waitForRegionServerToStart(HBaseCluster.java:173)
        at org.apache.hadoop.hbase.chaos.actions.Action.startRs(Action.java:142)
        at org.apache.hadoop.hbase.chaos.actions.RestartActionBaseAction.restartRs(RestartActionBaseAction.java:52)
        at org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingTableAction.perform(RestartRsHoldingTableAction.java:56)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR$ActionCallable.call(IntegrationTestMTTR.java:585)
        at org.apache.hadoop.hbase.mttr.IntegrationTestMTTR$ActionCallable.call(IntegrationTestMTTR.java:576)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18353,"HBASE-14614 disabled TestCorruptedRegionStoreFile, as it depends on a half-implemented reopen of a region when a store file goes missing.

This JIRA tracks the work to fix/enable the test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20872,"running
{code:java}
mvn clean test{code}
on hbase-spark fails with
{code:java}
Cause: java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMasterUncompilable source code - package org.apache.hbase.thirdparty.io.netty.channel does not exist
at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:136)
at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:212)
at org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:159)
at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:250)
at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:121)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:1042)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:988)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:859)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:853)
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:782)
...
Cause: java.lang.ExceptionInInitializerError:
at org.apache.hadoop.hbase.regionserver.HRegionServer.setupNetty(HRegionServer.java:688)
at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:547)
at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:486)
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:131)
at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:212)
at org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:159)
...
Cause: java.lang.RuntimeException: Uncompilable source code - package org.apache.hbase.thirdparty.io.netty.channel does not exist
at org.apache.hadoop.hbase.util.NettyEventLoopGroupConfig.<clinit>(NettyEventLoopGroupConfig.java:20)
at org.apache.hadoop.hbase.regionserver.HRegionServer.setupNetty(HRegionServer.java:688)
at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:547)
at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:486)
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:131)
at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:212){code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19169,"I got the following error running rowcounter against hadoop3 beta1 based on commit a9f0c5d4e2c85c1faae1b4b277e3c290c8b81d2a :
{code}
2017-11-03 17:10:59,583 INFO  [main] mapreduce.Job: Task Id : attempt_1509641483571_0006_m_000029_1, Status : FAILED
Error: java.lang.ArrayIndexOutOfBoundsException: 2
	at org.apache.hadoop.hbase.mapreduce.TableSplit$Version.fromCode(TableSplit.java:77)
	at org.apache.hadoop.hbase.mapreduce.TableSplit.readFields(TableSplit.java:285)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:71)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:372)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:760)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18296,"Saw this in logs while debugging other failing tests:

{noformat}
2017-06-29 13:54:15,995 ERROR [M:0;172.18.16.40:55484] server.NIOServerCnxnFactory$1(44): Thread Thread[M:0;172.18.16.40:55484,5,FailOnTimeoutGroup] died
java.lang.NullPointerException
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.removeChore(ProcedureExecutor.java:656)
	at org.apache.hadoop.hbase.master.assignment.AssignmentManager.stop(AssignmentManager.java:233)
	at org.apache.hadoop.hbase.master.HMaster.stopServiceThreads(HMaster.java:1154)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1189)
	at java.lang.Thread.run(Thread.java:748)
{noformat}

I think it was related to an initialization failure, but we should code more defensively anyway",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17996,"Impala includes HBase in its local test environment, and we have found that intermittently, the HBase master node fails to start when we are testing on RHEL7.

In these failures, what we typically see in the logs is this:
{noformat}
17/04/29 21:33:47 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x15bbd21b797000a, negotiated timeout = 90000
17/04/29 21:33:47 INFO client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
17/04/29 21:33:48 INFO master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/localhost,16000,1493526758211 from backup master directory
{noformat}

On a successful startup, the log looks like this:
{noformat}
17/04/16 21:32:29 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x15b7a2ed6860005, negotiated timeout = 90000
17/04/16 21:32:29 INFO client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
17/04/16 21:32:30 INFO util.FSUtils: Created version file at hdfs://localhost:20500/hbase with version=8
17/04/16 21:32:31 INFO master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
{noformat}

So the event that we don't see in the failed start up attempts is {{master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region}}.

The full logs will be attached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19076,"After HBASE-16321 ensure findbugs jsr305 jar isn't present, we have failures with the hbase-error-prone module.

{code}
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (min-maven-min-java-banned-xerces) @ hbase-error-prone ---
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M1:enforce (banned-jsr305) @ hbase-error-prone ---
[WARNING] Rule 0: org.apache.maven.plugins.enforcer.BannedDependencies failed with message:
We don't allow the JSR305 jar from the Findbugs project, see HBASE-16321.
Found Banned Dependency: com.google.code.findbugs:jsr305:jar:1.3.9
Use 'mvn dependency:tree' to locate the source of the banned dependencies.
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18345,"Incorrect mocking, easy fix

Tests run: 7, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 67.898 sec <<< FAILURE! - in org.apache.hadoop.hbase.tool.TestCanaryTool
testReadTableTimeouts(org.apache.hadoop.hbase.tool.TestCanaryTool)  Time elapsed: 11.727 sec  <<< FAILURE!
org.mockito.exceptions.verification.junit.ArgumentsAreDifferent: 
Argument(s) are different! Wanted:
mockAppender.doAppend(
    <custom argument matcher>
);
-> at org.apache.hadoop.hbase.tool.TestCanaryTool.testReadTableTimeouts(TestCanaryTool.java:150)
Actual invocation has different arguments:
mockAppender.doAppend(
    org.apache.log4j.spi.LoggingEvent@7ed49a7f
);
-> at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.hbase.tool.TestCanaryTool.testReadTableTimeouts(TestCanaryTool.java:150)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19971,"From https://builds.apache.org/job/HBASE-Flaky-Tests/25784/testReport/junit/org.apache.hadoop.hbase.regionserver/TestMajorCompaction/testDataBlockEncodingInCacheOnly_2_/ :
{code}
java.io.IOException: java.lang.IllegalArgumentException: In CellChunkMap, cell must be associated with chunk.. We were looking for a cell at index 0
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.majorCompaction(TestMajorCompaction.java:206)
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.majorCompactionWithDataBlockEncoding(TestMajorCompaction.java:186)
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.testDataBlockEncodingInCacheOnly(TestMajorCompaction.java:166)
Caused by: java.lang.IllegalArgumentException: In CellChunkMap, cell must be associated with chunk.. We were looking for a cell at index 0
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.majorCompaction(TestMajorCompaction.java:206)
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.majorCompactionWithDataBlockEncoding(TestMajorCompaction.java:186)
	at org.apache.hadoop.hbase.regionserver.TestMajorCompaction.testDataBlockEncodingInCacheOnly(TestMajorCompaction.java:166)
{code}
From the index of the test, EAGER policy was used.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18900,"HBASE-17290 fixes data loss bug.

Bulk loaded hfile replication support is in branch-1.3

This issue is to backport HBASE-17290 to branch-1.3",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19347,"In the download hbase-1.1.12-src.tar.gz the directory hbase-native-client is missing. 


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19824,"There are two cells in table t1:
{code}
ROW                                                         COLUMN+CELL
 r1                                                         column=f1:a1, timestamp=1516313683984, value=a2
 r1                                                         column=f1:b1, timestamp=1516313700744, value=b2
{code}
When SingleColumnValueFilter is used in shell command, no filtering was done:
{code}
hbase(main):022:0> scan 't1', {FILTER => ""SingleColumnValueFilter('f1', 'a1', =, 'binary:a2')""}
ROW                                                         COLUMN+CELL
 r1                                                         column=f1:a1, timestamp=1516313683984, value=a2
 r1                                                         column=f1:b1, timestamp=1516313700744, value=b2
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18712,"Add -X in dev-support/hbase-personality.sh for precommit unit tests so that we have more information when ""The forked VM terminated without saying properly goodbye"" happens again.

The following (initial proposal) doesn't apply to jdk 1.8 and has limited benefit:

Currently hbase-surefire.argLine doesn't specify MaxPermSize for the test run(s).

This sometimes resulted in mvn build prematurely exiting, leaving some large tests behind.
The tests would be deemed timed out.

As indicated by the following post:

https://stackoverflow.com/questions/23260057/the-forked-vm-terminated-without-saying-properly-goodbye-vm-crash-or-system-exi

We should specify large enough MaxPermSize so that mvn build doesn't end prematurely.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20005,"By adding message for the assertions, the test failed at:
{code}
     ok = table.checkAndMutate(ROW, FAMILY).qualifier(QUALIFIER)
         .ifMatches(CompareOperator.GREATER, value4).thenDelete(delete);
-    assertTrue(ok);
+    assertTrue(""gr"", ok);
{code}
I ran the test with MemoryCompactionPolicy.NONE but it still failed at the same place.

Both branch-2 and master have this intermittent test failure.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20137,"It was the single test that failed the hbase-2 nightlies in #440 at the hadoop2 stage.

The failure manifests as a timeout. It actually has an interesting cause calling into question some of the clauses in UnassignProcedure#remoteCallFailed.

We are running a disabletable concurrent with a shutdown. pid=309 is the disable. pid=311 is the interesting one. The below is a little hard to read -- the exception 'message' is the the current procedure as a String... hard to parse, fixing -- but we are trying to unassign as part of a the disabletable. Our RPC fails because the server we are trying to rpc too is currently being processed as crashed (pid=308 is a servercrashprocedure for this server). As part of the processing of the failed RPC we will expire the server -- if we can't RPC to it, it must be gone. The current procedure is then suspended until it gets woken up by the servercrashprocedure triggered by the expire.... only in this case we are shutting down so the expire is ignored... The current procedure is left in its suspend state. This prevents the Master going down. So we time out.

2018-03-05 11:29:22,507 INFO  [PEWorker-13] assignment.RegionTransitionProcedure(213): Dispatch pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524; rit=CLOSING, location=1cfd208ff882,40584,1520249102524
2018-03-05 11:29:22,508 WARN  [PEWorker-13] assignment.RegionTransitionProcedure(187): Remote call failed pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524; rit=CLOSING, location=1cfd208ff882,40584,1520249102524; exception=pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524 to 1cfd208ff882,40584,1520249102524
2018-03-05 11:29:22,508 WARN  [PEWorker-13] assignment.UnassignProcedure(276): Expiring server pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524; rit=CLOSING, location=1cfd208ff882,40584,1520249102524, exception=org.apache.hadoop.hbase.master.assignment.FailedRemoteDispatchException: pid=311, ppid=309, state=RUNNABLE:REGION_TRANSITION_DISPATCH; UnassignProcedure table=Group_ns:testKillRS, region=de7534c208a06502537cd95c248b3043, server=1cfd208ff882,40584,1520249102524 to 1cfd208ff882,40584,1520249102524
2018-03-05 11:29:22,508 WARN  [PEWorker-13] master.ServerManager(580): Expiration of 1cfd208ff882,40584,1520249102524 but server shutdown already in progress

I need to cater for case where the expire server is rejected.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19733,"Currently build is failing (https://builds.apache.org/job/HBase-TRUNK_matrix/4363/jdk=JDK%201.8%20(latest),label=(Hadoop%20&&%20!H5)/console) due to:
{code}
[ERROR] src/main/java/org/apache/hadoop/hbase/thrift/TBoundedThreadPoolServer.java:[291,78] (blocks) EmptyBlock: Must have at least one statement.
...
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:2.17:check (checkstyle) on project hbase-thrift: You have 1 Checkstyle violation. -> [Help 1]
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13405,"Once in a while I'm seeing the following, running #testContainedRegionOverlap test in IDE after clean install (mac osx, hbase master):

{code}
regionserver.HRegionServer(1863): Post open deploy tasks for tableContainedRegionOverlap,A,1428099123733.03a139b02119e99ef08149addd9a7996.
2015-04-03 15:12:11,695 INFO  [PostOpenDeployTasks:03a139b02119e99ef08149addd9a7996] regionserver.HRegionServer(1956): Failed to report region transition, will retry
java.io.InterruptedIOException: Origin: InterruptedException
	at org.apache.hadoop.hbase.util.ExceptionUtil.asInterrupt(ExceptionUtil.java:65)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:313)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(HRegionServer.java:1955)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1882)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:241)
Caused by: java.lang.InterruptedException: callId: 158 methodName: ReportRegionStateTransition param {TODO: class org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$ReportRegionStateTransitionRequest}
	at io.netty.util.concurrent.DefaultPromise.await0(DefaultPromise.java:333)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:266)
	at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:42)
	at org.apache.hadoop.hbase.ipc.AsyncRpcClient.call(AsyncRpcClient.java:226)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.reportRegionStateTransition(RegionServerStatusProtos.java:9030)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(HRegionServer.java:1946)
	... 2 more
2015-04-03 15:12:11,696 INFO  [B.defaultRpcServer.handler=1,queue=0,port=51217] master.MasterRpcServices(237): Client=mantonov//10.1.4.219 set balanceSwitch=false
2015-04-03 15:12:11,696 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(388): maste
{code}

and then: 
{code}
015-04-03 15:12:11,796 INFO  [Thread-3019] client.HBaseAdmin$10(981): Started disable of tableContainedRegionOverlap
2015-04-03 15:12:21,641 INFO  [B.defaultRpcServer.handler=1,queue=0,port=51217] master.HMaster(1645): Client=mantonov//10.1.4.219 disable tableContainedRegionOverlap

java.lang.AssertionError: 
Expected :[]
Actual   :[NOT_DEPLOYED, HOLE_IN_REGION_CHAIN]
 <Click to see difference>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.assertNoErrors(HbckTestingUtil.java:92)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testContainedRegionOverlap(TestHBaseFsck.java:941)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13862,"I can reproduce it by running mvn test -Dtest=TestRegionRebalancing on fresh master about 1 out of 3-4 runs.

{code}
unning org.apache.hadoop.hbase.TestRegionRebalancing
2015-06-08 12:00:52.125 java[45610:5873722] Unable to load realm info from SCDynamicStore
Tests run: 2, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 26.743 sec <<< FAILURE! - in org.apache.hadoop.hbase.TestRegionRebalancing
testRebalanceOnRegionServerNumberChange[0](org.apache.hadoop.hbase.TestRegionRebalancing)  Time elapsed: 15.599 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.apache.hadoop.hbase.TestRegionRebalancing.testRebalanceOnRegionServerNumberChange(TestRegionRebalancing.java:144)

testRebalanceOnRegionServerNumberChange[1](org.apache.hadoop.hbase.TestRegionRebalancing)  Time elapsed: 10.671 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.apache.hadoop.hbase.TestRegionRebalancing.testRebalanceOnRegionServerNumberChange(TestRegionRebalancing.java:144)


Results :

Failed tests:
  TestRegionRebalancing.testRebalanceOnRegionServerNumberChange:144 null
  TestRegionRebalancing.testRebalanceOnRegionServerNumberChange:144 null

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14335,"TestAssignmentManagerOnCluster#testSSHWhenDisablingTableRegionsInOpeningOrPendingOpenState is occasionally timing out when cleaning up after a test. Depends on environment. Given the right timing we get a timeout. One one test host, fails with 7u79. On another, passes with 7u79, fails with 8u45.

{noformat}
Running org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster
Tests run: 17, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 85.924 sec <<< 
FAILURE! - in org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster
testSSHWhenDisablingTableRegionsInOpeningOrPendingOpenState(org.apache.hadoop.hb
ase.master.TestAssignmentManagerOnCluster)  Time elapsed: 60.036 sec  <<< ERROR!
java.lang.Exception: test timed out after 60000 milliseconds
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hbase.client.HBaseAdmin.deleteTable(HBaseAdmin.java
:724)
        at org.apache.hadoop.hbase.HBaseTestingUtility.deleteTable(HBaseTestingU
tility.java:1581)
        at org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.testSSH
WhenDisablingTableRegionsInOpeningOrPendingOpenState(TestAssignmentManagerOnClus
ter.java:676)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13887,"The build instructions in the online manual do not describe the extra steps we need to take to build 0.98. Add a section on this.

A quick enumeration of the differences:

1. Source assemblies will be missing the hbase-hadoop1-compat module. This should be fixed in the POM somehow. What I do now is untar the src tarball, cp -a the module over, then tar up the result. (It's a hack in a release script.)

2. We must munge POMs for building hadoop1 and hadoop2 variants and then execute two builds pointing Maven at each munged POM. The generate-hadoop-X-poms script requires bash
{noformat}
$ bash dev-support/generate-hadoopX-poms.sh $version $version-hadoop1
$ bash dev-support/generate-hadoopX-poms.sh $version $version-hadoop2
{noformat}
Build Hadoop 1
{noformat}
  $ mvn -f pom.xml.hadoop1 clean install -DskipTests -Prelease && \
      mvn -f pom.xml.hadoop1 install -DskipTests site assembly:single \
        -Prelease && \
      mvn -f pom.xml.hadoop1 deploy -DskipTests -Papache-release
  $ cp hbase-assembly/target/hbase*-bin.tar.gz $release_dir
{noformat}
Build Hadoop 2
{noformat}
  $ mvn -f pom.xml.hadoop2 clean install -DskipTests -Prelease && \
      mvn -f pom.xml.hadoop2 install -DskipTests site assembly:single \
        -Prelease && \
      mvn -f pom.xml.hadoop2 deploy -DskipTests -Papache-release
  $ cp hbase-assembly/target/hbase*-bin.tar.gz $release_dir
{noformat}

3. Current HEAD of 0.98 branch enforces a requirement that the release be built with a JDK no more recent than the compile language level. For 0.98, that is 1.6, therefore the ancient 6u45 JDK. This JDK suffers from [JDK-6521495|http://bugs.java.com/bugdatabase/view_bug.do?bug_id=6521495] so the following workaround is required in order to deploy artifacts to Apache's Nexus:
3.a. Download https://www.bouncycastle.org/download/bcprov-jdk15on-152.jar and https://www.bouncycastle.org/download/bcprov-ext-jdk15on-152.jar into $JAVA_HOME/lib/ext.
3.b. Edit $JAVA_HOME/lib/security/java.security and add the BouncyCastle provider as the first provider: 
{noformat}
security.provider.1=org.bouncycastle.jce.provider.BouncyCastleProvider
{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16795,"I did a naive update of docs on branch-1.1 from master like so:
{noformat}
$ git co master src
...
{noformat}
and the result failed a RAT check. Looking at rat.txt I noticed we are including binaries in our source tarball, checked in as part of HBASE-14785. 
{noformat}
HBASE-14785 Addendum: Add an in-project Maven repo

 src/main/site/resources/css/site.css                             |   1 -
 .../maven-fluido-skin/1.5-HBASE/maven-fluido-skin-1.5-HBASE.jar  | Bin 0 -> 344936 bytes
 .../maven-fluido-skin/1.5-HBASE/maven-fluido-skin-1.5-HBASE.pom  | 718 ++++++++++++++++++++++++++++
 .../maven/skins/maven-fluido-skin/maven-metadata-local.xml       |  12 +
 4 files changed, 730 insertions(+), 1 deletion(-)
{noformat}
I'm not sure why RAT flagged this in that 1.1 build when I see that previously we have copied back docs from master into the branch. Perhaps previous copies have been more selective. 

This change has been committed for over a year. Let's make sure we have discussed this and determined it is appropriate. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14341,"if you build a source assembly according to the book:

{quote}
mvn clean install -DskipTests assembly:single -Dassembly.file=hbase-assembly/src/main/assembly/src.xml -Prelease
{quote}

Then the resultant artifact has an extra set of the shaded modules at the top level (in addition to the ones in the hbase-shaded module)

{code}
$ ls -lah hbase-1.1.2/
total 608
drwxr-xr-x  32 busbey  staff   1.1K Aug 30 17:14 .
drwxr-xr-x   3 busbey  staff   102B Aug 30 17:14 ..
-rw-r--r--   1 busbey  staff   162K Aug 30 16:42 CHANGES.txt
-rw-r--r--   1 busbey  staff    36K Aug 30 16:15 LICENSE.txt
-rw-r--r--   1 busbey  staff   1.5K Aug 30 16:15 NOTICE.txt
-rw-r--r--   1 busbey  staff   1.4K Aug 30 16:15 README.txt
drwxr-xr-x  31 busbey  staff   1.0K Aug 30 16:42 bin
drwxr-xr-x   9 busbey  staff   306B Aug 30 16:42 conf
drwxr-xr-x  24 busbey  staff   816B Aug 30 16:42 dev-support
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-annotations
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:58 hbase-assembly
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-checkstyle
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-client
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-common
drwxr-xr-x   5 busbey  staff   170B Aug 30 16:58 hbase-examples
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-hadoop-compat
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-hadoop2-compat
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:58 hbase-it
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-prefix-tree
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-procedure
drwxr-xr-x   5 busbey  staff   170B Aug 30 16:56 hbase-protocol
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:56 hbase-resource-bundle
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-rest
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-server
drwxr-xr-x   5 busbey  staff   170B Aug 30 16:42 hbase-shaded
drwxr-xr-x   3 busbey  staff   102B Aug 30 16:42 hbase-shaded-client
drwxr-xr-x   3 busbey  staff   102B Aug 30 16:42 hbase-shaded-server
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:58 hbase-shell
drwxr-xr-x   3 busbey  staff   102B Aug 30 16:57 hbase-testing-util
drwxr-xr-x   4 busbey  staff   136B Aug 30 16:57 hbase-thrift
-rw-r--r--   1 busbey  staff    94K Aug 30 16:42 pom.xml
drwxr-xr-x   3 busbey  staff   102B Aug 30 16:15 src
$ diff -r hbase-1.1.2/hbase-shaded-client hbase-1.1.2/hbase-shaded/hbase-shaded-client
Only in hbase-1.1.2/hbase-shaded/hbase-shaded-client: target
$ diff -r hbase-1.1.2/hbase-shaded-server hbase-1.1.2/hbase-shaded/hbase-shaded-server
Only in hbase-1.1.2/hbase-shaded/hbase-shaded-server: target
{code}

they're the same as the correct ones and they don't build by default since the top level pom doesn't mention them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16929,"HBASE-16626 added default method of shipped() to RegionScanner.

However, when building master branch of Phoenix against 2.0 SNAPSHOT, I got:
{code}
[ERROR] /a/phoenix/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/DelegateRegionScanner.java:[27,8] org.apache.phoenix.coprocessor.DelegateRegionScanner is not abstract and does not override  abstract method shipped() in org.apache.hadoop.hbase.regionserver.Shipper
[ERROR] /a/phoenix/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/BaseScannerRegionObserver.java:[344,36] <anonymous org.apache.phoenix.coprocessor.BaseScannerRegionObserver$1> is not         abstract and does not override abstract method shipped() in org.apache.hadoop.hbase.regionserver.Shipper
{code}
Here is the snippet for DelegateRegionScanner:
{code}
public class DelegateRegionScanner implements RegionScanner {
{code}
It seems adding default method in RegionScanner is not enough for downstream projects.

After moving the default method to Shipper interface, the above two compilation errors are gone in Phoenix.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14750,"While writing an application that uses HBase I ran into the problem that although I have setup the hbase-site.xml in the {{HBASE_CONF_DIR}}; the settings in this file are not picked up in my application.

In several places I find instructions to include things like the {{hbase.zookeeper.quorum}} in a properties file and the explicitly set these value from within the application (I have actually done this in the past quite a few times).

Although this works I expect the system to automatically pickup the settings I have installed already which are picked up by tools like the hbase shell and pig.

So I ended up writing this helper method:
{code:java}
    public static Configuration createConfiguration() {
        String hbaseConfDir = System.getenv(""HBASE_CONF_DIR"");
        if (hbaseConfDir == null) {
            hbaseConfDir = ""/etc/hbase/conf"";
        }

        Configuration conf = HBaseConfiguration.create();
        conf.addResource(new Path(hbaseConfDir + ""/hbase-site.xml""));
        return conf;
    }
{code}

I expect HBaseConfiguration.create() to give me a working config in an environment where everything for all the other HBase clients has already been setup correctly.

My proposal is to change the HBaseConfiguration.create() to effectively include what my helper method does.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9022,https://builds.apache.org/job/PreCommit-HBASE-Build/6428//testReport/org.apache.hadoop.hbase.regionserver.wal/TestHLogSplit/testIOEOnOutputThread/,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4030,"-- We've been seeing intermittent failures of calls to LoadIncrementalHFiles.  When this happens the node that made the call will see a FileNotFoundException such as this:

2011-06-23 15:47:34.379566500 java.net.SocketTimeoutException: Call to s8.XXX/67.2",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17117,"We started seeing clients persistently throwing errors as they were trying to talk to a region that was non existent (split a few days ago). We verified that the region was deleted from meta when the split happened.

On performing a raw scan on meta, the deleted version for the split region appears, which also does on performing a normal reversed scan. Since MetaScanner uses a reversed scan, this explains why clients see non existent regions.

We also verified that there was no in-memory corrupt state by failing over the master. When we trigger major compaction on meta, the problem goes away further confirming the fact that we were seeing deleted versions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15406,"This was what I did on cluster with 1.4.0-SNAPSHOT built Thursday:

Run 'hbase hbck -disableSplitAndMerge' on gateway node of the cluster
Terminate hbck early
Enter hbase shell where I observed:
{code}
hbase(main):001:0> splitormerge_enabled 'SPLIT'
false
0 row(s) in 0.3280 seconds

hbase(main):002:0> splitormerge_enabled 'MERGE'
false
0 row(s) in 0.0070 seconds
{code}
Expectation is that the split / merge switches should be restored to default value after hbck exits.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16079,"#testLockupAroundBadAssignSync

https://builds.apache.org/view/All/job/HBase-1.3/751/jdk=latest1.8,label=yahoo-not-h2/testReport/junit/org.apache.hadoop.hbase.regionserver/TestFailedAppendAndSync/testLockupAroundBadAssignSync/

Error Message

test timed out after 300000 milliseconds
Stacktrace

org.junit.runners.model.TestTimedOutException: test timed out after 300000 milliseconds
	at org.mockito.internal.debugging.LocationImpl.toString(LocationImpl.java:29)
	at java.lang.String.valueOf(String.java:2994)
	at java.lang.StringBuilder.append(StringBuilder.java:131)
	at org.mockito.exceptions.Reporter.wantedButNotInvoked(Reporter.java:320)
	at org.mockito.internal.verification.checkers.MissingInvocationChecker.check(MissingInvocationChecker.java:42)
	at org.mockito.internal.verification.AtLeast.verify(AtLeast.java:38)
	at org.mockito.internal.verification.MockAwareVerificationMode.verify(MockAwareVerificationMode.java:21)
	at org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:72)
	at org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29)
	at org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:38)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:61)
	at org.apache.hadoop.hbase.Server$$EnhancerByMockitoWithCGLIB$$323c5f5b.abort(<generated>)
	at org.apache.hadoop.hbase.regionserver.TestFailedAppendAndSync.testLockupAroundBadAssignSync(TestFailedAppendAndSync.java:239)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17810,"I saw that some fixes HBASE-17746 were in branch-1. So, I used this branch to see if I am getting any failures.
This is the result:
Results :

Failed tests:
  TestFuzzyRowFilter.testSatisfiesForward:80 expected:<YES> but was:<NO_NEXT>
  TestFuzzyRowFilter.testSatisfiesReverse:120 expected:<YES> but was:<NEXT_EXISTS>
Tests in error:
  TestSeekToBlockWithEncoders.testSeekToBlockWithDecreasingCommonPrefix:140->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffFamilyAndQualifer:249->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffQualifer:160->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffQualiferOnSameRow:183->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffQualiferOnSameRow1:206->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithDiffQualiferOnSameRowButDescendingInSize:229->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekToBlockWithNonMatchingSeekKey:65->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekingToBlockToANotAvailableKey:117->seekToTheKey:270 禄 NoClassDefFound
  TestSeekToBlockWithEncoders.testSeekingToBlockWithBiggerNonLength1:91->seekToTheKey:270 禄 NoClassDefFound
  TestHFileEncryption.testHFileEncryption:232 禄 NoClassDefFound Could not initia...
  TestSeekTo.testSeekBeforeWithReSeekTo:199->testSeekBeforeWithReSeekToInternals:216 禄 NoClassDefFound
  TestSeekTo.testSeekBefore:145->testSeekBeforeInternals:161 禄 NoClassDefFound C...
  TestSeekTo.testSeekTo:292->testSeekToInternals:308 禄 NoClassDefFound Could not...

Tests run: 1106, Failures: 2, Errors: 13, Skipped: 22
--------------------------------------------------------------------------------------------
Results :

Failed tests:
  IntegrationTestRegionReplicaReplication.testIngest:112->runIngestTest:214 Load failed with error code 1
  IntegrationTestBulkLoad.testBulkLoad:213->runLoad:223->runLinkedListMRJob:296 expected:<true> but was:<false>
  IntegrationTestImportTsv.testGenerateAndLoad:203 expected:<0> but was:<1>
  IntegrationTestLoadAndVerify.testLoadAndVerify:544->doLoad:353 null
  IntegrationTestWithCellVisibilityLoadAndVerify>IntegrationTestLoadAndVerify.testLoadAndVerify:544->doLoad:244->IntegrationTestLoadAndVerify.doLoad:353 null
Tests in error:
  IntegrationTestIngestWithACL>IntegrationTestBase.setUp:148->setUpCluster:64->IntegrationTestIngest.setUpCluster:84 禄 IO
  IntegrationTestMTTR.testKillRsHoldingMeta:278->run:319 禄 Execution java.io.IOE...
  IntegrationTestMTTR.testRestartRsHoldingTable:273->run:319 禄 Execution java.io...
  IntegrationTestBigLinkedList.testContinuousIngest:1798 禄 Runtime Generator fai...
  IntegrationTestBigLinkedListWithVisibility.testContinuousIngest:637 禄 Runtime ...
  IntegrationTestReplication>IntegrationTestBigLinkedList.testContinuousIngest:1798 禄 Runtime

Tests run: 32, Failures: 5, Errors: 6, Skipped: 2

Any idea what could be the reason for above failures?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17375,"Recently, we find our hbase compaction thread never end.  Assume we have following cells:
{quote}
<A,a> 1
<A,v> 1
<Aaeeee,a> 1
<Aaeeee,v> 1
<Abc,a> 1
<Abc,v> 1
<Abde,a> 1
<Abde,v> 1
{quote}

If we encode above datas into prefix tree block, then it looks like:
!row trie example.PNG!

Assume the current row is {color:red}Abc{color} (e.g. the current row node is 4), then the previous row should be *Aaeeee* (e.g. 2). However previousRowInternal return {color:red}A{color}(e.g. 1)

After investigation, I believe it's the bug of PrefixTreeArrayReversibleScanner#previousRowInternal.

{code}
  private boolean previousRowInternal() {
    //...
    while (!beforeFirst) {
      //....
      // what if currentRowNode is nub?
      if (currentRowNode.hasOccurrences()) {// escape clause
        currentRowNode.resetFanIndex();
        return true;// found some values
      }
    }
{code}

currentRowNode.hasOccurrences() only test whether it has cell or not. But in the case of  currentRowNode.isNub() is true, previousRowInternal should follow the previous fan instead of return.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16487,"HBASE-15152 included the prefix tree module as dependency to TableMapReduceUtil. but the hardcoded string of the class name was wrong. HBASE-16360 fixed the hardcoded string. 

but, I was looking at the comment above and I can't figure out where is the circular dependency.
{code}
// PrefixTreeCodec is part of the hbase-prefix-tree module. If not included in MR jobs jar
// dependencies, MR jobs that write encoded hfiles will fail.
// We used reflection here so to prevent a circular module dependency.
// TODO - if we extract the MR into a module, make it depend on hbase-prefix-tree
{code}
from the pom.xml of the prefix-tree module I don't see hbase-server. but I can see prefix-tree module in the hbase-server/pom.xml. the TableMapReduceUtil is in hbase-server.. so in theory we don't have any circular dependency.
we can just probably drop all that try/catch block with the Class.forName() and just simply use org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeCodec as we do for the others. 

(or at least we should end up with a test to cover the that Class.fromName() in case we rename the PrefixTreeCodec or the namespace in the future and forget to update this reference)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16885,"I tried to compile master branch of Phoenix against 2.0-SNAPSHOT and observed some compilation errors.

/phoenix/phoenix-core/src/main/java/org/apache/hadoop/hbase/regionserver/LocalIndexStoreFileScanner.java:[31,54] cannot find symbol
  symbol:   class Reader
  location: class org.apache.hadoop.hbase.regionserver.StoreFile

/phoenix/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/MultiHfileOutputFormat.java:[300,16] cannot find symbol
  symbol:   class Writer
  location: class org.apache.hadoop.hbase.regionserver.StoreFile

The above inner classes of StoreFile are marked public as of branch-1.

We should deprecate them in 1.x release.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3706,"HDFS is kinda dumb regards rereplication in that if it notices missing replicas, its crass in the way it goes about making redress; there is no facility for limiting the rate of rereplication (HDFS-1195).  We've seen the case where hdfs is rereplicating at such a rate after DN crash, it fills the network hampering data serving.  This issue is about noting this prob. and helping out/keeping an eye on HDFS-1195.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12818,"Starting in late December, our internal runs on branch-1 have failed every few days with the following:
{code}
java.lang.AssertionError: Archived hfiles [] is missing snapshot file:c7ed21029d4e4cb28fdd138a28c8f3e7
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testSnapshotHFileArchiving(TestSnapshotFromMaster.java:347)
{code}
A full log of the stdout from one of these runs can be found [on Gist|https://gist.github.com/dimaspivak/1c27a5d95e26c4bedc4f]; the relevant portion seems to be
{code}
2015-01-07 05:04:06,015 DEBUG [B.defaultRpcServer.handler=3,queue=0,port=55325] util.FSTableDescriptors(177): Exception during readTableDecriptor. Current table name = test
org.apache.hadoop.hbase.TableInfoMissingException: No table descriptor file under hdfs://localhost:42974/user/jenkins/test-data/ce542e14-a8e7-4764-8a68-8fb6401ebeb8/data/default/test
	at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorFromFs(FSTableDescriptors.java:509)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptorFromFs(FSTableDescriptors.java:487)
	at org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:172)
	at org.apache.hadoop.hbase.master.HMaster.listTableDescriptors(HMaster.java:2165)
	at org.apache.hadoop.hbase.master.MasterRpcServices.getTableDescriptors(MasterRpcServices.java:787)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:42402)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2028)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:744)
{code}

I've yet to see this on upstream runs, but I'll keep an eye out. Also, note that this is unrelated to HBASE-9072, which had the same test failing for other reasons back in 2013.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4953,"When doing a kill -9 on all HBase processes and attempting to re-start HBase, the master does not properly assign the root region. The /hbase/root-region-server znode still contains the old regionserver, but the regionserver referenced in it does not get assigned the root region. This might get resolved after the znode expires, though, but some testing is required.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6930,"When processing the multiPut, multiMutations or multiDelete operations, each IPC handler thread tries to acquire a lock for each row key in these batches. If there are duplicated row keys in these batches, previously the IPC handler thread will repeatedly acquire the same row key again and again.

So the optimization is to sort each batch operation based on the row key in the client side, and skip acquiring the same row lock repeatedly in the server side.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10643,"When RS is brought up with XX:MaxDirectMemorySize of 22GB or higher, RS fails after a successful start. From the RS logs it looks like the bucketCache memory allocation is taking more time makes the RS considered dead by ZK. One option to fix the problem would be to allocate the bucketCache before registering with ZK. 

2014-02-28 18:54:42,967 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 33496ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-02-28 18:54:42,967 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 33496ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-02-28 18:54:42,967 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 23988ms
GC pool 'ParNew' had collection(s): count=1 time=24432ms
2014-02-28 18:54:43,006 FATAL [regionserver60020] regionserver.HRegionServer: ABORTING region server bbg-master2.bbg-test.hdp,60020,1393628951236: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing bbg-master2.bbg-test.hdp,60020,1393628951236 as dead server
        at org.apache.hadoop.hbase.master.ServerManager.checkIsDead(ServerManager.java:341)
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:254)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12255,"I have a phoenix table 'EVENT', and the table have a index 'IDX_DATE_HOUR_X'.
I restarted hdfs without stop hbase, after then, the hbase table cann't be scaned.
I try to restart hbase, the all hbase table still cann't be scaned.
the regionserver log have many exception like this:

2014-10-13 19:33:05,287 INFO  [A01101303447-V1,60020,1413199890407-recovery-writer--pool4-t3] client.AsyncProcess: #4, waiting for some tasks to finish. Expected max=0, tasksSent=9, tasksDone=8, currentTasksDone=8, retries=8 hasError=fal
se, tableName=IDX_DATE_HOUR_X
2014-10-13 19:33:05,298 INFO  [A01101303447-V1,60020,1413199890407-recovery-writer--pool4-t2] client.AsyncProcess: #5, waiting for some tasks to finish. Expected max=0, tasksSent=9, tasksDone=8, currentTasksDone=8, retries=8 hasError=fal
se, tableName=IDX_DATE_HOUR_X
2014-10-13 19:33:05,311 INFO  [A01101303447-V1,60020,1413199890407-recovery-writer--pool4-t1] client.AsyncProcess: #6, waiting for some tasks to finish. Expected max=0, tasksSent=9, tasksDone=8, currentTasksDone=8, retries=8 hasError=fal
se, tableName=IDX_DATE_HOUR_X
2014-10-13 19:33:06,452 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving A01101303447-V1,60020,1413199414409's hlogs to my queue
2014-10-13 19:33:15,325 INFO  [A01101303447-V1,60020,1413199890407-recovery-writer--pool4-t1] client.AsyncProcess: #6, waiting for some tasks to finish. Expected max=0, tasksSent=10, tasksDone=9, currentTasksDone=9, retries=9 hasError=fa
lse, tableName=IDX_DATE_HOUR_X
2014-10-13 19:33:15,333 INFO  [htable-pool6-t2] client.AsyncProcess: #6, table=IDX_DATE_HOUR_X, attempt=10/350 failed 12 ops, last exception: org.apache.hadoop.hbase.exceptions.RegionOpeningException: org.apache.hadoop.hbase.exceptions.R
egionOpeningException: Region IDX_DATE_HOUR_X,t\x00\x00\x00\x00\x00,1413186874829.9a92abb84768b129df3faedb877f7bea. is opening on A01101303447-V1,60020,1413199890407
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2759)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:4213)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3437)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29593)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2027)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
        at java.lang.Thread.run(Thread.java:744)



-------------------------------
After two days's try, i found that:
If idisable 'EVENT', other tables can be scanned, then i enable 'EVENT' manually, the region log show that NullPointExceptin has occur then replaying WAL, the following is log:

2014-10-13 19:25:21,043 INFO  [RS_OPEN_REGION-A01101303447-V1:60020-1] regionserver.HRegion: Replaying edits from hdfs://localhost/hbase-0.98/data/default/EVENT/def4a581d4ad963cbb8cad32cbfbab2e/recovered.edits/0000000000000000002
2014-10-13 19:25:21,048 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t2-SendThread(localhost:2182)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2182. Will not attempt to authe
nticate using SASL (unknown error)
2014-10-13 19:25:21,049 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t2-SendThread(localhost:2182)] zookeeper.ClientCnxn: Socket connection established to localhost/0:0:0:0:0:0:0:1:2182, initiating session
2014-10-13 19:25:21,051 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x199c8484 connecting to ZooKeeper ensemble=localhost:2182
2014-10-13 19:25:21,051 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2182 sessionTimeout=90000 watcher=hconnection-0x199c8484, quorum=lo
calhost:2182, baseZNode=/hbase
2014-10-13 19:25:21,052 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3-SendThread(localhost:2182)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2182. Will not attempt to authe
nticate using SASL (unknown error)
2014-10-13 19:25:21,052 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3-SendThread(localhost:2182)] zookeeper.ClientCnxn: Socket connection established to localhost/0:0:0:0:0:0:0:1:2182, initiating session
2014-10-13 19:25:21,053 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t2-SendThread(localhost:2182)] zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2182, sessionid = 0x149093
fc1c80203, negotiated timeout = 90000
2014-10-13 19:25:21,055 INFO  [A01101303447-V1,60020,1413199414409-recovery-writer--pool17-t3-SendThread(localhost:2182)] zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2182, sessionid = 0x149093
fc1c80204, negotiated timeout = 90000
2014-10-13 19:25:21,103 ERROR [RS_OPEN_REGION-A01101303447-V1:60020-1] handler.OpenRegionHandler: Failed open of region=EVENT,\x18,1413186838852.def4a581d4ad963cbb8cad32cbfbab2e., starting to roll back the global memstore size.
java.lang.NullPointerException
2014-10-13 19:25:21,104 INFO  [RS_OPEN_REGION-A01101303447-V1:60020-1] handler.OpenRegionHandler: Opening of region {ENCODED => def4a581d4ad963cbb8cad32cbfbab2e, NAME => 'EVENT,\x18,1413186838852.def4a581d4ad963cbb8cad32cbfbab2e.', START
KEY => '\x18', ENDKEY => '\x19'} failed, transitioning from OPENING to FAILED_OPEN in ZK, expecting version 28
2014-10-13 19:25:21,104 DEBUG [RS_OPEN_REGION-A01101303447-V1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x149093fc1c80001, quorum=localhost:2182, baseZNode=/hbase Transitioning def4a581d4ad963cbb8cad32cbfbab2e from RS_ZK_REGION_OPE
NING to RS_ZK_REGION_FAILED_OPEN
2014-10-13 19:25:21,107 DEBUG [RS_OPEN_REGION-A01101303447-V1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x149093fc1c80001, quorum=localhost:2182, baseZNode=/hbase Transitioned node def4a581d4ad963cbb8cad32cbfbab2e from RS_ZK_REGION
_OPENING to RS_ZK_REGION_FAILED_OPEN
2014-10-13 19:25:21,108 ERROR [RS_OPEN_REGION-A01101303447-V1:60020-2] handler.OpenRegionHandler: Failed open of region=EVENT,\x15,1413186838852.4592fbc9db5e6eb05c812dcd81f5fa4d., starting to roll back the global memstore size.
java.lang.NullPointerException
2014-10-13 19:25:21,108 INFO  [RS_OPEN_REGION-A01101303447-V1:60020-2] handler.OpenRegionHandler: Opening of region {ENCODED => 4592fbc9db5e6eb05c812dcd81f5fa4d, NAME => 'EVENT,\x15,1413186838852.4592fbc9db5e6eb05c812dcd81f5fa4d.', START
KEY => '\x15', ENDKEY => '\x16'} failed, transitioning from OPENING to FAILED_OPEN in ZK, expecting version 28
2014-10-13 19:25:21,108 DEBUG [RS_OPEN_REGION-A01101303447-V1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x149093fc1c80001, quorum=localhost:2182, baseZNode=/hbase Transitioning 4592fbc9db5e6eb05c812dcd81f5fa4d from RS_ZK_REGION_OPE
NING to RS_ZK_REGION_FAILED_OPEN
2014-10-13 19:25:21,111 DEBUG [RS_OPEN_REGION-A01101303447-V1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x149093fc1c80001, quorum=localhost:2182, baseZNode=/hbase Transitioned node 4592fbc9db5e6eb05c812dcd81f5fa4d from RS_ZK_REGION
_OPENING to RS_ZK_REGION_FAILED_OPEN
2014-10-13 19:25:21,113 ERROR [RS_OPEN_REGION-A01101303447-V1:60020-0] handler.OpenRegionHandler: Failed open of region=EVENT,\x1B,1413186838852.b45c35d23b23fda5643ec5d79083488e., starting to roll back the global memstore size.
java.lang.NullPointerException



 After deleteing the 'recovered.edits' in the 'EVENT' table's region, the hbase table can be scanned. so i think the reason maybe that:
after restart hbase, the regionserver begin opening the region and replaying WAL, when replaying the EVENT's WAL, because EVENT has a index table IDX_DATE_HOUR_X, so the replay process should operate IDX_DATE_HOUR_X, but at this moment, the IDX_DATE_HOUR_X table's region is in OPENING stats, it is't unavaiabled, so the EVENT replaying process Time and time again to retry and throw Exception aging and again.

if I disable EVENT first, others hbase table recory successfully, but when i enable EVENT, the region log occur java.lang.NullPointerException, this make the region transition to OPEN_FAILED.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16858,"{code}
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 603.9 sec - in org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEnd
Exception in thread ""Thread-2545"" java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.Arrays.copyOfRange(Arrays.java:3664)
	at java.lang.StringBuffer.toString(StringBuffer.java:671)
	at java.io.BufferedReader.readLine(BufferedReader.java:359)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.maven.surefire.shade.org.apache.maven.shared.utils.cli.StreamPumper.run(StreamPumper.java:66)
Exception in thread ""Thread-2543"" java.lang.OutOfMemoryError: GC overhead limit exceeded
Exception in thread ""Thread-2549"" java.lang.OutOfMemoryError: GC overhead limit exceeded
Exception in thread ""Thread-2527"" java.lang.OutOfMemoryError: GC overhead limit exceeded
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17078,"HBase build with hadoop.profile=3.0 is failing as hbase-assembly\src\main\assembly\hadoop-three-compat.xml is not present.
{code}	
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 06:18 min
[INFO] Finished at: 2016-11-12T13:17:48+05:30
[INFO] Final Memory: 230M/1118M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-assembly-plugin:2.4:single (default-cli) on project hbase-assembly: Error reading assemblies: Error locating assembly descriptor: src/main/assembly/hadoop-three-compat.xml
[ERROR]
[ERROR] [1] [INFO] Searching for file location: D:\gitHome\hbaseMaster\hbase-assembly\src\main\assembly\hadoop-three-compat.xml
[ERROR]
[ERROR] [2] [INFO] File: D:\gitHome\hbaseMaster\hbase-assembly\src\main\assembly\hadoop-three-compat.xml does not exist.
[ERROR]
[ERROR] [3] [INFO] File: D:\gitHome\hbaseMaster\src\main\assembly\hadoop-three-compat.xml does not exist.
[ERROR] -> [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hbase-assembly
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13556,"Long time ago, back in HBASE-8015, we noted that 'system tables' should be treated special when assigning; they should go out after hbase:meta and before userspace tables and that we should fix this in a follow-on issue (https://issues.apache.org/jira/browse/HBASE-8408?focusedCommentId=13728267&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13728267). This is the follow-up issue.

Do system tables like namespace need to keep their own WAL to make it easier recovering and assigning these tables ahead of userspace tables?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17529,"I built tar ball using master branch based on commit 616f4801b06a8427a03ceca9fb8345700ce1ad71.

Was running the following command:

hbase org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList -DinMemoryCompaction=BASIC Loop 4 6 1000000 /tmp/hbase-biglinkedlist-verify 6 --monkey slowDeterministic

Here was related snippet:
{code}
2017-01-24 21:29:00,107 DEBUG [RpcServer.deafult.FPBQ.Fifo.handler=0,queue=0,port=16000] procedure2.ProcedureExecutor: Stored MergeTableRegionsProcedure (table=IntegrationTestBigLinkedList regions=[IntegrationTestBigLinkedList,,1485292220242.4c5ea240e86ef22ec7264b1153dd557d., IntegrationTestBigLinkedList,\x0E8\xE3\x8E8\xE3\x8E8,1485292220242.6cdb98dfed41ea689b3cd66478c2c580. ] forcible=false), procId=12, owner=hbase, state=RUNNABLE:MERGE_TABLE_REGIONS_PREPARE
2017-01-24 21:29:00,108 DEBUG [ProcedureExecutorWorker-14] wal.WALProcedureStore: Set running procedure count=1, slots=24
2017-01-24 21:29:00,127 ERROR [ProcedureExecutorWorker-14] procedure2.ProcedureExecutor: CODE-BUG: Uncatched runtime exception for procedure: MergeTableRegionsProcedure (table=IntegrationTestBigLinkedList regions=[IntegrationTestBigLinkedList,,1485292220242.4c5ea240e86ef22ec7264b1153dd557d., IntegrationTestBigLinkedList,\x0E8\xE3\x8E8\xE3\x8E8,1485292220242.6cdb98dfed41ea689b3cd66478c2c580. ] forcible=false), procId=12, owner=hbase, state=RUNNABLE:MERGE_TABLE_REGIONS_MOVE_REGION_TO_SAME_RS
java.lang.ArrayIndexOutOfBoundsException
        at org.apache.hadoop.hbase.util.ByteBufferUtils.copyFromBufferToArray(ByteBufferUtils.java:1024)
        at org.apache.hadoop.hbase.nio.MultiByteBuff.get(MultiByteBuff.java:628)
        at org.apache.hadoop.hbase.ipc.RpcServer$ByteBuffByteInput.read(RpcServer.java:1483)
        at org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteInputByteString.copyToInternal(ByteInputByteString.java:105)
        at org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.toByteArray(ByteString.java:651)
        at org.apache.hadoop.hbase.RegionLoad.getName(RegionLoad.java:50)
        at org.apache.hadoop.hbase.ServerLoad.getRegionsLoad(ServerLoad.java:236)
        at org.apache.hadoop.hbase.master.procedure.MergeTableRegionsProcedure.getRegionLoad(MergeTableRegionsProcedure.java:774)
        at org.apache.hadoop.hbase.master.procedure.MergeTableRegionsProcedure.MoveRegionsToSameRS(MergeTableRegionsProcedure.java:461)
        at org.apache.hadoop.hbase.master.procedure.MergeTableRegionsProcedure.executeFromState(MergeTableRegionsProcedure.java:142)
        at org.apache.hadoop.hbase.master.procedure.MergeTableRegionsProcedure.executeFromState(MergeTableRegionsProcedure.java:72)
        at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:154)
        at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:708)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1332)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeProcedure(ProcedureExecutor.java:1133)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$800(ProcedureExecutor.java:76)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$WorkerThread.run(ProcedureExecutor.java:1588)
{code}
Master log to be attached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15993,Add support for regular expression in table names in backup/restore/set operations.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14129,"We were doing a cluster restart the other day.  Some regionservers did not shut down cleanly.  Upon restart our locality went from 99% to 5%.  Upon looking at the AssignmentManager.joinCluster() code it calls AssignmentManager.processDeadServersAndRegionsInTransition().
If the failover flag gets set for any reason it seems we don't call assignAllUserRegions().  Then it looks like the balancer does the work in assigning those regions, we don't use a locality aware balancer and we lost our region locality.

I don't have a solid grasp on the reasoning for these checks but there could be some potential workarounds here.

1. After shutting down your cluster, move your WALs aside (replay later).  
2. Clean up your zNodes 

That seems to work, but requires a lot of manual labor.  Another solution which I prefer would be to have a flag for ./start-hbase.sh --clean 

If we start master with that flag then we do a check in AssignmentManager.processDeadServersAndRegionsInTransition()  thus if this flag is set we call: assignAllUserRegions() regardless of the failover state.

I have a patch for the later solution, that is if I am understanding the logic correctly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8028,"In case there is an exception while doing the log-sync, the memstore is not rollbacked, while the mvcc is _always_ forwarded to the writeentry created at the beginning of the operation. This may lead to scanners seeing results which are not synched to the fs.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17400,"Looping TestHRegionWithInMemoryFlush with commit 0e48665641b16cd9b250503696b926a568063654 , I got the following error at iteration #33:
{code}
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 600.163 sec <<< FAILURE! - in org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush
org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush  Time elapsed: 600.019 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 10 minutes
  at java.lang.Object.wait(Native Method)
  at org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.waitForRead(MultiVersionConcurrencyControl.java:218)
  at org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.completeAndWait(MultiVersionConcurrencyControl.java:149)
  at org.apache.hadoop.hbase.regionserver.HRegion.getNextSequenceId(HRegion.java:2731)
  at org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2446)
  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2342)
  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2313)
  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2303)
  at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1600)
  at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1505)
  at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1455)
  at org.apache.hadoop.hbase.HBaseTestingUtility.closeRegionAndWAL(HBaseTestingUtility.java:374)
  at org.apache.hadoop.hbase.regionserver.TestHRegion.testWritesWhileScanning(TestHRegion.java:3985)
{code}
See attached test output for details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10396,"HBaseAdmin has the constructor:
{code}
  public HBaseAdmin(Configuration c)
  throws MasterNotRunningException, ZooKeeperConnectionException {
    this.conf = HBaseConfiguration.create(c);
    this.connection = HConnectionManager.getConnection(this.conf);
    ...
{code}
As shown in above code, HBaseAdmin will get a cached HConnection or create a new HConnection and use this HConnection to connect to Master. Then, HBaseAdmin will delete the HConnection when connecting to master fail as follows:
{code}
    while ( true ){
      try {
        this.connection.getMaster();
        return;
      } catch (MasterNotRunningException mnre) {
        HConnectionManager.deleteStaleConnection(this.connection);
        this.connection = HConnectionManager.getConnection(this.conf);
      }
{code} 
The above code will invoke HConnectionManager#deleteStaleConnection to delete the HConnection from global HConnection cache. The risk is that the deleted HConnection might be sharing by other threads, such as HTable or HTablePool. Then, these threads which sharing the deleted HConnection will get closed HConnection exception:
{code}
org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@61bc59aa closed
{code}
If users use HTablePool, the situation will become worse because closing HTable will only return HTable to HTablePool which won't reduce the reference count of the closed HConnection. Then, the closed HConnection will always be used before clearing HTablePool. In 0.94, some modules such as Rest server are using HTablePool, therefore may suffer from this problem. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6651,"There are some operations in HTablePool accessing PoolMap in multiple places without any explicit synchronization. 

For example HTablePool.closeTablePool() calls PoolMap.values(), and calls PoolMap.remove(). If other threads add new instances to the pool in the middle of the calls, the newly added instances might be dropped. (HTablePool.closeTablePool() also has another problem that calling it by multiple threads causes accessing HTable by multiple threads.)

Moreover, PoolMap is not thread safe for the same reason.

For example PoolMap.put() calles ConcurrentMap.get() and calles ConcurrentMap.put(). If other threads add a new instance to the concurent map in the middle of the calls, the new instance might be dropped.

And also implementations of Pool have the same problems.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9739,"Just ran into a scenario where HBaseClient became permanently useless after we interrupted the using thread.
The problem is here:
{code}
      } catch(IOException e) {
        markClosed(e);
{code}
In sendParam(...).
If the IOException is caused by an interrupt we should not close the connection.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10028,"The current documentation of the metrics is incomplete and at point incorrect (HDFS latencies are in ns rather than ms for example).
We should clean this up and add other related metrics as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17841,"When writing unit test for HBASE-17287, I noticed that the wait for master to come down after hdfs enters safe mode times out (where meta server still has unflushed edits).
The same test in branch-1 passes fine.

Looking at org.apache.hadoop.hbase.master.procedure.TestSafemodeBringsDownMaster-output.txt , I don't see occurrence of ServerCrashProcedure.

While in branch-1, there is something similar to the following:
{code}
  at org.apache.hadoop.hdfs.DFSClient.rename(DFSClient.java:1661)
  at org.apache.hadoop.hdfs.DistributedFileSystem.rename(DistributedFileSystem.java:525)
  at org.apache.hadoop.hbase.master.MasterFileSystem.getLogDirs(MasterFileSystem.java:364)
  at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:429)
  at org.apache.hadoop.hbase.master.MasterFileSystem.splitMetaLog(MasterFileSystem.java:343)
  at org.apache.hadoop.hbase.master.MasterFileSystem.splitMetaLog(MasterFileSystem.java:334)
  at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.processMeta(ServerCrashProcedure.java:351)
  at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.executeFromState(ServerCrashProcedure.java:239)
  at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.executeFromState(ServerCrashProcedure.java:73)
  at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:139)
  at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:506)
  at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1152)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17820,"I used this command ""mvn clean install -Dhadoop-two.version=2.6.0 -DskipTests"" to build hbase-1.2.4 source code. 
Build failed at hbase-assembly module.

This is the fail message: 
""Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.5:process (default) on project hbase-assembly: Error rendering velocity resource. Error invoking method 'get(java.lang.Integer)' in java.util.ArrayList at META-INF/LICENSE.vm[line 1671, column 8]: InvocationTargetException: Index: 0, Size: 0 -> [Help 1]"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16431,Class `HTableWrapper` must either declared abstract or implement abstract method 'setRpcTimeout(int)' in 'Table',,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17311,"In preparation to big refactoring (separate project for backup) we need to move  'hbase:system' table out of HBase system namespace.  
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17548,"While investigating HBASE-17529, I wanted to trigger region merge where the
two (adjacent) regions are on different region servers.

I produced tar ball based on commit 85d701892ed969380a8bcca9c9f4e306c74af941

For table.jsp?name=IntegrationTestBigLinkedList, e.g., where there're
multiple regions for the table, I don't see regions listing.
Same with other multi-region tables.

First reported here:
http://search-hadoop.com/m/HBase/YGbbJglgx1N2qvO1",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15130,"branch 98 version backport for HBASE-14355

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17300,"Attached is the test case. I have added some comments so hopefully the test makes sense. It actually is causing test failures on the Phoenix branches.

The test fails consistently using HBase-0.98.23. It exhibits flappy behavior with the 1.2 branch (failed twice in 5 tries). 

{code}
@Test
    public void testNullCheckAndPut() throws Exception {
            try (HBaseAdmin admin = TEST_UTIL.getHBaseAdmin()) {
                Callable<Boolean> c1 = new CheckAndPutCallable();
                Callable<Boolean> c2 = new CheckAndPutCallable();
                ExecutorService e = Executors.newFixedThreadPool(5);
                Future<Boolean> f1 = e.submit(c1);
                Future<Boolean> f2 = e.submit(c2);
                assertTrue(f1.get() || f2.get());
                assertFalse(f1.get() && f2.get());
            }    
        }
    }
    
    
    private static final class CheckAndPutCallable implements Callable<Boolean> {
        @Override
        public Boolean call() throws Exception {
            byte[] rowToLock = ""ROW"".getBytes();
            byte[] colFamily = ""COLUMN_FAMILY"".getBytes();
            byte[] column = ""COLUMN"".getBytes();
            byte[] newValue = ""NEW_VALUE"".getBytes();
            byte[] oldValue = ""OLD_VALUE"".getBytes();
            byte[] tableName = ""table"".getBytes();
            boolean acquired = false;
                try (HBaseAdmin admin = TEST_UTIL.getHBaseAdmin()) {
                    HTableDescriptor tableDesc = new HTableDescriptor(TableName.valueOf(tableName));
                    HColumnDescriptor columnDesc = new HColumnDescriptor(colFamily);
                    columnDesc.setTimeToLive(600);
                    tableDesc.addFamily(columnDesc);
                    try {
                        admin.createTable(tableDesc);
                    } catch (TableExistsException e) {
                        // ignore
                    }
                    try (HTableInterface table = admin.getConnection().getTable(tableName)) {
                        Put put = new Put(rowToLock);
                        put.add(colFamily, column, oldValue); // add a row with column set to oldValue
                        table.put(put);
                        put = new Put(rowToLock);
                        put.add(colFamily, column, newValue);
                        // only one of the threads should be able to get return value of true for the expected value of oldValue
                        acquired = table.checkAndPut(rowToLock, colFamily, column, oldValue, put); 
                        if (!acquired) {
                           // if a thread didn't get true before, then it shouldn't get true this time either
                           // because the column DOES exist
                           acquired = table.checkAndPut(rowToLock, colFamily, column, null, put);
                        }
                    }
                }
            }  
            return acquired;
        }
    }
{code}


cc [~apurtell], [~jamestaylor], [~lhofhansl]. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16115,"We ran into an interesting phenomenon which can easily render a cluster unusable.

We loaded some tests data into a test table and forced a manual compaction through the UI. We have some compaction hooks implemented in a region observer, which writes back to another HBase table when the compaction finishes. We noticed that this coprocessor is not setup correctly, it seems the security context is missing.

The interesting part is that this _only_ happens when the compaction is triggere through the UI. Automatic compactions (major or minor) or when triggered via the HBase shell (folling a kinit) work fine. Only the UI-triggered compactions cause this issues and lead to essentially neverending compactions, immovable regions, etc.

Not sure what exactly the issue is, but I wanted to make sure I capture this.

[~apurtell], [~ghelmling], FYI.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6725,"When multiple threads race using CAP with and a lock on the same row, several instances may be allowed to update the cell with the new value (although the expected value is different).
If all threads race with a wrong expected value and a lock, none will be able to update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6660,"Recently I upgraded three data centers to our own checkout of 0.92.2, last commit :

{noformat}
commit 5accb6a1be4776630126ac21d07adb652b74df95
Author: Zhihong Yu <tedyu@apache.org>
Date:   Mon Aug 20 18:19:45 2012 +0000
HBASE-6608 Fix for HBASE-6160, META entries from daughters can be deleted before parent entries, shouldn't compare HRegionInfo's (Enis)
{noformat}

Two upgrades went fine, upgrade to one data center failed. Failed in the sense that ROOT and META assignment took forever. Panic struck I restarted master and all region servers. I may have deleted zookeeper node /hbase/root-region-server as well, dont ask me why :-( 

After this I managed to get ROOT assigned. But META assignment got stuck again. 

The log is here : https://raw.github.com/gist/3455435/adebd118b47aa3d715201010aa09e5eb8930033c/npe_rs_0.92.2.log

Notice how region server was stuck in a loop of NPE (grep processBatchCallback). There is one more NPE related to zookeeper constructor. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6465,"Through the master and regionserver log,I find load balancer repeatedly
close and open region in the same regionserver(period in
hbase.balancer.period ).
Does this is a bug in load balancer and how can I dig into or avoid this?


the hbase and hadoop version is
HBase Version0.94.0, r1332822Hadoop Version0.20.2-cdh3u1,
rbdafb1dbffd0d5f2fbc6ee022e1c8df6500fd638
the following is a detail log about the same region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956,
and it repeats again and again.:
2012-07-16 00:12:49,843 INFO org.apache.hadoop.hbase.master.HMaster: balance
hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592
2012-07-16 00:12:49,843 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of
region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
(offlining)
2012-07-16 00:12:49,843 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Creating unassigned node for
93caf5147d40f5dd4625e160e1b7e956 in a CLOSING state
2012-07-16 00:12:49,845 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Sent CLOSE to
192.168.1.2,60020,1342017399608 for region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
2012-07-16 00:12:50,555 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_CLOSED, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,555 DEBUG
org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED
event for 93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,555 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE;
was=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
state=CLOSED, ts=1342368770556, server=192.168.1.2,60020,1342017399608
2012-07-16 00:12:50,555 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Creating (or updating) unassigned node for
93caf5147d40f5dd4625e160e1b7e956 with OFFLINE state
2012-07-16 00:12:50,558 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=M_ZK_REGION_OFFLINE, server=10.75.18.34,60000,1342017369575,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,558 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Found an existing plan
for
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
destination server is 192.168.1.2,60020,1342002082592
2012-07-16 00:12:50,558 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Using pre-existing plan
for region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.;
plan=hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592
2012-07-16 00:12:50,558 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Assigning region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
to 192.168.1.2,60020,1342002082592
2012-07-16 00:12:50,574 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENING, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,635 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENING, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,639 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENED, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:12:50,639 DEBUG
org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED
event for
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
from 192.168.1.2,60020,1342017399608; deleting unassigned node
2012-07-16 00:12:50,640 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Deleting existing unassigned node for
93caf5147d40f5dd4625e160e1b7e956 that is in expected state
RS_ZK_REGION_OPENED
2012-07-16 00:12:50,641 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: The znode of region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
has been deleted.
2012-07-16 00:12:50,641 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Successfully deleted unassigned node for
region 93caf5147d40f5dd4625e160e1b7e956 in expected state
RS_ZK_REGION_OPENED
2012-07-16 00:12:50,641 INFO
org.apache.hadoop.hbase.master.AssignmentManager: The master has opened the
region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
that was online on 192.168.1.2,60020,1342017399608
2012-07-16 00:17:49,870 INFO org.apache.hadoop.hbase.master.HMaster: balance
hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592
2012-07-16 00:17:49,870 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of
region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
(offlining)
2012-07-16 00:17:49,870 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Creating unassigned node for
93caf5147d40f5dd4625e160e1b7e956 in a CLOSING state
2012-07-16 00:17:49,872 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Sent CLOSE to
192.168.1.2,60020,1342017399608 for region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
2012-07-16 00:17:50,464 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_CLOSED, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,464 DEBUG
org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED
event for 93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,464 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE;
was=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
state=CLOSED, ts=1342369070465, server=192.168.1.2,60020,1342017399608
2012-07-16 00:17:50,464 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Creating (or updating) unassigned node for
93caf5147d40f5dd4625e160e1b7e956 with OFFLINE state
2012-07-16 00:17:50,467 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=M_ZK_REGION_OFFLINE, server=10.75.18.34,60000,1342017369575,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,467 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Found an existing plan
for
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
destination server is 192.168.1.2,60020,1342002082592
2012-07-16 00:17:50,467 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Using pre-existing plan
for region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.;
plan=hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592
2012-07-16 00:17:50,467 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Assigning region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
to 192.168.1.2,60020,1342002082592
2012-07-16 00:17:50,509 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENING, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,761 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENING, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,774 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: Handling
transition=RS_ZK_REGION_OPENED, server=192.168.1.2,60020,1342017399608,
region=93caf5147d40f5dd4625e160e1b7e956
2012-07-16 00:17:50,774 DEBUG
org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED
event for
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
from 192.168.1.2,60020,1342017399608; deleting unassigned node
2012-07-16 00:17:50,774 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Deleting existing unassigned node for
93caf5147d40f5dd4625e160e1b7e956 that is in expected state
RS_ZK_REGION_OPENED
2012-07-16 00:17:50,775 DEBUG
org.apache.hadoop.hbase.master.AssignmentManager: The znode of region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
has been deleted.
2012-07-16 00:17:50,775 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign:
master:60000-0x4384d0a47f40068 Successfully deleted unassigned node for
region 93caf5147d40f5dd4625e160e1b7e956 in expected state
RS_ZK_REGION_OPENED
2012-07-16 00:17:50,775 INFO
org.apache.hadoop.hbase.master.AssignmentManager: The master has opened the
region
trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.
that was online on 192.168.1.2,60020,1342017399608
2012-07-16 00:22:49,916 INFO org.apache.hadoop.hbase.master.HMaster: balance
hri=trackurl_status_list,zO6u4o8,1342291884831.93caf5147d40f5dd4625e160e1b7e956.,
src=192.168.1.2,60020,1342017399608, dest=192.168.1.2,60020,1342002082592",,,,,,,241748,,,,,Wed Nov 16 22:00:12 UTC 2016,,,,,,0|i02c6v:,11576,,,,,,,,"06/Jul/12 20:55;jdcryans;This issue only seems to be in 0.90, it does this:

{code}
private static InetSocketAddress getResolvedAddress(InetSocketAddress address) {
  String bindAddress = getBindAddressInternal(address);
  int port = address.getPort();
  return new InetSocketAddress(bindAddress, port);    
}
{code}

Except that getBindAddressInternal() can return null (and show the message ""Could not resolve the DNS name of data03.movetest-a.domain.com"") and it's not checked so the {{InetSocketAddress}} gets passed a null.

In 0.92 and 0.94, {{ServerName}} doesn't do this kind of resolving. ",16/Nov/16 22:00;stack;Seems like an old issue probably a problem in old hbase. Reopen if can repro in new context.
HBASE-9968,"When we check whether the dead region is carrying root or meta, first we will check any transition znode for the region is there or not. In this case it got deleted. So from zookeeper we cannot find the region location. 
{code}
    try {
      data = ZKAssign.getData(master.getZooKeeper(), hri.getEncodedName());
    } catch (KeeperException e) {
      master.abort(""Unexpected ZK exception reading unassigned node for region=""
        + hri.getEncodedName(), e);
    }
{code}
Now we will check from the AssignmentManager whether its in online regions or not
{code}
    ServerName addressFromAM = getRegionServerOfRegion(hri);
    boolean matchAM = (addressFromAM != null &&
      addressFromAM.equals(serverName));
    LOG.debug(""based on AM, current region="" + hri.getRegionNameAsString() +
      "" is on server="" + (addressFromAM != null ? addressFromAM : ""null"") +
      "" server being checked: "" + serverName);
{code}
From AM we will get null because  while adding region to online regions we will check whether the RS is in onlineservers or not and if not we will not add the region to online regions.
{code}
      if (isServerOnline(sn)) {
        this.regions.put(regionInfo, sn);
        addToServers(sn, regionInfo);
        this.regions.notifyAll();
      } else {
        LOG.info(""The server is not in online servers, ServerName="" + 
          sn.getServerName() + "", region="" + regionInfo.getEncodedName());
      }
{code}


Even though the dead regionserver carrying ROOT region, its returning false. After that ROOT region never assigned.

Here are the logs
{code}
2013-11-11 18:04:14,730 INFO org.apache.hadoop.hbase.catalog.RootLocationEditor: Unsetting ROOT region location in ZooKeeper
2013-11-11 18:04:14,775 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for -ROOT-,,0.70236052 so generated a random one; hri=-ROOT-,,0.70236052, src=, dest=HOST-10-18-40-69,60020,1384173244404; 1 (online=1, available=1) available servers
2013-11-11 18:04:14,809 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region -ROOT-,,0.70236052 to HOST-10-18-40-69,60020,1384173244404
2013-11-11 18:04:18,375 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@12133926; serverName=HOST-10-18-40-69,60020,1384173244404
2013-11-11 18:04:26,213 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=HOST-10-18-40-69,60020,1384173244404, region=70236052/-ROOT-
2013-11-11 18:04:26,213 INFO org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for -ROOT-,,0.70236052 from HOST-10-18-40-69,60020,1384173244404; deleting unassigned node
2013-11-11 18:04:31,553 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: based on AM, current region=-ROOT-,,0.70236052 is on server=null server being checked: HOST-10-18-40-69,60020,1384173244404
2013-11-11 18:04:31,561 DEBUG org.apache.hadoop.hbase.master.ServerManager: Added=HOST-10-18-40-69,60020,1384173244404 to dead servers, submitted shutdown handler to be executed, root=false, meta=false
{code}
{code}
2013-11-11 18:04:32,323 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: The znode of region -ROOT-,,0.70236052 has been deleted.
2013-11-11 18:04:32,323 INFO org.apache.hadoop.hbase.master.AssignmentManager: The server is not in online servers, ServerName=HOST-10-18-40-69,60020,1384173244404, region=70236052
2013-11-11 18:04:32,323 INFO org.apache.hadoop.hbase.master.AssignmentManager: The master has opened the region -ROOT-,,0.70236052 that was online on HOST-10-18-40-69,60020,1384173244404
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3792,"The TableInputFormat creates an HTable using a new Configuration object, and it never cleans it up. When running a Mapper, the TableInputFormat is instantiated and the ZK connection is created. While this connection is not explicitly cleaned up, the Mapper process eventually exits and thus the connection is closed. Ideally the TableRecordReader would close the connection in its close() method rather than relying on the process to die for connection cleanup. This is fairly easy to implement by overriding TableRecordReader, and also overriding TableInputFormat to specify the new record reader.

The leak occurs when the JobClient is initializing and needs to retrieves the splits. To get the splits, it instantiates a TableInputFormat. Doing so creates a ZK connection that is never cleaned up. Unlike the mapper, however, my job client process does not die. Thus the ZK connections accumulate.

I was able to fix the problem by writing my own TableInputFormat that does not initialize the HTable in the getConf() method and does not have an HTable member variable. Rather, it has a variable for the table name. The HTable is instantiated where needed and then cleaned up. For example, in the getSplits() method, I create the HTable, then close the connection once the splits are retrieved. I also create the HTable when creating the record reader, and I have a record reader that closes the connection when done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4988,"If metaserver crash now,
All the splitting regionserver will abort theirself.
Becasue the code
{code}
this.journal.add(JournalEntry.PONR);
MetaEditor.offlineParentInMeta(server.getCatalogTracker(),
            this.parent.getRegionInfo(), a.getRegionInfo(), b.getRegionInfo());
{code}
If the JournalEntry is PONR, split's roll back will abort itselef.

It is terrible in huge putting environment when metaserver crash
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4921,"The HTable initialization does something like this : 

{code}this.connection.locateRegion(tableName, HConstants.EMPTY_START_ROW);{code}

What is the rationale behind this ? What would happen if this region is in flight ? I ran into a problem where I disabled the first region of the table and now I can't create an HTable instance to this table.

Disabling the first region is like disabling the entire table from a client perspective. I feel this is not the correct behavior.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4633,"Relevant Jiras: https://issues.apache.org/jira/browse/HBASE-2937,
https://issues.apache.org/jira/browse/HBASE-4003

We have been using the 'hbase.client.operation.timeout' knob
introduced in 2937 for quite some time now. It helps us enforce SLA.
We have two HBase clusters and two HBase client clusters. One of them
is much busier than the other.

We have seen a deterministic behavior of clients running in busy
cluster. Their (client's) memory footprint increases consistently
after they have been up for roughly 24 hours.
This memory footprint almost doubles from its usual value (usual case
== RPC timeout disabled). After much investigation nothing concrete
came out and we had to put a hack
which keep heap size in control even when RPC timeout is enabled. Also
note , the same behavior is not observed in 'not so busy
cluster.

The patch is here : https://gist.github.com/1288023",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3782,"I've been testing HBASE-1861 in 0.90.2, which adds multi-family support for bulk upload tools.

I found that when running the importtsv program, some reduce tasks fail with a File Not Found exception if there are no keys in the input data which fall into the region assigned to that reduce task.  From what I can determine, it seems that an output directory is created in the write() method and expected to exist in the writeMetaData() method...if there are no keys to be written for that reduce task, the write method is never called and the output directory is never created, but writeMetaData is expecting the output directory to exist...thus the FnF exception:

2011-03-17 11:52:48,095 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.io.FileNotFoundException: File does not exist: hdfs://master:9000/awardsData/_temporary/_attempt_201103151859_0066_r_000000_0
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:468)
	at org.apache.hadoop.hbase.regionserver.StoreFile.getUniqueFile(StoreFile.java:580)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat$1.writeMetaData(HFileOutputFormat.java:186)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat$1.close(HFileOutputFormat.java:247)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:567)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:408)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)

Simply checking if the file exists should fix the issue. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4324,"Because we use a single znode for /unassigned, and we re-list it every time its contents change, assignment speed per region is O(number of unassigned regions) rather than O(1). Every time something changes about one unassigned region, the master has to re-list the entire contents of the directory inside of AssignmentManager.nodeChildrenChanged().",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4246,"We ran into the following sequence of events:
- master startup failed after only ROOT had been assigned (for another reason)
- restarted the master without restarting other servers. Since there was at least one region assigned, it went through the failover code path
- master scanned META and inserted every region into /hbase/unassigned in ZK.
- then, it called ""listChildren"" on the /hbase/unassigned znode, and crashed with ""Packet len6080218 is out of range!"" since the IPC response was larger than the default maximum.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2213,"right now we take the default HCD fields and 'snapshot' them into every HCD.  So things like 'BLOCKCACHE' and 'FILESIZE' are in every table, even if they don't differ from the defaults.  If the default changes in a meanful/important way, the user is left with the unenviable task of (a) determining this happened and (b) actually going through and disabling/altering the tables to fix it.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16806,"In a new project checkout, Eclipse complains it cant find shaded protobufs though they src is checked in (FYI [~syuanjiang]) This issue came in with the recent commit:

{code}
commit 95c1dc93fb6780f66fd8ebb57914a050b75b9b11
Author: stack <stack@apache.org>
Date:   Mon Oct 3 21:37:32 2016 -0700

    HBASE-15638 Shade protobuf
    Which includes
...
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14776,"We require patches to be created using 'git format-patch' or 'git diff', so patches should be tested using 'git am' or 'git apply', not 'patch -pX'. This causes false errors in the Jenkins patch tester.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15598,"In CloneSnapshotProcedure#preCloneSnapshot():
{code}
      ProcedureSyncWait.getMasterQuotaManager(env)
        .checkNamespaceTableAndRegionQuota(getTableName(), manifest.getRegionManifestsMap().size());
{code}
Here is related code in SnapshotManifest#getRegionManifestsMap() :
{code}
    if (regionManifests == null || regionManifests.size() == 0) return null;
...
{code}
When there is no region manifest, null would be returned, resulting in NPE in CloneSnapshotProcedure#preCloneSnapshot()",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13559,"We had some regions stay un-assigned. They were in pending open on a server that was dead. The cluster was restarted as a whole a few times and then the regions were stuck until a manual assign was performed on them.

I know timing things out has been a pain. Could we have a timeout on servers that are not alive?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16265,"See https://builds.apache.org/job/HBase-TRUNK_matrix/1265/jdk=latest1.8,label=yahoo-not-h2/testReport/org.apache.hadoop.hbase.spark/BulkLoadSuite/Wide_Row_Bulk_Load__Test_multi_family_and_multi_column_tests_with_one_column_family_with_custom_configs_plus_multi_region/ :
{code}
File does not exist: /tmp/junit811617169708528768/junit7419829633245108670/f1/b934f7ee0d414de5ab3457d057b9df64&#010; at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)&#010; at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)&#010; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1828)&#010; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1799)&#010; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1712)&#010; at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:587)&#010; at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:365)&#010; at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)&#010; at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)&#010; at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)&#010; at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)&#010; at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)&#010; at java.security.AccessController.doPrivileged(Native Method)&#010; at javax.security.auth.Subject.doAs(Subject.java:422)&#010; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)&#010; at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)&#010;
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14549,"Looking at the code, I find that the logic is unnecessarily complex.
We indicate in updateReaders that the scanner stack needs to be reset. Then almost all store scanner (and derived classes) methods need to check and actually reset the scanner stack.
Compaction are rare, we should reset the scanner stack in update readers, and hence avoid needing to check in all methods.

Patch forthcoming.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15059,Currently HBase 0.94 cannot be compiled against Hadoop 2.7.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13667,"We can backport Split transaction, region merge transaction interfaces to branch 1.0 and 0.98 without changing coprocessor hooks. Then it should be compatible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15585,"While you can do all kinds of things with coprocessors, like arbitrarily discard memstore data or replace files randomly during compaction, I believe the ultimate power and flexibility is not there. The patch aims to address this shortcoming.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15249,"AMS (Ambari Metrics System) developer found the following scenario:

Metrics table was pre-split with many regions on large cluster (1600 nodes).
After some time, AMS stopped working because region normalizer merged the regions into few big regions which were not able to serve high read / write load.
This is a big problem since the write requests flood the regions faster than the splits can happen resulting in poor performance.

We should consider setting reasonable lower bound on region count.
If the table is pre-split, we can use initial region count as the lower bound.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5516,"Usage of GZip is leading to resident memory leak in 0.90.
We need to have something similar to HBASE-5387 in 0.90. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15207,"Balancer seems to have gotten stuck in 1.2.0RC1 soon after Master joins running cluster (previous Master had been killed by chaos monkey). Investigate. At least fix the crazy logging which made me notice the stuck balancer.

Last night my logs filled with this (10x256MB log files):

....
2016-02-01 11:25:26,958 DEBUG [B.defaultRpcServer.handler=9,queue=0,port=16000] balancer.BaseLoadBalancer: Lowest locality region server with non zero regions is ve0542.halxg.cloudera.com with locality 0.0
2016-02-01 11:25:26,958 DEBUG [B.defaultRpcServer.handler=9,queue=0,port=16000] balancer.BaseLoadBalancer:  Lowest locality region index is 0 and its region server contains 1 regions
...


Added by this:

commit 54028140f4f19a6af81c8c8f29dda0c52491a0c9
Author: tedyu <yuzhihong@gmail.com>
Date:   Thu Aug 13 09:11:59 2015 -0700

    HBASE-13376 Improvements to Stochastic load balancer (Vandana Ayyalasomayajula)

Looks like balancer got stuck. Logging at ten lines a millisecond.

Here is lead up. Nothing in particular jumps out. Rerun doesn't show this.

{code}
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0526.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0532.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0538.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Lowest locality region server with non zero regions is ve0540.halxg.cloudera.com with locality 0.0
2016-01-28 05:56:22,572 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer:  Lowest locality region index is 0 and its region server contains 1 regions
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0526.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0532.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0538.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Lowest locality region server with non zero regions is ve0540.halxg.cloudera.com with locality 0.0
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer:  Lowest locality region index is 0 and its region server contains 1 regions
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0526.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0532.halxg.cloudera.com had 0 regions.
2016-01-28 05:56:22,573 DEBUG [ve0524.halxg.cloudera.com,16000,1453988766013_ChoreService_1] balancer.BaseLoadBalancer: Server ve0538.halxg.cloudera.com had 0 regions.
....
{code}

Nothing else is happening on this master

Happens just after a Master joins cluster after being killed by a monkey.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13068,"I just came across in interesting exception:
{code}
Caused by: java.io.IOException: Call 10 not added as the connection newbunny/127.0.0.1:60020/ClientService/lars (auth:SIMPLE)/60000 is closing
        at org.apache.hadoop.hbase.ipc.RpcClient$Connection.addCall(RpcClient.java:495)
        at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1534)
        at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
        ... 13 more
{code}

Called from here:
{code}
        at org.apache.hadoop.hbase.client.ScannerCallable.close(ScannerCallable.java:291)
        at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:160)
        at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:115)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:91)
        at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:247)
{code}

This happened when I scanned with multiple client against a single region server when all data is filtered at the server by a filter.
I had 10 clients, the region server has 30 handles.

This means the scanners are not getting closed and their lease has to expire.

The workaround is to increase hbase.ipc.client.connection.maxidletime.
But it's strange that this *only* happens at close time. And since I am not using up all handlers there shouldn't be any starvation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1803,"this is a problem because we'd like to, for example, flush edits every second, yet we dont want to run all threads at a 10s interval (eg: lease checking, etc)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1826,"the replication level affects sync performance, so being able to tweak the r= level for HLog only can help.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1155,"In order to guarantee that an HLog sync() flushes the data to the HDFS, we will need to invoke FSDataOutputStream.sync() per HADOOP-4379.

Currently, there is no access to the underlying FSDataOutputStream from SequenceFile.Writer, as it is a package private member.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1700,"Look at the below from a cluster startup:

{code}
2009-07-24 16:42:04,013 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0006339440,1248391327448 from aa0-000-15.u.powerset.com,60020,1248453637413; 1 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0093409083,1248414246318 from aa0-000-15.u.powerset.com,60020,1248453637413; 2 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0132179111,1248393175577 from aa0-000-15.u.powerset.com,60020,1248453637413; 3 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0140578751,1248393308563 from aa0-000-15.u.powerset.com,60020,1248453637413; 4 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_PROCESS_OPEN: TestTable,0037750701,1248391815865 from aa0-000-15.u.powerset.com,60020,1248453637413; 5 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0144734891,1248393369432 from aa0-000-15.u.powerset.com,60020,1248453637413; 6 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0006339440,1248391327448 from aa0-000-15.u.powerset.com,60020,1248453637413; 7 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0093409083,1248414246318 from aa0-000-15.u.powerset.com,60020,1248453637413; 8 of 11
2009-07-24 16:42:04,014 [IPC Server handler 19 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_OPEN: TestTable,0132179111,1248393175577 from aa0-000-15.u.powerset.com,60020,1248453637413; 9 of 11
{code}

A regionserver, in the one report has messages reporting both region OPENING and region OPEN messages on the same region.  Regionserver should save the master work and do some edits on its side only returning the OPEN message.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1666,"initial scan completed flag is set on scanner though it hasn't been deployed never mind scanned.  This means we pass out of safe mode soon after startup.

Even if metascanner is fixed so initialScan does not complete till after .META. has been scanned the first time, 'safe mode' seems to mess with region assignment in a way that makes it crawl.

Investigate and fix.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-934,"From Rong-en who has two regionservers:

{code}
When the second HRS starts up, but when all regions
are still not assigned to the first server. The 2nd HRS keeps
silence (though it's visible at master's ui). Once all regions are
assigned to first server, the balancer kicks in. Finally, the
regions are evenly split to two servers.
{code}

And then on IRC:

{code}
[21:38]    <rafan>    st^ack: got my mail?
[21:48]    <st^ack>    You have two HRSs?
[21:49]    <st^ack>    There is an odd decision made in the master that goes something like ""is there only one regionserver? or are there more"". If it decides the answer is 1, it just dumps all to it.
[21:49]    <st^ack>    My guess is that in your case, it decided that all regions were for server 1.
[21:50]    <st^ack>    Mind making a JIRA? Let the master parcel out the regions... the rate can vary with the number of OPEN messages it gets back.
[21:50]    <st^ack>    Allow that other regions could come in meantime? 
{code}

If many regions, master should allow that while its assigning, other regionservers could come online rather than make the binary decision ""There is only one regionserver in this cluster""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1742,"I killed server with -ROOT-.  It came back eventually but meantime we'd asked a server to open a region.  It failed in the below but then we never try to open the region elsewhere.
{code}
 803 2009-08-04 03:21:12,599 [regionserver/XX.XX.XX.140:60020.worker] ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: unable to process message: MSG_REGION_OPEN: TestTable,0916642860,1249356036404
 804 java.lang.reflect.UndeclaredThrowableException
 805     at $Proxy2.getRegionInfo(Unknown Source)
 806     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRootRegion(HConnectionManager.java:874)
 807     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:515)
 808     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:491)
 809     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:565)
 810     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:524)
 811     at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:491)
 812     at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:125)
 813     at org.apache.hadoop.hbase.RegionHistorian.online(RegionHistorian.java:315)
 814     at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:1564)
 815     at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:1485)
 816     at java.lang.Thread.run(Unknown Source)
 817 Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: -ROOT-,,0
 818     at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2261)
 819     at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionInfo(HRegionServer.java:1741)
 820     at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
 821     at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
 822     at java.lang.reflect.Method.invoke(Unknown Source)
 823     at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
 824     at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
 825 
 826     at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:720)
 827     at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:328)
 828     ... 12 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1461,"I have been playing with ZK recovery and other crash scenarios.  There is a very rare but potential bug where a region can be assigned to be open on an existing regionserver, but the regionserver itself doesn't have the region open.

The HMaster should also check the opposite of what it does - make sure that regions assigned to server X are actually _open_ on that server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3192,"A .META. without an HRI entry should never happen but if it does, it should not cause master shutdown (master is on a hair-trigger at mo. so that issues are noticed quickly).  HBASE-3151 fixed being able to deal w/ empty HRI.  This issue is about adding a test to verify hbase stays up (make sure chore runs and that test does meta scanning with MetaScanner and MetaReader).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3698,Can get them from Server Interface.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3425,"On regionserver startup, the regionserver receives an HServerAddress from the master as a Writable.  It's a string hostname and an integer port.  Our master is also appending the port to the string, so when they are concatenated it becomes hadoopnode98:60020:60020 and the HServerAddress cannot be instantiated.  

This should probably be fixed in the master as well, but I don't know where it happens.  The attached patch handles it in the regionserver.

Regionserver startup log:

2011-01-06 15:55:48,813 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Connected to master at hadoopmaster.hotpads.srv:60000
2011-01-06 15:55:48,857 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Telling master at hadoopmaster.hotpads.srv:60000 that we are up
2011-01-06 15:55:48,910 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Config from master: hbase.regionserver.address=HadoopNode98.hotpads.srv:60020
2011-01-06 15:55:48,910 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Config from master: fs.default.name=hdfs://hadoopmaster.hotpads.srv:54310/hbase
2011-01-06 15:55:48,910 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://hadoopmaster.hotpads.srv:54310/hbase
2011-01-06 15:55:48,945 ERROR org.apache.hadoop.hbase.HServerAddress: Could not resolve the DNS name of HadoopNode98.hotpads.srv:60020:60020
2011-01-06 15:55:48,945 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: STOPPED: Failed initialization
2011-01-06 15:55:48,947 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Failed init
java.lang.IllegalArgumentException: Could not resolve the DNS name of HadoopNode98.hotpads.srv:60020:60020
        at org.apache.hadoop.hbase.HServerAddress.checkBindAddressCanBeResolved(HServerAddress.java:105)
        at org.apache.hadoop.hbase.HServerAddress.<init>(HServerAddress.java:76)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.handleReportForDutyResponse(HRegionServer.java:798)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.tryReportForDuty(HRegionServer.java:1394)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:522)
        at java.lang.Thread.run(Thread.java:619)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2354,we should use the old code which is more efficient and may have better error reporting for small number of commit rows. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2356,"we need a better test for this and a fix. i have seen, and have heard other people complain, about situations when regions move and the client does not seem to always relocate the region properly in a post HBASE-2066 hbase client.  I have seen cases where this DOES work so there is investigation to be done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2800,"TestMergeMeta and TestMergeTool both fail in hudson yet pass on local workstations.  Looking at the error for TestMergeMeta, the test complains '.META.' is online and thus cannot merge, but according to the code, these regions are being closed after they were created, and the mini HBase cluster is not started.  

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2671,"{code}java.lang.NullPointerException
    at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:351)
    at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:313)
    at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:176)
    at org.apache.hadoop.ipc.Client.getConnection(Client.java:860)
    at org.apache.hadoop.ipc.Client.call(Client.java:720)
    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
    at $Proxy7.getProtocolVersion(Unknown Source)
    at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
    at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
    at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
    at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
    at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:95)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:746)
    at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.init(MiniHBaseCluster.java:161)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:427)
    at org.apache.hadoop.hbase.MiniHBaseCluster$MiniHBaseClusterRegionServer.run(MiniHBaseCluster.java:169)
    at java.lang.Thread.run(Thread.java:619)
{code}

See log attached to hbase-2614 for better context.

This issue is likely related to HBASE-2425, ""Crossport HADOOP-1849 rpc fix""

Brought it into 0.21.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3898,It hangs for 15 minutes.  I see a NPE trying to split a region.  The splitKey passed is null.  Looks to be by-product of recent compaction refactorings.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2493,"We use it in an unsafe manner in  HBasedBackedTransactionalLogger and in IndexedRegion. On upgrading from 20.1 to 0.20.4-RC I start to get CME's in HTable.

Fix by moving to an HTablePool.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2232,"The following code, which attempts to insert certain number of rows into a table. 
This is running with hbase 0.20.3 after downloading without changing config.
Does not work if there is more than 500K or so rows .
I can see data being created in $HBASE_HOME/TestTable/xxxx/test_family where xxxx is a number. 
But the data disappear once it get 3  files of size around 16MB.
I guess it is being compacted or moved to somewhere ? But I see nothing in $HBASE_HOME/TestTable/compaction.dir.

To create 2Million rows , run it as  java  Test 2000
To create 10 Millions rows, run it as java Test 10000


import java.io.*;
import java.util.*;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.io.BatchUpdate;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.HBaseAdmin;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.ResultScanner;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.util.Bytes;

public class Test{

    public static HTable getTable(HBaseConfiguration config, String tableName, String[] columnFamilies)throws IOException{
	HBaseAdmin admin  = new HBaseAdmin(config);	
	createTable(admin, tableName, columnFamilies);
	HTable table =  new HTable(config, tableName);	
	table.setAutoFlush(false);
	table.setWriteBufferSize(1024*1024*12);
	return table;
    }

    public static boolean createTable(HBaseAdmin admin, String tableName, String[] columnFamilies)throws IOException{
	if(admin.tableExists(tableName))return false;
	HTableDescriptor desc  = new HTableDescriptor(tableName);
	for(String s : columnFamilies){
	    HColumnDescriptor col = new HColumnDescriptor(s.getBytes());
	    col.setMaxVersions(1);
	    desc.addFamily(col);
	}
	admin.createTable(desc);
	return true;
    }
    
    public static void test_serial_insert(HTable table, String family, int count)throws IOException{ 
	byte[] bf = Bytes.toBytes(family);
	for(int i = 0; i < count; i++){
	    int  id          = i;
	    byte[] qualifier = Bytes.toBytes(i); // ""i""
	    byte[] key       = Bytes.toBytes(i);
	    byte[] val       = Bytes.toBytes(i);
	    Put put = new Put(key);
	    put.setWriteToWAL(false); 
	    put.add(bf, qualifier, 0, val); 
	    table.put(put);
	    if( (i+1) % 1000000 == 0){System.out.println( (i+1)/1000000 +  ""  M""); }
	}
	table.flushCommits();
    }

    public static void count(HTable table)throws IOException{
	Scan scan = new Scan();
	ResultScanner scanner = table.getScanner(scan);       
	Result result = null;
	int i = 0;
	while( (result = scanner.next()) != null  ){
	    byte[] key  = result.getRow();
	    ++i;
	    if(i % 10000 == 0)System.out.println(i);
	}
	System.out.println(""TOTAL========== ""+i);
    }

    public static void removeTable(HBaseAdmin admin, String tableName)throws IOException{
	if(!admin.tableExists(tableName))return;
	admin.disableTable(tableName);
	admin.deleteTable(tableName);
    }
    
    public static void main(String[] args)throws Exception{
	int k = 1000;
	boolean insert = true;
	if(args.length > 0){
	    if(""read"".equals(args[0]))insert = false;
	    else k = Integer.parseInt(args[0]);
	}
	
	HBaseConfiguration config = new HBaseConfiguration();
	String tableName = ""TestTable"";
	String familyName = ""test_family"";
	HBaseAdmin admin  = new HBaseAdmin(config);
	removeTable(admin, tableName);
	HTable table = getTable(config, tableName, new String[]{familyName});
	if(insert)test_serial_insert(table, familyName, k*1000);
	count(table);
    }
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2278,"My tests have picked up a regression on branch:

test:
     [echo] contrib: indexed
...
    [junit] Running org.apache.hadoop.hbase.regionserver.TestHRegionWithIdxRegionNoIndexes
    [junit] Tests run: 41, Failures: 1, Errors: 0, Time elapsed: 18.382 sec
    [junit] Test org.apache.hadoop.hbase.regionserver.TestHRegionWithIdxRegionNoIndexes FAILED


Error Message

i=101 expected:<1000> but was:<0>

Stacktrace

junit.framework.AssertionFailedError: i=101 expected:<1000> but was:<0>
	at org.apache.hadoop.hbase.regionserver.TestHRegion.testWritesWhileGetting(TestHRegion.java:2085)

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3933,"NullPointerException while hmaster starting.
{code}
      java.lang.NullPointerException
        at java.util.TreeMap.getEntry(TreeMap.java:324)
        at java.util.TreeMap.get(TreeMap.java:255)
        at org.apache.hadoop.hbase.master.AssignmentManager.addToServers(AssignmentManager.java:1512)
        at org.apache.hadoop.hbase.master.AssignmentManager.regionOnline(AssignmentManager.java:606)
        at org.apache.hadoop.hbase.master.AssignmentManager.processFailover(AssignmentManager.java:214)
        at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:402)
        at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:283)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14659,"As i said in HBASE-14654
This testcase was hanged twice recently.   

the two QA information:
https://builds.apache.org/job/PreCommit-HBASE-Build/16118/console
https://builds.apache.org/job/PreCommit-HBASE-Build/16117/console

I notice that the two QA running simultaneously on same machine H0.
I doubt If there are some common resources the two QA conflicts.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7755,"I was looking at and profiling the BlockEncoding code to figure out how to make it faster. One issue that jumped out was we call ByteBuffer.allocate(...) for each single KV.
As an experiment I tried using the MemStoreLAB code to allocate those buffers.

Here are some preliminary numbers, all scanning 10m rows (all in cache):
* no encoding: 5.2s
* FAST_DIFF without patch: 7.3s
* FAST_DIFF with patch and small LAB: 4.1s
* FAST_DIFF with patch and large LAB: 11s

So this is very sensitive to the right sizing of the LAB.

Need to do a bit more testing, but it seems that there is a chance to actually make scanning with block encoding faster than without!
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12325,"If there are several snapshots exported to a single directory, it's nice to be able to remove the oldest one. Since snapshots in the same directory can share files it's not as simple as just removing all files in a snapshot.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9904,"The HTable client cannot retry a scan operation in the getRegionServerWithRetries code path.
This will result in the client missing data. This can be worked around using hbase.client.retries.number to 1.

The whole problem is that Callable knows nothing about retries and the protocol it dances to as well doesn't support retires.
This fix will keep Callable protocol (ugly thing worth merciless refactoring) intact but will change
ScannerCallable to anticipate retries. What we want is to make failed operations to be identities for outside world:
N1 , N2 , F3 , N3 , F4 , F4 , N4 ... = N1 , N2 , N3 , N4 ...
where Nk are successful operation and Fk are failed operations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5210,"We run an overnight map/reduce job that loads data from an external source and adds that data to an existing HBase table.  The input files have been loaded into hdfs.  The map/reduce job uses the HFileOutputFormat (and the TotalOrderPartitioner) to create HFiles which are subsequently added to the HBase table.  On at least two separate occasions (that we know of), a range of output would be missing for a given day.  The range of keys for the missing values corresponded to those of a particular region.  This implied that a complete HFile somehow went missing from the job.  Further investigation revealed the following:

 * Two different reducers (running in separate JVMs and thus separate class loaders)
 * in the same server can end up using the same file names for their
 * HFiles.  The scenario is as follows:
 * 	1.	Both reducers start near the same time.
 * 	2.	The first reducer reaches the point where it wants to write its first file.
 * 	3.	It uses the StoreFile class which contains a static Random object 
 * 		which is initialized by default using a timestamp.
 * 	4.	The file name is generated using the random number generator.
 * 	5.	The file name is checked against other existing files.
 * 	6.	The file is written into temporary files in a directory named
 * 		after the reducer attempt.
 * 	7.	The second reduce task reaches the same point, but its StoreClass
 * 		(which is now in the file system's cache) gets loaded within the
 * 		time resolution of the OS and thus initializes its Random()
 * 		object with the same seed as the first task.
 * 	8.	The second task also checks for an existing file with the name
 * 		generated by the random number generator and finds no conflict
 * 		because each task is writing files in its own temporary folder.
 * 	9.	The first task finishes and gets its temporary files committed
 * 		to the ""real"" folder specified for output of the HFiles.
 *     10.	The second task then reaches its own conclusion and commits its
 * 		files (moveTaskOutputs).  The released Hadoop code just overwrites
 * 		any files with the same name.  No warning messages or anything.
 * 		The first task's HFiles just go missing.
 * 
 *  Note:  The reducers here are NOT different attempts at the same 
 *  	reduce task.  They are different reduce tasks so data is
 *  	really lost.

I am currently testing a fix in which I have added code to the Hadoop 
FileOutputCommitter.moveTaskOutputs method to check for a conflict with
an existing file in the final output folder and to rename the HFile if
needed.  This may not be appropriate for all uses of FileOutputFormat.
So I have put this into a new class which is then used by a subclass of
HFileOutputFormat.  Subclassing of FileOutputCommitter itself was a bit 
more of a problem due to private declarations.

I don't know if my approach is the best fix for the problem.  If someone
more knowledgeable than myself deems that it is, I will be happy to share
what I have done and by that time I may have some information on the
results.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14113,"mvn package -DskipTests

Compile failed!  

{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.2:compile (default-compile) on project hbase-client: Compilation failure: Compilation failure:
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/BinaryComparator.java:[54,3] method does not override or implement a method from a supertype
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/NullComparator.java:[64,3] method does not override or implement a method from a supertype
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/LongComparator.java:[51,5] method does not override or implement a method from a supertype
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/BitComparator.java:[137,3] method does not override or implement a method from a supertype
[ERROR] /Users/chenheng/apache/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/BinaryPrefixComparator.java:[56,3] method does not override or implement a method from a supertype
{code}

My java version:
{code}
java version ""1.8.0_40""
Java(TM) SE Runtime Environment (build 1.8.0_40-b25)
Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, mixed mode)
{code}


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9939,"Under load when I disabled network interface, all HBase threads were locked out.  I was expecting these threads to be released based on client.operation.timeout and rpc,timeout.

Here is a link for  thread dump.
https://www.dropbox.com/s/y1ng3yoywq09x2u/HBaseClient_Threaddump.txt

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6153,"I had a RS crash with the following:

2012-05-31 18:34:42,534 DEBUG org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://ip-10-140-14-134.ec2.internal:8020/apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/.tmp/294a7a31f04949b8bf07682a43157b35 to hdfs://ip-10-140-14-134.ec2.internal:8020/apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/f1/294a7a31f04949b8bf07682a43157b35
2012-05-31 18:34:42,536 WARN org.apache.hadoop.hbase.regionserver.Store: Unable to rename hdfs://ip-10-140-14-134.ec2.internal:8020/apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/.tmp/294a7a31f04949b8bf07682a43157b35 to hdfs://ip-10-140-14-134.ec2.internal:8020/apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/f1/294a7a31f04949b8bf07682a43157b35
2012-05-31 18:34:42,541 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: ABORTING region server ip-10-68-7-146.ec2.internal,60020,1338343120038: Replay of HLog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: TestLoadAndVerify_1338488017181,\x15\xD9\x01\x00\x00\x00\x00\x00/000087_0,1338491364569.8974506aa04c5a04e5cc23c11de0039d.
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1288)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1172)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1114)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:400)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:374)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:243)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.FileNotFoundException: File does not exist: /apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/f1/294a7a31f04949b8bf07682a43157b35
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1901)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.<init>(DFSClient.java:1892)
        at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:636)
        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:154)
        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:427)
        at org.apache.hadoop.hbase.io.hfile.HFile.createReader(HFile.java:387)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.<init>(StoreFile.java:1008)
        at org.apache.hadoop.hbase.regionserver.StoreFile.open(StoreFile.java:470)
        at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:548)
        at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:595)


On the NameNode logs:
2012-05-31 18:34:42,588 WARN org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.unprotectedRenameTo: failed to rename /apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/.tmp/294a7a31f04949b8bf07682a43157b35 to /apps/hbase/data/TestLoadAndVerify_1338488017181/8974506aa04c5a04e5cc23c11de0039d/f1/294a7a31f04949b8bf07682a43157b35 because destination's parent does not exist


I haven't looked deeply yet but I guess it is a race of some sort.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3138,"Testing rolling restart i turned up the following condition.

Master is joining an extant cluster and is trying to clean up RIT.  Then the server hosting .META. is shutdown in the middle of it all.  Deal.  Here is exception.

{code}
2010-10-21 06:45:58,592 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=sv2borg187,60020,1287643131919, region=efcd899283e96f20faa317772f52adca
2010-10-21 06:45:58,616 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
org.apache.hadoop.ipc.RemoteException: java.io.IOException: Server not running
    at org.apache.hadoop.hbase.regionserver.HRegionServer.checkOpen(HRegionServer.java:2198)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1499)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:561)
    at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025)

    at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:749)
    at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:255)
    at $Proxy1.get(Unknown Source)
    at org.apache.hadoop.hbase.catalog.MetaReader.getRegion(MetaReader.java:286)
    at org.apache.hadoop.hbase.master.AssignmentManager.processRegionInTransition(AssignmentManager.java:250)
    at org.apache.hadoop.hbase.master.AssignmentManager.processFailover(AssignmentManager.java:209)
    at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:392)
    at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:268)
2010-10-21 06:45:58,617 INFO org.apache.hadoop.hbase.master.HMaster: Aborting
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8064,"when hconnection is used by one matchine,the connection return to the pool. if anather matchine reget the connection,it can be resued.
but in the code the caching map don't be managered correctly",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6144,"RS abcdn0590 is live, but Master does not have it on its onlineserver list. So, Master put up the hlog for splitting as shown in the Master log below:
{code}
2012-05-17 21:43:57,692 INFO org.apache.hadoop.hbase.master.SplitLogManager: task /hbase/splitlog/hdfs%3A%2F%2Fnamenode.xyz.com%2Fhbase%2F.logs%2Fabcdn0590.xyz.com%2C60020%2C1337315957185-splitting%2Fabcdn0590.xyz.com%252C60020%252C1337315957185.1337315957711 acquired by abcdn0770.xyz.com,60020,1337315956278. 
{code}

After splitting succeeded, Master deleted the file:
{code}
2012-05-17 21:43:58,721 DEBUG org.apache.hadoop.hbase.master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitlog/hdfs%3A%2F%2Fnamenode.xyz.com%2Fhbase%2F.logs%2Fabcdn0590.xyz.com%2C60020%2C1337315957185-splitting%2Fabcdn0590.xyz.com%252C60020%252C1337315957185.1337315957711
{code}

RS abcdn0590 lost the lease to RS abcdn0770, and try to do a Log Roller which closes the current hlog, and create a new one, as shown in the namenode log:
{code}
2012-05-17 21:43:58,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(newblock=blk_2867982016684075739_12741027, file=/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185-splitting/abcdn0590.xyz.com%2C60020%2C1337315957185.1337315957711, newgenerationstamp=12911920, newlength=134, newtargets=[10.115.13.24:50010, 10.115.15.46:50010, 10.115.15.23:50010]) successful
2012-05-17 21:43:59,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.logs/abcdn0590.xyz.com,60020,1337315957185/abcdn0590.xyz.com%2C60020%2C1337315957185.1337316238882. blk_3811725326431482476_12913541{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.115.13.24:50010|RBW], ReplicaUnderConstruction[10.115.17.18:50010|RBW], ReplicaUnderConstruction[10.115.17.15:50010|RBW]]}
{code}
 
When RS 0590 try to close the old hlog 1337315957711, it received fatal error below due to the original hlog is already deleted. The fatal error will cause RS abcdn0590 to shutdown itself later.
{code}
2012-05-17 21:43:58,889 ERROR org.apache.hadoop.hbase.master.HMaster: Region server ^@^@abcdn0590.xyz.com,60020,1337315957185 reported a fatal error:
ABORTING region server abcdn0590.xyz.com,60020,1337315957185: IOE in log roller
Cause:
java.io.FileNotFoundException: File does not exist: hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185/abcdn0590.xyz.com%2C60020%2C1337315957185.1337315957711
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:742)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.rollWriter(HLog.java:583)
        at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:94)
{code}
 
RS abcdn0590 shutdown at around 21:44. But in the /hbase/.logs dir, it left two sub folder for the RS abcdn0590 with the same startcode 1337315957185 , they are
路         /hbase/.logs/abcdn0590.xyz.com,60020,1337315957185-splitting/
路         /hbase/.logs/abcdn0590.xyz.com,60020,1337315957185/
 
Later on, at around 21:46:30, Master retry log splitting, this time,  it still consider RS abcdn0590 as dead RS and try to put up its hlog for others to grab and split. It finds the folder /hbase/.logs/abcdn0590.xyz.com,60020,1337315957185/, and the first step it does is to rename it to adding suffix of 鈥搒plitting.  However, the same folder already exist. The rename function does not handle the case where the destination folder already exist, instead, the behavior is putting the src folder under the dst folder, so the path structure looks like dst/src/file. In our case, It is /hbase/.logs.20120518.1204/abcdn0590.xyz.com,60020,1337315957185-splitting/abcdn0590.xyz.com,60020,1337315957185/abcdn0590.xyz.com%2C60020%2C1337315957185.1337316238882.
 
This is from the master log, we can see that two folders for the same RS 0590 at same startcode exists:
{code}
2012-05-17 21:46:30,749 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1329941607395-splitting doesn't belong to a known region server, splitting
2012-05-17 21:46:30,749 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185 doesn't belong to a known region server, splitting
2012-05-17 21:46:30,749 INFO org.apache.hadoop.hbase.master.MasterFileSystem: Log folder hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185-splitting doesn't belong to a known region server, splitting
 
2012-05-17 21:46:30,962 DEBUG org.apache.hadoop.hbase.master.MasterFileSystem: Renamed region directory: hdfs://namenode.xyz.com/hbase/.logs/abcdn0590.xyz.com,60020,1337315957185-splitting
{code}

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5805,"Trace:

java.lang.AssertionError: Results should contain region test,ccc,1334638013935.b9d77206f6eb226928b898e66fd1d508. for row 'ccc'
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.verifyRegionResults(TestServerCustomProtocol.java:363)
	at org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.testNullReturn(TestServerCustomProtocol.java:330)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5779,"Steps to reproduce: 
- change permission of /hbase to a user other than one running hbase
- delete hbase.id if already exists
- start master, it will try to create cluster ID file in /hbase and fail while doing so with org.apache.hadoop.security.AccessControlException

From this point it will go to infinite loop. 

Reason: org.apache.hadoop.hbase.util.FSUtils.setClusterId  has a wait > 0 and no control over retries when called during master initialization. 

Quoting : checkRootDir in MasterFileSystem
{noformat}
// Make sure cluster ID exists
    if (!FSUtils.checkClusterIdExists(fs, rd, c.getInt(
        HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000))) {
      FSUtils.setClusterId(fs, rd, UUID.randomUUID().toString(), c.getInt(
          HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000));
    }

{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4822,"TestCoprocessorEndpoint is failing intermittently in Jenkins.  The errors are all similar to:
{noformat}
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint
-------------------------------------------------------------------------------
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 30.562 sec <<< FAILURE!
testAggregation(org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint)  Time elapsed: 0.069 sec  <<< FAILURE!
java.lang.AssertionError: Invalid result expected:<180> but was:<190>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.testAggregation(TestCoprocessorEndpoint.java:149)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5092,"  
Region is in PENDING_OPEN state and disable and enable are blocked.

We occasionally find if two assignments which have a short interval time will lead to a PENDING_OPEN state staying in the regionInTransition map and blocking the disable and enable table actions.

We found that the second assignment will set the zknode of this region to M_ZK_REGION_OFFLINE then set the state in assignmentMananger's regionInTransition map to PENDING_OPEN and abort its further operation because of finding the the region is already in the regionserver by a RegionAlreadyInTransitionException.
At the same time the first assignment is tickleOpening and find the version of the zknode is messed up by the  second assignment, so the OpenRegionHandler print out the following two lines:

{noformat} 
2011-12-23 22:12:15,197 WARN  [RS_OPEN_REGION-data16,59892,1324649528415-0] zookeeper.ZKAssign(788): regionserver:59892-0x1346b43b91e0002 Attempt to transition the unassigned node for 15237599c632752b8cfd3d5a86349768 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING failed, the node existed but was version 2 not the expected version 1
2011-12-23 22:12:15,197 WARN  [RS_OPEN_REGION-data16,59892,1324649528415-0] handler.OpenRegionHandler(403): Failed refreshing OPENING; region=15237599c632752b8cfd3d5a86349768, context=post_region_open
{noformat} 

After that it tries to turn the state to FAILED_OPEN, but also failed due to wrong version,

this is the output:

{noformat} 
2011-12-23 22:12:15,199 WARN  [RS_OPEN_REGION-data16,59892,1324649528415-0] zookeeper.ZKAssign(812): regionserver:59892-0x1346b43b91e0002 Attempt to transition the unassigned node for 15237599c632752b8cfd3d5a86349768 from RS_ZK_REGION_OPENING to RS_ZK_REGION_FAILED_OPEN failed, the node existed but was in the state M_ZK_REGION_OFFLINE set by the server data16,59892,1324649528415
2011-12-23 22:12:15,199 WARN  [RS_OPEN_REGION-data16,59892,1324649528415-0] handler.OpenRegionHandler(307): Unable to mark region {NAME => 'table1,,1324649533045.15237599c632752b8cfd3d5a86349768.', STARTKEY => '', ENDKEY => '', ENCODED => 15237599c632752b8cfd3d5a86349768,} as FAILED_OPEN. It's likely that the master already timed out this open attempt, and thus another RS already has the region.
{noformat} 

So after all that, the PENDING_OPEN state is left in the assignmentMananger's regionInTransition map and none will deal with it further,
This kind of situation will wait until the master find the state out of time.


The following is the test code:

{code:title=test.java|borderStyle=solid}
@Test
  public void testDisableTables() throws IOException {
    for (int i = 0; i < 20; i++) {
      HTableDescriptor des = admin.getTableDescriptor(Bytes.toBytes(table1));
      List<HRegionInfo> hris = TEST_UTIL.getHBaseCluster().getMaster()
          .getAssignmentManager().getRegionsOfTable(Bytes.toBytes(table1));
      TEST_UTIL.getHBaseCluster().getMaster()
          .assign(hris.get(0).getRegionName());
  
      TEST_UTIL.getHBaseCluster().getMaster()
          .assign(hris.get(0).getRegionName());
  
      admin.disableTable(Bytes.toBytes(table1));
      admin.modifyTable(Bytes.toBytes(table1), des);
      admin.enableTable(Bytes.toBytes(table1));
    }
  }

{code}

To fix this,we add a line to 

public static int ZKAssign.transitionNode() to make endState.RS_ZK_REGION_FAILED_OPEN transition pass.

{code:title=ZKAssign.java|borderStyle=solid}
   if((!existingData.getEventType().equals(beginState))
      //add the following line to make endState.RS_ZK_REGION_FAILED_OPEN transition pass.
      &&(!endState.equals(endState.RS_ZK_REGION_FAILED_OPEN))) {
      LOG.warn(zkw.prefix(""Attempt to transition the "" +
        ""unassigned node for "" + encoded +
        "" from "" + beginState + "" to "" + endState + "" failed, "" +
        ""the node existed but was in the state "" + existingData.getEventType() +
        "" set by the server "" + serverName));
      return -1;
    }
{code}

Run the test case again we found that before the first assignment trans the state from offline to opening, the second assignment could set the state to offline again and messed up the version of zknode.


In OpenRegionHandler.process() the following part failed and make the process() return.
{code:title=OpenRegionHandler.java|borderStyle=solid}
 if (!transitionZookeeperOfflineToOpening(encodedName,
          versionOfOfflineNode)) {
        LOG.warn(""Region was hijacked? It no longer exists, encodedName="" +
          encodedName);
        return;
{code}      }

//So we add the following code to the part to make this open region process to FAILED_OPEN.

{code:title=OpenRegionHandler.java|borderStyle=solid}
 if (!transitionZookeeperOfflineToOpening(encodedName,
          versionOfOfflineNode)) {
        LOG.warn(""Region was hijacked? It no longer exists, encodedName="" +
          encodedName);
        tryTransitionToFailedOpen(regionInfo);
        return;
      }
{code}

After the two amendments, two adjacent assignments will not lead to an unhandled PENDING_OPEN state.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4866,"NPE encountered in users's HMaster logs:

{code}
11/11/22 23:45:37 FATAL master.HMaster: Unhandled exception. Starting shutdown.
java.lang.NullPointerException
   at org.apache.hadoop.hbase.master.AssignmentManager.regionOnline(AssignmentManager.java:731)
   at org.apache.hadoop.hbase.master.AssignmentManager.processFailover(AssignmentManager.java:215)
   at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:422)
   at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:295)
{code}

From user list: http://mail-archives.apache.org/mod_mbox/hbase-user/201111.mbox/%3C4ECC9AFC.6030307%40qualtrics.com%3E
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4590,"In the following case:

1.first,kill all the regionservers
2.then, start all the regionservers immediately
3.then, kill all the regionservers immediately
4.then, start all the regionservers immediately

Master may assign META region twice , and make two regionserver carrying META region.

Through logs, we find that:
Before 1, Regionserver A carrys the META region,

Between 2 and 3 , master receives Regionserver A startup message and is ready to assign meta region to Regionserver B

But, it fails because of 3, and then reassign meta region to Regionserver C,Then ,it is successful after 4,

when 4 , Regionserver C is started earlier than Regionserver A , and Regionserver A is started earlier than Regionserver C successfully online the META region. Therefore, when master receives Regionserver A startup message in 4, it consider Regionserver A carryed META region through  CatalogTracker and create a MetaServerShutdownHandler

In MetaServerShutdownHandler's process(), after completing split hlog, Regionserver C has already onlined META region,
however it will execute the following code all the same where isCarryingMeta() return true :
if (isCarryingMeta())this.services.getAssignmentManager().assignMeta();

After that, META region will online on two regionservers


In order to prevent it , we should verify meta region location before assign Meta region .
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7116,"org.apache.hadoop.hbase.TestZooKeeper unit tests were failed with testClientSessionExpired method as follwoing:

---------------------------------------------------------

Tests run: 5, Failures: 1, Errors: 0, Skipped: 0

testClientSessionExpired(org.apache.hadoop.hbase.TestZooKeeper)

java.lang.AssertionError:
at org.apache.hadoop.hbase.TestZooKeeper.testClientSessionExpired(TestZooKeeper.java:114)

impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-datanode.properties, hadoop-metrics2.properties
2012-01-22 01:44:45,764 WARN  [main] util.MBeans(59): Hadoop:service=DataNode,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
2012-01-22 01:46:07,153 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(336): org.apache.hadoop.hbase.TestZooKeeper-0x135015e9f9e000d Received Disconnected from ZooKeeper, ignoring
2012-01-22 01:46:07,157 WARN  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@55565556] datanode.DataXceiverServer(138): DatanodeRegistration(127.0.0.1:41145, storageID=DS-1858213200-9.123.196.159-41145-1327167899969, infoPort=36485, ipcPort=55138):DataXceiveServer:java.nio.channels.AsynchronousCloseException

Shutting down DataNode 0
2012-01-22 01:46:08,160 WARN  [main] util.MBeans(73): Hadoop:service=DataNode,name=FSDatasetState-UndefinedStorageId-1051654067
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-UndefinedStorageId-1051654067
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7868,"By HFilePerformanceEvaluation seems that 0.94 is slower then 0.92

Looking at the profiler for the Scan path, seems that most of the time, compared to 92, is spent in the metrics dictionary lookup. [~eclark] pointed out the new per family/block metrics.

By commenting the metrics call in HFileReaderV2, the performance seems to get better, but maybe metrics is not the only problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13110,"TestCoprocessorEndpoint hangs with repeated RPC retries (RpcRetryingCallerImpl.callWithRetries) after the ProtobufCoprocessorService throws the test exception. Looks like a change on trunk has broken TestCoprocessorEndpoint.

jstack of interest:
{noformat}
""main"" prio=5 tid=0x00007f87eb003000 nid=0x1303 in Object.wait() [0x0000000105173000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        - waiting on <0x00000007c91aedf8> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:162)
        - locked <0x00000007c91aedf8> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.callExecService(RegionCoprocessorRpcChannel.java:
95)
        at org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.callBlockingMethod(CoprocessorRpcChannel.java:73)
        at org.apache.hadoop.hbase.ipc.protobuf.generated.TestRpcServiceProtos$TestProtobufRpcProto$BlockingStub.error(TestRpcServiceProtos.java:378)
        at org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.testCoprocessorError(TestCoprocessorEndpoint.java:308)
{noformat}

Tail of the log has entries like:
{noformat}
2015-02-25 18:50:03,659 DEBUG [B.defaultRpcServer.handler=3,queue=0,port=56093] ipc.CallRunner(110): B.defaultRpcServer.handler=3,queue=0,port=56093: callId: 75 service: ClientService methodName: ExecService size: 141 connection: 10.3.31.30:56149
java.io.IOException: Test exception
	at org.apache.hadoop.hbase.coprocessor.ProtobufCoprocessorService.error(ProtobufCoprocessorService.java:64)
	at org.apache.hadoop.hbase.ipc.protobuf.generated.TestRpcServiceProtos$TestProtobufRpcProto.callMethod(TestRpcServiceProtos.java:210)
	at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:6883)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.execServiceOnRegion(RSRpcServices.java:1696)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.execService(RSRpcServices.java:1678)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:31309)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2038)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13249,"In refreshCache, if step 3 fails for some reason, the successive call may return success directly but the cache is already corrupt (got cleared in the previous failed call):
{quote}
    // 1. update the modified time
    this.lastModifiedTime = lastTimestamp;

    // 2.clear the cache
    this.cache.clear();
    Map<String, SnapshotDirectoryInfo> known = new HashMap<String, SnapshotDirectoryInfo>();

    // 3. check each of the snapshot directories
{quote}

This will cause files got deleted unexpectedly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5289,"This might happen on heavy load in case of lagging HBase when sharing one HConnection by multiple threads:

{noformat}
2012-01-26 13:59:38,396 ERROR [http://*:8080-251-EventThread] zookeeper.ClientCnxn$EventThread(532): Error while calling watcher
java.lang.NullPointerException
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.resetZooKeeperTrackers(HConnectionManager.java:533)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.abort(HConnectionManager.java:1536)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:344)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:262)
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:530)
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:506)
{noformat}

The following code is not protected against NPE:

{code}
    private synchronized void resetZooKeeperTrackers()
        throws ZooKeeperConnectionException {
      LOG.info(""Trying to reconnect to zookeeper"");
      masterAddressTracker.stop();
      masterAddressTracker = null;
      rootRegionTracker.stop();
      rootRegionTracker = null;
      clusterId = null;
      this.zooKeeper = null;
      setupZookeeperTrackers();
    }
{code}

In some cases as proven by the log snippet above it might happen that either masterAddressTracker or rootRegionTracker might be null.
Because of the NPE the code can't reach setupZookeeperTrackers() call.

This should be fixed at least the way as shown in one of the patches in HBASE-5153

{code}
      LOG.info(""Trying to reconnect to zookeeper."");
      if (this.masterAddressTracker != null) {
        this.masterAddressTracker.stop();
        this.masterAddressTracker = null;
      }
      if (this.rootRegionTracker != null) {
        this.rootRegionTracker.stop();
        this.rootRegionTracker = null;
      }
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9066,"This new test has failed a few times over last day or so.

Here is a sample w/ two fails in it.

http://54.241.6.143/job/HBase-0.95/707/

Hope you don't mind me assigning it to you Chris.

I'm going to disable these two tests for now so can get some good test runs in over the w/e.  Thanks boss.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9292,"Running some simple loading tests i ran into the following running on hadoop-2.1.0-beta.

{code}
2013-08-20 16:51:56,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2013-08-20 16:51:56,314 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 655761 synced till here 655750
2013-08-20 16:51:56,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042714402 with entries=985, filesize=122.5 M; new WAL /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716311
2013-08-20 16:51:56,378 WARN  [Thread-4788] hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716311 could only be replicated to 0 nodes instead of minReplication (=1).  There are 5 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2458)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:525)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:387)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59582)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)

        at org.apache.hadoop.ipc.Client.call(Client.java:1347)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at $Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1220)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1073)
...
{code}

Thereafter the server is up but useless and can't go down because it just keeps doing this:


{code}
2013-08-20 16:51:56,380 FATAL [RpcServer.handler=3,port=60020] wal.FSHLog: Could not sync. Requesting roll of hlog
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716311 could only be replicated to 0 nodes instead of minReplication (=1).  There are 5 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2458)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:525)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:387)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59582)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)

        at org.apache.hadoop.ipc.Client.call(Client.java:1347)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at $Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1220)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1073)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:509)
...
{code}

It goes on like this for ever.

here is a bit more log:

{code}
2013-08-21 04:30:07,932 ERROR [regionserver60020.logSyncer] wal.FSHLog: Error while syncing, requesting close of hlog
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716482 could only be replicated to 0 nodes instead of minReplication (=1).  There are 5 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2458)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:525)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:387)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59582)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)

        at org.apache.hadoop.ipc.Client.call(Client.java:1347)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at $Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1220)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1073)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:509)
                                                                                                                                                                                          2993503,2-9   Bot
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)

        at org.apache.hadoop.ipc.Client.call(Client.java:1347)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy13.addBlock(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy13.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:266)
        at $Proxy14.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1220)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1073)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:509)
2013-08-21 04:30:07,932 FATAL [regionserver60020.logSyncer] wal.FSHLog: Could not sync. Requesting roll of hlog
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /hbase/WALs/a2434.halxg.cloudera.com,60020,1377031955847/a2434.halxg.cloudera.com%2C60020%2C1377031955847.1377042716482 could only be replicated to 0 nodes instead of minReplication (=1).  There are 5 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2458)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:525)
{code}

We broke something in here (hadoop-2.0.1-beta going bad of a sudden is interesting tooo)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12846,"Several cases in TestZKLessAMOnCluster frequently fail with timeouts.

On Jenkins: https://builds.apache.org/job/HBase-0.98/791/testReport/

Locally, when failing:

Running org.apache.hadoop.hbase.master.TestZKLessAMOnCluster
Tests run: 17, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 842.524 sec <<< FAILURE! - in org.apache.hadoop.hbase.master.TestZKLessAMOnCluster

Locally, when passing:

Running org.apache.hadoop.hbase.master.TestZKLessAMOnCluster
Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.072 sec - in org.apache.hadoop.hbase.master.TestZKLessAMOnCluster
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12880,"During my work on patch HBASE-7332 I stumbled on strange behaviour in RegionStates. Split region doesn't removed from regionStates in regionOffline() method and RegionState for this region sits in regionStates map indefinitely long (until RS rebooted).
(that is clearly seen in HBASE-7332 by simple creating table and splitting it from command line).

Is that was intended to be so and some chore eventually will remove it from regionStates (didn't find with fast code scanning) or here can be resource leak?

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3243,"I ran some YCSB benchmarks which resulted in about 150 regions worth of data overnight. Then I disabled the table, and the master for some reason closed one region on the wrong server. The server ignored this, but the region remained open on a different server, which later flipped out when it tried to flush due to hlog accumulation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6015,"When after the 1st round of run and possible fixes, HBCK does a rerun to check the consistency of the regions. At this rerun
1.It should check all the regions which it checked in the 1st round. 
2.It should check only those regions which it checked in the 1st round. Might be some other regions can come out of the timelag check at rerun time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5312,"This is in reference to the mail sent in the dev mailing list
""Closed parent region present in Hlog.lastSeqWritten"".

The sceanrio described is

We had a region that was split into two daughters.  When the hlog roll tried to flush the region there was an entry in the HLog.lastSeqWritten that was not flushed or removed from the lastSeqWritten during the parent close.
Because this flush was not happening subsequent flushes were getting blocked
{code}
 05:06:44,422 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Too many
 hlogs: logs=122, maxlogs=32; forcing flush of 1 regions(s):
 2acaf8e3acfd2e8a5825a1f6f0aca4a8
 05:06:44,422 WARN org.apache.hadoop.hbase.regionserver.LogRoller: Failed
 to schedule flush of 2acaf8e3acfd2e8a5825a1f6f0aca4a8r=null,
requester=null
 05:10:48,666 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Too many
 hlogs: logs=123, maxlogs=32; forcing flush of 1 regions(s):
 2acaf8e3acfd2e8a5825a1f6f0aca4a8
 05:10:48,666 WARN org.apache.hadoop.hbase.regionserver.LogRoller: Failed
 to schedule flush of 2acaf8e3acfd2e8a5825a1f6f0aca4a8r=null,
requester=null
 05:14:46,075 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Too many
 hlogs: logs=124, maxlogs=32; forcing flush of 1 regions(s):
 2acaf8e3acfd2e8a5825a1f6f0aca4a8
 05:14:46,075 WARN org.apache.hadoop.hbase.regionserver.LogRoller: Failed
 to schedule flush of 2acaf8e3acfd2e8a5825a1f6f0aca4a8r=null,
requester=null
 05:15:41,584 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Too many
 hlogs: logs=125, maxlogs=32; forcing flush of 1 regions(s):
 2acaf8e3acfd2e8a5825a1f6f0aca4a8
 05:15:41,584 WARN org.apache.hadoop.hbase.regionserver.LogRoller: Failed
 to schedule flush of 2acaf8e3acfd2e8a5825a1f6f0aca4a8r=null,

{code}

Lets see what happened for the region 2acaf8e3acfd2e8a5825a1f6f0aca4a8
{code}
2012-01-06 00:30:55,214 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming flushed file at hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/2acaf8e3acfd2e8a5825a1f6f0aca4a8/.tmp/1755862026714756815 to hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/2acaf8e3acfd2e8a5825a1f6f0aca4a8/value/973789709483406123
2012-01-06 00:30:58,946 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Instantiated Htable_UFDR_016,049790700093168-04565200000,1325809837958.0ebe5bd7fcbc09ee074d5600b9d4e062.
2012-01-06 00:30:59,614 INFO org.apache.hadoop.hbase.regionserver.Store: Added hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/2acaf8e3acfd2e8a5825a1f6f0aca4a8/value/973789709483406123, entries=7537, sequenceid=20312223, memsize=4.2m, filesize=2.9m
2012-01-06 00:30:59,787 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished snapshotting, commencing flushing stores
2012-01-06 00:30:59,787 INFO org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~133.5m for region Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8. in 21816ms, sequenceid=20312223, compaction requested=true
2012-01-06 00:30:59,787 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8. because regionserver20020.cacheFlusher; priority=0, compaction queue size=5840

{code}

A user triggered split has been issued to this region which can be seen in the above logs.
The flushing of this region has resulted in a seq id 20312223.

The region has been splitted and the parent region has been closed
{code}
00:31:12,607 INFO org.apache.hadoop.hbase.regionserver.SplitTransaction: Starting split of region Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8.
00:31:13,694 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Closing Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8.: disabling compactions & flushes
00:31:13,694 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8.
00:31:13,718 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8.
00:31:39,552 INFO org.apache.hadoop.hbase.catalog.MetaEditor: Offlined parent region Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8. in META
00:31:41,374 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/259d0c620c9105928e52713f4a5a252e/value/239119195230239381.2acaf8e3acfd2e8a5825a1f6f0aca4a8, isReference=true, isBulkLoadResult=false, seqid=20201181, majorCompaction=false


2012-01-06 00:31:42,529 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/52ff3c7c6df6e0337876bbca29cee84a/value/973789709483406123.2acaf8e3acfd2e8a5825a1f6f0aca4a8, isReference=true, isBulkLoadResult=false, seqid=20312224, majorCompaction=false

2012-01-06 00:31:42,532 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://192.168.1.103:9000/hbase/Htable_UFDR_031/259d0c620c9105928e52713f4a5a252e/value/973789709483406123.2acaf8e3acfd2e8a5825a1f6f0aca4a8, isReference=true, isBulkLoadResult=false, seqid=20312223, majorCompaction=false

INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region split, META updated, and report to master. Parent=Htable_UFDR_031,00332,1325808823997.2acaf8e3acfd2e8a5825a1f6f0aca4a8., new regions: Htable_UFDR_031,00332,1325809872607.259d0c620c9105928e52713f4a5a252e., Htable_UFDR_031,003732800093168-03594291912,1325809872607.52ff3c7c6df6e0337876bbca29cee84a.. Split took 29sec

{code}
In the above logs we can also see that the new daugher regions have the next seq id as 20312223 and 20312224.

{code}
DEBUG org.apache.hadoop.hbase.regionserver.wal.HLog: Found 1 hlogs to remove out of total 4; oldest outstanding sequenceid is 20312224 from region 2acaf8e3acfd2e8a5825a1f6f0aca4a8
{code}
Now we see that the parent region which was clsoed has a seq id 20312224 which is not flushed.
So further flush are failing as the region is already removed from onlineRegionList.
The doubt here is before the region could be closed, a put has arrived for this region.  But due to some reason the flush has  not happened for that. We tried to dig this, but not able to get this problem again.
0.90.5 version + few 0.90.6 patches ( before 0.90.6RC0)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5972,"Noticed 20-minute hangs when doing a namenode kill test on our production shadow cluster. All regionservers terminated except one, which got stuck with the following. There might be some race conditions/deadlocks on compaction thread shutdown worth investigating.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3464,"I have a seed application that is executed via maven and runs a
single JVM ApplicationStarter that starts up hdfs, regionserver, hmaster
threads. It does some seeding then shuts those down in reverse order.
So this isn't a typical way of running hbase to be sure. However it has
always worked until I upgraded to HBase 0.90.0.

I didn't notice it when I was originally testing 0.90.0 because it only
seems to be happening on our EC2.small build server node when I run this
particular seeder.

Running the same thing locally on my mac works.

Attached is the error output starting from when the HRegionServer.stop() is
called to when HMaster.shutdown() is called and it starts looping forever in
letRegionServersShutdown().

It looks like RegionServerTracker is getting to ""RegionServer ephemeral node
deleted, processing expiration"" but then because it can't get the
HServerInfo it doesn't follow-through with actually expiring it.

The reason it can't get the HServerInfo is because it is looking for ""localhost."" instead of ""localhost"".

My /etc/hosts file was vanilla. But when I removed the following form hbase-site.xml:

<property>
       <name>hbase.master.dns.interface</name>
       <value>lo</value>
</property>
<property>
      <name>hbase.regionserver.dns.interface</name>
      <value>lo</value>
</property>

The issue went away.

So something about the ""lo"" interface isn't getting parsed right on that particular machine (An EC2 M.small running Ubuntu 9).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4924,"From Roman:

{code}
> 聽3. This is a little bit more sinister and it is not clear what
> 聽the resolution path here is. When compiled against .23
> 聽the MiniMRCluster dependency latches onto artifact
> 聽hadoop-mapreduce/test. There are 2 problems with that:
> 聽 聽1. this works only accidentally (but as long as it does
> 聽 聽may be it is fine) since we don't have an explicit
> 聽 聽dependency on hadoop-mapreduce test artifact (nor
> 聽 聽should we, I think!).
>
> 聽 聽2. MiniMRCluster from there is soon to be deprecated
> 聽 聽(MAPREDUCE-3169) ans HBaseTestingUtility should
> 聽 聽really transition onto using MiniMRClientClusterFactory
> 聽 聽to get a MiniMRCluster.
{code}

I think there already an issue for #2 above (courtesy of Andrew IIRC).  We should fix #1 too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5571,"If we restart master when it is disabling one table, the table will be disabling forever.

In current logic, Region CLOSE RPC will always returned NotServingRegionException because RS has already closed the region before we restart master. So table will be disabling forever because the region will in RIT all along.

In another case, when AssignmentManager#rebuildUserRegions(), it will put parent regions to AssignmentManager.regions, so we can't close these parent regions until it is purged by CatalogJanitor if we execute disabling the table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5528,"In current log-splitting retry logic, it will retry forever if throws IOException, I think we'd better change it to numbered times, and abort master when retries exhausted.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5532,"We found error log (NullPointerException) below on our online cluster:

2012-03-05 00:17:09,592 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker: Caught exception
java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.Store.isMajorCompaction(Store.java:878)
        at org.apache.hadoop.hbase.regionserver.Store.isMajorCompaction(Store.java:857)
        at org.apache.hadoop.hbase.regionserver.HRegion.isMajorCompaction(HRegion.java:3017)
        at org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker.chore(HRegionServer.java:1172)
        at org.apache.hadoop.hbase.Chore.run(Chore.java:66)

After Check the code we found although it already check whether store files has null reader at the begin of the function(isMajorCompaction), but it still has some possibility the reader is closed before it return(eg mini compaction). So we need to check store file reader before we use it to avoid this NPE


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6664,"Gregory over in https://reviews.apache.org/r/6670/ explains the issue.  See the comment here at https://reviews.apache.org/r/6670/diff/1/?file=142078#file142078line88  Its about when tests call areSerializedFieldsEqual to figure if objects are equal.  When its comparators, and the comparator has been subclassed or is made of multiple sub comparators, then we'll not compare right.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5157,Backporting to 0.90.6 considering the importance of the issue.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6898,"Based on conversation here: http://mail-archives.apache.org/mod_mbox/hbase-dev/201209.mbox/%3CCAPcDmSvS-MpZLGXU0gpYUYz9JoqghcZEngML_JYEtWPCXhYvAw%40mail.gmail.com%3E

In short, we should have a single, committer accessible and audit-able place to store custom build artifacts for HBase.

Occasionally, we need to build custom artifacts for HBase that haven't made it into the upstream projects. In the past we have hosted them in various committer's people.apache.org/ publicly visible object hosting sites (which just need a certain file structure to work as maven repositories). While the best course of action is to get the upstream projects to release a version with the change we require, this is not always possible immediately and for the short term we need the modified artifact. 

This ticket would add a branch to the hbase source and update the pom to point to the apache visible svn tree to act as the pseudo-maven respositories. This gives us a low friction, auditable, committter accessible place to upload custom build artifacts. They can also be easily removed as the upstream projects release new versions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3093,"When calling Delete.deleteColumns to delete (all versions of) a column, the columns with a qualifier that is alphabetical higher than the deleted column are deleted as well when the cells have timestamp 0.
When the cells have a timestamp higher than 0 this is not the case.

The test case DeleteColumnsTest (tested against HBase 0.89.0-r1004203-3076) contains a scenario showing this behaviour :
- put values in 3 columns (A, B and C) of the same column family at timestamp 0.
- delete all versions of column B (using Delete.deleteColumns() )
- read columns A and C
- result : for column A a result is given, for column C not (the alphabetical order is in play here!)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7451,"Hi Matteo Bertozzi and Jesse Yates, My observation is base on code in github 锛?https://github.com/matteobertozzi/hbase/
If we create a snapshot and meet regionserver timeout. Rs will be lock and can not put any data. Please take a look at log below :

// regionserver snapshot timeout
org.apache.hadoop.hbase.server.commit.distributed.DistributedCommitException: org.apache.hadoop.hbase.server.errorhandling.exception.OperationAttemptTimeoutException: Timeout elapsed! Start:1356518666984, End:1356518667584, diff:600, max:600 ms
at org.apache.hadoop.hbase.server.commit.distributed.DistributedThreePhaseCommitErrorDispatcher.wrap(DistributedThreePhaseCommitErrorDispatcher.java:135)
at org.apache.hadoop.hbase.server.commit.distributed.DistributedThreePhaseCommitErrorDispatcher.operationTimeout(DistributedThreePhaseCommitErrorDispatcher.java:71)
at org.apache.hadoop.hbase.server.commit.ThreePhaseCommit$1.receiveError(ThreePhaseCommit.java:92)
at org.apache.hadoop.hbase.server.commit.ThreePhaseCommit$1.receiveError(ThreePhaseCommit.java:89)
at org.apache.hadoop.hbase.server.errorhandling.OperationAttemptTimer$1.run(OperationAttemptTimer.java:71)
at java.util.TimerThread.mainLoop(Timer.java:512)
at java.util.TimerThread.run(Timer.java:462)
Caused by: org.apache.hadoop.hbase.server.errorhandling.exception.OperationAttemptTimeoutException: Timeout elapsed! Start:1356518666984, End:1356518667584, diff:600, max:600 ms
... 3 more
2012-12-26 18:44:57,211 DEBUG org.apache.hadoop.hbase.server.commit.TwoPhaseCommit: Running cleanup phase.
2012-12-26 18:44:57,211 DEBUG org.apache.hadoop.hbase.regionserver.snapshot.operation.SnapshotOperation: Cleanup snapshot - handled in sub-tasks on error
2012-12-26 18:44:57,212 DEBUG org.apache.hadoop.hbase.serv

//Waiting for 'commit allowed' latch and do not exist

2012-12-26 18:44:57,211 DEBUG org.apache.hadoop.hbase.server.commit.TwoPhaseCommit: Running cleanup phase.
2012-12-26 18:44:57,211 DEBUG org.apache.hadoop.hbase.regionserver.snapshot.operation.SnapshotOperation: Cleanup snapshot - handled in sub-tasks on error
2012-12-26 18:44:57,212 DEBUG org.apache.hadoop.hbase.server.commit.TwoPhaseCommit: Running finish phase.
2012-12-26 18:44:57,212 DEBUG org.apache.hadoop.hbase.regionserver.snapshot.operation.SnapshotOperation: Finish snapshot - handling in subtasks on error
2012-12-26 18:44:57,212 WARN org.apache.hadoop.hbase.server.errorhandling.OperationAttemptTimer: Timer already marked completed, ignoring!
2012-12-26 18:45:01,990 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:06,990 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:11,991 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:16,991 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:17,002 INFO org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Received children changed event:/hbase-TERRY-73/online-snapshot/prepare
2012-12-26 18:45:17,002 INFO org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Recieved start event.
2012-12-26 18:45:17,002 DEBUG org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Looking for new operations under znode:/hbase-TERRY-73/online-snapshot/prepare
2012-12-26 18:45:17,003 INFO org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Received children changed event:/hbase-TERRY-73/online-snapshot/abort
2012-12-26 18:45:17,003 INFO org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Recieved abort event.
2012-12-26 18:45:17,003 DEBUG org.apache.hadoop.hbase.server.commit.distributed.zookeeper.ZKTwoPhaseCommitCohortMemberController: Checking for aborted operations on node:/hbase-TERRY-73/online-snapshot/abort
2012-12-26 18:45:21,991 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:26,992 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:31,992 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:36,992 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:41,992 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:43,481 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: LRU Stats: total=11.77 MB, free=1.39 GB, max=1.4 GB, blocks=5, accesses=96, hits=91, hitRatio=94.79%, cachingAccesses=96, cachingHits=91, cachingHitsRatio=94.79%, evictions=0, evicted=0, evictedPerRun=NaN
2012-12-26 18:45:46,993 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:51,993 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:45:56,993 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:01,994 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:06,994 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:11,994 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:16,994 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:21,995 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:26,995 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:31,995 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:36,996 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)
2012-12-26 18:46:41,996 DEBUG org.apache.hadoop.hbase.util.Threads: Waiting for 'commit allowed' latch. (sleep:5000 ms)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7308,"HBase-TRUNK-on-Hadoop-2.0.0 #287 had one example:
{code}
Tests in error:
  testRegionCaching(org.apache.hadoop.hbase.client.TestHCM): test timed out after 60000 milliseconds
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6947,"From trunk build #3421 (https://builds.apache.org/job/HBase-TRUNK/3421/testReport/junit/org.apache.hadoop.hbase.coprocessor.example/TestZooKeeperScanPolicyObserver/testScanPolicyObserver/ and https://builds.apache.org/job/HBase-TRUNK/3414/testReport/junit/org.apache.hadoop.hbase.coprocessor.example/TestZooKeeperScanPolicyObserver/testScanPolicyObserver/):
{code}
java.lang.AssertionError: expected:<2> but was:<0>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.junit.Assert.assertEquals(Assert.java:456)
	at org.apache.hadoop.hbase.coprocessor.example.TestZooKeeperScanPolicyObserver.testScanPolicyObserver(TestZooKeeperScanPolicyObserver.java:105)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6810,"In build #3348, TestZKPermissionsWatcher#testPermissionsWatcher failed:
{code}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:92)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.junit.Assert.assertTrue(Assert.java:54)
	at org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.testPermissionsWatcher(TestZKPermissionsWatcher.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)

Standard Output

Starting DataNode 0 with dfs.data.dir: /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/dfs/data/data1,/x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/dfs/data/data2
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0

Standard Error

2012-09-18 20:29:59,306 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(639): Starting up minicluster with 1 master(s) and 1 regionserver(s) and 1 datanode(s)
2012-09-18 20:29:59,373 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(294): Created new mini-cluster data directory: /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e
2012-09-18 20:29:59,374 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting test.cache.data to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/cache_data in system properties and HBase conf
2012-09-18 20:29:59,374 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting hadoop.tmp.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/hadoop_tmp in system properties and HBase conf
2012-09-18 20:29:59,374 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting hadoop.log.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/hadoop_logs in system properties and HBase conf
2012-09-18 20:29:59,376 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting mapred.output.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/mapred_output in system properties and HBase conf
2012-09-18 20:29:59,376 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting mapred.local.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/mapred_local in system properties and HBase conf
2012-09-18 20:29:59,377 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting mapred.system.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/mapred_system in system properties and HBase conf
2012-09-18 20:29:59,377 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(491): Setting mapred.temp.dir to /x1/jenkins/jenkins-slave/workspace/HBase-TRUNK/trunk/hbase-server/target/test-data/0d33b8f6-92e9-4547-8f41-896f54a6c1f9/dfscluster_f21fe306-e20e-4a9b-9d9f-61dae4f25f3e/mapred_temp in system properties and HBase conf
2012-09-18 20:29:59,740 WARN  [pool-1-thread-1] impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-namenode.properties, hadoop-metrics2.properties
2012-09-18 20:29:59,933 INFO  [pool-1-thread-1] log.Slf4jLog(67): Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2012-09-18 20:30:00,005 INFO  [pool-1-thread-1] log.Slf4jLog(67): jetty-6.1.26
2012-09-18 20:30:00,038 INFO  [pool-1-thread-1] log.Slf4jLog(67): Extract jar:file:/home/jenkins/.m2/repository/org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar!/webapps/hdfs to /tmp/Jetty_localhost_36636_hdfs____.l2m074/webapp
2012-09-18 20:30:00,363 INFO  [pool-1-thread-1] log.Slf4jLog(67): Started SelectChannelConnector@localhost:36636
2012-09-18 20:30:00,445 WARN  [pool-1-thread-1] impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-datanode.properties, hadoop-metrics2.properties
2012-09-18 20:30:00,446 WARN  [pool-1-thread-1] util.MBeans(59): Hadoop:service=DataNode,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
	at com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:120)
	at com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:143)
	at com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:183)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:941)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:917)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:56)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.initSystemMBean(MetricsSystemImpl.java:500)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:140)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:40)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1520)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1496)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:417)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:432)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:653)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:603)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:572)
	at org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.beforeClass(TestZKPermissionsWatcher.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2012-09-18 20:30:00,509 INFO  [pool-1-thread-1] log.Slf4jLog(67): jetty-6.1.26
2012-09-18 20:30:00,521 INFO  [pool-1-thread-1] log.Slf4jLog(67): Extract jar:file:/home/jenkins/.m2/repository/org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar!/webapps/datanode to /tmp/Jetty_localhost_49745_datanode____.h2811i/webapp
2012-09-18 20:30:00,713 INFO  [pool-1-thread-1] log.Slf4jLog(67): Started SelectChannelConnector@localhost:49745
2012-09-18 20:30:00,785 INFO  [pool-1-thread-1] zookeeper.MiniZooKeeperCluster(196): Started MiniZK Cluster and connect 1 ZK server on client port: 54880
2012-09-18 20:30:01,281 DEBUG [pool-1-thread-1] util.FSUtils(442): Created version file at hdfs://localhost:42338/user/jenkins/hbase with version=7
2012-09-18 20:30:01,352 DEBUG [pool-1-thread-1] client.HConnectionManager(2453): Set serverside HConnection retries=100
2012-09-18 20:30:01,400 INFO  [pool-1-thread-1] ipc.HBaseRpcMetrics(65): Initializing RPC Metrics with hostName=HMaster, port=57673
2012-09-18 20:30:01,460 DEBUG [pool-1-thread-1] zookeeper.ZKUtil(102): master:57673 opening connection to ZooKeeper with ensemble (localhost:54880)
2012-09-18 20:30:01,476 INFO  [pool-1-thread-1] zookeeper.RecoverableZooKeeper(101): The identifier of this process is 25567@hemera
2012-09-18 20:30:01,496 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(265): master:57673 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2012-09-18 20:30:01,499 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(342): master:57673-0x139db12b83f0000 connected
2012-09-18 20:30:01,548 WARN  [pool-1-thread-1] impl.MetricsSystemImpl(137): Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-hbase.properties, hadoop-metrics2.properties
2012-09-18 20:30:01,549 WARN  [pool-1-thread-1] util.MBeans(59): Hadoop:service=hbase,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
	at com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:120)
	at com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:143)
	at com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:183)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:941)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:917)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:56)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.initSystemMBean(MetricsSystemImpl.java:500)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:140)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:40)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl.<init>(BaseMetricsSourceImpl.java:70)
	at org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.<init>(MasterMetricsSourceImpl.java:51)
	at org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceImpl.<init>(MasterMetricsSourceImpl.java:43)
	at org.apache.hadoop.hbase.master.metrics.MasterMetricsSourceFactoryImpl.create(MasterMetricsSourceFactoryImpl.java:33)
	at org.apache.hadoop.hbase.master.metrics.MasterMetrics.<init>(MasterMetrics.java:40)
	at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:383)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:132)
	at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:200)
	at org.apache.hadoop.hbase.LocalHBaseCluster.<init>(LocalHBaseCluster.java:150)
	at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:209)
	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:89)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:693)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:666)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:661)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:603)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:572)
	at org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.beforeClass(TestZKPermissionsWatcher.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2012-09-18 20:30:01,614 DEBUG [pool-1-thread-1] client.HConnectionManager(2453): Set serverside HConnection retries=100
2012-09-18 20:30:01,643 INFO  [pool-1-thread-1] ipc.HBaseRpcMetrics(65): Initializing RPC Metrics with hostName=MiniHBaseCluster$MiniHBaseClusterRegionServer, port=56450
2012-09-18 20:30:01,702 INFO  [pool-1-thread-1] hfile.CacheConfig(350): Allocating LruBlockCache with maximum size 422.2m
2012-09-18 20:30:01,711 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(237): master:57673-0x139db12b83f0000 /hbase/shutdown does not exist. Watcher is set.
2012-09-18 20:30:01,714 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.ActiveMasterManager(149): Deleting ZNode for /hbase/backup-masters/hemera.apache.org,57673,1348000201449 from backup master directory
2012-09-18 20:30:01,716 WARN  [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.RecoverableZooKeeper(141): Node /hbase/backup-masters/hemera.apache.org,57673,1348000201449 already deleted, and this is not a retry
2012-09-18 20:30:01,717 WARN  [Master:0;hemera.apache.org,57673,1348000201449] hbase.ZNodeClearer(58): No filename given to save the znode used, it won't be saved (Environment variable HBASE_ZNODE_FILE is not set).
2012-09-18 20:30:01,717 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.ActiveMasterManager(158): Master=hemera.apache.org,57673,1348000201449
2012-09-18 20:30:01,722 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] master.SplitLogManager(175): timeout = 25000
2012-09-18 20:30:01,722 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] master.SplitLogManager(176): unassigned timeout = 180000
2012-09-18 20:30:01,724 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.SplitLogManager(806): found 0 orphan tasks and 0 rescan nodes
2012-09-18 20:30:01,761 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] util.FSUtils(571): Created cluster ID file at hdfs://localhost:42338/user/jenkins/hbase/hbase.id with ID: 5dbaab6f-b03b-4631-b4f3-dbaffefbe1e9
2012-09-18 20:30:01,785 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.MasterFileSystem(395): BOOTSTRAP: creating ROOT and first META regions
2012-09-18 20:30:01,785 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(3834): creating HRegion -ROOT- HTD == '-ROOT-', {METHOD => 'table_att', IS_META => 'true', IS_ROOT => 'true'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = hdfs://localhost:42338/user/jenkins/hbase Table name == -ROOT-
2012-09-18 20:30:01,791 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(458): FileSystem doesn't support getDefaultBlockSize
2012-09-18 20:30:01,794 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(429): HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true, optionallogflushinternal=1000ms
2012-09-18 20:30:01,805 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2012-09-18 20:30:01,805 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.SequenceFileLogWriter(193): Path=hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.logs/hlog.1348000201794, compression=false
2012-09-18 20:30:01,805 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(653):  for /user/jenkins/hbase/-ROOT-/70236052/.logs/hlog.1348000201794
2012-09-18 20:30:01,805 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(501): Using getNumCurrentReplicas--HDFS-826
2012-09-18 20:30:01,813 INFO  [pool-1-thread-1] regionserver.ShutdownHook(87): Installed shutdown hook thread: Shutdownhook:RegionServer:0;hemera.apache.org,56450,1348000201701
2012-09-18 20:30:01,815 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.ZKUtil(102): regionserver:56450 opening connection to ZooKeeper with ensemble (localhost:54880)
2012-09-18 20:30:01,816 INFO  [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.RecoverableZooKeeper(101): The identifier of this process is 25567@hemera
2012-09-18 20:30:01,817 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701-EventThread] zookeeper.ZooKeeperWatcher(265): regionserver:56450 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2012-09-18 20:30:01,818 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.ZKUtil(235): regionserver:56450 Set watcher on existing znode /hbase/master
2012-09-18 20:30:01,818 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701-EventThread] zookeeper.ZooKeeperWatcher(342): regionserver:56450-0x139db12b83f0001 connected
2012-09-18 20:30:01,824 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.ZKUtil(1141): regionserver:56450-0x139db12b83f0001 Retrieved 36 byte(s) of data from znode /hbase/master and set watcher; PBUF\x0A\x1E\x0A\x11hemera.ap...
2012-09-18 20:30:01,825 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701] zookeeper.ZKUtil(237): regionserver:56450-0x139db12b83f0001 /hbase/shutdown does not exist. Watcher is set.
2012-09-18 20:30:01,834 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(474): Instantiated -ROOT-,,0.70236052
2012-09-18 20:30:01,840 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] util.FSUtils(167): Creating file=hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/.regioninfo with permission=rwxrwxrwx
2012-09-18 20:30:02,283 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] regionserver.HStore(215): hbase.hstore.compaction.min = 3
2012-09-18 20:30:02,329 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] util.ChecksumType$2(77): Checksum can use java.util.zip.CRC32
2012-09-18 20:30:02,350 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(622): Onlined -ROOT-,,0.70236052; next sequenceid=1
2012-09-18 20:30:02,351 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(3834): creating HRegion .META. HTD == '.META.', {METHOD => 'table_att', IS_META => 'true'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = hdfs://localhost:42338/user/jenkins/hbase Table name == .META.
2012-09-18 20:30:02,353 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(458): FileSystem doesn't support getDefaultBlockSize
2012-09-18 20:30:02,360 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(429): HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true, optionallogflushinternal=1000ms
2012-09-18 20:30:02,363 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2012-09-18 20:30:02,364 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.SequenceFileLogWriter(193): Path=hdfs://localhost:42338/user/jenkins/hbase/.META./1028785192/.logs/hlog.1348000202360, compression=false
2012-09-18 20:30:02,364 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(653):  for /user/jenkins/hbase/.META./1028785192/.logs/hlog.1348000202360
2012-09-18 20:30:02,364 INFO  [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(501): Using getNumCurrentReplicas--HDFS-826
2012-09-18 20:30:02,365 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(474): Instantiated .META.,,1.1028785192
2012-09-18 20:30:02,368 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] util.FSUtils(167): Creating file=hdfs://localhost:42338/user/jenkins/hbase/.META./1028785192/.tmp/.regioninfo with permission=rwxrwxrwx
2012-09-18 20:30:02,785 INFO  [StoreOpenerThread-.META.,,1.1028785192-1] regionserver.HStore(215): hbase.hstore.compaction.min = 3
2012-09-18 20:30:02,790 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(622): Onlined .META.,,1.1028785192; next sequenceid=1
2012-09-18 20:30:02,803 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(954): Closing -ROOT-,,0.70236052: disabling compactions & flushes
2012-09-18 20:30:02,804 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(975): Updates disabled for region -ROOT-,,0.70236052
2012-09-18 20:30:02,804 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1481): Started memstore flush for -ROOT-,,0.70236052, current region memstore size 352.0
2012-09-18 20:30:02,805 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1528): Finished snapshotting -ROOT-,,0.70236052, commencing wait for mvcc, flushsize=352
2012-09-18 20:30:02,805 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1538): Finished snapshotting, commencing flushing stores
2012-09-18 20:30:02,826 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] util.FSUtils(167): Creating file=hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a with permission=rwxrwxrwx
2012-09-18 20:30:02,838 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] hfile.HFileWriterV2(142): Initialized with CacheConfig:enabled [cacheDataOnRead=false] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheCompressed=false]
2012-09-18 20:30:02,841 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.StoreFile$Writer(1021): Delete Family Bloom filter type for hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a: CompoundBloomFilterWriter
2012-09-18 20:30:02,857 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.StoreFile$Writer(1241): NO General Bloom and NO DeleteFamily was added to HFile (hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a) 
2012-09-18 20:30:02,857 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HStore(767): Flushed , sequenceid=2, memsize=352.0, into tmp file hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a
2012-09-18 20:30:02,881 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HStore(792): Renaming flushed file at hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.tmp/5971150f6ed745bda83363123504803a to hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/info/5971150f6ed745bda83363123504803a
2012-09-18 20:30:02,893 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HStore(815): Added hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/info/5971150f6ed745bda83363123504803a, entries=2, sequenceid=2, filesize=836.0
2012-09-18 20:30:02,894 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1617): Finished memstore flush of ~352.0/352, currentsize=0.0/0 for region -ROOT-,,0.70236052 in 90ms, sequenceid=2, compaction requested=false
2012-09-18 20:30:02,897 INFO  [StoreCloserThread--ROOT-,,0.70236052-1] regionserver.HStore(635): Closed info
2012-09-18 20:30:02,897 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1023): Closed -ROOT-,,0.70236052
2012-09-18 20:30:02,898 INFO  [Master:0;hemera.apache.org,57673,1348000201449.logSyncer] wal.HLog$LogSyncer(1245): Master:0;hemera.apache.org,57673,1348000201449.logSyncer exiting
2012-09-18 20:30:02,898 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(1007): closing hlog writer in hdfs://localhost:42338/user/jenkins/hbase/-ROOT-/70236052/.logs
2012-09-18 20:30:03,309 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(975): Moved 1 log files to /user/jenkins/hbase/-ROOT-/70236052/.oldlogs
2012-09-18 20:30:03,311 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(954): Closing .META.,,1.1028785192: disabling compactions & flushes
2012-09-18 20:30:03,311 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(975): Updates disabled for region .META.,,1.1028785192
2012-09-18 20:30:03,312 INFO  [StoreCloserThread-.META.,,1.1028785192-1] regionserver.HStore(635): Closed info
2012-09-18 20:30:03,312 INFO  [Master:0;hemera.apache.org,57673,1348000201449] regionserver.HRegion(1023): Closed .META.,,1.1028785192
2012-09-18 20:30:03,312 INFO  [Master:0;hemera.apache.org,57673,1348000201449.logSyncer] wal.HLog$LogSyncer(1245): Master:0;hemera.apache.org,57673,1348000201449.logSyncer exiting
2012-09-18 20:30:03,313 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(1007): closing hlog writer in hdfs://localhost:42338/user/jenkins/hbase/.META./1028785192/.logs
2012-09-18 20:30:03,724 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] wal.HLog(975): Moved 1 log files to /user/jenkins/hbase/.META./1028785192/.oldlogs
2012-09-18 20:30:03,762 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] fs.HFileSystem(196): Starting addLocationsOrderInterceptor with class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2012-09-18 20:30:03,763 INFO  [Master:0;hemera.apache.org,57673,1348000201449] fs.HFileSystem(243): Added intercepting call to namenode#getBlockLocations
2012-09-18 20:30:03,783 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(102): hconnection 0x2bfa91 opening connection to ZooKeeper with ensemble (localhost:54880)
2012-09-18 20:30:03,784 INFO  [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.RecoverableZooKeeper(101): The identifier of this process is 25567@hemera
2012-09-18 20:30:03,786 DEBUG [Master:0;hemera.apache.org,57673,1348000201449-EventThread] zookeeper.ZooKeeperWatcher(265): hconnection 0x2bfa91 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2012-09-18 20:30:03,787 DEBUG [Master:0;hemera.apache.org,57673,1348000201449-EventThread] zookeeper.ZooKeeperWatcher(342): hconnection 0x2bfa91-0x139db12b83f0002 connected
2012-09-18 20:30:03,788 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(1141): hconnection 0x2bfa91-0x139db12b83f0002 Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$5dbaab6f-b03b-4631-b...
2012-09-18 20:30:03,788 INFO  [Master:0;hemera.apache.org,57673,1348000201449] client.HConnectionManager$HConnectionImplementation(662): ClusterId is 5dbaab6f-b03b-4631-b4f3-dbaffefbe1e9
2012-09-18 20:30:03,791 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] catalog.CatalogTracker(240): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@959fa1
2012-09-18 20:30:03,792 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(237): master:57673-0x139db12b83f0000 /hbase/root-region-server does not exist. Watcher is set.
2012-09-18 20:30:03,793 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(237): master:57673-0x139db12b83f0000 /hbase/unassigned/1028785192 does not exist. Watcher is set.
2012-09-18 20:30:03,798 DEBUG [Master:0;hemera.apache.org,57673,1348000201449] zookeeper.ZKUtil(237): master:57673-0x139db12b83f0000 /hbase/balancer does not exist. Watcher is set.
2012-09-18 20:30:03,820 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(265): master:57673-0x139db12b83f0000 Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/shutdown
2012-09-18 20:30:03,820 DEBUG [RegionServer:0;hemera.apache.org,56450,1348000201701-EventThread] zookeeper.ZooKeeperWatcher(265): regionserver:56450-0x139db12b83f0001 Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/shutdown
2012-09-18 20:30:03,821 INFO  [Master:0;hemera.apache.org,57673,1348000201449] master.HMaster(539): Server active/primary master; hemera.apache.org,57673,1348000201449, sessionid=0x139db12b83f0000, cluster-up flag was=false
2012-09-18 20:3",,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4371,"When writing unit tests for HBASE-4325, I noticed this:

create 'table0', 'f1','f2'
create 'table1', 'f1','f2'
create 'table2', 'f1','f2'
scan '.META.', { STARTROW=> 'table2' }

Which outputs table1 which is < table2.


hbase(main):007:0> scan '.META.', { STARTROW => 'table2' }
ROW                                                          COLUMN+CELL                                                                                                                                                                    
 table0,,1315776873140.ddc11620ad6d62eb6840853ecca46f39.     column=info:regioninfo, timestamp=1315776873202, value=REGION => {NAME => 'table0,,1315776873140.ddc11620ad6d62eb6840853ecca46f39.', TableName => 'table0', STARTKEY => '', END
                                                             KEY => '', ENCODED => ddc11620ad6d62eb6840853ecca46f39,}                                                                                                                       
 table0,,1315776873140.ddc11620ad6d62eb6840853ecca46f39.     column=info:server, timestamp=1315776873233, value=grimlock:44226                                                                                                              
 table0,,1315776873140.ddc11620ad6d62eb6840853ecca46f39.     column=info:serverstartcode, timestamp=1315776873233, value=1315776026457                                                                                                      
 table1,,1315776052776.dfbfdd038b1e42d38eff46e8282a15e5.     column=info:regioninfo, timestamp=1315776052829, value=REGION => {NAME => 'table1,,1315776052776.dfbfdd038b1e42d38eff46e8282a15e5.', TableName => 'table1', STARTKEY => '', END
                                                             KEY => '', ENCODED => dfbfdd038b1e42d38eff46e8282a15e5,}                                                                                                                       
 table1,,1315776052776.dfbfdd038b1e42d38eff46e8282a15e5.     column=info:server, timestamp=1315776052871, value=grimlock:44226                                                                                                              
 table1,,1315776052776.dfbfdd038b1e42d38eff46e8282a15e5.     column=info:serverstartcode, timestamp=1315776052871, value=1315776026457                                                                                                      
 table2,,1315776057157.5c6df57acb426b02660315e97bff80ff.     column=info:regioninfo, timestamp=1315776057207, value=REGION => {NAME => 'table2,,1315776057157.5c6df57acb426b02660315e97bff80ff.', TableName => 'table2', STARTKEY => '', END
                                                             KEY => '', ENCODED => 5c6df57acb426b02660315e97bff80ff,}                                                                                                                       
 table2,,1315776057157.5c6df57acb426b02660315e97bff80ff.     column=info:server, timestamp=1315776057232, value=grimlock:44226                                                                                                              
 table2,,1315776057157.5c6df57acb426b02660315e97bff80ff.     column=info:serverstartcode, timestamp=1315776057232, value=1315776026457                                                                                                      
3 row(s) in 0.0370 seconds
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5828,See recent 0.90 builds up on jenkins: https://builds.apache.org/view/G-L/view/HBase/job/hbase-0.90/471/console,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5309,hbasemaster:60010/jmx throws an NoSuchMethodError exception,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5214,"In master, both the shutdown threads and balancer thread could change the region state. It could create some race condition. HBase-4899 fixes the issue under normal situation. Still it seems like there is a really small time window HBase-4899 won't cover.

T1. ServerShutdownHandler. the check for ""if (rit != null && !rit.isClosing() && !rit.isPendingClose()"" return false as the region is still in closing state. It is actually closed by the RS; Master's state is ""closing"" due to the delay in ZK notification.
T2. Right after the above check, ZK notification happens and Master starts the opening of the region as requested by load balancer.
T3. ""else { this.services.getAssignmentManager().assign(e.getKey(), true); }"" is called for another assignment.

Also HBase-5094 has fixes and discussion about this.

Could we make it such that only one thread can transition a region at a time?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4836,"Messing around w/ 0.92 on cluster I got myself into a situation where the master would not go down because we were hung as follows in an infinite wait on meta to come up:

{code}
""MASTER_SERVER_OPERATIONS-sv4r11s38,7001,1321897362552-2"" prio=10 tid=0x000000004205d800 nid=0x19f6 waiting for monitor entry [0x00007fe4eb3f1000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:457)
        - waiting to lock <0x00000000ca199190> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:426)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:253)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:168)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)

""MASTER_SERVER_OPERATIONS-sv4r11s38,7001,1321897362552-1"" prio=10 tid=0x000000004237b000 nid=0x19f4 waiting for monitor entry [0x00007fe4ebefc000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:457)
        - waiting to lock <0x00000000ca199190> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:426)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:253)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:168)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)

""MASTER_SERVER_OPERATIONS-sv4r11s38,7001,1321897362552-0"" prio=10 tid=0x00007fe4ec610800 nid=0x18e1 waiting on condition [0x00007fe4eb4f2000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getRegionServerWithRetries(HConnectionManager.java:1295)
        at org.apache.hadoop.hbase.client.HTable.get(HTable.java:655)
        at org.apache.hadoop.hbase.catalog.MetaReader.get(MetaReader.java:245)
        at org.apache.hadoop.hbase.catalog.MetaReader.getRegion(MetaReader.java:347)
        at org.apache.hadoop.hbase.catalog.MetaReader.readRegionLocation(MetaReader.java:287)
        at org.apache.hadoop.hbase.catalog.MetaReader.getMetaRegionLocation(MetaReader.java:274)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.getMetaServerConnection(CatalogTracker.java:399)
        - locked <0x00000000ca199190> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:458)
        - locked <0x00000000ca199190> (a java.util.concurrent.atomic.AtomicBoolean)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:426)
        at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:253)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:168)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
{code}

This bit of code needs a bit of refactor such that we can get in state of hosting server -- whether its stopped/stopping or not.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5323,"We know that while parsing the HLog we expect the proper length from HDFS.
In WALReaderFSDataInputStream
{code}
              assert(realLength >= this.length);
{code}
We are trying to come out if the above condition is not satisfied.  But if SSH.splitLog() gets this problem then it lands in the run method of EventHandler.  This kills the SSH thread and so further assignment does not happen.  If ROOT and META are to be assigned they cannot be.
I think in this condition we abort the master by catching such exceptions.
Please do suggest.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5116,"As part of HBASE-5094 we found the possibility of doubly assignments of regions.  This JIRA is to avoid such double assignments.

The idea is to get the regions corresponding to an RS in the the META and compare the regions online in the RS.  Remove those regions from the online list if they dont match.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12236,"As discussed in thread 'NoSuchMethodError using zipkin with hbase 0.98.5', HBaseSpanReceiver.config() method from htrace-hbase module expects parameter of type org.htrace.HTraceConfiguration.

However, org.apache.hadoop.hbase.trace.HBaseHTraceConfiguration in 0.98 extends org.cloudera.htrace.HTraceConfiguration , leading to the following compilation error when building htrace-hbase against 0.98:
{code}
[ERROR]
/home/hadoop/git/htrace/htrace-hbase/src/main/java/org/htrace/impl/HBaseSpanReceiver.java:[341,12]
error: method configure in class HBaseSpanReceiver cannot be applied to
given types;
{code}
Thanks to Abhishek Kumar who reported the above issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10542,"I got this in one of my test runs: 
{code}
<error type=""java.util.ConcurrentModificationException"">java.util.ConcurrentModificationException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:894)
        at java.util.HashMap$KeyIterator.next(HashMap.java:928)
        at org.cloudera.htrace.TraceTree.&lt;init&gt;(TraceTree.java:48)
        at org.apache.hadoop.hbase.trace.TestHTraceHooks.testTraceCreateTable(TestHTraceHooks.java:118)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
{code}

It looks like TraceTree ctor, clones the spans collection, but iterates over the original argument, rather than cloned. 

I don't know enough of HTrace to fix it, so just reporting it here. [~eclark] FYI. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10185,"Throwing a DoNotRetryIOException inside  Writable.write(Dataoutput) method doesn't prevent HBase from retrying. Debugging the code locally, I figured that the bug lies in the way HBaseClient simply throws an IOException when it sees that a connection has been closed unexpectedly.  

Method:
public Writable call(Writable param, InetSocketAddress addr,
                       Class<? extends VersionedProtocol> protocol,
                       User ticket, int rpcTimeout)

Excerpt of code where the bug is present:
while (!call.done) {
        if (connection.shouldCloseConnection.get()) {
          throw new IOException(""Unexpected closed connection"");
        }

Throwing this IOException causes the ServerCallable.translateException(t) to be a no-op resulting in HBase retrying. 

From my limited view and understanding of the code, one way I could think of handling this is by looking at the closeConnection member variable of a connection to determine what kind of exception should be thrown. 

Specifically, when a connection is closed, the current code does this: 

    protected synchronized void markClosed(IOException e) {
      if (shouldCloseConnection.compareAndSet(false, true)) {
        closeException = e;
        notifyAll();
      }
    }

Within HBaseClient's call method, the code could possibly be modified to:

while (!call.done) {
        if (connection.shouldCloseConnection.get() ) {
                 if(connection.closeException instanceof                   DoNotRetryIOException) {
throw closeException;
}
          throw new IOException(""Unexpected closed connection"");
        }
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11711,"Currently TestZooKeeper attempts to launch to masters and the info ports collide. This disables the info port for this test.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3087,"This was discussed on an email thread and then summarized in a comment from stack over in HBASE-2888 (which is a more broad jira):

{quote}
Setting hbase.period in hadoop-metrics.properties doesn't seem to have an effect; counts are off. Here's what I noticed digging in code:
'hadoop-metrics.properties' gets read up into a metrics attributes map but nothing seems to be done w/ them subsequently. Reading up in hadoop, in branch-0.20/src/core/org/apache/hadoop/metrics/package.html, it seems to imply that we need to getAttribute and set them after we make a metrics Context; i.e. in this case, call setPeriod in RegionServerMetrics, etc.?

More broadly, need to make sure settings in hadoop-metrics.properties take effect when changed.
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3413,"I recently experienced a cluster malfunction which was caused by a change in DNS config for services co-hosted on the machines running region servers.

The RS are specified using IP addresses in the 'regionservers' file. Those machines are 1.example.com to N.example.com (there are A RRs for those names to each of the N IP addresses in 'regionservers').

Until recently, the PTR RRs for the RS IPs were those x.example.com names.

Then a service was deployed on some of the x.example.com machines, and new A RRs were added for svc.example.com which point to each of the IPs used for the service.

Jointly new PTR records were added too for the given IPs. Those PTR records have 'svc.example.com' as their PTRDATA, and this is causing the HBase cluster to get completely confused.

Since it is perfectly legal to have multiple PTR records, it seems important to make the canonicalization of RS more robust to DNS tweaks.

Maybe generating a UUID when a RS is started would help, this UUID could be used to register the RS in ZK and we would not rely on DNS for obtaining a stable canonical name (which may not even exist...).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6768,"I have a CF with one qualifier, data size is > 5 MB, when i try to read the raw binary data as octet-stream using curl, rest server got crashed and curl throws exception as

{code}
 curl -v -H ""Accept: application/octet-stream"" http://abcdefgh-hbase003.test1.test.com:9090/table1/row_key1/cf:qualifer1 > /tmp/out

* About to connect() to abcdefgh-hbase003.test1.test.com port 9090
*   Trying xx.xx.xx.xxx... connected
* Connected to abcdefgh-hbase003.test1.test.com (xx.xxx.xx.xxx) port 9090
> GET /table1/row_key1/cf:qualifer1 HTTP/1.1
> User-Agent: curl/7.15.5 (x86_64-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5
> Host: abcdefgh-hbase003.test1.test.com:9090
> Accept: application/octet-stream
> 
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0< HTTP/1.1 200 OK
< Content-Length: 5129836
< X-Timestamp: 1347338813129
< Content-Type: application/octet-stream
  0 5009k    0 16272    0     0   7460      0  0:11:27  0:00:02  0:11:25 13872transfer closed with 1148524 bytes remaining to read
 77 5009k   77 3888k    0     0  1765k      0  0:00:02  0:00:02 --:--:-- 3253k* Closing connection #0

curl: (18) transfer closed with 1148524 bytes remaining to read

{code}

Couldn't find the exception in rest server log or no core dump either. This issue is constantly reproducible. Even i tried with HBase Rest client (HRemoteTable) and i could recreate this issue if the data size is > 10 MB (even with MIME_PROTOBUF accept header)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8100,"The documentation on the Wiki for the Scan methods in Thrift are wrong.  The wiki page is http://wiki.apache.org/hadoop/Hbase/ThriftApi.  The openScanner, getScannerResult and closeScanner methods aren't methods in the Thrift interface.  They should be scannerOpen, scannerGet, and scannerClose.  Some of the method paramaters might need to be changed too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2110,Move to ivy broke pulling in hbase.css from the static webapp; investigate.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10577,"In the new disruptor based FSHLog, the Syncer threads are handed a batch of SyncFuture objects from the RingBufferHandler. The Syncer then invokes a sync call on the current writer instance.
This handing of batch is done in serially in RingBufferHandler, that is, every syncer receives a non overlapping batch of SyncFutures. Once synced, Syncer thread updates highestSyncedSequence.

In the run method of Syncer, we have:
{code}
            long currentHighestSyncedSequence = highestSyncedSequence.get();
            if (currentSequence < currentHighestSyncedSequence) {
              syncCount += releaseSyncFuture(takeSyncFuture, currentHighestSyncedSequence, null);
              // Done with the 'take'.  Go around again and do a new 'take'.
              continue;
            }
{code}
I find this logic of polling the BlockingQueue again in this condition un-necessary. When the currentHighestSyncedSequence is already greater than currentSequence, then doesn't it mean some other Syncer has already synced SyncFuture of these ops ? And, we should just go ahead and release all the SyncFutures for this batch to unblock the handlers. That would avoid polling the Blockingqueue for all SyncFuture objects in this case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11570,"HBase provide an export snapshot command to MR copy the snapshot files into a remove cluster. However, if current cluster is not running MR, but target cluster is, we will need to export the list of files into the target cluster and run a distcp from there.

To do so, given a snapshot name we need HBase to provide the list of files belonging to it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7928,"{code}
    try {
      HTable metaTable = new HTable(config, Bytes.toBytes("".META.""));
      Scan scan = new Scan();
      scan.setStartRow(Bytes.toBytes(""e""));
      scan.setStopRow(Bytes.toBytes(""z""));
      ResultScanner scanner = metaTable.getScanner(scan);
      Result[] results = scanner.next(100);
      while (results.length > 0) {
        for (Result result : results) {
          System.out.println(Bytes.toString(result.getRow()));
        }
        results = scanner.next(100);
      }
      scanner.close();
      metaTable.close();
    } catch (Exception e) {
      e.printStackTrace();
    }
{code}

This code will not return any result even if there is 10 tables with names starting with ""d"" to ""w"", including one table called ""entry"". If you comment the setStopRow you will get results, but will still get rows starting with ""d"" even if setStartRow is set to ""e"".

Same code using with a user table is working fine.

Facing the same issue with the shell.

scan '.META.' , {STARTROW => 'e', LIMIT => 10} is returning rows starting by ""d"".

scan '.META.' , {STARTROW => 'e', STOPROW => 'v', LIMIT => 10} is not returning anything.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3527,"Hi,
I am using 0.20.6 version of hbase. Got the following error while closing a table.

> Caused by: java.lang.IndexOutOfBoundsException: toIndex = 1
>        at java.util.SubList.<init>(AbstractList.java:602)
>        at java.util.RandomAccessSubList.<init>(AbstractList.java:758)
>        at java.util.AbstractList.subList(AbstractList.java:468)
>        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:668)
>        at org.apache.hadoop.hbase.client.HTable.close(HTable.java:682)
>
>
 Thanks,
 Murali Krishna",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3046,We're seeing an EOFE playing recovered.edits file loading region.  See http://permalink.gmane.org/gmane.comp.java.hadoop.hbase.user/12312 thread.  I took a look.  It looks like last record in file is incomplete as though we're not flushing.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3487,"while testing I was having problems with my master aborting early on, which causes trouble with the regionservers... they are SUPPOSED to wait forever for the master to come up, but they eventually 'give up' without saying anything helpful.  For example this was in the log:

2011-01-27 17:27:25,912 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:27:28,912 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:27:31,912 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:27:34,912 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:27:37,913 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: No master found, will retry
2011-01-27 17:28:37,593 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: LRU Stats: total=3.26 MB, free=393.42 MB, max=396.68 MB, blocks=1, accesses=69, hits=64, hitRatio=92.75%%, cachingAccesses=65, cachingHits=64, cachingHitsRatio=98.46%%, evictions=0, evicted=0, evictedPerRun=NaN

then nothing else.  It had been well over 3 minutes at this point.  jstacking the process shows lots of threads running, but the process is effectively dead and only kill -9 will get rid of it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3477,"It seems that the filters will not be invoke when there are only a few data in the table.

I added some logs to the org.apache.hadoop.hbase.filte. PrefixFilter, and has a MyInputFormat extends hbase.mapred.TableInputFormat, the deprecated mapred APIs.

The log added to PrefixFilter
{noformat} 
  public boolean filterRowKey(byte[] buffer, int offset, int length) {
    log.info(""TODO: filterRowKey invoked"");
    if (buffer == null || this.prefix == null) {
        log.info(""TODO: #1 of filter"");
      return true;
    }
    if (length < prefix.length) {
   ...
  }
{noformat} 

This is the code in my InputFormat's configure method.
{noformat} 
byte[] prefix = Bytes.toBytes(""001"");
Filter filter = new PrefixFilter(prefix);
setRowFilter(filter);
{noformat} 

And the job setup code.
{noformat} 
job.setInputFormat(MyInputFormat.class);
FileInputFormat.addInputPaths(job, ""my_table_in_hbase"");
job.set(TableInputFormat.COLUMN_LIST, ""data:"");
{noformat} 

When I put lots of data (> 500,000) in the table, the filter works well, but when I put only a few data (<100) in the table, it seems that the filter will not be invoked,  and the log in the filter has no output either.

This is the log output when lots of data in the table
{noformat} 
2011-01-25 16:43:59,568 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: default constructor
2011-01-25 16:44:01,728 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: filterRowKey invoked
2011-01-25 16:44:01,728 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: #3 of filter
2011-01-25 16:44:01,728 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: filterAllRemaining invoked
2011-01-25 16:44:01,729 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: filterAllRemaining invoked
2011-01-25 16:44:01,729 INFO org.apache.hadoop.hbase.filter.PrefixFilter: TODO: filterAllRemaining invoked
{noformat} ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3458,HBASE-3449 'Server shutdown handlers deadlocked waiting for META' describes case where we could block waiting on -ROOT- deploy but all of the handlers on master are occupied waiting on -ROOT- leaving none open to handle -ROOT-.  HBASE-3449 workaround makes the likelihood low.  This issue is about fixing it once and for all (cancel of the excecutor and requeuing or some such device).,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3390,"I see double-assign during a rolling restart test.  Its happening when master joins existing cluster... half the RSs have reported in but its taking on splits anyways (I have it splitting and balancing continuously).  A split comes in immediately followed by a balance.  What I think is happening is that the split comes in and clears a CLOSING from RIT as part of its cleanup of parent region references.  This is messing up the run of balancers' close somehow; we're getting node created and children changed zk events and this makes somehow for the double closed.

I'm enabling zk logging and will try harder to hunt this one down.

Not creating as BLOCKER on 0.90.0 because I think its ok to disable balancer while rolling restart is going on -- and the current rolling restart is a horror anyways doing its maximmal region moving.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3197,"I created a DAO object for loading and storing data into HBase. The DAO has a HBaseConfiguration field, created inside the DAO constructor. Each DAO's method creates a new HTable using the class's HBaseConfiguration. The problem shows up when subsequent writings (using a put) are invoked, since not all the data is written. Moreover this behaviour is not deterministic: invoking the same writings never writes all the data, but the missing ones change every time.
I solved this situation removing the class's HBaseConfiguration and creating a new HBaseConfiguration inside each method.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3190,"Table disabling was interrupted by kill -9 all part of hbase and now we cannot do anything with this table, disabling doesn't show any exception:
hbase(main):019:0> disable 'NGolden_CTU'
0 row(s) in 0.0250 seconds


but droping show this:
hbase(main):020:0> drop 'NGolden_CTU'   

ERROR: org.apache.hadoop.hbase.TableNotDisabledException: org.apache.hadoop.hbase.TableNotDisabledException: NGolden_CTU
        at org.apache.hadoop.hbase.master.HMaster.checkTableModifiable(HMaster.java:861)
        at org.apache.hadoop.hbase.master.handler.TableEventHandler.<init>(TableEventHandler.java:52)
        at org.apache.hadoop.hbase.master.handler.DeleteTableHandler.<init>(DeleteTableHandler.java:42)
        at org.apache.hadoop.hbase.master.HMaster.deleteTable(HMaster.java:779)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:570)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025)

Here is some help for this command:
          Drop the named table. Table must first be disabled. If table has
          more than one region, run a major compaction on .META.:

          hbase> major_compact "".META.""

after this nothing strange is in logs

when we restart hbase we get this:

2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.                                                        
2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780005 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING                                                         
2010-11-03 08:56:37,892 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_RS_OPEN_REGION                                                                                                                                                  
java.lang.NullPointerException                                                                                                                                                                                                                                                         
        at org.apache.hadoop.hbase.util.Writables.getWritable(Writables.java:75)                                                                                                                                                                                                       
        at org.apache.hadoop.hbase.executor.RegionTransitionData.fromBytes(RegionTransitionData.java:198)                                                                                                                                                                              
        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNode(ZKAssign.java:669)                                                                                                                                                                                                
        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNodeOpening(ZKAssign.java:549)                                                                                                                                                                                         
        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNodeOpening(ZKAssign.java:542)                                                                                                                                                                                         
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.transitionZookeeperOfflineToOpening(OpenRegionHandler.java:208)                                                                                                                                              
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:89)                                                                                                                                                                           
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)                                                                                                                                                                                                    
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)                                                                                                                                                                                         
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)                                                                                                                                                                                             
        at java.lang.Thread.run(Thread.java:619)                                                                              



Other logs with this region:

hbase@db2a:logs$ grep ""0c8579e52b0ea3f2dab5b6a857ad030b"" hbase-hbase-master-db2a.goldenline.pl.log 
2010-11-03 08:54:02,575 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Async create of unassigned node for 0c8579e52b0ea3f2dab5b6a857ad030b with OFFLINE state
2010-11-03 08:54:03,555 DEBUG org.apache.hadoop.hbase.master.AssignmentManager$CreateUnassignedAsyncCallback: rs=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=OFFLINE, ts=1288770842575, server=db2a.goldenline.pl,60020,1288770551154
2010-11-03 08:54:03,777 DEBUG org.apache.hadoop.hbase.master.AssignmentManager$ExistsUnassignedAsyncCallback: rs=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=OFFLINE, ts=1288770842575
2010-11-03 08:54:42,836 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=PENDING_OPEN, ts=1288770843777
2010-11-03 08:54:42,836 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_OPEN for too long, reassigning region=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=PENDING_OPEN, ts=1288770843777
2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. so generated a random one; hri=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b., src=, dest=db2b.goldenline.pl,60020,1288770553679; 2 (online=2, exclude=null) available servers
2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. to db2b.goldenline.pl,60020,1288770553679
2010-11-03 08:56:12,824 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=db2a.goldenline.pl,60020,1288770551154, region=0c8579e52b0ea3f2dab5b6a857ad030b
2010-11-03 08:56:12,975 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=db2a.goldenline.pl,60020,1288770551154, region=0c8579e52b0ea3f2dab5b6a857ad030b
2010-11-03 08:56:12,976 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for 0c8579e52b0ea3f2dab5b6a857ad030b; deleting unassigned node
2010-11-03 08:56:12,976 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Deleting existing unassigned node for 0c8579e52b0ea3f2dab5b6a857ad030b that is in expected state RS_ZK_REGION_OPENED
2010-11-03 08:56:12,978 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Successfully deleted unassigned node for region 0c8579e52b0ea3f2dab5b6a857ad030b in expected state RS_ZK_REGION_OPENED
2010-11-03 08:56:13,011 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Opened region NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. on db2a.goldenline.pl,60020,1288770551154





hbase@db2a:logs$ grep ""0c8579e52b0ea3f2dab5b6a857ad030b"" hbase-hbase-regionserver-db2a.goldenline.pl.log 
2010-11-03 08:54:04,470 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received request to open region: NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:12,770 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:12,770 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region: REGION => {NAME => 'NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.', STARTKEY => '3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E', ENDKEY => '3065-d_2010_9_11_47D955785DEC3CE95377D70F67BA5ABC', ENCODED => 0c8579e52b0ea3f2dab5b6a857ad030b, TABLE => {{NAME => 'NGolden_CTU', FAMILIES => [{NAME => 'c', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'LZO', VERSIONS => '1', TTL => '-1', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}]}}
2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Instantiated NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:12,939 INFO org.apache.hadoop.hbase.regionserver.StoreFile$Reader: Loaded row bloom filter metadata for hdfs://db2a:50001/hbase/NGolden_CTU/0c8579e52b0ea3f2dab5b6a857ad030b/c/561636411807463667
2010-11-03 08:56:12,939 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://db2a:50001/hbase/NGolden_CTU/0c8579e52b0ea3f2dab5b6a857ad030b/c/561636411807463667, isReference=false, isBulkLoadResult=false, seqid=1820373362, majorCompaction=true
2010-11-03 08:56:12,939 INFO org.apache.hadoop.hbase.regionserver.HRegion: Onlined NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.; next sequenceid=1820373363
2010-11-03 08:56:12,939 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2010-11-03 08:56:12,970 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2010-11-03 08:56:12,971 INFO org.apache.hadoop.hbase.catalog.MetaEditor: Updated row NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. in region .META.,,1 with server=db2a.goldenline.pl:60020, startcode=1288770551154
2010-11-03 08:56:12,971 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2010-11-03 08:56:12,973 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2010-11-03 08:56:12,973 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Opened NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.




hbase@db2b:logs$  grep ""0c8579e52b0ea3f2dab5b6a857ad030b"" hbase-hbase-regionserver-db2b.goldenline.pl.log
2010-11-03 08:54:42,840 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received request to open region: NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.
2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780005 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2959,"In HBASE-2248, the code in {{HRegion#get}} was changed like so:
{code}
-  private void get(final Store store, final Get get,
-    final NavigableSet<byte []> qualifiers, List<KeyValue> result)
-  throws IOException {
-    store.get(get, qualifiers, result);
+  /*
+   * Do a get based on the get parameter.
+   */
+  private List<KeyValue> get(final Get get) throws IOException {
+    Scan scan = new Scan(get);
+
+    List<KeyValue> results = new ArrayList<KeyValue>();
+
+    InternalScanner scanner = null;
+    try {
+      scanner = getScanner(scan);
+      scanner.next(results);
+    } finally {
+      if (scanner != null)
+        scanner.close();
+    }
+    return results;
   }
{code}
So instead of doing a {{get}} straight on the {{Store}}, we now open a scanner.  The problem is that we eventually end up in {{ScanQueryMatcher}} where the constructor does: {{this.startKey = KeyValue.createFirstOnRow(scan.getStartRow());}}.  This entails that if we have a very wide row (thousands of columns), the scanner will need to go through thousands of {{KeyValue}}'s before finding the right entry, because it always starts from the beginning of the row, whereas before it was much more straightforward.

This problem was under the radar for a while because the overhead isn't too unreasonable, but later on, {{incrementColumnValue}} was changed to do a {{get}} under the hood.  At StumbleUpon we do thousands of ICV per second, so thousand of times per second we're scanning some really wide rows.  When a row is contented, this results in all the IPC threads being stuck on acquiring a row lock, while one thread is doing the ICV (albeit slowly due to the excessive scanning).  When all IPC threads are stuck, the region server is unable to serve more requests.

As a nice side effect, fixing this bug will make {{get}} and {{incrementColumnValue}} faster, as well as the first call to {{next}} on a scanner.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2848,"From an hbase admirer:

""t seems that having -verbose:gc in $HBASE_OPTS in
conf/hbase-env.sh is making some scripts unhappy:
$ ./bin/start-hbase.sh
[1: ssh: [1: Name or service not known
CMS-initial-mark:: ssh: CMS-initial-mark:: Name or service not known
6696K(83008K),: ssh: 6696K(83008K),: Name or service not known
0K(63872K)]: ssh: 0K(63872K)]: Name or service not known
secs]: ssh: secs]: Name or service not known
[Times:: ssh: [Times:: Name or service not known
....""

I've seen this myself.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3077,"HBASE-3063 has a bit of detail.  The new master is better around disable, delete but still not good enough.  This issue is about digging in a bit.  While disable and enable are not just flags up in zk, setting either is followed by the actual open/close of regions.  We need to add support to the master where it can follow swift enabling/disabling.  HBASE-3063 add some lag to the delete so we'll wait on region close before we go ahead and remove the region but we should be able to do better here too... e.g.  make use of Nicolas's new interrupt compactions so delete doesn't ahve to wait on ongoing compactions... and we could add an abort of specific regions only so we could  just crash them closed rather than wait on flushes if they are going to be just deleted anyways.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2929,"When HBaseAdmin.disableTable() was called for the following table, it seemed to hang:

NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479

This is jstack for client:

""main"" prio=10 tid=0x000000005c4ac800 nid=0x3ce9 in Object.wait() [0x0000000041060000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:485)
        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:721)
        - locked <0x00002aaabc6433a0> (a org.apache.hadoop.hbase.ipc.HBaseClient$Call)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:333)
        at $Proxy10.disableTable(Unknown Source)
        at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:467)
        at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:446)

Here is snippet from the region server log where the region is located:
http://pastebin.com/S1fHN7cM

Here is snippet from master log:
http://pastebin.com/8ZL7qihk

I found that only one region from NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479 (currently disabled) remained in the table as of now.

In master server log, I can see 3 actions on any of the other regions in the table:

2010-08-18 06:41:55,345 INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_CLOSE: NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,D68741A06F0EB8AF4D8579BF17864031,1282075349107 from us01-ciqps1-grid06.carrieriq.com,60020,1282088004819; 1 of 15
2010-08-18 06:41:55,345 DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: ProcessRegionClose of NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,D68741A06F0EB8AF4D8579BF17864031,1282075349107, true, reassign: false
2010-08-18 06:41:55,365 INFO org.apache.hadoop.hbase.master.ProcessRegionClose$1: region closed: NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,D68741A06F0EB8AF4D8579BF17864031,1282075349107

But for NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,74A6A44B129151AD71C061D100F5CFA3,1282075834828 I only see one action:

2010-08-18 06:41:56,105 INFO org.apache.hadoop.hbase.master.ServerManager: Processing MSG_REPORT_CLOSE: NIGHTLYSTAGINGGRID-PACKAGESUMMARY-1282074317479,74A6A44B129151AD71C061D100F5CFA3,1282075834828 from us01-ciqps1-grid04.carrieriq.com,60020,1282087981085; 1 of 5",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2966,"We noticed in one case the HBase client program got stuck on Zookeeper.exists() call.
 
One of the threads was stuck here on the ZK call while holding an HBase level lock (regionLockObject in locateRegionInMeta()).

{code} 
""thrift-0-thread-8"" prio=10 tid=0x00007f189ca4c000 nid=0x550f in Object.wait() [0x0000000044241000]
   java.lang.Thread.State: WAITING (on object monitor)
                at java.lang.Object.wait(Native Method)
                at java.lang.Object.wait(Object.java:485)
                at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1278)
                - locked <0x00007f1903a0c280> (a org.apache.zookeeper.ClientCnxn$Packet)
                at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:804)
                at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:837)
                at org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.getRSDirectoryCount(ZooKeeperWrapper.java:765)
                at org.apache.hadoop.hbase.client.HTable.getCurrentNrHRS(HTable.java:173)
                at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:147)
                at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:124)
                at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:89)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.prefetchRegionCache(HConnectionManager.java:734)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:785)
                - locked <0x00007f190d868848> (a java.lang.Object)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:679)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:646)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionLocation(HConnectionManager.java:472)
                at org.apache.hadoop.hbase.client.ServerCallable.instantiateServer(ServerCallable.java:57)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:1147)
                at org.apache.hadoop.hbase.client.HTable.get(HTable.java:503)
{code} 

The remaining other threads are all waiting on the regionLockObject lock (held by the above thread) with stacks like:
 
{code}
thrift-0-thread-7"" prio=10 tid=0x00007f189ca4a800 nid=0x550e waiting for monitor entry [0x0000000044141000]
   java.lang.Thread.State: BLOCKED (on object monitor)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:783)
                - waiting to lock <0x00007f190d868848> (a java.lang.Object)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:679)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:646)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionLocation(HConnectionManager.java:472)
                at org.apache.hadoop.hbase.client.ServerCallable.instantiateServer(ServerCallable.java:57)
                at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:1147)
                at org.apache.hadoop.hbase.client.HTable.get(HTable.java:503)
{code}

Any ideas?
 
Meanwhile, I'll look into the ZK logs from the relevant time some more and get back if I have more information.
 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3011,"When NameNode is not available and HMaster detects it, it tries to shut down itself. However,the main thread stuck at waiting for other scanner threads to exit, which does not happen.

The main problem is that the shutdown request flag is not set to be true so other threads do not know that they need to exit.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1746,"Workaround is restart all masters... Then the ones that failed will come up.  So not really an important issue, but its kinda cool one so filing anyway.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2885,"As experienced by Karthik Kambatla, Vlad and Steve Kuo, HBase 0.20.5 exhibits inconsistent behavior when user tries to access data in a table.

One such case involves offline region for the underlying table.

See the following threads in hbase user mailing list:
How to delete an ""non-existent"" table
Flaky tableExists()

And this thread in hbase dev mailing list:
Data disappears and re-appears again after HBase cluster restart",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2875,I was running for several days with small amounts of data before I started loading lots of data. Upon the first split the region server crashed unable to fine the LZO library.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2833,Need a test case to verify the fix for HBASE-2781 ZKW.createUnassignedRegion doesn't make sure existing znode is in the right state,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2780,"This is on branch - I have 120 clients writing like crazy into a table, it's definitely not disabled. But the web UI says it is. Attaching meta scan.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2759,"I deleted a node in the UNASSIGNED dir, and saw this in the logs. I think it's harmless, but worth fixing:

2010-06-20 21:16:15,008 DEBUG org.apache.hadoop.hbase.master.HMaster: Event NodeDeleted with state SyncConnected with path /hbase/UNASSIGNED/1028785192
2010-06-20 21:16:15,008 DEBUG org.apache.hadoop.hbase.master.ZKMasterAddressWatcher: Got event NodeDeleted with path /hbase/UNASSIGNED/1028785192
2010-06-20 21:16:15,008 DEBUG org.apache.hadoop.hbase.master.ZKMasterAddressWatcher: Master address ZNode deleted, notifying waiting masters
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2624,"Saw this test failure on my Hudson:

org.apache.hadoop.hbase.client.RetriesExhaustedException: Still had 11 puts left after retrying 4 times.
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.processBatchOfPuts(HConnectionManager.java:1428)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:540)
	at org.apache.hadoop.hbase.TestMultiParallelPut.doATest(TestMultiParallelPut.java:93)
	at org.apache.hadoop.hbase.TestMultiParallelPut.testParallelPutWithRSAbort(TestMultiParallelPut.java:65)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2723,Saw a timeout of this test on my Hudson (prior to the master ZK change),,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2563,"We've deprecated io.Cell, so we should probably deprecate methods which return or accept Cell values. See http://hadoop.apache.org/hbase/docs/r0.20.4/api/org/apache/hadoop/hbase/io/class-use/Cell.html for the complete list. Here are some selections:

* getCellValue(), getCellValue(byte[], byte[]), and getCellValues() methods of client.Result
* Entry.getValue() and Entry.setValue(Cell) methods of io.RowResult
* cellFromHBase(Cell[]) and cellFromHBase(Cell) methods of thrift.ThriftUtilities
* Writables.cellToLong(Cell), Writables.cellToString(Cell), and Writables.getHRegionInfo(Cell) methods of hbase.util

Also some hbase.rest stuff, but I don't know what's going on there.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2505,"Was just testing the 0.20.4rc5 on a cluster that had a newer format of log files and noticed this:
- If an IOE occurs splitting one log, it will not continue trying to split other logs
- the IOEs are logged to stdout, not to log4j
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2106,"Here is a question from Adam Silberstein who is having trouble writing this list:

""I'm running on a particular cluster of machines and seeing worse than expected performance.  I've run on a different, but identical, cluster of machines and gotten about 2-4x better throughput and latency.  I've checked all of the configuration settings and they are all the same.  The only thing I observe that looks odd is the memory usage by each region server.  I've allocated 6 GB heap space to each.  There is a total of 20GB of records on each.  When I use ""top"" to observe memory usage, I see that the region server process does have 6GB of virtual memory.  When I start running a workload, I can see the amount of resident memory climbing.  However, it always stops at 2GB.  Since I have 20 GB on each region server, I'd expect the process to use all the memory allocated it

""Is there a reasonable explanation for why it stops at 2GB, and/or has anyone seen this happen""

I took a look at the cache code and I see that it has an int for maximum size in the constructor argument though internally its using a long for maximum size.  I wonder if this is the issue?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1948,"I have an existing hbase table with data in it. When I restart hadoop, hbase and zookeeper, I am able to read all of the data that existed in the table prior to the restart. However when I write data to the table, it does not get reflected. 

When I do a disable <table> and then an enable <table> on an hbase shell. The data that was written to the table now appears and the table is up to date. However, even after this my thrift client still sees the old data and not the updated values.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1882,"Bits got flipped (it seems) on a read so a key going into hfile was < the previous.  We throw an exception that causes HRS restart.  Just put bad edits aside rather than die.

From elsif up on list:

{code}
Our HBase system ended up in a looping situation trying to continuously
re-assign a damaged region across the HBase cluster. We could not properly
scan or store data in the affected table.

The triggering event that caused this cascade of errors was an
java.io.IOException: Added a key not lexically larger than previous

From the HBase shell ""scan '.META.' command we confirmed the name of the
damaged encoded
region stored in hdfs. In an attempt to fix this, the data directory for
the impacted region
was moved off hdfs and the region was able to be restarted with a blank
slate.

Is there a better way to handle this type of failure?

Is there a way to generate an hlog to re-import the data files we moved
away?

HBase Version: 0.20.0, r805538
Hadoop Version: 0.20.0-plus4681, r767961

Here are the log entries leading up to the event:

2009-09-25 06:57:53,836 INFO org.apache.hadoop.hbase.regionserver.HLog:
Roll /hbase/.logs/hfs-030035,60020,1253122636703/hlog.dat.1253883473798,
entries=1479, calcsize=49659443, filesize=49589196. New hlog
/hbase/.logs/hfs-030035,60020,1253122636703/hlog.dat.1253887073833
2009-09-25 07:05:50,089 INFO
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Forced flushing of
fc_test,\x2Fdata\x2Fmalware\x2F873fc5b61af807827381f120ad7d746984d49426eb3c8b5523b6142285ee0844027f6b45eb8f18aff21b52071a9664e05ceca112a9ff5949c16cda3f27c9c7c2,1253728360248

because global memstore limit of 396.9m exceeded; currently 397.0m and
flushing till 24
8.1m


2009-09-25 07:05:53,294 INFO
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Forced flushing of
fc_test,\x2Fdata\x2Fdir\x2Fdfd2e9615461d03ba7c22d6d804ec23c3dba1587ffb91736d0e90df0b8aa659d6f55efe49552a83271d9e115bd1d706b865dc42008

52493400819628a7be0fc2\x2F2009-09-23_143101\x2Fxml,1253765882755 because
global memstore limit of 396.9m exceeded; currently 357.1m and flushing
till
248.1m

2009-09-25 07:05:55,583 FATAL
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Replay of hlog
required. Forcing serve
r
shutdown

org.apache.hadoop.hbase.DroppedSnapshotException: region:
fc_test,\x2Fdata\x2Fdir\x2Fdfd2e9615461d03ba7c22d6d804ec23c3dba1587ffb91736d0e90df0b8aa659d6f55efe49552a83271d9e115bd1d706b865dc4200852493400819628a7be0fc2\x2F2009-09-23_143101\

x2Fxml,1253765882755


at
org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:950)

at
org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:843)
   at
org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:241)

at
org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushSomeRegions(MemStoreFlusher.java:352)

at
org.apache.hadoop.hbase.regionserver.MemStoreFlusher.reclaimMemStoreMemory(MemStoreFlusher.java:321)

   at
org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1809)


   at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)
   at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
   at java.lang.reflect.Method.invoke(Unknown Source)
   at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
   at
org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
Caused by: java.io.IOException: Added a key not lexically larger than
previous
key=^@?/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4^D11ff79bb955c50b99c8f80fdff0b4beb413d8ea/2009-09-25_034206^Ejson:^@^@^A#?M?)^D,

lastkey=^@?/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4d11ff79bb955c50b99c8f80fdff0b4beb413d8ea^Ejson:^@^@^A#?M?#^D

   at
org.apache.hadoop.hbase.io.hfile.HFile$Writer.checkKey(HFile.java:517)
   at org.apache.hadoop.hbase.io.hfile.HFile$Writer.append(HFile.java:479)
   at org.apache.hadoop.hbase.io.hfile.HFile$Writer.append(HFile.java:447)
   at
org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:525)

   at
org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:489)
2009-09-25 07:05:55,608 INFO
org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics:
request=0.0, regions=15,
 stores=30, storefiles=43, storefileIndexSize=3, memstoreSize=396,
usedHeap=540, maxHeap=992, blockCacheSize=73256760, blo
ckCacheFree=967258312, blockCacheCount=1128, blockCacheHitRatio=90
2009-09-25 07:05:55,609 WARN
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Flush failed
2009-09-25 07:05:55,684 INFO org.apache.hadoop.ipc.HBaseServer: Stopping
server on 60020


Here are the log entries after restarting:

2009-09-28 11:36:16,608 INFO org.apache.hadoop.ipc.HBaseServer: IPC
Server handler 0 on 60020: starting
2009-09-28 11:36:16,620 ERROR
org.apache.hadoop.hbase.regionserver.HRegionServer:
org.apache.hadoop.hbase.NotServingRegionException:
[B@1a001ff               at
org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionS
erver.java:2263)

at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.
java:1767)

at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
       at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown
Source)                  at
sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
       at java.lang.reflect.Method.invoke(Unknown
Source)                              at
org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
       at
org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

{code}

....

and

{code}
stack wrote:
> On Mon, Sep 28, 2009 at 3:27 PM, elsif <elsif.then@gmail.com> wrote:
>
>
>> Our HBase system ended up in a looping situation trying to continuously
>> re-assign a damaged region across the HBase cluster. We could not properly
>> scan or store data in the affected table.
>>
>> The triggering event that caused this cascade of errors was an
>> java.io.IOException: Added a key not lexically larger than previous
>>
>>
>
>
> Here are the offending keys purportedly:
>
> key=^@?/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4^D11ff79bb955c50b99c8f80fdff0b4beb413d8ea/2009-09-25_034206^Ejson:^@^@^A#?M?)^D,
> lastkey=^@?/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4d11ff79bb955c50b99c8f80fdff0b4beb413d8ea^Ejson:^@^@^A#?M?#^D
>
>
>
> It seems like keys are fine till we get to '^D'.    Can you make these keys
> or comment on them?  The '^D' is a printable version of whatever the bit of
> binary was here.  Do you have an idea what it was?  Can you remanufacture
> this condition?  Something in our comparator is messing up?  Is that
> possible?
>
>

The keys are all plain text strings with no special characters.  Not
sure where the '^D' would come from since the same processes is used to
generate all the keys.
> This is in .META. table?
>

This is from a regular table.
>
>
>
>
>
> >From the HBase shell ""scan '.META.' command we confirmed the name of the
>
>> damaged encoded
>> region stored in hdfs. In an attempt to fix this, the data directory for
>> the impacted region
>> was moved off hdfs and the region was able to be restarted with a blank
>> slate.
>>
>> Is there a better way to handle this type of failure?
>>
>>
>>
>
> There is a script that will repair the broke files rewriting them removing
> the offending edit.  I'd point you at the script only its up in an Apache
> JIRA and thats sick at the moment.
>
> You could try running:
>
> ./bin/hbase org.apache.hadoop.hbase.io.hfile.HFile
>
> It has diagnostic and outputting facility.  Pass it the bad files.
>
>
>
I scanned each of the files with the -k option, no warnings were generated.

I also extracted all the key values from each file - none of them appear
to contain the key with the '^D'.

The 'key' and 'lastkey' listed above were contained in the
oldlogfile.log.  I opened the oldlogfile.log with a hex editor and
verified that the key does not contain any binary characters where the
'^D' is shown in the error log.  The character is actually a lowercase 'd':

/data/dir/e22677afdb73cc17ed82a974058859e5e74b78ca5a7917cceaa500d2dd3198094ecf91792e8ddafc4768cfb4d11ff79bb955c50b99c8f80fdff0b4beb413d8ea/2009-09-25_034206

It would seem this was a read error of some kind.

>
>
>> Is there a way to generate an hlog to re-import the data files we moved
>> away?
>>
>>
>>
>
> Above mentioned script is probably the better way to go.
>
>
>
>
>> HBase Version: 0.20.0, r805538
>> Hadoop Version: 0.20.0-plus4681, r767961
>>
>>
>>
> Are these release 0.20.0?
>
The hadoop is release 0.20.0 - the hbase is a pre-release svn checkout.
> St.Ack
>
>
>
>
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1894,"The region server appears to reference blocks from deleted log files after compaction.  Stopping the affected region server causes the region to be reassigned and appears to function properly again.

We have seen two instances this week where this caused the region server to get stuck with the following error:

hbase-root-regionserver-hfs-030015.log:2009-10-07 12:24:41,853 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_6092375271544310747_250240 from any node:  java.io.IOException: No live nodes contain current block
.
.
.
/opt/hbase/logs/hbase-root-regionserver-hfs-030015.log:java.io.IOException: Cannot open filename /hbase/fc_test/1209236691/json/9131415140626575165
/opt/hbase/logs/hbase-root-regionserver-hfs-030015.log:2009-10-07 13:09:47,343 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_6092375271544310747_250240 from any node:  java.io.IOException: No live nodes contain current block

From the hdfs log we can see that the block in question was part of a compaction log:

hadoop-root-namenode-hfs-030010.log:2009-10-07 08:48:31,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/fc_test/compaction.dir/1209236691/2099727166320402414. blk_6092375271544310747_250240
hadoop-root-namenode-hfs-030010.log:2009-10-07 08:48:31,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.4.30.39:50010 is added to blk_6092375271544310747_250240 size 360813
hadoop-root-namenode-hfs-030010.log:2009-10-07 08:48:31,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.4.30.23:50010 is added to blk_6092375271544310747_250240 size 360813
hadoop-root-namenode-hfs-030010.log:2009-10-07 08:48:31,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.4.30.16:50010 is added to blk_6092375271544310747_250240 size 360813

From the same log we see the block deleted:

hadoop-root-namenode-hfs-030010.log:2009-10-07 12:13:20,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.4.30.39:50010 to delete  blk_-8366798629992987785_250239 blk_-278212026264018289_224708 blk_4131756856877489141_230749 blk_6092375271544310747_250240 blk_-1303356519220271320_144130
hadoop-root-namenode-hfs-030010.log:2009-10-07 12:13:26,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.4.30.23:50010 to delete  blk_3405064566022477311_135928 blk_-7806500863137897827_139699 blk_6092375271544310747_250240
hadoop-root-namenode-hfs-030010.log:2009-10-07 12:13:29,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* ask 10.4.30.16:50010 to delete  blk_-3938002954120963098_139149 blk_2284074818158875873_144134 blk_519099260905493191_222718 blk_7684159545746656462_144137 blk_7857071994919747100_144127 blk_6311161030310597085_135919 blk_-8366798629992987785_250239 blk_5638304438869005376_142347 blk_-1019479064035180992_143997 blk_4131756856877489141_230749 blk_6092375271544310747_250240 blk_-1520990752128999182_192595 blk_1714900485284856973_230761 blk_-1303356519220271320_144130

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1296,"From a private mail with J茅r么me Thi猫vre:

""Two times I got the same kind of problems described by schubert zhang in the thread *HDFS unbalance issue. (HBase over HDFS). *The first time, I found one of my regionserver  with a full disk, whereas the others were at 10% of their capacity. I saw a lot of move file command at hadoop level from the full regionserver to others, but after check on the hdfs, I can see that hadoop copies the file but fails to delete it.  As the regionserver disk was full, it didn't work anymore, even after hadoop and hbase restart. I had to delete all the data.

""The second time this problem occurs I stopped the row insertion process before the disk was full. After hadoop and hbase restart, hadoop has deleted the files and the system was operational.
It seems that in some cases where the system is heavily loaded with continuous writes and compactions, hadoop can't remove files.""

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1343,Generating thrift bindings with a current release of thrift breaks the python demo client. The attached patch fixes the demo client code.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2104,"When a regionservers is stopped (shutdown or crash) and on the same moment a client performs a scan on that regionserver no exception is thrown at client side nor a reconnect toanother regionsserver is tried.
The ResultScanner.Iterator.hasNext ()just returns false, so the client assumes that there are no records anymore.


In the ScannerCallable.call I notice that the java.net.ConnectionException is catched and a empyt Result array is returned.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2096,"When starting the regionserver (issue also reproduces on master), I get the following error: 

---
2010-01-06 15:10:48,208 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: vmInputArguments=[-Xmx1000m, -XX:+HeapDumpOnOutOfMemoryError, -XX:+UseConcMarkSweepGC, -XX:+CMSIncrementalMode, -Dhbase.log.dir=/Users/adragomi/hbase/bin/../logs, -Dhbase.log.file=hbase-adragomi-regionserver-adragomi-mac.corp.adobe.com.log, -Dhbase.home.dir=/Users/adragomi/hbase/bin/.., -Dhbase.id.str=adragomi, -Dhbase.root.logger=INFO,DRFA]
2010-01-06 15:10:48,211 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Can not start region server because java.lang.NoSuchMethodException: org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(org.apache.hadoop.hbase.HBaseConfiguration)
	at java.lang.Class.getConstructor0(Class.java:2706)
	at java.lang.Class.getConstructor(Class.java:1657)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.doMain(HRegionServer.java:2313)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2394)
---

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1775,"In http://wiki.apache.org/hadoop/Hbase/HowToContribute it clearly states:
{code}
 o All public classes and methods should have informative Javadoc comments. 
{code}

(it should probably read ""correct and informative"")

I have seen missing input parameters and return values. Paying attention to details like this will also lessen the number of questions seen on the hbase-user mailing list.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1603,"Here is the master.  Region TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246462685358 was split at 16:11:42,865.  My MR job failed at 18:12:26,462 with this:

{code}
2009-07-01 18:12:26,462 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server Some server for region TestTable,锟?1246464670313, row '锟斤拷		', but failed after 10 attempts.
Exceptions:
...
{code}

Why after ten attempts did the client not find the region?

{code}
2009-07-01 16:11:42,865 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_SPLIT: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246462685358: Daughters; TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313, TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 1 of 3
2009-07-01 16:11:42,866 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 to aa0-000-15.u.powerset.com,60020,1246461673026
2009-07-01 16:11:42,866 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 to aa0-000-15.u.powerset.com,60020,1246461673026
2009-07-01 16:11:45,905 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_PROCESS_OPEN: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 1 of 3
2009-07-01 16:11:45,905 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 2 of 3
2009-07-01 16:11:45,906 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 3 of 3
2009-07-01 16:11:45,906 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 open on 208.76.44.142:60020
2009-07-01 16:11:45,906 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: updating row TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 in region .META.,,1 with startcode 1246461673026 and server 208.76.44.142:60020
2009-07-01 16:11:45,908 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 open on 208.76.44.142:60020
2009-07-01 16:11:45,908 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: updating row TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 in region .META.,,1 with startcode 1246461673026 and server 208.76.44.142:60020
2009-07-01 17:46:42,670 [IPC Server handler 0 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_SPLIT: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313: Daughters; TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246470379467, TestTable,\x00\x00\x08\x04\x05\x07\x02\x05\x04\x08,1246470379467 from aa0-000-15.u.powerset.com,60020,1246461673026; 5 of 7
{code}

Here is over on the regionserver:

{code}
2009-07-01 16:11:42,865 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_SPLIT: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246462685358: Daughters; TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313, TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 1 of 3
2009-07-01 16:11:42,866 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 to aa0-000-15.u.powerset.com,60020,1246461673026
2009-07-01 16:11:42,866 [IPC Server handler 2 on 60001] INFO org.apache.hadoop.hbase.master.RegionManager: Assigning region TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 to aa0-000-15.u.powerset.com,60020,1246461673026
2009-07-01 16:11:45,905 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_PROCESS_OPEN: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 1 of 3
2009-07-01 16:11:45,905 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 2 of 3
2009-07-01 16:11:45,906 [IPC Server handler 8 on 60001] INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 from aa0-000-15.u.powerset.com,60020,1246461673026; 3 of 3
2009-07-01 16:11:45,906 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 open on X.X.X.142:60020
2009-07-01 16:11:45,906 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: updating row TestTable,\x00\x00\x06\x05\x01\x05\x07\x09\x08\x00,1246464670313 in region .META.,,1 with startcode 1246461673026 and server X.X.X4.142:60020
2009-07-01 16:11:45,908 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 open on X.X.X.142:60020
2009-07-01 16:11:45,908 [HMaster] INFO org.apache.hadoop.hbase.master.RegionServerOperation: updating row TestTable,\x00\x01\x01\x04\x04\x07\x02\x08\x08\x03,1246464670313 in region .META.,,1 with startcode 1246461673026 and server X.X.X.142:60020
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1469,"data4 in the test murmur hash is failing.  I commented out for now:

{code}
    // TODO: This if failing St.Ack
    // assertEquals(-969272041, hash.hash(data4, 4, data4.length-4, seed));
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8900,"Failed here:

https://builds.apache.org/job/hbase-0.95-on-hadoop2/169/testReport/junit/org.apache.hadoop.hbase.regionserver/TestRSKilledWhenMasterInitializing/testCorrectnessWhenMasterFailOver/

and

http://54.241.6.143/job/HBase-0.95-Hadoop-2/579/org.apache.hbase$hbase-server/testReport/junit/org.apache.hadoop.hbase.regionserver/TestRSKilledWhenMasterInitializing/org_apache_hadoop_hbase_regionserver_TestRSKilledWhenMasterInitializing/

{code}
java.lang.Exception: test timed out after 120000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hbase.zookeeper.ZKAssign.blockUntilNoRIT(ZKAssign.java:1002)
	at org.apache.hadoop.hbase.regionserver.TestRSKilledWhenMasterInitializing.testCorrectnessWhenMasterFailOver(TestRSKilledWhenMasterInitializing.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}

and with this:

{code}
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.TestRSKilledWhenMasterInitializing.tearDownAfterClass(TestRSKilledWhenMasterInitializing.java:83)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11411,"In doing read operations with ACL we were checking there is read permission granted on the table
{code}
AuthResult authResult = permissionGranted(opType, user, env, families, Action.READ);
    HRegion region = getRegion(env);
    TableName table = getTableName(region);
    Map<ByteRange, Integer> cfVsMaxVersions = Maps.newHashMap();
    for (HColumnDescriptor hcd : region.getTableDesc().getFamilies()) {
      cfVsMaxVersions.put(new SimpleByteRange(hcd.getName()), hcd.getMaxVersions());
    }
{code}
If there is no permission then we were checking for the type of cell level permission 
{code}
case CHECK_CELL_DEFAULT: {
        if (authManager.authorize(user, table, family, qualifier, Permission.Action.READ) ||
            authManager.authorize(user, table, cell, Permission.Action.READ)) {
          return ReturnCode.INCLUDE;
        }
      }
      break;
      // Cell permissions must authorize
      case CHECK_CELL_FIRST: {
        if (authManager.authorize(user, table, cell, Permission.Action.READ) &&
            authManager.authorize(user, table, family, qualifier, Permission.Action.READ)) {
          return ReturnCode.INCLUDE;
        }
{code}
For CELL_FIRST_STRATEGY 
-> if the user had granted READ permission on the table itself then even if cell level was not granting access we were able to read the cell.
->If table level READ permission was not there then the && condition was failing from reading any cell even with READ permission. 
The 2nd one was an intended behaviour but for the first one I think we should see if really the cell was readable too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8479,"With Roman, am trying to set up a bigtop ci of hbase 0.95 only we fail to compile.  It is the exotic generics that are going on over in AggregateClient.  Here is how we fail:

{code}
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[135,59] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds Q,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[208,59] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds Q,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[328,57] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds T,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[390,57] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds T,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[489,59] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds T,com.google.protobuf.Message
[ERROR] /mnt/jenkins/workspace/HBase-0.95/label/centos6/build/hbase/rpm/BUILD/hbase-0.95-SNAPSHOT/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/AggregationClient.java:[591,59] type parameters of <T>T cannot be determined; no unique maximal instance exists for type variable T with upper bounds T,com.google.protobuf.Message
[INFO] 6 errors 
{code}

I cannot reproduce locally but googling, I see that above is pretty common complaint when you move between compilers.  Various are the recommendations for fix but none definitive.  The easiest is dumbing down the generics which I tried but it only caused issues in other coprocessors.

If clues on how to fix this, I'm all ears.  Would like to get this bigtop ci build running.  Its cool.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6577,RegionScannerImpl.nextRow() is called when a filter filters the entire row. In that case we should seek to the next row rather then iterating over all versions of all columns to get there.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9980,"See HBASE-9834.

We should have a test that:
# generates a file with all kinds of objects serialized into it. Save that file as part of the HBase tests
# a test can then read the objects back from that file
# a test can regenerate that file

If both tests pass we can be reasonably sure that neither readFields nor write was changed in an incompatible way.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11075,Latest precommit builds I could see TestVisibilityLabelsWithDistributedLogReplay failing frequently.  Need to identify the root cause and fix it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9729,"mvn site fails on hadoopqa runs, and also on fresh checkouts. The problem seems to be that mvn site somehow does not trigger a correct reactor ordering. hbase-server is built before other components, and thus throws dependency errors because the other modules are not build yet. 

An example from https://builds.apache.org/job/PreCommit-HBASE-Build/7491//consoleFull: 
{code}
/home/jenkins/tools/maven/latest/bin/mvn compile site -DskipTests -DHBasePatchProcess > /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/patchprocess/patchSiteOutput.txt 2>&1
{code}


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11146,"See HBASE-11096.

in 0.99, HRegionServer is the base class of HMaster. 
master and regionserver share the same run method, the master instantiates both MasterCoprocessorHost and RegionServerCoprocessorHost


below is example logs, a coprocessor is start/stop twice--one is for real regionserver, the other is for the RegionServerCoprocessorHost in master.

2014-05-08 00:33:51,632 INFO [M:0;bdvm135:36021] coprocessor.TestCoprocessorStop$FooCoprocessor(66): st
art coprocessor on regionserver

2014-05-08 00:33:51,633 INFO [RS:0;bdvm135:47513] coprocessor.TestCoprocessorStop$FooCoprocessor(66): s
tart coprocessor on regionserver

...
2014-05-08 00:34:03,166 INFO [main] regionserver.HRegionServer(1624): call stack of stop
java.io.IOException
at org.apache.hadoop.hbase.regionserver.HRegionServer.stop(HRegionServer.java:1624)
at org.apache.hadoop.hbase.master.ServerManager.shutdownCluster(ServerManager.java:975)
at org.apache.hadoop.hbase.master.HMaster.shutdown(HMaster.java:1623)
at org.apache.hadoop.hbase.util.JVMClusterUtil.shutdown(JVMClusterUtil.java:256)
at org.apache.hadoop.hbase.LocalHBaseCluster.shutdown(LocalHBaseCluster.java:437)
at org.apache.hadoop.hbase.MiniHBaseCluster.shutdown(MiniHBaseCluster.java:519)
at org.apache.hadoop.hbase.coprocessor.TestCoprocessorStop.testStopped(TestCoprocessorStop.java:
114)
...
2014-05-08 00:34:03,215 INFO [main] regionserver.HRegionServer(1629): rsHost code path called

2014-05-08 00:34:03,228 DEBUG [main] coprocessor.CoprocessorHost(258): Stop coprocessor org.apache.hadoo
p.hbase.coprocessor.TestCoprocessorStop$FooCoprocessor
2014-05-08 00:34:03,462 INFO [main] coprocessor.TestCoprocessorStop$FooCoprocessor(88): create file hdf
s://localhost:8155/user/tianq/test-data/f0c9423c-e505-4feb-907e-c7bd6e16545b/regionserver1399534399680 r
eturn rc true

...

2014-05-08 00:34:03,482 INFO [main] regionserver.HRegionServer(1624): call stack of stop
java.io.IOException
at org.apache.hadoop.hbase.regionserver.HRegionServer.stop(HRegionServer.java:1624)
at org.apache.hadoop.hbase.util.JVMClusterUtil.shutdown(JVMClusterUtil.java:264)
at org.apache.hadoop.hbase.LocalHBaseCluster.shutdown(LocalHBaseCluster.java:437)
at org.apache.hadoop.hbase.MiniHBaseCluster.shutdown(MiniHBaseCluster.java:519)
at org.apache.hadoop.hbase.coprocessor.TestCoprocessorStop.testStopped(TestCoprocessorStop.java:
114)
2014-05-08 00:34:03,485 INFO [main] regionserver.HRegionServer(1629): rsHost code path called

2014-05-08 00:34:03,485 DEBUG [main] coprocessor.CoprocessorHost(258): Stop coprocessor org.apache.hadoo
p.hbase.coprocessor.TestCoprocessorStop$FooCoprocessor
2014-05-08 00:34:03,493 INFO [main] coprocessor.TestCoprocessorStop$FooCoprocessor(88): create file hdf
s://localhost:8155/user/tianq/test-data/f0c9423c-e505-4feb-907e-c7bd6e16545b/regionserver1399534399680 r
eturn rc false",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10076,MapReduce over Snapshots would be valuable on 0.94.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9740,"As described in HBASE-9737, a corrupt HFile in a region could lead to an assignment storm in the cluster since the Master will keep trying to assign the region to each region server one after another and obviously none will succeed.

The region server, upon detecting such a scenario should mark the region as ""RS_ZK_REGION_FAILED_ERROR"" (or something to the effect) in the Zookeeper which should indicate the Master to stop assigning the region until the error has been resolved (via an HBase shell command, probably ""assign""?)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11041,"Just found a test failing like this:
{code}
Error Message

HTableDescriptor is read-only

Stacktrace

java.lang.UnsupportedOperationException: HTableDescriptor is read-only
	at org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.addFamily(UnmodifyableHTableDescriptor.java:64)
	at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1302)
	at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1291)
	at org.apache.hadoop.hbase.HBaseTestingUtility.createMultiRegions(HBaseTestingUtility.java:1286)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.installTable(TestDistributedLogSplitting.java:485)
	at org.apache.hadoop.hbase.master.TestDistributedLogSplitting.testMasterStartsUpWithLogSplittingWork(TestDistributedLogSplitting.java:282)
{code}

The code that causes this looks like this:
{code}
    HTableDescriptor htd = table.getTableDescriptor();
    if(!htd.hasFamily(columnFamily)) {
      HColumnDescriptor hcd = new HColumnDescriptor(columnFamily);
      htd.addFamily(hcd);
    }
{code}

But note that table.getTableDescriptor() returns an UnmodifyableHTableDescriptor, so the add would *always* fail.

The specific test that failed was TestDistributedLogSplitting.testMasterStartsUpWithLogSplittingWork.
Looks like the HMaster did not have the last table descriptor state, yet.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10235,Namespace level grants are not checked by the AccessController in 0.96 also.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11067,"Due to HADOOP-10499, HBase cannot build against branch-2, I will upload patch shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5211,I can't seem to get this test to pass consistently on my laptop. Also my hudson occasionally tripps up on it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6169,"When RS got an ZK error when trying to create a ""CLOSING"" node in the process of closing a region, it hence aborts without completing closing of the region.
RS is then discovered dead by HMaster. ServerShutdownHandler does not try to reassign this region for it is in PENDING_CLOSE state; while all regions that originally belong to the dead RS get removed from the ""regions"" map.
TimeoutMonitor then endlessly tries to ""unassign"" this region with LOG message ""Region has been PENDING_CLOSE for too long"". The ""unassign"" returns without doing anything, for this region does not exist in the ""regions"" map:
  public void unassign(HRegionInfo region, boolean force, ServerName dest) {
    // TODO: Method needs refactoring.  Ugly buried returns throughout.  Beware!
    LOG.debug(""Starting unassignment of region "" +
      region.getRegionNameAsString() + "" (offlining)"");

    synchronized (this.regions) {
      // Check if this region is currently assigned
      if (!regions.containsKey(region)) {
        LOG.debug(""Attempted to unassign region "" +
          region.getRegionNameAsString() + "" but it is not "" +
          ""currently assigned anywhere"");
        return;
      }
    }
  ...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4064,"1. If there is a ""rubbish"" RegionState object with ""PENDING_CLOSE"" in regionsInTransition(The RegionState was remained by some exception which should be removed, that's why I called it as ""rubbish"" object), but the region is not currently assigned anywhere, TimeoutMonitor will fall into an endless loop:

2011-06-27 10:32:21,326 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=PENDING_CLOSE, ts=1309141555301
2011-06-27 10:32:21,326 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_CLOSE for too long, running forced unassign again on region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f.
2011-06-27 10:32:21,438 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining)
2011-06-27 10:32:21,441 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Attempted to unassign region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. but it is not currently assigned anywhere
2011-06-27 10:32:31,207 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=PENDING_CLOSE, ts=1309141555301
2011-06-27 10:32:31,207 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_CLOSE for too long, running forced unassign again on region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f.
2011-06-27 10:32:31,215 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining)
2011-06-27 10:32:31,215 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Attempted to unassign region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. but it is not currently assigned anywhere
2011-06-27 10:32:41,164 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=PENDING_CLOSE, ts=1309141555301
2011-06-27 10:32:41,164 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_CLOSE for too long, running forced unassign again on region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f.
2011-06-27 10:32:41,172 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining)
2011-06-27 10:32:41,172 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Attempted to unassign region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. but it is not currently assigned anywhere
.....

2  In the following scenario, two concurrent unassigning call of the same region may lead to the above problem:
the first unassign call send rpc call success, the master watched the event of ""RS_ZK_REGION_CLOSED"", process this event, will create a ClosedRegionHandler to remove the state of the region in master.eg.
while ClosedRegionHandler is running in  ""hbase.master.executor.closeregion.threads"" thread (A), another unassign call of same region run in another thread(B).
while thread B  run ""if (!regions.containsKey(region))"", this.regions have the region info, now  cpu switch to thread A.
The thread A will remove the region from the sets of ""this.regions"" and ""regionsInTransition"", then switch to thread B. the thread B run continue, will throw an exception with the msg of ""Server null returned java.lang.NullPointerException: Passed server is null for 9a6e26d40293663a79523c58315b930f"", but without removing the new-adding RegionState from ""regionsInTransition"",and it can not be removed for ever.


 public void unassign(HRegionInfo region, boolean force) {
    LOG.debug(""Starting unassignment of region "" +
      region.getRegionNameAsString() + "" (offlining)"");
    synchronized (this.regions) {
      // Check if this region is currently assigned
      if (!regions.containsKey(region)) {
        LOG.debug(""Attempted to unassign region "" +
          region.getRegionNameAsString() + "" but it is not "" +
          ""currently assigned anywhere"");
        return;
      }
    }
    String encodedName = region.getEncodedName();
    // Grab the state of this region and synchronize on it
    RegionState state;
    long stamp = -1;
    synchronized (regionsInTransition) {
      state = regionsInTransition.get(encodedName);
      if (state == null) {
        state = new RegionState(region, RegionState.State.PENDING_CLOSE);
        stamp =state.getStamp();               
        regionsInTransition.put(encodedName, state);
      } else if (force && state.isPendingClose()) {
        LOG.debug(""Attempting to unassign region "" +
            region.getRegionNameAsString() + "" which is already pending close ""
            + ""but forcing an additional close"");
        state.update(RegionState.State.PENDING_CLOSE);
      } else {
        LOG.debug(""Attempting to unassign region "" +
          region.getRegionNameAsString() + "" but it is "" +
          ""already in transition ("" + state.getState() + "")"");
        return;
      }
    }
    
    // Send CLOSE RPC
    HServerInfo server = null;
    synchronized (this.regions) {
      server = regions.get(region);
    }
}

2011-06-27 10:20:59,583 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining) 
2011-06-27 10:20:59,585 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Sent CLOSE to serverName=158-1-91-101,20020,1308983865292, load=(requests=0, regions=0, usedHeap=0, maxHeap=0) for region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. 
2011-06-27 10:22:15,299 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling new unassigned node: /hbase/unassigned/9a6e26d40293663a79523c58315b930f (region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f., server=158-1-91-101,20020,1308983865292, state=RS_ZK_REGION_CLOSED) 
2011-06-27 10:22:15,299 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_CLOSED, server=158-1-91-101,20020,1308983865292, region=9a6e26d40293663a79523c58315b930f 
2011-06-27 10:25:22,636 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out: test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=CLOSED, ts=1309141335247 
2011-06-27 10:25:22,636 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region 9a6e26d40293663a79523c58315b930f has been CLOSED for too long, waiting on queued ClosedRegionHandler to run or server shutdown 
2011-06-27 10:25:55,022 DEBUG org.apache.hadoop.hbase.master.handler.ClosedRegionHandler: Handling CLOSED event for 9a6e26d40293663a79523c58315b930f 
2011-06-27 10:25:55,022 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. 
2011-06-27 10:25:55,022 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:20000-0x230ba8b85230036 Deleting existing unassigned node for 9a6e26d40293663a79523c58315b930f that is in expected state RS_ZK_REGION_CLOSED 
2011-06-27 10:25:55,101 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:20000-0x230ba8b85230036 Successfully deleted unassigned node for region 9a6e26d40293663a79523c58315b930f in expected state RS_ZK_REGION_CLOSED 
2011-06-27 10:25:55,301 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining) 
2011-06-27 10:25:55,302 INFO org.apache.hadoop.hbase.master.AssignmentManager: Server null returned java.lang.NullPointerException: Passed server is null for 9a6e26d40293663a79523c58315b930f 
2011-06-27 10:32:21,326 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out: test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. state=PENDING_CLOSE, ts=1309141555301 
2011-06-27 10:32:21,326 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_CLOSE for too long, running forced unassign again on region=test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. 
2011-06-27 10:32:21,438 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Starting unassignment of region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. (offlining) 
2011-06-27 10:32:21,441 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Attempted to unassign region test2,070712,1308971310309.9a6e26d40293663a79523c58315b930f. but it is not currently assigned anywhere 

3  The following scenario shows how the above problem 2 happened:

(1)A table have a lot of regions, more than 70000 in my test. 
(2)Disable the table, if 'BulkDisabler.waitUntilDone' timeout, 'DisableTableHandler.process' will create another BulkDisabler object and start its thread pool. The region which was still online will call AssignmentManager.unassign again. so the same region ""AssignmentManager.unassign"" could be called concurrentlly more than 1. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10308,"Seen in 0.94 (both JDK6 and JDK7 builds)
{code}
Error Message

 Wanted but not invoked: procedure.sendGlobalBarrierComplete(); -> at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:344)  However, there were other interactions with this mock: -> at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:306) -> at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:311) -> at org.apache.hadoop.hbase.procedure.Procedure.call(Procedure.java:204) -> at org.apache.hadoop.hbase.procedure.Procedure.call(Procedure.java:204) -> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.memberAcquiredBarrier(ProcedureCoordinator.java:262) -> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.memberAcquiredBarrier(ProcedureCoordinator.java:262) -> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.abortProcedure(ProcedureCoordinator.java:217) -> at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:337) 

Stacktrace

Wanted but not invoked:
procedure.sendGlobalBarrierComplete();
-> at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:344)

However, there were other interactions with this mock:
-> at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:306)
-> at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:311)
-> at org.apache.hadoop.hbase.procedure.Procedure.call(Procedure.java:204)
-> at org.apache.hadoop.hbase.procedure.Procedure.call(Procedure.java:204)
-> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.memberAcquiredBarrier(ProcedureCoordinator.java:262)
-> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.memberAcquiredBarrier(ProcedureCoordinator.java:262)
-> at org.apache.hadoop.hbase.procedure.ProcedureCoordinator.abortProcedure(ProcedureCoordinator.java:217)
-> at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:337)

	at org.apache.hadoop.hbase.procedure.TestZKProcedure.waitAndVerifyProc(TestZKProcedure.java:344)
	at org.apache.hadoop.hbase.procedure.TestZKProcedure.testMultiCohortWithMemberTimeoutDuringPrepare(TestZKProcedure.java:319)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8256,"To make the Jenkin build more useful, it is good to keep it blue/green. We can mark those flaky tests flaky, and don't run them by default.  However, people can still run them.  We can also set up a Jekin build just for those flaky tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9374,"Per this [thread|http://mail-archives.apache.org/mod_mbox/hbase-dev/201308.mbox/%3cCANZa=GuLO0jTLs1fF+5_NRDczO+M=SSqjeAGVEeiCY8injbP8w@mail.gmail.com%3e] from the dev list.

{quote}
It appears that as of HBASE-1936, we now require that client applications have write access to hbase.local.dir. This is because ProtobufUtil instantiates a DyanamicClassLoader as part of static initialization. This classloader is used for instantiating Comparators, Filters, and Exceptions.
{quote}

Client applications do not need to use DynamicClassLoader and so should not require this write access.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9322,"I've been running tests on clusters with ""lots"" of regions, about 400, and I'm seeing weird contention in the client.

This one shows up a lot around the SoftValueSortedMap.

First I have this blocked thread on I'm not sure what:

{noformat}
""TestClient-12"" prio=10 tid=0x00007fb268872000 nid=0x3add waiting for monitor entry [0x00007fb251416000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.hadoop.hbase.util.SoftValueSortedMap.isEmpty(SoftValueSortedMap.java:210)
	- locked <0x00000000c1b70318> (a java.util.TreeMap)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getCachedLocation(HConnectionManager.java:1263)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1103)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1036)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:993)
{noformat}

This client waits on it:

{noformat}
""TestClient-14"" prio=10 tid=0x00007fb268876000 nid=0x3adf waiting for monitor entry [0x00007fb251214000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.hadoop.hbase.util.SoftValueSortedMap.lowerValueByKey(SoftValueSortedMap.java:189)
	- waiting to lock <0x00000000c1b70318> (a java.util.TreeMap)
	- locked <0x00000000c1b82120> (a org.apache.hadoop.hbase.util.SoftValueSortedMap)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getCachedLocation(HConnectionManager.java:1272)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1103)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1036)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:993)
{noformat}

As you can see it's also holding a lock, which I have 11 other clients waiting on:

{noformat}
""TestClient-13"" prio=10 tid=0x00007fb268874000 nid=0x3ade waiting for monitor entry [0x00007fb251315000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.hadoop.hbase.util.SoftValueSortedMap.lowerValueByKey(SoftValueSortedMap.java:189)
	- waiting to lock <0x00000000c1b82120> (a org.apache.hadoop.hbase.util.SoftValueSortedMap)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getCachedLocation(HConnectionManager.java:1272)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1103)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1036)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:993)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10172,"Hi, I want to upgrade hbase from 0.94 to 0.96. According to http://hbase.apache.org/book/upgrade0.96.html, I encountered a problem as follows:
{code}
Exception in thread ""main"" java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.
        at com.google.protobuf.GeneratedMessage.getUnknownFields(GeneratedMessage.java:180)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto.getSerializedSize(ClientNamenodeProtocolProtos.java:18005)
.....
{code}
hadoop version: hadoop-2.0.0-cdh4.2.1 
hbase version:hbase-0.94.0-cdh4.2.1
Thanks~",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9680,See latest 0.94 patch on HBASE-7404.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10102,"Example brought up by Niels Basjes on the user list:
If I do the following commands into the hbase shell
{code}
    create 't1', {NAME => 'c1', VERSIONS => 1}
    put 't1', 'r1', 'c1', 'One', 1000
    put 't1', 'r1', 'c1', 'Two', 2000
    put 't1', 'r1', 'c1', 'Three', 3000
    get 't1', 'r1'
    get 't1', 'r1' , {TIMERANGE => [0,1500]}

the result is this:

    get 't1', 'r1'
    COLUMN                     CELL
     c1:                       timestamp=3000, value=Three
    1 row(s) in 0.0780 seconds

    get 't1', 'r1' , {TIMERANGE => [0,1500]}
    COLUMN                     CELL
     c1:                       timestamp=1000, value=One
    1 row(s) in 0.1390 seconds
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9025,"I just saw this in a test run in 0.94:

{code}
Stacktrace

java.lang.NullPointerException
	at java.util.TreeMap.getEntry(TreeMap.java:324)
	at java.util.TreeMap.get(TreeMap.java:255)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testSplitDaughtersNotInMeta(TestHBaseFsck.java:1346)
...
{code}

The TreeMap in question here is actually returned from {{HTable.getRegionLocations()}}, which in turns calls {{MetaScanner.allTableRegions(getConfiguration(), getTableName(), false);}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7347,"Currently each store file is read only through the single reader regardless of how many concurrent read requests access that file.

This issue is to explore alternate designs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9188,"From https://builds.apache.org/job/hbase-0.95-on-hadoop2/231/testReport/org.apache.hadoop.hbase.util/TestHBaseFsck/testNotInMetaOrDeployedHole/ (region tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153):

expected:<[NOT_IN_META_OR_DEPLOYED, HOLE_IN_REGION_CHAIN]> but was:<[NOT_IN_META_OR_DEPLOYED, NOT_DEPLOYED, HOLE_IN_REGION_CHAIN]>

Here is snippet of test output:
{code}
2013-08-10 11:53:16,941 DEBUG [RS_CLOSE_REGION-vesta:38578-1] handler.CloseRegionHandler(168): set region closed state in zk successfully for region tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153. sn name: vesta.apache.org,38578,1376135290018
2013-08-10 11:53:16,941 DEBUG [RS_CLOSE_REGION-vesta:38578-1] handler.CloseRegionHandler(177): Closed region tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
2013-08-10 11:53:16,942 DEBUG [AM.ZK.Worker-pool-2-thread-13] master.AssignmentManager(782): Handling transition=RS_ZK_REGION_CLOSED, server=vesta.apache.org,38578,1376135290018, region=3ec6178a369a899c007fd89807b37153, current state from region state map ={3ec6178a369a899c007fd89807b37153 state=PENDING_CLOSE, ts=1376135596730, server=vesta.apache.org,38578,1376135290018}
2013-08-10 11:53:16,942 WARN  [AM.ZK.Worker-pool-2-thread-13] master.RegionStates(245): Closed region 3ec6178a369a899c007fd89807b37153 still on vesta.apache.org,38578,1376135290018? Ignored, reset it to null
2013-08-10 11:53:16,942 INFO  [AM.ZK.Worker-pool-2-thread-13] master.RegionStates(260): Transitioned from {3ec6178a369a899c007fd89807b37153 state=PENDING_CLOSE, ts=1376135596730, server=vesta.apache.org,38578,1376135290018} to {3ec6178a369a899c007fd89807b37153 state=CLOSED, ts=1376135596942, server=null}
2013-08-10 11:53:16,942 DEBUG [AM.ZK.Worker-pool-2-thread-13] handler.ClosedRegionHandler(92): Handling CLOSED event for 3ec6178a369a899c007fd89807b37153
2013-08-10 11:53:16,942 DEBUG [AM.ZK.Worker-pool-2-thread-13] master.AssignmentManager(1462): Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
...
2013-08-10 11:53:17,319 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(1815): getMetaTableRows: row -> tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.{ENCODED => 3ec6178a369a899c007fd89807b37153, NAME => 'tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.', STARTKEY => 'B', ENDKEY => 'C'}
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(1815): getMetaTableRows: row -> tableNotInMetaOrDeployedHole,C,1376135595424.c2ae2bddbe9302c4344c13936248ac9d.{ENCODED => c2ae2bddbe9302c4344c13936248ac9d, NAME => 'tableNotInMetaOrDeployedHole,C,1376135595424.c2ae2bddbe9302c4344c13936248ac9d.', STARTKEY => 'C', ENDKEY => ''}
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] util.TestHBaseFsck(231): tableNotInMetaOrDeployedHole,,1376135595423.9df585f7f666e1cd55d7b875aae22ece.
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] util.TestHBaseFsck(231): tableNotInMetaOrDeployedHole,A,1376135595424.90a7d5f2211951d321c9f29f4059671f.
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] util.TestHBaseFsck(231): tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
2013-08-10 11:53:17,320 INFO  [pool-1-thread-1] util.TestHBaseFsck(231): tableNotInMetaOrDeployedHole,C,1376135595424.c2ae2bddbe9302c4344c13936248ac9d.
2013-08-10 11:53:17,326 DEBUG [pool-1-thread-1] client.ClientScanner(218): Finished region={ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2013-08-10 11:53:17,327 INFO  [pool-1-thread-1] util.TestHBaseFsck(319): {ENCODED => 9df585f7f666e1cd55d7b875aae22ece, NAME => 'tableNotInMetaOrDeployedHole,,1376135595423.9df585f7f666e1cd55d7b875aae22ece.', STARTKEY => '', ENDKEY => 'A'}vesta.apache.org,41438,1376135289941
2013-08-10 11:53:17,328 INFO  [pool-1-thread-1] util.TestHBaseFsck(319): {ENCODED => 90a7d5f2211951d321c9f29f4059671f, NAME => 'tableNotInMetaOrDeployedHole,A,1376135595424.90a7d5f2211951d321c9f29f4059671f.', STARTKEY => 'A', ENDKEY => 'B'}vesta.apache.org,38578,1376135290018
2013-08-10 11:53:17,328 INFO  [pool-1-thread-1] util.TestHBaseFsck(283): RegionName: tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
2013-08-10 11:53:17,328 INFO  [pool-1-thread-1] util.TestHBaseFsck(287): Undeploying region {ENCODED => 3ec6178a369a899c007fd89807b37153, NAME => 'tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.', STARTKEY => 'B', ENDKEY => 'C'} from server vesta.apache.org,38578,1376135290018
2013-08-10 11:53:17,328 INFO  [RpcServer.handler=1,port=38578] regionserver.HRegionServer(3612): Received close region: 3ec6178a369a899c007fd89807b37153Transitioning in ZK: no. Version of ZK closing node:-1. Destination server:null
2013-08-10 11:53:17,329 ERROR [RpcServer.handler=1,port=38578] regionserver.HRegionServer(2473): Received CLOSE for a region which is not online, and we're not opening.
2013-08-10 11:53:17,330 WARN  [pool-1-thread-1] util.HBaseFsckRepair(156): Exception when closing region: tableNotInMetaOrDeployedHole,B,1376135595424.3ec6178a369a899c007fd89807b37153.
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: The region 3ec6178a369a899c007fd89807b37153 is not online, and is not opening.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2476)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:3617)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:14458)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2147)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1854)
{code}
Region was not deployed after hbck run.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6893,"In trunk build #3387 (https://builds.apache.org/view/G-L/view/HBase/job/HBase-TRUNK/3387/testReport/org.apache.hadoop.hbase/TestRegionRebalancing/testRebalanceOnRegionServerNumberChange_0_/):
{code}
java.lang.AssertionError: After 5 attempts, region assignments were not balanced.
	at org.junit.Assert.fail(Assert.java:93)
	at org.apache.hadoop.hbase.TestRegionRebalancing.assertRegionsAreBalanced(TestRegionRebalancing.java:219)
	at org.apache.hadoop.hbase.TestRegionRebalancing.testRebalanceOnRegionServerNumberChange(TestRegionRebalancing.java:139)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6928,"In build #3406, I saw:
{code}
java.lang.AssertionError: Column family prefix used twice: cf.cf.bt.Data.fsReadnumops
	at org.apache.hadoop.hbase.regionserver.metrics.SchemaMetrics.validateMetricChanges(SchemaMetrics.java:822)
	at org.apache.hadoop.hbase.regionserver.TestStoreFile.tearDown(TestStoreFile.java:89)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9223,"Observed behavior:

Command: hbase zkcli
There is an error message about a missing class:
{code}[root@data-compat-3 hbase]# hbase zkcli
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServerArg
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.zookeeper.ZooKeeperMainServerArg
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
{code}

It looks like this class is no longer in 0.95. 
ZKCli still continues in its startup and continues working (at least reads continue to work)

Expected behavior:
HBase Zkcli should not be looking for classes that are no longer part of HBase. This indicates an underlying issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8919,"Looking at this build: https://builds.apache.org/job/hbase-0.95-on-hadoop2/173/testReport/org.apache.hadoop.hbase.replication/TestReplicationQueueFailoverCompressed/queueFailover/

The only thing I can find that went wrong is that the recovered queue was not completely done because the source fails like this:

{noformat}
2013-07-10 11:53:51,538 INFO  [Thread-1259] regionserver.ReplicationSource$2(799): Slave cluster looks down: Call to hemera.apache.org/140.211.11.27:38614 failed on local exception: java.nio.channels.ClosedByInterruptException
{noformat}

And just before that it got:
{noformat}
2013-07-10 11:53:51,290 WARN  [ReplicationExecutor-0.replicationSource,2-hemera.apache.org,43669,1373457208379] regionserver.ReplicationSource(661): Can't replicate because of an error on the remote cluster: 
org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException): org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1594 actions: FailedServerException: 1594 times, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:158)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$500(AsyncProcess.java:146)
	at org.apache.hadoop.hbase.client.AsyncProcess.getErrors(AsyncProcess.java:692)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:2106)
	at org.apache.hadoop.hbase.client.HTable.batchCallback(HTable.java:689)
	at org.apache.hadoop.hbase.client.HTable.batchCallback(HTable.java:697)
	at org.apache.hadoop.hbase.client.HTable.batch(HTable.java:682)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.batch(ReplicationSink.java:239)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSink.replicateEntries(ReplicationSink.java:161)
	at org.apache.hadoop.hbase.replication.regionserver.Replication.replicateLogEntries(Replication.java:173)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.replicateWALEntry(HRegionServer.java:3735)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:14402)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2122)
	at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1829)

	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1369)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1573)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1630)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.replicateWALEntry(AdminProtos.java:15177)
	at org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.replicateWALEntry(ReplicationProtbufUtil.java:94)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.shipEdits(ReplicationSource.java:642)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:376)
{noformat}

I wonder what's closing the socket with an interrupt, it seems it still needs to replicate more data. I'll start by adding the stack trace for the message when it fails to replicate on a ""local exception"". Also I found a thread that wasn't shutdown properly that I'm going to fix to help with debugging.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6620,"Test flaps in autobuilds with assertion failure.


org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor.testPoolBehavior

Failing for the past 1 build (Since #2602 )
Took 3 ms.
Error Message

expected:<3> but was:<4>
Stacktrace

java.lang.AssertionError: expected:<3> but was:<4>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.junit.Assert.assertEquals(Assert.java:456)
	at org.apache.hadoop.hbase.client.TestFromClientSide.testPoolBehavior(TestFromClientSide.java:4334)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:47)
	at org.junit.rules.RunRules.evaluate(RunRules.java:18)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7280,"in cluster replication, if the master cluster have 2 tables which have column-family declared with replication scope = 1, and add a peer cluster which has only 1 table with the same name as the master cluster, in the ReplicationSource (thread in master cluster) for this peer, edits (logs) for both tables will be shipped to the peer, the peer will fail applying the edits due to TableNotFoundException, and this exception will also be responsed to the original shipper (ReplicationSource in master cluster), and the shipper will fall into an endless retry for shipping the failed edits without proceeding to read the remained(newer) log files and to ship following edits(maybe the normal, expected edit for the registered table). the symptom looks like the TableNotFoundException incurs endless retry and blocking normal table replication",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8614,"Running test suite on hadoop 2.0, I saw the following test failure:
{code}
testFavoredNodes(org.apache.hadoop.hbase.regionserver.TestRegionFavoredNodes)  Time elapsed: 0.106 sec  <<< ERROR!
org.apache.hadoop.hbase.exceptions.DroppedSnapshotException: region: table,rrr,1369355298031.1fdb1b446b02b497f0869a08adad7745.
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1568)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1429)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1347)
        at org.apache.hadoop.hbase.MiniHBaseCluster.flushcache(MiniHBaseCluster.java:531)
        at org.apache.hadoop.hbase.HBaseTestingUtility.flush(HBaseTestingUtility.java:961)
        at org.apache.hadoop.hbase.regionserver.TestRegionFavoredNodes.testFavoredNodes(TestRegionFavoredNodes.java:132)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.junit.runners.Suite.runChild(Suite.java:127)
        at org.junit.runners.Suite.runChild(Suite.java:26)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.util.FSUtils.create(FSUtils.java:293)
        at org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.createOutputStream(AbstractHFileWriter.java:268)
        at org.apache.hadoop.hbase.io.hfile.HFile$WriterFactory.create(HFile.java:427)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.<init>(StoreFile.java:791)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.<init>(StoreFile.java:733)
        at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:671)
        at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:799)
        at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:75)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:704)
        at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1813)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1543)
        ... 33 more
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1306)
        at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:283)
{code}
DistributedFileSystem#create() which supports favoredNodes parameter threw NullPointerException.
We should handle the NullPointerException and fall back to conventional DistributedFileSystem#create()",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5754,"Keith Turner re-wrote the accumulo continuous ingest test using gora, which has both hbase and accumulo back-ends.

I put a billion entries into HBase, and ran the Verify map/reduce job.  The verification failed because about 21K entries were missing.  The goraci [README|https://github.com/keith-turner/goraci] explains the test, and how it detects missing data.

I re-ran the test with 100 million entries, and it verified successfully.  
Both of the times I tested using a billion entries, the verification failed.
If I run the verification step twice, the results are consistent, so the problem is
probably not on the verify step.

Here's the versions of the various packages:

||package||version||
|hadoop|0.20.205.0|
|hbase|0.92.1|
|gora|http://svn.apache.org/repos/asf/gora/trunk r1311277|
|goraci|https://github.com/ericnewton/goraci  tagged 2012-04-08|

The change I made to goraci was to configure it for hbase and to allow it to build properly.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8626,"When RowMutations have a Delete followed by Put to same column family or columns or rows, only the Delete is happening while the Put is ignored so atomicity of RowMutations is broken for such cases.

Attached is a unit test where the following tests are failing:
- testDeleteCFThenPutInSameCF: Delete a column family and then Put to same column family.
- testDeleteColumnThenPutSameColumn: Delete a column and then Put to same column.
- testDeleteRowThenPutSameRow: Delete a row and then Put to same row
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8571,"Maybe it's just me, but I've been looking on trunk and I don't see where either RowCounter or CopyTable MapReduce can adjust the setCaching setting on the Scan instance.

Example from RowCounter...
{code}
   Job job = new Job(conf, NAME + ""_"" + tableName);
    job.setJarByClass(RowCounter.class);
    Scan scan = new Scan();
    scan.setCacheBlocks(false);
    Set<byte []> qualifiers = new TreeSet<byte[]>(Bytes.BYTES_COMPARATOR);
    if (startKey != null && !startKey.equals("""")) {
      scan.setStartRow(Bytes.toBytes(startKey));
    }
    if (endKey != null && !endKey.equals("""")) {
      scan.setStopRow(Bytes.toBytes(endKey));
    }
    scan.setFilter(new FirstKeyOnlyFilter());
    if (sb.length() > 0) {
      for (String columnName : sb.toString().trim().split("" "")) {
        String [] fields = columnName.split("":"");
        if(fields.length == 1) {
          scan.addFamily(Bytes.toBytes(fields[0]));
        } else {
          byte[] qualifier = Bytes.toBytes(fields[1]);
          qualifiers.add(qualifier);
          scan.addColumn(Bytes.toBytes(fields[0]), qualifier);
        }
      }
    }
    // specified column may or may not be part of first key value for the row.
    // Hence do not use FirstKeyOnlyFilter if scan has columns, instead use
    // FirstKeyValueMatchingQualifiersFilter.
    if (qualifiers.size() == 0) {
      scan.setFilter(new FirstKeyOnlyFilter());
    } else {
      scan.setFilter(new FirstKeyValueMatchingQualifiersFilter(qualifiers));
    }
    job.setOutputFormatClass(NullOutputFormat.class);
    TableMapReduceUtil.initTableMapperJob(tableName, scan,
      RowCounterMapper.class, ImmutableBytesWritable.class, Result.class, job);
    job.setNumReduceTasks(0);
    return job;

{code}

TableMapReduceUtil only serializes the Scan into the job, it doesn't adjust any of the settings.

Maybe I'm missing something, but this seems like a problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5556,"I started seeing this problem on our Ubuntu servers since 0.92.0, ^H isn't detected correctly anymore in the readline rb version that's shipped with jruby 1.6.5

It works when I use the 1.6.0 jar.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6417,"Trying to see what caused HBASE-6310, one of the things I figured is that the bad .META. row is actually one from the time that we were permitting meta splitting and that folder had just been staying there for a while.

So I tried to recreate the issue with -repair and it merged my good .META. region with the one that's 3 years old that also has the same start key. I ended up with a brand new .META. region!

I'll be attaching the full log in a separate file.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6116,"In HDFS-1783 I adapted Dhrubas changes to be used in Hadoop trunk.
This issue will include the necessary reflection changes to optionally enable this for the WALs in HBase.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7022,Bulk assigner needs to set regions offline in zookeeper one by one. I was wondering if we can have some performance improvement if we batch these operations using ZooKeeper#multi.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3395,"In StoreScanner::next(List<KeyValue> outResult, int limit)

        case SEEK_NEXT_ROW:
          // This is just a relatively simple end of scan fix, to short-cut end us if there is a
          // endKey in the scan.
          if (!matcher.moreRowsMayExistAfter(kv)) {
            outResult.addAll(results);
            return false;
          }

close() is not being called before returning false. In all other cases close is called before returning false. May be this is a problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6443,"Somehow, some WAL files have size 0. Distributed log splitting can't handle it.
HLogSplitter should ignore them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7607,"TestRegionServerCoprocessorExceptionWithAbort fails sometimes both on trunk and 0.94.X. The codebase is different in both. 

In 0.94.x, client retries to look at the root region, while the cluster is down and /hbase znode is no longer present.
""Check the value configured in 'zookeeper.znode.parent'. There could be a mismatch with the one configured in the master.""

I will file a separate jira for the trunk as the code is different there.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7990,This was brought up in discussion entitled 'HRegionInfo was null or empty in Meta errors',,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4107,"An issue was observed where upon shutdown of a regionserver the regionserver log was corrupt.  It appears from the following stacktrace that an Java heap memory exception occurred while writing the checksum to the WAL.  Corrupting the WAL can potentially cause data loss. 

2011-07-14 14:54:53,741 FATAL org.apache.hadoop.hbase.regionserver.wal.HLog: Could not append. Requesting close of hlog
java.io.IOException: Reflection
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.sync(SequenceFileLogWriter.java:147)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.sync(HLog.java:987)
        at org.apache.hadoop.hbase.regionserver.wal.HLog$LogSyncer.run(HLog.java:964)
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.GeneratedMethodAccessor1336.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.sync(SequenceFileLogWriter.java:145)
        ... 2 more
Caused by: java.lang.OutOfMemoryError: Java heap space
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$Packet.<init>(DFSClient.java:2375)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:3271)
        at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:150)
        at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:132)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3354)
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
        at org.apache.hadoop.io.SequenceFile$Writer.syncFs(SequenceFile.java:944)
        ... 6 more
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7337,"put multi versions of a row.
r1 cf:q  version:1 value:1
r1 cf:q  version:2 value:3
r1 cf:q  version:3 value:2
the filter in scan is set as below:
SingleColumnValueFilter valueF = new SingleColumnValueFilter(
        family,qualifier,CompareOp.EQUAL,new BinaryComparator(Bytes
.toBytes(""2"")));

then i found all of the three versions will be emmitted, then i set latestVersionOnly to false, the result does no change.

{code}
  public ReturnCode filterKeyValue(KeyValue keyValue) {
    // System.out.println(""REMOVE KEY="" + keyValue.toString() + "", value="" + Bytes.toString(keyValue.getValue()));
    if (this.matchedColumn) {
      // We already found and matched the single column, all keys now pass
      return ReturnCode.INCLUDE;
    } else if (this.latestVersionOnly && this.foundColumn) {
      // We found but did not match the single column, skip to next row
      return ReturnCode.NEXT_ROW;
    }
    if (!keyValue.matchingColumn(this.columnFamily, this.columnQualifier)) {
      return ReturnCode.INCLUDE;
    }
    foundColumn = true;
    if (filterColumnValue(keyValue.getBuffer(),
        keyValue.getValueOffset(), keyValue.getValueLength())) {
      return this.latestVersionOnly? ReturnCode.NEXT_ROW: ReturnCode.INCLUDE;
    }
    this.matchedColumn = true;
    return ReturnCode.INCLUDE;
  }
{code}
From the code above, it seeems that version 3 will be first emmited, and set matchedColumn to true, which leads the following version 2 and 1 emmited too.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7865,"I faced 3 regions (out of 8) never stopping today. This is pretty bad because the script is supposed to wait until all the RS stopped to re-start everything, therefor, servers are never going back online.

HBASE-7838 will help with that and will kill the RSs. But that will not really solve the root cause.

Attached are the jstack for the 3 servers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7287,"When regions merge is failing because the files have the same sequenceID, the expected region is still created even if it's not used, which leaves the system with inconsistencies. The new region creation should be moved after the sequenceID test to avoid this issue, until we find a way to merge regions with the same sequenceID.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7696,"See here:
https://builds.apache.org/job/HBase-0.94/796/testReport/org.apache.hadoop.hbase.client/

and here:
https://builds.apache.org/job/HBase-0.94/794/testReport/org.apache.hadoop.hbase.client/",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6666,"This is an idea I had some time back. It would be nice if a RegionObserver (or Endpoint) could get access to all other regions on the same RegionServer to efficiently make updates to those regions as well (instead of going through the standard HTable path).

Together with a smart region placement strategy this can lead to much better performance for some coprocessor tasks.
Maybe it could be abstracted in a special HTable implementation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7302,"c++ client requires HRegionThriftServer.
We need to port HRegionThriftServer to using thrift2.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7155,"RootRegionTracker.getRootRegionLocation() declares that it can throw an InterruptedException, but it can't. This exception is rethrown by many other functions reaching the HBaseAdmin API.

If we remove the throws statement from the HBaseAdmin API libraries already compiled will work fine, but if the user is trying to catch an InterruptedException around one of those methods the compiler will complain.

Should we clean this up?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7136,"ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
java.lang.IllegalStateException: Schema metrics requested before table/CF name initialization: {""tableName"":""null"",""cfName"":""null""}
at org.apache.hadoop.hbase.regionserver.metrics.SchemaConfigured.getSchemaMetrics(SchemaConfigured.java:182)
at org.apache.hadoop.hbase.io.hfile.LruBlockCache.updateSizeMetrics(LruBlockCache.java:310)
at org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(LruBlockCache.java:274)
at org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(LruBlockCache.java:293)
at org.apache.hadoop.hbase.io.hfile.DoubleBlockCache.getBlock(DoubleBlockCache.java:102)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.getBlockFromCache(HFileReaderV2.java:266)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:348)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.readNextDataBlock(HFileReaderV2.java:587)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.next(HFileReaderV2.java:996)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:233)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:145)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.enforceSeek(StoreFileScanner.java:351)
at org.apache.hadoop.hbase.regionserver.KeyValueHeap.pollRealKV(KeyValueHeap.java:333)
at org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:291)


When we put the hfile block to SlabCache, it will drop the SchemaMetrics, howerver, if we cache this block to LruBlockCache, it will throw above exception ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4254,"Currently some 30 or so tests are failing on the ""HBase-trunk-on-hadoop-23"" build. It looks like most are reflection-based issues.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2441,"If the RS loses its ZK session before it reports for duty, the abort() call will trigger an NPE, and then the stop boolean doesn't get toggled. The RS will then loop forever trying to register itself in the expired ZK session, and fill up the logs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6880,"In looking into a TestReplication failure, I found out sometimes assignRoot could fail, for example, RS is not serving traffic yet.  In this case, the master will keep waiting for root to be available, which could never happen.
 
Need to gracefully terminate master if root is not assigned properly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2271,tableindexed.TestIndexedTable is hanging on 0.20 branch. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3378,"We recently saw several occurrences of NPE. Here is one of them:
{noformat}
2010-12-20 08:57:14,214 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.io.IOException: java.io.IOException: java.lang.NullPointerException

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
	at org.apache.hadoop.hbase.client.HBaseAdmin.modifyTable(HBaseAdmin.java:887)
	at org.apache.hadoop.hbase.client.HBaseAdmin.modifyTable(HBaseAdmin.java:791)
	at org.apache.hadoop.hbase.client.HBaseAdmin.flush(HBaseAdmin.java:703)
{noformat}

In master server log, I only found:
{noformat}
2010-12-20 16:57:19,357 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 15 on 60000, call modifyTable([B@5b591d0b, TABLE_FLUSH, null) from 10.202.114.157:2760: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
2010-12-20 16:57:19,357 WARN org.apache.hadoop.ipc.HBaseServer: IPC Server Responder, call modifyTable([B@5b591d0b, TABLE_FLUSH, null) from 10.202.114.157:2760: output error
2010-12-20 16:57:19,357 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 17 on 60000, call modifyTable([B@3781ec07, TABLE_FLUSH, null) from 10.202.114.136:35448: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
2010-12-20 16:57:19,358 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 15 on 60000 caught: java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:126)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324)
        at org.apache.hadoop.hbase.ipc.HBaseServer.channelWrite(HBaseServer.java:1210)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Responder.processResponse(HBaseServer.java:698)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Responder.doRespond(HBaseServer.java:762)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1026)
{noformat}

RemoteExceptionHandler should be able to handle NPE.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6111,"I have started seeing this issue in our environment.  HBASE-1672 was closed as non reproducible, so I cloned it here.

I have a 367M record table, compressed with snappy, and running a vanilla MR SCAN with no filters spawns 441 Mappers.  The cluster currently has 216 slots for mappers, and the first wave all report 100% data-local mappers.  As the second wave of mappers come up they don't get run locally to the RS and data locality drops.

This kills our environment, as it saturates the network at 120M which is very clear on ganglia.

I am really happy to help diagnose this, but need some guidance on what to do.  I don't know enough yet about how task assignment works in MR to determine why the machines are picking up random tasks for their second effort and not one for the local RS.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1672,"The number of data local map tasks while scanning a table is only about 10% of the total map tasks...
My table had 280 regions and 13M records... The number of map tasks in the scan job were equal to the number of regions (280). Only 25 of them were data local tasks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6720,See discussion on HBASE-3866,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6668,"hbase(main):002:0> disable 'logTable'
0 row(s) in 2.0910 seconds

hbase(main):003:0> disable 'logTable'
0 row(s) in 0.0260 seconds

and we can found table are disabled in log when  disable first appears
but when i disable it again the client just return seemed to be sucessful and I can not find any log described it in the log.

look into the admin.rb, find below

    #----------------------------------------------------------------------------------------------
    # Disables a table
    def disable(table_name)
      tableExists(table_name)
      return if disabled?(table_name)
      @admin.disableTable(table_name)
    end

that would confuse us when we found it disabled already but returns nothing 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6767,"in shell I issued:
{code}split 'TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4.'{code}

that resulted in the following error:
{code}2012-09-12 18:45:55,950 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4. not splittable because midkey=null
2012-09-12 18:46:04,267 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4. not splittable because midkey=null
2012-09-12 18:47:31,820 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4. not splittable because midkey=null
2012-09-12 18:47:35,028 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Region TestTable,,1347475507959.8021113e9c87e1b2f7914ff5b1644cc4. not splittable because midkey=null{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4952,"When I start the HBase trunk master on my five-node cluster, it gets stuck in the state ""initializing master service threads"" for a minute or two, then ""waiting for regionserver number to settle"", and only then starts log splitting. We don't have such delays in the 0.89-fb master, and I believe we can optimize the new master to eliminate these delays as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3814,"Once abort() on a regionserver is called we should have a timeout thread that does Runtime.halt() if the rs gets stuck somewhere during abort processing.

===


Pumahbase132 has following the logs .. the dfsclient is not able to set up a write pipeline successfully ... it tries to abort ... but while aborting it gets stuck. I know there is a check that if we are aborting because filesystem is closed then we should not try to flush the logs while aborting. But in this case the fs is up and running, just that it is not functioning.

2011-04-21 23:48:07,082 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream 10.38.131.53:50010  for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280java.io.IOException: Bad connect ack with firstBadLink 10.38.133.33:50010
2011-04-21 23:48:07,082 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-8967376451767492285_6537229 for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280
2011-04-21 23:48:07,125 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream 10.38.131.53:50010  for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280java.io.IOException: Bad connect ack with firstBadLink 10.38.134.59:50010
2011-04-21 23:48:07,125 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_7172251852699100447_6537229 for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280 

2011-04-21 23:48:07,169 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream 10.38.131.53:50010  for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280java.io.IOException: Bad connect ack with firstBadLink 10.38.134.53:50010
2011-04-21 23:48:07,169 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-9153204772467623625_6537229 for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280
2011-04-21 23:48:07,213 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream 10.38.131.53:50010  for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280java.io.IOException: Bad connect ack with firstBadLink 10.38.134.49:50010
2011-04-21 23:48:07,213 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-2513098940934276625_6537229 for file /PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280
2011-04-21 23:48:07,214 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:3560)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2700(DFSClient.java:2720)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2977)

2011-04-21 23:48:07,214 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_-2513098940934276625_6537229 bad datanode[1] nodes == null
2011-04-21 23:48:07,214 WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file ""/PUMAHBASE002-SNC5-HBASE/.logs/pumahbase132.snc5.facebook.com,60020,1303450732026/pumahbase132.snc5.facebook.com%3A60020.1303450732280"" - Aborting...
2011-04-21 23:48:07,216 FATAL org.apache.hadoop.hbase.regionserver.wal.HLog: Could not append. Requesting close of hlog

And then the RS gets stuck trying to roll the logs ...

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5340,"I was attempting to do a bulk load and got this error message.  Unfortunately it didn't tell me which file had the problem.

{code}
Exception in thread ""main"" java.io.IOException: Trailer 'header' is wrong; does the trailer size match content?
        at org.apache.hadoop.hbase.io.hfile.HFile$FixedFileTrailer.deserialize(HFile.java:1527)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readTrailer(HFile.java:885)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.loadFileInfo(HFile.java:819)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.tryLoad(LoadIncrementalHFiles.java:204)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(LoadIncrementalHFiles.java:173)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.run(LoadIncrementalHFiles.java:452)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.main(LoadIncrementalHFiles.java:457)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4001,"When the region server R1 and data node D1 running in the same machine and let's assuem this machine pub into repair,
the master will try to reassign all the regions in the region server to other region server R2. But at that time, the name node hasn't figure out the bad data node D1.
So the region server R2 will try to open the region from the D1, which will failed and retried. Then the master believes it took TOO LONG to open this region, so it reassign to R3...

The story continues until the name node figure out the bad datanode D1 and finally region server Rn opens the region and do the compaction for the store file. 
All previous region servers cannot the region later and find the file doesn't exist since it has been compacted.


So the solution is that when region has been OPENING for too long, the master should not reassign region.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4183,The checkFileSystem() function in FSUtils closes down the FileSystem for the HRegionServer by default if the FileSystem is not available. Ideally we should let the the HRegionServer threads exit and then shutdown the FileSystem. The checkFileSystem() function should not by default kill the FileSystem.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4702,"Doing a row count for a large table via Mapreduce may take long time.
Trying to set the default cache size but there is no knob to tune it.

See here for more details, http://search-hadoop.com/m/ECEs6237AIX&subj=Re+speeding+up+rowcount



",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4659,"scan.addColumn(Bytes.toBytes(""Info""), Bytes.toBytes(""value""));
scan.setMaxVersions();
SingleColumnValueFilter scvf = new SingleColumnValueFilter(Bytes.toBytes(""Info""), Bytes.toBytes(""value""), CompareOp.EQUAL, Bytes.toBytes(""test""));
scvf.setLatestVersionOnly(false);
scan.setFilter(scvf);


it can not filter previous versions",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5322,"I have a hbase table which holds data for more than 10GB. Now I used the same client scanner to scan which fails and reports,

""Could not seek StoreFileScanner[HFileScanner for reader reader=hdfs"".

This issue occurs only for the table which holds huge data and not for tables holding small data.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6345,"HDFS uses fault injection to test pipeline failure in addition to mock, spy. HBase uses mock, spy. But there are cases where mock, spy aren't convenient.

Some example from DFSClientAspects.aj :
{code}
  pointcut pipelineInitNonAppend(DataStreamer datastreamer):
    callCreateBlockOutputStream(datastreamer)
    && cflow(execution(* nextBlockOutputStream(..)))
    && within(DataStreamer);

  after(DataStreamer datastreamer) returning : pipelineInitNonAppend(datastreamer) {
    LOG.info(""FI: after pipelineInitNonAppend: hasError=""
        + datastreamer.hasError + "" errorIndex="" + datastreamer.errorIndex);
    if (datastreamer.hasError) {
      DataTransferTest dtTest = DataTransferTestUtil.getDataTransferTest();
      if (dtTest != null)
        dtTest.fiPipelineInitErrorNonAppend.run(datastreamer.errorIndex);
    }
  }
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6395,"MAPREDUCE-3451 added Fair Scheduler to MRv2

TestFSSchedulerApp was added under src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair but its package was declared to be org.apache.hadoop.yarn.server.resourcemanager.scheduler",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6320,"After modularization, the command to build the tarball on wiki:
http://wiki.apache.org/hadoop/Hbase/HowToRelease

mvn clean site install assembly:single 

Doesn't work any more.

[ERROR] Failed to execute goal org.apache.maven.plugins:maven-assembly-plugin:2.3:single (default-cli) on project hbase: Failed to create assembly: Artifact: org.apache.hbase:hbase-common:jar:0.95-SNAPSHOT (included by module) does not have an artifact with a file. Please ensure the package phase is run before the assembly is generated. -> [Help 1]


Matteo told me we have to use 

mvn -DskipTests package assembly:assembly


I think we should make assembly:single work.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6258,"Issue tracking backport of some relatively small region splitting fixes into 0.90.7:

HBASE-4816: Regionserver wouldn't go down because split happened exactly at same time we issued bulk user region close call on our way out - fixed in 0.92
HBASE-4881: Unhealthy region is on service caused by rollback of region splitting - fixed in 0.92
HBASE-5189: Add metrics to keep track of region-splits in RS - fixed in 0.94
HBASE-6158: Data loss if the words 'merges' or 'splits' are used as Column Family name - fixed in 0.92 and 0.94",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6009,"The additions to add backup masters to ClusterStatus are technically incompatible between clients and servers.  Older clients will basically not read the extra bits that the newer server pushes for the backup masters, thus screwing up the serialization for the next blob in the pipe.

For the Writable, we can add a total size field for ClusterStatus at the beginning, or we can have start and end markers.  I can make a patch for either approach; interested in whatever folks have to suggest.  Would be good to get this in soon to limit the damage to 0.92.1 (don't know if we can get this in in time for 0.94.0).

Either change will make us forward-compatible starting with when the change goes in, but will not fix the backwards incompatibility, which we will have to mark with a release note as there have already been releases with this change.

Hopefully we can do this in a cleaner way when wire compat rolls around in 0.96.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5856,"In HBaseAdmin 
  public void split(final String tableNameOrRegionName)
  throws IOException, InterruptedException {
    split(Bytes.toBytes(tableNameOrRegionName));  // string -> byte 
  }
In HRegionInfo
  this.regionNameStr = Bytes.toStringBinary(this.regionName);  // byte -> string
Should we use Bytes.toBytesBinary in HBaseAdmin 锛?,,,,,,,,,,,,,,,,,,,,,,24/Apr/12 09:36;aoxiang;HBASE-5856-0.92.patch;https://issues.apache.org/jira/secure/attachment/12523949/HBASE-5856-0.92.patch,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,2012-04-23 18:36:38.863,,false,,,,,,,,,,,,236743,,,,,Wed May 02 02:18:32 UTC 2012,,,,,,0|i068qn:,34347,,,,,,,,23/Apr/12 10:06;aoxiang;for example",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1801,"If you have a cluster running for some time, you probably have more regions on DFS than in META. Here is a tool to remove them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5677,"If region be assigned When the master is doing initialization(before do processFailover),the region will be duplicate openhandled.
because the unassigned node in zookeeper will be handled again in AssignmentManager#processFailover()
it cause the region in RIT,thus the master never does balance.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4311,"When refactoring TestHBaseFsckRepair to add more hbck test cases, I noticed that HBaseTestingUtility.createMultiRegions uses an existing table with empty region, adds more regions, and then attempts to remove the region.  The region remains in meta and is causes hbck to report at inconsistency. Ideally these test table generation utility functions should generate clean tables.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3772,"I ran across this issue on a 0.20 based branch, so I'm not sure if this is still an issue for 0.90+.  However, 0.90 and current trunk do still make use of DNS.getDefaultHost(), so I wanted to open this for discussion.

In 0.20, the problem was:

 1. configure hbase-site.xml with hbase.regionserver.dns.interface=xxx
 2. IP bound on interface xxx has reverse DNS correctly configured
 3. DNS.getDefaultHost() calls DNS.reverseDns() for this IP, which does a JNDI bind to the DNS provider, returning the *absolute* hostname: host1.my.domain.
 4. RS reports startup to master as host1.my.domain.,60020,1234...
 5. BaseScanner when scanning .META. sees region assignments as not valid because the resolved hostname from IP goes through InetSocketAddress.getHostName() which returns the canonicalized form (host1.my.domain != host1.my.domain. though they are equivalent)

I know the master <-> RS negotiated hostname has completely changed for 0.90.  So hopefully this is no longer an issue and we can close as invalid and go have a beer.  But given the underlying problem in DNS.getDefaultHost(), I wanted to confirm this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1339,"{code}
2009-04-22 02:10:34,710 WARN /: /master.jsp:
java.lang.NullPointerException
    at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$1.processRow(HConnectionManager.java:344)
    at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:64)
    at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:29)
    at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.listTables(HConnectionManager.java:351)
    at org.apache.hadoop.hbase.client.HBaseAdmin.listTables(HBaseAdmin.java:121)
    at org.apache.hadoop.hbase.generated.master.master_jsp._jspService(master_jsp.java:121)
    at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:94)
    at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
    at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
    at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
    at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
    at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
    at org.mortbay.http.HttpServer.service(HttpServer.java:954)
    at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
    at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
    at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
    at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
    at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
    at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5106,"Old hbase client which talks to the new hbase server could not understand the new metadata.  We should re-think how to check setData BADVERSION error.

How about we check the full actual data?  If the actual data in ZK is what we want to set, then we are good.  Of course, this data could be set actually by someone else, in this case, is it safe not to throw a KeeperException?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3217,"I tried writing a few unit tests in the scope of HBASE-3216 since the previous one was only testing a best case scenario but it's at least currently not able to fix the case where .META. says the assignment is on server A when in fact it's on server B (the region gets closed but never reopened).

Stack says the breakage probably happened with the new master.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3742,"We got this in the context of HBASE-3741, a region was closed by a region server but the master wasn't expecting it and didn't do anything about it. We had to force assign it back.

{quote}
2011-04-05 15:15:55,812 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: master:60000-0x42ec2cece810b68 Retrieved 93 byte(s) of data from znode /prodjobs/unassigned/1470298961 and set watcher; region=stumbles_by_userid2,'锟斤拷锟斤拷绌楋拷锟斤拷6,1266566087256, server=sv4borg42,60020,1300920459477, state=RS_ZK_REGION_CLOSING
2011-04-05 15:15:55,812 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling new unassigned node: /prodjobs/unassigned/1470298961 (region=stumbles_by_userid2,'锟斤拷锟斤拷绌楋拷锟斤拷6,1266566087256, server=sv4borg42,60020,1300920459477, state=RS_ZK_REGION_CLOSING)
2011-04-05 15:15:55,812 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_CLOSING, server=sv4borg42,60020,1300920459477, region=1470298961
2011-04-05 15:15:55,812 WARN org.apache.hadoop.hbase.master.AssignmentManager: Received CLOSING for region 1470298961 from server sv4borg42,60020,1300920459477 but region was in  the state null and not in expected PENDING_CLOSE or CLOSING states
2011-04-05 15:15:55,843 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher: master:60000-0x42ec2cece810b68 Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/prodjobs/unassigned/1470298961
2011-04-05 15:15:55,843 DEBUG org.apache.hadoop.hbase.zookeeper.ZKUtil: master:60000-0x42ec2cece810b68 Retrieved 93 byte(s) of data from znode /prodjobs/unassigned/1470298961 and set watcher; region=stumbles_by_userid2,'锟斤拷锟斤拷绌楋拷锟斤拷6,1266566087256, server=sv4borg42,60020,1300920459477, state=RS_ZK_REGION_CLOSED
2011-04-05 15:15:55,843 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_CLOSED, server=sv4borg42,60020,1300920459477, region=1470298961
2011-04-05 15:15:55,843 WARN org.apache.hadoop.hbase.master.AssignmentManager: Received CLOSED for region 1470298961 from server sv4borg42,60020,1300920459477 but region was in  the state null and not in expected PENDING_CLOSE or CLOSING states
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-862,"Daniel Leffel has an install of 500 regions on 4 nodes.  He's running 0.2.0.

On restart, load balancing is running while the 600 regions are being initially opened.  Makes for churn.  Load balancing should wait before it cuts in.

Have also seen on occasion that it will not find equilibrium after a restart.

Adding a node is catastrophic.  >20% of the regions were closed and were taking the longest time to show up on the new server.  I would think that the region balancing would work in more sophisticated and gradual manner.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1787,"Down in guts of TableServers is a static map keyed by HBaseConfiguration instance.  If in such as HTable constructor, you keep passing the same HBaseConfiguration instance, then you will get back a previously made TableServers with cached region locations, zk connection setup, etc.   If you pass a new HBaseConfiguration each time, then on each new HTable, a new TableServers instance will be built with attendant zk setup and resource costs etc.

Users are surprised by this behavior: ""What seems like a bug to me is that the configuration object is caching state.  I understand if HTable hangs on to connections until it is closed.  And I understand how calling new HTABLE twice might open a new connection.  That all seems okay.  What I wouldn't expect is that using an old configuration object will give me different behavior from using a new one.  A configuration seems like a static thing to me.  It should only change if I change it."" -- Our Jim Firby",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1910,"From Tatsuya Kawano up on hbase-user@

{quote}
50 client threads who try to put millions of records, autoFlush(false), flushCommits() on every 5,000 put. After inserting about 3 million records, a deadlock occurred on a region server who has both the table and index regions loaded.

I have attached a full thread dump of the deadlocked region server, and you can see IPC Server handlers are blocked in org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.updateIndex().

I found the flowing FIXME comment on updateIndex() method, and it seems this is the deadlock I'm having.

{code}
  // FIXME: This call takes place in an RPC, and requires an RPC. This makes for
  // a likely deadlock if the number of RPCs we are trying to serve is >= the
  // number of handler threads.
  private void updateIndex(IndexSpecification indexSpec, byte[] row,
      SortedMap<byte[], byte[]> columnValues) throws IOException {
{code}

I use HBase 0.20.1 and my region servers were running with 10 RPC handler threads on each (default).

Maybe you can workaround this by adding more RPC handlers (increase the value of ""hbase.regionserver.handler.count"" in hbase-site.xml)
{quote}

Opening this issue to track the FIXME.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2736,"When trying to disable a table, the shell exhausts the retries, then throws the following: 

{noformat}
ERROR: org.apache.hadoop.hbase.RegionException: Retries exhausted, it took too long to wait for the table t1 to be disabled.
{noformat}

in HBaseAdmin.java:disableTable, after disabling, the code checks again, using isTableDisabled, which always returns false. 

Also, after running a disable, in Zookeeper, in ""/hbase/UNASSIGNED"", I get an entry, which is exactly the name of the only region of the table I am trying to disable. This leads me to believe this bug is somehow linked to HBASE-2694.

This reproduces on my machine, our cluster, with freshly installed HBase, with new data, as well as with old one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2766,"If both -ROOT- and .META. are located on the same regionserver, and that regionserver crashes, the master is unable to reassign these tables to a new regionserver. 

Andrew writes:
""I ran a webtable scenario up on EC2 using the latest TM-2 and a cluster with 1 ZK, 1 master, 5 slaves, and 1 auxiliary node, using the HBase cluster scripts at  https://tm-files.s3.amazonaws.com/hbase-ec2.tar.bz2. On the aux node I uploaded the Faulkner utility --  https://tm-files.s3.amazonaws.com/faulkner.tar.gz  -- and ran the 'webtable.sh' script in that tarball. On the master I waited about 30 minutes for a fair amount of regions to proliferate and then ran:

    # nice -10 hbase shell
    hbase> count 'TestTable'

and walked away, leaving it to chew on the heavy write load and scan.

At some point during this test scenario a region server crashed, due to a JVM segfault. The client (Faulkner) never recovered.

As far as I can see, in this test scenario the master never reassigns regions away from a crashed RS.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3027,"Just ran into this up on Alexey's cluster.  He updated to SU github and it looks like some regions had recovered.edits files under them.  The newer code was trying to read the file as a directory and failing with the plain but at same time cryptic mssage:

{code}
Caused by: org.apache.hadoop.ipc.RemoteException: java.io.FileNotFoundException: Parent path is not a directory: /hbase/mysql_word_documents/c574e848df63a14054e054545da2d3f3/recovered.edits   
{code}

It'd be a small thing to add a check if 'recovered.edits' is a file and process it as such when reading in recovered edits.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1459,"I just saw this on my 0.19.1 cluster:

2009-05-30 03:57:19,559 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: table,rowkey,1243547152622
    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:897)
    at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:790)
    at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:228)
    at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.run(MemcacheFlusher.java:138)
Caused by: java.util.ConcurrentModificationException
    at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)
    at java.util.TreeMap$EntryIterator.next(TreeMap.java:1136)
    at java.util.TreeMap$EntryIterator.next(TreeMap.java:1131)
    at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:678)
    at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:636)
    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:882)
    ... 3 more",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1891,"I ran my program multiple times and this is happening almost all the time.

Basically, the ResultScanner is skipping a full cache of rows. I set my caching size to 1000, and when I expect to see row 60000 it gave me 60999.

My code (will attach here) is creating a new table with a single column family and qualifier, and then write 1 million rows with ascending keys, then immediately read them back to verify.


The HBase code is from:
http://svn.apache.org/repos/asf/hadoop/hbase/trunk at
Exported revision 821973.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2079,"From hbase-user.  I'm putting it into 0.20.3   Shows when multiple concurrent threads.

{code}
On Wed, Dec 30, 2009 at 5:59 AM, Dmitriy Lyfar <dlyfar@gmail.com> wrote:

Exception in thread ""Thread-9"" java.util.ConcurrentModificationException
   at
java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)
   at java.util.AbstractList$Itr.next(AbstractList.java:343)
   at
org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1028)
   at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:979)
   at
org.apache.hadoop.conf.Configuration.iterator(Configuration.java:1015)
   at
org.apache.hadoop.hbase.HBaseConfiguration.hashCode(HBaseConfiguration.java:63)
   at java.util.WeakHashMap.get(WeakHashMap.java:348)
   at
org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:97)
   at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:123)
   at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:105)
   at InserterThread.run(hbase_client.java:53)
   at java.lang.Thread.run(Thread.java:619
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2191,"I'm testing a simple bulk upload to HBase. Single table, single family. The aim is to upload 200M+ lines into HBase. I've  tried to commit the upload in various batches, from 1 line at time to 25000 lines at time. Each time, at seemingly random point, the upload fails in commit with a org.apache.hadoop.hbase.NotServingRegionException

Failure stack trace from the client:
---
10/02/07 16:38:40 DEBUG transactional.TransactionManager: Begining transaction 5311384003652808027
10/02/07 16:38:40 DEBUG transactional.TransactionState: Adding new hregion [db,,1265553236583] to transaction [5311384003652808027]
10/02/07 16:38:46 DEBUG transactional.TransactionManager: atempting to commit trasaction: id: 5311384003652808027, particpants: 1
10/02/07 16:38:46 DEBUG transactional.TransactionManager: Region [db,,1265553236583] votes to commit transaction 5311384003652808027
10/02/07 16:38:46 DEBUG transactional.TransactionManager: Commiting [5311384003652808027]
10/02/07 16:38:46 DEBUG transactional.TransactionManager: Committed transaction [5311384003652808027] in [379]ms
10/02/07 16:38:46 DEBUG transactional.TransactionManager: Begining transaction -5274908504613584338
10/02/07 16:38:46 DEBUG transactional.TransactionState: Adding new hregion [db,,1265553236583] to transaction [-5274908504613584338]
10/02/07 16:38:47 DEBUG client.HConnectionManager$TableServers: Removed db,,1265553236583 for tableName=db from cache because of \x00\x00\x01\x24\xAC\xC3\x98\x1C
10/02/07 16:38:47 DEBUG client.HConnectionManager$TableServers: Cached location for db,,1265553236583 is 1.1.1.1:43917
10/02/07 16:38:48 DEBUG client.HConnectionManager$TableServers: Removed db,,1265553236583 for tableName=db from cache because of \x00\x00\x01\x24\xAC\xC3\x98\x1C
10/02/07 16:38:48 DEBUG client.HConnectionManager$TableServers: Cached location for db,,1265553236583 is 1.1.1.1:43917
10/02/07 16:38:49 DEBUG client.HConnectionManager$TableServers: Removed db,,1265553236583 for tableName=db from cache because of \x00\x00\x01\x24\xAC\xC3\x98\x1C
10/02/07 16:38:49 DEBUG client.HConnectionManager$TableServers: locateRegionInMeta attempt 0 of 10 failed; retrying after sleep of 1000 because: No server address listed in .META. for region db,\x00\x00\x01\x24\xAC\xA5\xEAB,1265553527794
10/02/07 16:38:49 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 for tableName=.META. from cache because of db,\x00\x00\x01\x24\xAC\xC3\x98\x1C,99999999999999
10/02/07 16:38:49 DEBUG client.HConnectionManager$TableServers: Cached location for .META.,,1 is 1.1.1.1:43917
10/02/07 16:38:50 DEBUG client.HConnectionManager$TableServers: Cached location for db,\x00\x00\x01\x24\xAC\xA5\xEAB,1265553527794 is 1.1.1.1:43917
10/02/07 16:38:50 DEBUG transactional.TransactionState: Adding new hregion [db,\x00\x00\x01\x24\xAC\xA5\xEAB,1265553527794] to transaction [-5274908504613584338]
10/02/07 16:38:51 DEBUG transactional.TransactionManager: atempting to commit trasaction: id: -5274908504613584338, particpants: 2
10/02/07 16:38:51 DEBUG transactional.TransactionManager: Commit of transaction [-5274908504613584338] was unsucsessful
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: db,,1265553236583
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2266)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.getTransactionalRegion(TransactionalRegionServer.java:131)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.commitRequest(TransactionalRegionServer.java:179)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:723)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:333)
        at $Proxy0.commitRequest(Unknown Source)
        at org.apache.hadoop.hbase.client.transactional.TransactionManager.prepareCommit(TransactionManager.java:94)
        at org.apache.hadoop.hbase.client.transactional.TransactionManager.tryCommit(TransactionManager.java:151)
        at dbloader.dbLoader.run2(dbLoader.java:181)
        at dbloader.dbLoader.main(dbLoader.java:24)
Exception in thread ""main"" org.apache.hadoop.hbase.client.transactional.CommitUnsuccessfulException: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: db,,1265553236583
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2266)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.getTransactionalRegion(TransactionalRegionServer.java:131)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.commitRequest(TransactionalRegionServer.java:179)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at org.apache.hadoop.hbase.client.transactional.TransactionManager.prepareCommit(TransactionManager.java:135)
        at org.apache.hadoop.hbase.client.transactional.TransactionManager.tryCommit(TransactionManager.java:151)
        at dbloader.dbLoader.run2(dbLoader.java:181)
        at dbloader.dbLoader.main(dbLoader.java:24)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: db,,1265553236583
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:2266)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.getTransactionalRegion(TransactionalRegionServer.java:131)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.commitRequest(TransactionalRegionServer.java:179)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:723)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:333)
        at $Proxy0.commitRequest(Unknown Source)
        at org.apache.hadoop.hbase.client.transactional.TransactionManager.prepareCommit(TransactionManager.java:94)
        ... 3 more
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2192,"After a commit has failed with org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.NotServingRegionException: db,,1265553236583 (see HBASE-2191 for more information) any further transactions to the same table fail. (other tables untested)

Waiting for ~10 hours doesn't seem to clear the situation, neither does calling truncate and major_compact on the table and major_compact on .META.. only known way to resolve the situation is to restart hbase.

client end stack trace:
---
10/02/07 16:40:47 DEBUG transactional.TransactionState: Adding new hregion [db,,1265553637903] to transaction [6991420346725617933]
10/02/07 16:40:48 DEBUG client.HConnectionManager$TableServers: Removed db,,1265553637903 for tableName=db from cache because of \x00\x00\x01\x24\xAC\x9C\xAF,
10/02/07 16:40:48 DEBUG client.HConnectionManager$TableServers: locateRegionInMeta attempt 0 of 10 failed; retrying after sleep of 1000 because: No server address listed in .META. for region db,,1265553637903
10/02/07 16:40:48 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 for tableName=.META. from cache because of db,\x00\x00\x01\x24\xAC\x9C\xAF,,99999999999999
10/02/07 16:40:48 DEBUG client.HConnectionManager$TableServers: Cached location for .META.,,1 is 1.1.1.1:43917
10/02/07 16:40:49 DEBUG client.HConnectionManager$TableServers: Cached location for db,,1265553637903 is 1.1.1.1:43917
Exception in thread ""main"" org.apache.hadoop.hbase.client.transactional.UnknownTransactionException: org.apache.hadoop.hbase.client.transactional.UnknownTransactionException: transaction: [6991420346725617933], region: [db,,1265553637903]
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.getTransactionState(TransactionalRegion.java:574)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.put(TransactionalRegion.java:297)
        at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.put(TransactionalRegionServer.java:241)
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:1041)
        at org.apache.hadoop.hbase.client.transactional.TransactionalTable.put(TransactionalTable.java:153)
        at dbloader.dbLoader.run2(dbLoader.java:179)
        at dbloader.dbLoader.main(dbLoader.java:24)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2532,"For reading an object out a sequencefile, a no argument constructor is required... 
if not you end up with a  java.lang.NoSuchMethodException

From Owen O'Malley

Assumption for Writables that should be documented somewhere:
 * Each type must have a 0 argument constructor.
 * Each call to write must not assume any shared state.
 * Each call to readFields must consume exactly the number of bytes
produced by write.

SequenceFile also assumes:
 * All keys are exactly the same type (not polymorphic).
 * All values are exactly the same type.
 * Both types are specified by the writer in the create call.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3427,"Is this a bug ?

example> hbase-site.xml is in conf/hbase-site.xml
so I wrote below.

HBaseConfiguration config = new HBaseConfiguration();
config.addResource(HBaseClient.class.getResource(""/conf/hbase-default.xml""));
config.addResource(HBaseClient.class.getResource(""/conf/hbase-site.xml""));

config.set(""hbase.zookeeper.quorum"", ""192.168.0.203"");
config.set(""hbase.zookeeper.property.clientPort"", ""2181"");

but, when I use IndexedTable, cannot create table(almost locking) because IndexedTableAdmin.reIndexTable

IndexedTableAdmin.java
 private void reIndexTable(byte[] baseTableName, IndexSpecification indexSpec) throws IOException {
    HTable baseTable = new HTable(baseTableName);
   .. ..
}

We should use HTable(String, HBaseConfiguration), I think.

because of that, I moved the config files to src/  not src/conf/ ***.xml

This is so confused. we should explain this more in java doc. or would be fixing it



",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2881,"The TestAdmin test fails on trunk intermittently because it is unable to ""enable"" a ""disabled"" table. However, the root cause seems to be that much earlier, at ""createTable"" time the table's region got assigned to 2 region servers. And this later confuses the ""disable""/""enable"" code.

createTable goes down to RegionManager.java:createRegion:

{code}
public void createRegion(HRegionInfo newRegion, HRegionInterface server,
      byte [] metaRegionName)
  throws IOException {
    // 2. Create the HRegion
    HRegion region = HRegion.createHRegion(newRegion, this.master.getRootDir(),
      master.getConfiguration());

    // 3. Insert into meta
    HRegionInfo info = region.getRegionInfo();
    byte [] regionName = region.getRegionName();

    Put put = new Put(regionName);
    put.add(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER,
        Writables.getBytes(info));
    server.put(metaRegionName, put);

    // 4. Close the new region to flush it to disk.  Close its log file too.
    region.close();
    region.getLog().closeAndDelete();

    // 5. Get it assigned to a server
    setUnassigned(info, true);
  }
{code}

Between, after #3, but before #5, if the MetaScanner runs, it'll find this region in unassigned state and also assign it out.

And then #5 comes along at again ""force"" sets this region to be unassigned... causing it to get assigned again to a different region server (as part of the RegionManager's job of assigning out regions waiting to be assigned along with region server heart beats).

---

The test in question that diffs is TestAdmin:testHundredsOfTable(). I tried repro'ing this more reliable by modifying the test to have the metascanner run more frequently:

{code}
  TEST_UTIL.getConfiguration().setInt(""hbase.master.meta.thread.rescanfrequency"", 1000);// 1 seconds
{code}

(instead of the default 60seconds); but it didn't help improve the reproducibility.

---


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2911,"While working on the HBase Explorer front end in Hue I found a few inconsistencies between the plain text version of values versus the JSON representation. From an email conversation:

Plain Text
---------------

$ curl -H ""curl -H ""Accept: text/plain"" localhost:8888/status/cluster
1 live servers, 0 dead servers, 5.0000 average load

1 live servers
   de1-app-mbp-2.fritz.box:62884 1280924907616
       requests=0, regions=5
       heapSizeMB=27
       maxHeapSizeMB=995

       t2,,1280917558997
           stores=3
           storefiless=0
           storefileSizeMB=0
           memstoreSizeMB=0
           storefileIndexSizeMB=0
       usertable,,1280917566604
           stores=3
           storefiless=2
           storefileSizeMB=224
           memstoreSizeMB=0
           storefileIndexSizeMB=0
       .META.,,1
           stores=2
           storefiless=1
           storefileSizeMB=0
           memstoreSizeMB=0
           storefileIndexSizeMB=0
       t1,,1280917554475
           stores=3
           storefiless=0
           storefileSizeMB=0
           memstoreSizeMB=0
           storefileIndexSizeMB=0
       \-ROOT\-,,0
           stores=1
           storefiless=1
           storefileSizeMB=0
           memstoreSizeMB=0
           storefileIndexSizeMB=0

JSON
---------

And curling the JSON yields:

$ curl -H ""Accept: application/json"" localhost:8888/status/cluster
{""requests"":0,""regions"":5,""averageLoad"":5.0,""DeadNodes"":[null],""LiveNodes"":[{""Node"":{""startCode"":1280924907616,""requests"":0,""name"":""de1-app-mbp-2.fritz.box:62884"",""maxHeapSizeMB"":995,""heapSizeMB"":27,""Region"":[{""stores"":3,""storefiles"":0,""storefileSizeMB"":0,""storefileIndexSizeMB"":0,""name"":""dDIsLDEyODA5MTc1NTg5OTc="",""memstoreSizeMB"":0},{""stores"":3,""storefiles"":2,""storefileSizeMB"":224,""storefileIndexSizeMB"":0,""name"":""dXNlcnRhYmxlLCwxMjgwOTE3NTY2NjA0"",""memstoreSizeMB"":0},{""stores"":2,""storefiles"":1,""storefileSizeMB"":0,""storefileIndexSizeMB"":0,""name"":""Lk1FVEEuLCwx"",""memstoreSizeMB"":0},{""stores"":3,""storefiles"":0,""storefileSizeMB"":0,""storefileIndexSizeMB"":0,""name"":""dDEsLDEyODA5MTc1NTQ0NzU="",""memstoreSizeMB"":0},{""stores"":1,""storefiles"":1,""storefileSizeMB"":0,""storefileIndexSizeMB"":0,""name"":""LVJPT1QtLCww"",""memstoreSizeMB"":0}]}}]}


And another one:

I have another one with .META. and \-ROOT\-, in my small sample setup (all local, /tmp etc.) I see this in the master UI:

Name	 Region Server	 Encoded Name	 Start Key	 End Key
.META.,,1	10.0.0.43:60030	 -		

But running the same against Stargate I get:

$ curl -H ""Accept: application/json"" http://localhost:8888/.META./regions
{""name"":"".META.""}

while a ""normal"" user table with a single row has

Name	 Region Server	 Encoded Name	 Start Key	 End Key
t1,,1281111615489	10.0.0.43:60030	 1127696125		

and through Stargate:

$ curl -H ""Accept: application/json"" http://localhost:8888/t1/regions
{""name"":""t1"",""Region"":[{""location"":""10.0.0.43:54988"",""endKey"":"""",""startKey"":"""",""id"":1281111615489,""name"":""t1,,1281111615489""}]}

So the internal tables are not reported right.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-667,"Internally, came across a hung regionserver.  Here is relevant excerpt from thread dump:

{code}
""ResponseProcessor for block blk_-6991279486194843565"" daemon prio=1 tid=0x00002aab3ac13c50 nid=0x7ad7 runnable [0x0000000043080000..0x0000000043080d00]
        at java.net.SocketInputStream.socketRead0(Native Method)
        at java.net.SocketInputStream.read(Unknown Source)
        at java.io.DataInputStream.readFully(Unknown Source)
        at java.io.DataInputStream.readLong(Unknown Source)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:1734)

...

""IPC Server handler 3 on 60020"" daemon prio=1 tid=0x00002aab3c05abf0 nid=0x6b61 waiting for monitor entry [0x0000000042878000..0x0000000042878d00]
        at org.apache.hadoop.hbase.HLog.append(HLog.java:371)
        - waiting to lock <0x00002aaab69d1180> (a java.lang.Integer)
        at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1629)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1432)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1552)
        at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

.....

""IPC Server handler 1 on 60020"" daemon prio=1 tid=0x00002aab3c3220a0 nid=0x6b5f waiting for monitor entry [0x0000000042676000..0x0000000042676c00]
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:2126)
        - waiting to lock <0x00002aaab69d1a28> (a java.util.LinkedList)
        at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:141)
        at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:100)
        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:86)
        - locked <0x00002aaab69d15b0> (a org.apache.hadoop.dfs.DFSClient$DFSOutputStream)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:41)
        at java.io.DataOutputStream.write(Unknown Source)
        - locked <0x00002aaab69d1228> (a org.apache.hadoop.fs.FSDataOutputStream)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:990)
        - locked <0x00002aaab69d1050> (a org.apache.hadoop.io.SequenceFile$Writer)
        at org.apache.hadoop.hbase.HLog.append(HLog.java:387)
        - locked <0x00002aaab69d1180> (a java.lang.Integer)
        at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1629)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1432)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1552)
        at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

.....

""DataStreamer for file /hbase/aa0-005-2.u.powerset.com/log_208.76.45.223_1212443824255_60020/hlog.dat.000 block blk_-6991279486194843565"" daemon prio=1 tid=0x00002aab3c1b2e70 nid=0x6b50 runnable [0x0000000041969000..0x0000000041969c80]
        at java.net.SocketOutputStream.socketWrite0(Native Method)
        at java.net.SocketOutputStream.socketWrite(Unknown Source)
        at java.net.SocketOutputStream.write(Unknown Source)
        at java.io.BufferedOutputStream.write(Unknown Source)
        - locked <0x00002aaab7652b70> (a java.io.BufferedOutputStream)
        at java.io.DataOutputStream.write(Unknown Source)
        - locked <0x00002aaab7652288> (a java.io.DataOutputStream)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1631)
        - locked <0x00002aaab69d1a28> (a java.util.LinkedList)
{code}

I've seen this before.  I saw this this morning where a pure hadoop client was hung in same way.  This is hadoop 0.16.4.  Seems like a pure hadoop prob.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1094,"After a large amount of file (~400,000) , once in a while during rapid inserts RegionServer returns NotServingRegionException when doing batchUpdate. 
A restart of the client usually fixes the problem , but it happens again after a while. 

LogFiles excerpts: 

*RegionServer*
2008-12-16 09:17:14,413 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1333
2008-12-16 09:17:14,413 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1334
2008-12-16 09:17:14,414 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_7750693789795884606_1536 wrote packet seqno:1333 size:65557 offsetInBlock:19507200 lastPacketInBlock:false
2008-12-16 09:17:14,439 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 in 2sec
2008-12-16 09:17:14,441 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting split of region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,442 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits: masked=rwxr-xr-x
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Compactions and cache flushes disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Scanners disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,461 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,462 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,462 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395. Current region memcache size 236.3k
2008-12-16 09:17:14,463 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960: masked=rwxr-xr-x
2008-12-16 09:17:14,484 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960/data: masked=rwxr-xr-x
2008-12-16 09:17:14,505 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960/index: masked=rwxr-xr-x
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 0
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1
2008-12-16 09:17:14,525 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.211:50010
2008-12-16 09:17:14,526 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,527 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,530 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:0 size:65557 offsetInBlock:0 lastPacketInBlock:false
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 2
2008-12-16 09:17:14,531 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:1 size:65557 offsetInBlock:65024 lastPacketInBlock:false
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 2
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 3
2008-12-16 09:17:14,532 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:2 size:65557 offsetInBlock:130048 lastPacketInBlock:false
2008-12-16 09:17:14,533 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_4611894842462358439_1544 wrote packet seqno:3 size:49273 offsetInBlock:195072 lastPacketInBlock:true
2008-12-16 09:17:14,534 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:14,535 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 1
2008-12-16 09:17:14,536 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 2
2008-12-16 09:17:14,538 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 3
2008-12-16 09:17:14,538 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_4611894842462358439_1544
2008-12-16 09:17:14,557 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,557 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.211:50010
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,558 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,561 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-6152926948595840609_1544 wrote packet seqno:0 size:276 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:14,564 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:14,564 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-6152926948595840609_1544
2008-12-16 09:17:14,586 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/obde_content/info/5474929915463365960: masked=rwxr-xr-x
2008-12-16 09:17:14,609 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,609 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,610 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,613 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_2767846628464404081_1545 wrote packet seqno:0 size:38 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:14,616 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:14,617 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_2767846628464404081_1545
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Added /hbase/my_table/1608250010/obde_content/mapfiles/5474929915463365960 with 56 entries, sequence id 235152, data size 236.3k, file size 238.2k
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memcache flush for region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 in 182ms, sequence id=235152, compaction requested=true
2008-12-16 09:17:14,644 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 1608250010/obde_content
2008-12-16 09:17:14,644 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395
2008-12-16 09:17:14,649 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 60020, call batchUpdate([B@552a2a7d, row => f+C7Y24r+apSz+joQUhiQQ==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,651 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/mapfiles/1405033884904780036.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:14,694 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/info/1405033884904780036.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:14,717 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,717 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:14,718 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,719 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,721 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-4579777298287321197_1547 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:14,724 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:14,724 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-4579777298287321197_1547
2008-12-16 09:17:14,745 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate([B@18084038, row => hflk16ESykcggRSkrq7vgQ==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,746 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/mapfiles/215038473253378290.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:14,790 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/info/215038473253378290.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:14,813 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:14,837 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@74da3b58, row => rG4yO2bs4Rw+JU4QKY7X2w==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,847 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:14,848 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:14,849 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:14,864 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate([B@51575d48, row => aNq6QyMT+FePc7M78PaQMQ==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,885 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@63442ff5, row => iA4QenOmdZMbB8PTQPSnRw==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:14,998 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020, call batchUpdate([B@59eb5159, row => t5gRF1zQOrx27LTUS84ADA==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,023 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 60020, call batchUpdate([B@132fa7c8, row => Tu0dl1jFT2spZmEZundPoA==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,045 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 1333
2008-12-16 09:17:15,226 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@4696de68, row => Skj4FHgWdrR+DSOppIaG6Q==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,237 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call batchUpdate([B@16a3f072, row => gWd3yPCu6A9CxjBAhO3UPg==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,453 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk packet full seqno 1334
2008-12-16 09:17:15,453 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_7750693789795884606_1536 wrote packet seqno:1334 size:65557 offsetInBlock:19572224 lastPacketInBlock:false
2008-12-16 09:17:15,486 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate([B@171591e3, row => ddd8ecfGPwfgKzuLNMvOAw==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,498 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@452719a0, row => bJOTHv64AsNoFYsh7D0UyA==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,508 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate([B@6a76000a, row => XVNFoDhT1NeKnT0YwhopHg==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,548 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 60020, call batchUpdate([B@2b753bb9, row => jHxdShcit3A24oL3HHHgdg==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,557 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@7b4286a2, row => VYUtICqregww41FxZUJkig==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,558 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 1335
2008-12-16 09:17:15,659 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-1532247345865982631_1549 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:15,661 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:15,661 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-1532247345865982631_1549
2008-12-16 09:17:15,679 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/mapfiles/4722584128214377088.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:15,721 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/1010339458/obde_content/info/4722584128214377088.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:15,744 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:15,745 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020, call batchUpdate([B@3f229bc1, row => WQXUl6gepHza8rVTmr8BSA==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,745 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:15,746 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:15,747 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:15,750 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_9044590686588152812_1551 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:15,752 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:15,752 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_9044590686588152812_1551
2008-12-16 09:17:15,774 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/mapfiles/6108448749728539444.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:15,797 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@74d3776e, row => hfCFR4B8pMF3mnY9mMnkDQ==, {column => obde_content:, value => '...'}, -1) from MY.IP.212:46198: error: org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
org.apache.hadoop.hbase.NotServingRegionException: Region my_table,RQue7uxNoe59vJxljcd1rQ==,1229374459395 closed
	at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1875)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1380)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1109)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-12-16 09:17:15,817 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/splits/2015194550/obde_content/info/6108448749728539444.1608250010: masked=rwxr-xr-x
2008-12-16 09:17:15,841 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient writeChunk allocating new packet 0
2008-12-16 09:17:15,841 DEBUG org.apache.hadoop.dfs.DFSClient: Allocating new block
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.102:50010
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: pipeline = MY.IP.213:50010
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: Connecting to MY.IP.102:50010
2008-12-16 09:17:15,842 DEBUG org.apache.hadoop.dfs.DFSClient: Send buf size 131071
2008-12-16 09:17:15,848 DEBUG org.apache.hadoop.dfs.DFSClient: DataStreamer block blk_-3568743239673676944_1553 wrote packet seqno:0 size:84 offsetInBlock:0 lastPacketInBlock:true
2008-12-16 09:17:15,850 DEBUG org.apache.hadoop.dfs.DFSClient: DFSClient received ack for seqno 0
2008-12-16 09:17:15,850 DEBUG org.apache.hadoop.dfs.DFSClient: Closing old block blk_-3568743239673676944_1553
2008-12-16 09:17:15,876 DEBUG org.apache.hadoop.dfs.DFSClient: /hbase/my_table/1608250010/",,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1652,"Scanning a sparse column over a narrow range of rows can take far longer than expected because the check for the end of the range is not performed on new rows unless there is a column match, so it may end up scanning an entire region or table.

Background:
I have a table with 1 billion+ rows, and one cell in each row, generally small (10-1000 bytes).  The columns are all in a single family and fairly sparse.  For one query, I run scans on it to scan usually a narrow range of the table for the first 30 cells ina certain column.  I know that all the rows that contain that column lie within a certain range.  I use HTable.getScanner(byte[][] columns, byte[] startRow, RowFilterInterface filter) passing it the particular column I'm looking for, a startRow, and a filter set containing a StopRowFilter wrapped in a WhileMatchRowFilter to enforce the end of the range.  Sometimes the query is very fast (< 1 sec), but if the table doesn't contain 30 rows with that column, it can be very slow, a minute or two.  I expected that since the range was small, for example, just 120 rows, the query wouldn't take long to scan the rows.

After some pondering and perusing of the source code, I think I understand what is going on.  It looks like the Scanner is scanning the rest of the table to find rows containing the column without allowing the StopRowFilter to stop the scan at the end of the range.  I think I can work around this by not specifying the column I want in the getScanner() method and instead putting an additional filter in the filter set to filter out other columns.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1325,"HBase wants to have large heaps - store lots of cached objects to make things faster in RAM.

But Java garbage collection wants to touch every object in heap.

How does this work at 3gb heaps?  6gb heaps?  The more ram we can use in HBase the better performance we can get.  If java GC holds us back, we might need to do something else.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1806,"What I'm seeing is that BaseScanner misses updates made by an update milliseconds before -- even hundreds of milliseconds before.  See hbase-1784 where I'm seeing double-assignment of regions.

Scanners do not respect row locks.  They should else could return a row with partial updates committed.  What if a .META. region has tens of storefiles and a scan does a get full row which takes a long time.  Say an update comes in during this read.  First it will go in because no row lock is outstanding.  Second, we'll miss the edit given we look at things in order -- memstore, then each storefile down to the oldest.  What if the update is followed by an update of server state; e.g. region is moved out of intransition state?  And inside in same server, say the master, it makes decisions dependent on what it sees when it does a scanner#next; e.g. BaseScanner checking for assignment?

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1723,"The method getRowWithTimestampTs of the thrift interface changed behavior from version 0.19 to 0.20:

In 0.19, it returned only cells with exactly the given timestamp, 0.20 it to returns cells with a timestamp before (not including) the given timestamp.

It needs to be clearified, which one is the desired behavior.

I attach a patch to make 0.20 conform with 0.19 (only return cells with exactly the given timestamp), if this is what is wanted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1691,"When running MR jobs on 0.19.0 Hadoop, the hadoop core libraries get loaded by the classloader before 0.20 libraries included in the job jar.  HBaseClient makes a call to org.apache.hadoop.net.NetUtils.connect on line 305 which does not exist in previous versions of the hadoop jars and therefore results in NoSuchMethodErrors getting thrown.

As a simple workaround, you can replace the call

NetUtils.connect(socket, remoteId.getAddress(), 20000);

with

socket.connect(remoteId.getAddress(), 20000);

Note, however, that the javadoc on the NetUtils.connect() method makes mention of sun's implementation of stuff being less than wonderful, so the existence of this JIRA and this workaround should not be taken as meaning that this is actually a recommended solution.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1601,"During an MR job, ZK expires one of the nodes. This results in losing contact with a region server and eventually the map task timing out and the job failing.

Attaching the following logs:
1. HBase master logs
2. Logs from the web UI
3. Logs from the particular RS that went down.
4. Logs from the particular node that ZK expired.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-488,"In hql.jsp, if I make hql that returns zero results, eg 'select nosuchcolumn from table', I get a 500 page with the text

HTTP ERROR: 500

getState() == BEFORE_XML_DECLARATION

The search returns zero results in the hbase shell.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1555,"during a huge import (high concurrenty, 56 writers) I have seen:

java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:832)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:822)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1775)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.lang.NullPointerException
        at java.util.concurrent.ConcurrentHashMap$Segment.put(ConcurrentHashMap.java:426)
        at java.util.concurrent.ConcurrentHashMap.put(ConcurrentHashMap.java:883)
        at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1557)
        at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1610)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1225)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1197)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1768)
        ... 5 more
2009-06-19 20:13:55,672 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: java.lang.NullPointerException
2009-06-19 20:13:55,672 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 5 on 60020, call put([B@3160e069, [Lorg.apache.hadoop.hbase.client.Put;@4f2d26d2) from 10.10.20.226
:38741: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:832)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:822)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1775)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.lang.NullPointerException
        at java.util.concurrent.ConcurrentHashMap$Segment.put(ConcurrentHashMap.java:426)
        at java.util.concurrent.ConcurrentHashMap.put(ConcurrentHashMap.java:883)
        at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1557)
        at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1610)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1225)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1197)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1768)
        ... 5 more",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1227,"When issuing a command like:

  POST /api/users/scanner?column=habbit:football&start_row=Alice&end_row=Bob

The resultant scanner appears to ignore the start_row and end_row constraints, so that a command like:

  POST /api/users/scanner/1?limit=1000

returns results outside of the specified range e.g. the row for ""William"" will be returned.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1141,"While working on a Cell cache, we have found during random-read tests that the number of columns has an enormous impact on performance.  Accounting for increased HDFS access time, there is still a great deal of time being spent coming out of the Region and then across the wire to HTable.

Erik Holstad has done this testing and will post some of his results here when completed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-958,"I got a couple of these just now:

{code}
2008-10-25 00:05:25,192 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: Processing message (Retry: 0)
java.io.IOException: java.io.IOException: java.lang.IllegalArgumentException: server cannot be null
        at org.apache.hadoop.hbase.master.MetaRegion.<init>(MetaRegion.java:42)
        at org.apache.hadoop.hbase.master.ProcessRegionStatusChange.<init>(ProcessRegionStatusChange.java:45)
        at org.apache.hadoop.hbase.master.ProcessRegionOpen.<init>(ProcessRegionOpen.java:50)
        at org.apache.hadoop.hbase.master.ServerManager.processRegionOpen(ServerManager.java:467)
        at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:340)
        at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:314)
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:233)
        at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:569)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:623)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:622)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:539)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:48)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:404)
        at java.lang.Thread.run(Thread.java:674)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-856,"When data is inserted into Region that is on the different machine than the Master it is not immidiately available in the scanner that is using RowFilter
Here is the output of the test case on 3 nodes (tmptable_0 and tmptable_2 were placed on the region servers that are not running master server).
---------------DelayTest----------------
table tmptable_0 created
table tmptable_1 created
table tmptable_2 created
***********************************
table tmptable_0 test start
inserting some sample data into random row id (aaaaa-2108369209)
inserted
testing if the new row is available through get method
confirming that data:test value = test of row aaaaa-2108369209 is available
testing if the new row is available through scanner with filter
...................................
the new row has been found within 35 seconds
table tmptable_0 test finish
***********************************
***********************************
table tmptable_1 test start
inserting some sample data into random row id (aaaaa-20410017)
inserted
testing if the new row is available through get method
confirming that data:test value = test of row aaaaa-20410017 is available
testing if the new row is available through scanner with filter

the new row has been found within 0 seconds
table tmptable_1 test finish
***********************************
***********************************
table tmptable_2 test start
inserting some sample data into random row id (aaaaa1756705479)
inserted
testing if the new row is available through get method
confirming that data:test value = test of row aaaaa1756705479 is available
testing if the new row is available through scanner with filter
....................
the new row has been found within 20 seconds
table tmptable_2 test finish
***********************************
---------------DONE----------------

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1674,"when i suspend my system and resume it ... regionserver does not start back. looks like it actually shuts down completely. but the master and the zookeeper resume properly. 

i cannot stop-hbase.sh also properly. it goes on for a long time without doing anything. i have kill the master and zookeeper processes manually and do to ""start-hbase.sh"" to get back to the normal state.

irfan@damascus:~/qw/sandbox_7/qws$ stop-hbase.sh 
stopping master....................................................................................................

irfan@damascus:~$ jps
956 
11871 JobTracker
1816 HMaster
5908 Launcher
1742 HQuorumPeer
11790 SecondaryNameNode
3352 
32390 RunJar
11974 TaskTracker
4656 Child
11673 DataNode
6121 Jps
4669 Child
11568 NameNode
12770 PluginMain

irfan@damascus:~/apps/hbase-latest/logs$ tail -1000f hbase-irfan-regionserver-damascus.log
...
...
...
2009-07-19 11:48:59,538 INFO org.apache.hadoop.hbase.regionserver.HRegion: region site,,1247899770208/471872655 available; sequence id is 0
2009-07-19 11:48:59,539 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region site,,1247899770208
2009-07-19 11:48:59,542 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region site,,1247899770208 in 0sec
2009-07-19 11:58:09,369 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: compactions no longer limited
2009-07-19 12:47:59,493 INFO org.apache.hadoop.hbase.regionserver.HLog: Roll /hbase/.logs/damascus,60020,1247984279075/hlog.dat.1247984279311, entries=109890, calcsize=18397518, filesize=12396338. New hlog /hbase/.logs/damascus,60020,1247984279075/hlog.dat.1247987879487
2009-07-19 15:37:42,291 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12291a8d2be0001 to sun.nio.ch.SelectionKeyImpl@1542a75
java.io.IOException: TIMED OUT
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
2009-07-19 15:37:42,292 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 7207717ms, ten times longer than scheduled: 3000
2009-07-19 15:37:42,292 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: unable to report to master for 7207717 milliseconds - retrying
2009-07-19 15:37:42,294 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 7212721ms, ten times longer than scheduled: 10000
2009-07-19 15:37:42,295 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12291a8d2be0005 to sun.nio.ch.SelectionKeyImpl@628704
java.io.IOException: TIMED OUT
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
2009-07-19 15:37:42,296 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_5565548861312875890_4766java.net.SocketTimeoutException: 63000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:15928 remote=/127.0.0.1:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2369)

2009-07-19 15:37:42,297 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_5565548861312875890_4766 bad datanode[0] 127.0.0.1:50010
2009-07-19 15:37:42,298 FATAL org.apache.hadoop.hbase.regionserver.LogRoller: Log rolling failed with ioe: 
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2495)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$1600(DFSClient.java:2048)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2211)
2009-07-19 15:37:42,300 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics: request=0.0, regions=3, stores=6, storefiles=4, storefileIndexSize=0, memstoreSize=0, usedHeap=29, maxHeap=996, blockCacheSize=1961680, blockCacheFree=416131792, blockCacheCount=2, blockCacheHitRatio=99
2009-07-19 15:37:42,300 INFO org.apache.hadoop.hbase.regionserver.LogRoller: LogRoller exiting.
2009-07-19 15:37:42,300 INFO org.apache.hadoop.hbase.regionserver.LogFlusher: regionserver/127.0.1.1:60020.logFlusher exiting
2009-07-19 15:37:42,392 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: Disconnected, type: None, path: null
2009-07-19 15:37:44,192 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server localhost/127.0.0.1:2181
2009-07-19 15:37:44,193 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/127.0.0.1:55018 remote=localhost/127.0.0.1:2181]
2009-07-19 15:37:44,193 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-19 15:37:44,197 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12291a8d2be0005 to sun.nio.ch.SelectionKeyImpl@118cb72
java.io.IOException: Session Expired
	at org.apache.zookeeper.ClientCnxn$SendThread.readConnectResult(ClientCnxn.java:548)
	at org.apache.zookeeper.ClientCnxn$SendThread.doIO(ClientCnxn.java:661)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:897)
2009-07-19 15:37:44,198 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x12291a8d2be0005
2009-07-19 15:37:44,199 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn for session: 0x12291a8d2be0005
2009-07-19 15:37:44,199 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn for session: 0x12291a8d2be0005
2009-07-19 15:37:44,199 INFO org.apache.zookeeper.ZooKeeper: Session: 0x12291a8d2be0005 closed
2009-07-19 15:37:44,200 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-07-19 15:37:44,297 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server localhost/127.0.0.1:2181
2009-07-19 15:37:44,297 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/127.0.0.1:55020 remote=localhost/127.0.0.1:2181]
2009-07-19 15:37:44,297 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-19 15:37:44,298 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12291a8d2be0001 to sun.nio.ch.SelectionKeyImpl@d4b411
java.io.IOException: Session Expired
	at org.apache.zookeeper.ClientCnxn$SendThread.readConnectResult(ClientCnxn.java:548)
	at org.apache.zookeeper.ClientCnxn$SendThread.doIO(ClientCnxn.java:661)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:897)
2009-07-19 15:37:44,299 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: Expired, type: None, path: null
2009-07-19 15:37:45,302 INFO org.apache.hadoop.ipc.HBaseServer: Stopping server on 60020
2009-07-19 15:37:45,303 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 4 on 60020: exiting
2009-07-19 15:37:45,303 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Stopping infoServer
2009-07-19 15:37:45,314 INFO org.apache.hadoop.ipc.HBaseServer: Stopping IPC Server Responder
2009-07-19 15:37:45,352 INFO org.apache.hadoop.hbase.regionserver.MemStoreFlusher: regionserver/127.0.1.1:60020.cacheFlusher exiting
2009-07-19 15:37:45,353 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: regionserver/127.0.1.1:60020.compactor exiting
2009-07-19 15:37:45,353 INFO org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker: regionserver/127.0.1.1:60020.majorCompactionChecker exiting
2009-07-19 15:37:45,353 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: On abort, closed hlog
2009-07-19 15:37:45,354 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed .META.,,1
2009-07-19 15:37:45,354 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed site,,1247899770208
2009-07-19 15:37:45,354 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed -ROOT-,,0
2009-07-19 15:37:45,354 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: aborting server at: 127.0.1.1:60020
2009-07-19 15:37:45,362 INFO org.apache.hadoop.ipc.HBaseServer: Stopping IPC Server listener on 60020
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 3 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 2 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 0 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 9 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 8 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 7 on 60020: exiting
2009-07-19 15:37:45,372 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 6 on 60020: exiting
2009-07-19 15:37:45,373 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 5 on 60020: exiting
2009-07-19 15:37:45,373 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 1 on 60020: exiting
2009-07-19 15:37:52,295 INFO org.apache.hadoop.hbase.Leases: regionserver/127.0.1.1:60020.leaseChecker closing leases
2009-07-19 15:37:52,295 INFO org.apache.hadoop.hbase.Leases: regionserver/127.0.1.1:60020.leaseChecker closed leases
2009-07-19 15:37:52,295 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting
2009-07-19 15:37:52,295 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x12291a8d2be0001
2009-07-19 15:37:52,295 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn for session: 0x12291a8d2be0001
2009-07-19 15:37:52,296 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn for session: 0x12291a8d2be0001
2009-07-19 15:37:52,296 INFO org.apache.zookeeper.ZooKeeper: Session: 0x12291a8d2be0001 closed
2009-07-19 15:37:52,296 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-07-19 15:37:52,398 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/127.0.1.1:60020 exiting
2009-07-19 15:37:52,399 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Starting shutdown thread.
2009-07-19 15:37:52,400 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Shutdown thread complete

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1092,"This is an odd one.  We open a region and load up its store files.  Part of loading store files is confirming presence of MapFile index files (reconstituting them even if missing).  The below log is of region open and then seconds later, failing to find the index files when we go to look at them for sake of metrics:

{code}
2008-12-28 00:06:19,330 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_OPEN: content,10a1c144cf729885001e71a5ff5108dc,1230416158498
2008-12-28 00:06:19,330 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region content,10a1c144cf729885001e71a5ff5108dc,1230416158498/2030495720
2008-12-28 00:06:19,337 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/url/info/4139998553412763261, isReference=false, sequence id=13310628, length=54275, majorCompaction=false
2008-12-28 00:06:19,368 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/url/info/4467064002967944271, isReference=false, sequence id=9760762, length=432827, majorCompaction=false
2008-12-28 00:06:19,373 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/url/info/5563124412728188459, isReference=false, sequence id=12406630, length=22596, majorCompaction=false
2008-12-28 00:06:19,379 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/url/info/7040855870376599550, isReference=false, sequence id=12795530, length=4163, majorCompaction=false
2008-12-28 00:06:19,379 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 4 file(s) in hstore 2030495720/url, max sequence id 13310628
2008-12-28 00:06:19,496 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Applied 0, skipped 2078 because sequence id <= 13310628
2008-12-28 00:06:19,687 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/info/info/4076087643455354411, isReference=false, sequence id=9760762, length=1491212, majorCompaction=false
2008-12-28 00:06:19,691 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/info/info/4178444212265859440, isReference=false, sequence id=13310628, length=156148, majorCompaction=false
2008-12-28 00:06:19,697 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/info/info/7223110203696352566, isReference=false, sequence id=12406630, length=84614, majorCompaction=false
2008-12-28 00:06:19,703 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/info/info/8629305049543986640, isReference=false, sequence id=12795530, length=9293, majorCompaction=false
2008-12-28 00:06:19,704 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 4 file(s) in hstore 2030495720/info, max sequence id 13310628
2008-12-28 00:06:19,773 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /data/hbase/content/compaction.dir/888098363/content/mapfiles/3159110292991346789 to /data/hbase/content/888098363/content/mapfiles/6086595812879433437
2008-12-28 00:06:19,787 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed  compaction of 888098363/content store size is 172.4m
2008-12-28 00:06:19,791 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 888098363/info: 1.4m; Skipped 2 file(s), size: 1221094
2008-12-28 00:06:19,801 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Started compaction of 2 file(s)  into /data/hbase/content/compaction.dir/888098363/info/mapfiles/2317624608256855622
2008-12-28 00:06:19,821 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Applied 0, skipped 2078 because sequence id <= 13310628
2008-12-28 00:06:19,879 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /data/hbase/content/compaction.dir/888098363/info/mapfiles/2317624608256855622 to /data/hbase/content/888098363/info/mapfiles/2738033219360665217
2008-12-28 00:06:19,883 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/content/info/2253403598042963153, isReference=false, sequence id=13310628, length=12491312, majorCompaction=false
2008-12-28 00:06:19,887 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/content/info/4596284995168293361, isReference=false, sequence id=9760762, length=158138153, majorCompaction=false
2008-12-28 00:06:19,896 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed  compaction of 888098363/info store size is 1.4m
2008-12-28 00:06:19,898 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 888098363/url: 405.9k; Skipped 2 file(s), size: 339984
2008-12-28 00:06:19,904 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Started compaction of 2 file(s)  into /data/hbase/content/compaction.dir/888098363/url/mapfiles/1108952767537472093
2008-12-28 00:06:19,924 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/content/info/7464468628166271570, isReference=false, sequence id=12406630, length=11058492, majorCompaction=false
2008-12-28 00:06:19,930 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /data/hbase/content/2030495720/content/info/7703689073557380324, isReference=false, sequence id=12795530, length=183695, majorCompaction=false
2008-12-28 00:06:19,931 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 4 file(s) in hstore 2030495720/content, max sequence id 13310628
2008-12-28 00:06:19,958 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /data/hbase/content/compaction.dir/888098363/url/mapfiles/1108952767537472093 to /data/hbase/content/888098363/url/mapfiles/4113677425818108069
2008-12-28 00:06:19,976 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed  compaction of 888098363/url store size is 403.6k
2008-12-28 00:06:19,978 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region content,846510f382e9a0ae5655f03cb772830d,1230384248550 in 0sec
2008-12-28 00:06:19,979 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting  compaction on region content,e2f10daf46269ad3cc25766aa3bf48c4,1230416165744
2008-12-28 00:06:19,981 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 2100409777/content: 170.2m; Skipped 1 file(s), size: 144757669
2008-12-28 00:06:19,996 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Started compaction of 2 file(s)  into /data/hbase/content/compaction.dir/2100409777/content/mapfiles/7166480659109830957
2008-12-28 00:06:20,033 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Applied 0, skipped 2078 because sequence id <= 13310628
2008-12-28 00:06:20,127 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Deleting old log file: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/2030495720/oldlogfile.log
2008-12-28 00:06:20,137 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Next sequence id for region content,10a1c144cf729885001e71a5ff5108dc,1230416158498 is 13310629
2008-12-28 00:06:20,138 INFO org.apache.hadoop.hbase.regionserver.HRegion: region content,10a1c144cf729885001e71a5ff5108dc,1230416158498/2030495720 available
....
2008-12-28 00:06:21,008 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Started compaction of 2 file(s)  into /data/hbase/content/compaction.dir/2100409777/url/mapfiles/744229794307693860
2008-12-28 00:06:21,030 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: error getting store file index size for 2030495720/content: java.io.FileNotFoundException: File does not exist: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/2030495720/content/mapfiles/7703689073557380324/index
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
        at org.apache.hadoop.hbase.regionserver.HStoreFile.indexLength(HStoreFile.java:488)
        at org.apache.hadoop.hbase.regionserver.HStore.getStorefilesIndexSize(HStore.java:2174)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doMetrics(HRegionServer.java:936)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:333)
        at java.lang.Thread.run(Thread.java:619)

2008-12-28 00:06:21,032 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: error getting store file index size for 2030495720/info: java.io.FileNotFoundException: File does not exist: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/2030495720/info/mapfiles/8629305049543986640/index
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
        at org.apache.hadoop.hbase.regionserver.HStoreFile.indexLength(HStoreFile.java:488)
        at org.apache.hadoop.hbase.regionserver.HStore.getStorefilesIndexSize(HStore.java:2174)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doMetrics(HRegionServer.java:936)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:333) 
        at java.lang.Thread.run(Thread.java:619)

2008-12-28 00:06:21,053 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: error getting store file index size for 2030495720/url: java.io.FileNotFoundException: File does not exist: hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/content/2030495720/url/mapfiles/7040855870376599550/index
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
        at org.apache.hadoop.hbase.regionserver.HStoreFile.indexLength(HStoreFile.java:488)
        at org.apache.hadoop.hbase.regionserver.HStore.getStorefilesIndexSize(HStore.java:2174)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doMetrics(HRegionServer.java:936)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:333)
        at java.lang.Thread.run(Thread.java:619)
...
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1472,"Attempting to connect to an HBase 0.19.1 server with the HBase 0.19.0 client jars raises an exception that states the HBase server is not running.

This is misleading; it should state that the server is running an incompatible version.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1409,"When we create a table with the following schema:

{NAME => 'jobs_global', IS_ROOT => 'false', IS_META => 'false', MAX_FILESIZE => '134217728', FAMILIES => [{NAM
E => 'job', BLOOMFILTER => 'false', COMPRESSION => 'NONE', VERSIONS => '1', LENGTH => '2147483647', TTL => '86
400', IN_MEMORY => 'false', BLOCKCACHE => 'false'}], INDEXES => []}

The TTL is set to 86400 which should expire after 1 day, but the truth is that it expired before 86400 seconds.
To reproduce, create a table with the above schema and run some stress testing to create some splits and compaction,
usually in 4 - 5 hours, the row key will start missing from the Scanners.

By invoking HTable.get() and HTable.getRow(), the column appears to exist.
But if you launch a scanner or a MapReduce task to scan the table, the key will be missing.

By running a simple MapReduce task that prints out all the key value, you can tell some keys are already missing prior to its expiration time.

When we alter the table's TTL to a longer time, e.g. 604800, the row key appears in the scanner.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-888,"Might be related to HBASE-644?

In my regionserver log I see this:

2008-09-17 21:36:06,335 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@ff0be7b, row => Sn5MiT-wIYUoud4gqyj0r-==, {column => anchor:anchor_text, value => '...'}) f
rom 208.76.44.97:41671: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.io.SequenceFile$Writer.checkAndWriteSync(SequenceFile.java:970)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1012)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:979)
        at org.apache.hadoop.hbase.regionserver.HLog.append(HLog.java:395)
        at org.apache.hadoop.hbase.regionserver.HRegion.update(HRegion.java:1631)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1417)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1145)
        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-09-17 21:36:06,336 WARN org.apache.hadoop.ipc.Server: IPC Server Responder, call batchUpdate([B@ff0be7b, row => Sn5MiT-wIYUoud4gqyj0r-==, {column => anchor:anchor_text, value => '...'}) from x.x.44.97:41671: output error
2008-09-17 21:36:06,336 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020 caught: java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(Unknown Source)
        at sun.nio.ch.SocketChannelImpl.write(Unknown Source)
        at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:587)
        at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:651)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:909)

2008-09-17 21:36:06,336 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020: exiting
2008-09-17 21:37:06,312 FATAL org.apache.hadoop.hbase.regionserver.Flusher: Replay of hlog required. Forcing server restart
org.apache.hadoop.hbase.DroppedSnapshotException: region: enwiki3,4m7aFqMi8ijHEpBxTuzP3k==,1221687099180
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1079)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:977)
        at org.apache.hadoop.hbase.regionserver.Flusher.flushRegion(Flusher.java:174)
        at org.apache.hadoop.hbase.regionserver.Flusher.flushSomeRegions(Flusher.java:268)
        at org.apache.hadoop.hbase.regionserver.Flusher.reclaimMemcacheMemory(Flusher.java:253)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1144)
        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
Caused by: java.io.IOException: Call failed on local exception
        at org.apache.hadoop.ipc.Client.call(Client.java:718)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
        at org.apache.hadoop.dfs.$Proxy1.getFileInfo(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at org.apache.hadoop.dfs.$Proxy1.getFileInfo(Unknown Source)
        at org.apache.hadoop.dfs.DFSClient.getFileInfo(DFSClient.java:566)
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:390)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:667)
        at org.apache.hadoop.hbase.regionserver.HStoreFile.<init>(HStoreFile.java:149)
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:591)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:569)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1066)
        ... 10 more
Caused by: java.nio.channels.ClosedByInterruptException
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(Unknown Source)
        at sun.nio.ch.SocketChannelImpl.write(Unknown Source)
        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)
        at java.io.BufferedOutputStream.flush(Unknown Source)
        at java.io.DataOutputStream.flush(Unknown Source)
        at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:478)
        at org.apache.hadoop.ipc.Client.call(Client.java:705)
        ... 25 more
2008-09-17 21:37:06,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: coral-dfs.cluster.powerset.com/208.76.44.135:10000. Already tried 0 time(s).
2008-09-17 21:37:06,346 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate([B@52fac63b, row => 6PceOtjHe-VpiGbS5DZgMV==, {column => [..], value => '...'}) from x.x.44.96:44885: error: java.io.IOException: Cannot append; log is closed
java.io.IOException: Cannot append; log is closed
        at org.apache.hadoop.hbase.regionserver.HLog.append(HLog.java:376)
        at org.apache.hadoop.hbase.regionserver.HRegion.update(HRegion.java:1631)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1417)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1145)
        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
2008-09-17 21:37:06,346 WARN org.apache.hadoop.ipc.Server: IPC Server Responder, call batchUpdate([B@52fac63b, row => 6PceOtjHe-VpiGbS5DZgMV==, {column => [...], value => '...'}) from 208.76.44.96:44885: output error
2008-09-17 21:37:06,346 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020 caught: java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(Unknown Source)
        at sun.nio.ch.SocketChannelImpl.write(Unknown Source)
        at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:587)
        at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:651)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:909)

2008-09-17 21:37:06,346 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020: exiting
2008-09-17 21:37:54,491 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 3236781325465377548 lease expired
2008-09-17 21:37:54,492 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region enwiki,MHw740LAdNxzM68Dn7LXs-==,1220059653599
2008-09-17 21:37:54,492 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region enwiki,MHw740LAdNxzM68Dn7LXs-==,1220059653599
2008-09-17 21:37:54,492 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region enwiki,MHw740LAdNxzM68Dn7LXs-==,1220059653599
2008-09-17 21:37:54,492 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/anchor
2008-09-17 21:37:54,493 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/misc
2008-09-17 21:37:54,493 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/alternate_title
2008-09-17 21:37:54,493 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/page
2008-09-17 21:37:54,493 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 370784783/alternate_url
2008-09-17 21:37:54,493 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed enwiki,MHw740LAdNxzM68Dn7LXs-==,1220059653599
2008-09-17 21:37:54,493 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting
2008-09-17 21:38:07,581 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: Shutting down HRegionServer: file system not available
java.io.IOException: File system is not available
        at org.apache.hadoop.hbase.util.FSUtils.checkFileSystemAvailable(FSUtils.java:82)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.checkFileSystem(HRegionServer.java:1484)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1150)
        at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
Caused by: java.io.IOException: Call failed on local exception
        at org.apache.hadoop.ipc.Client.call(Client.java:718)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
        at org.apache.hadoop.dfs.$Proxy1.getFileInfo(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at org.apache.hadoop.dfs.$Proxy1.getFileInfo(Unknown Source)
        at org.apache.hadoop.dfs.DFSClient.getFileInfo(DFSClient.java:566)
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:390)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:667)
        at org.apache.hadoop.hbase.util.FSUtils.checkFileSystemAvailable(FSUtils.java:69)
        ... 7 more
:


The result is that every call to the regionserver hangs because the regionserver can't touch the DFS, because the DFSClient is closed.  The regionserver won't restart either.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-829,"Seen on a 4 node cluster during the reduce phase of a MR job that only deleteAll rows, one of the region server failed after a filesystem not available exception. When restarted, it got assigned some regions but in the web UI none was shown when clicking on the HRS address. Also in the master page 0 region was shown for that HRS so the total number of regions was under the real number.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1080,"This lock assigning regions looks broad.

{code}
""IPC Server handler 6 on 60000"" daemon prio=10 tid=0x00007ff2d00ab400 nid=0x645b in Object.wait() [0x000000004330b000..0x000000004330cd70]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:695)
	- locked <0x00007ff2e8e2b3b0> (a org.apache.hadoop.hbase.ipc.HBaseClient$Call)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:321)
	at $Proxy2.batchUpdates(Unknown Source)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$2.call(HConnectionManager.java:916)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$2.call(HConnectionManager.java:914)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerForWithoutRetries(HConnectionManager.java:872)
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.processBatchOfRows(HConnectionManager.java:913)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1270)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:1241)
	- locked <0x00007ff2e8c01b90> (a org.apache.hadoop.hbase.client.HTable)
	at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:1221)
	- locked <0x00007ff2e8c01b90> (a org.apache.hadoop.hbase.client.HTable)
	at org.apache.hadoop.hbase.RegionHistorian.add(RegionHistorian.java:239)
	at org.apache.hadoop.hbase.RegionHistorian.add(RegionHistorian.java:218)
	at org.apache.hadoop.hbase.RegionHistorian.addRegionAssignment(RegionHistorian.java:142)
	at org.apache.hadoop.hbase.master.RegionManager.assignRegionsToMultipleServers(RegionManager.java:282)
	at org.apache.hadoop.hbase.master.RegionManager.assignRegions(RegionManager.java:220)
	- locked <0x00007ff2e895d3f8> (a java.util.Collections$SynchronizedSortedMap)
	at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:382)
	at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:324)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:240)
	at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:570)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:892)

....
{code}

Its messing up assigning root it seems.

We are stuck in here.  Doesn't look like we'll break out though maybe we time out?

{code}
  public Writable call(Writable param, InetSocketAddress addr, 
                       UserGroupInformation ticket)  
                       throws InterruptedException, IOException {
    Call call = new Call(param);
    Connection connection = getConnection(addr, ticket, call);
    connection.sendParam(call);                 // send the parameter
    synchronized (call) {
      while (!call.done) {
        try {
          call.wait();                           // wait for the result
        } catch (InterruptedException ignored) {}
      }
...
{code}

... down in HBaseClient. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-935,"Our hdfs is having issues.  Not just hbase is complaining.  During a storm of downing regionservers because of failed flush attempts, master has gotten itself locked up over location of root region.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-870,"This morning, the pset master got into a locked up state.  Was stuck for tens of minutes doing the below logging.  Cluster was unusable during this time:

{code}
....
2008-09-04 18:06:45,893 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner REGION => {NAME => 'enwiki,YSWgGYWLLur87bjpYfj5--==,1220070599758', STARTKEY => 'YSWgGYWLLur87bjpYfj5--==', ENDKEY => 'Y_dJHSiXE_hJ8jmGEgg1Dk==', ENCODED => 1060266767, TABLE => {{NAME => 'enwiki', IS_ROOT => 'false'
, IS_META => 'false', FAMILIES => [{NAME => 'alternate_title', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'anchor', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGT
H => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'alternate_url', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'page', BLOOMFILTER => 'false', VERSIONS => '21
47483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'misc', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}]}}}, SERVER => 'XX.XX.XX.1
83:60020', STARTCODE => 1219794634959
2008-09-04 18:06:45,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 1 time(s).
2008-09-04 18:06:46,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 2 time(s).
2008-09-04 18:06:47,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 3 time(s).
2008-09-04 18:06:48,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 4 time(s).
2008-09-04 18:06:49,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 5 time(s).
2008-09-04 18:06:50,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 6 time(s).
2008-09-04 18:06:51,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 7 time(s).
2008-09-04 18:06:52,398 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: <>, server: 208.76.44.68:60020}
2008-09-04 18:06:52,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 8 time(s).
2008-09-04 18:06:53,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 9 time(s).
2008-09-04 18:06:55,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 10 time(s).
2008-09-04 18:06:56,018 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: Connection refused
2008-09-04 18:06:56,045 DEBUG org.apache.hadoop.hbase.master.BaseScanner: RegionManager.rootScanner REGION => {NAME => '.META.,,1', STARTKEY => '', ENDKEY => '', ENCODED => 1028785192, TABLE => {{NAME => '.META.', IS_ROOT => 'false', IS_META => 'true', FAMILIES => [{NAME => 'info', BLOOMFILTER => 'false', COMPRESSI
ON => 'NONE', VERSIONS => '2147483647', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}, {NAME => 'historian', BLOOMFILTER => 'false', VERSIONS => '2147483647', COMPRESSION => 'NONE', LENGTH => '2147483647', TTL => '-1', IN_MEMORY => 'false', BLOCKCACHE => 'false'}]}}}, SERVER => '
208.76.44.48:60020', STARTCODE => 1219794657357
2008-09-04 18:07:01,084 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 1917, Num Servers: 69, Avg Load: 28.0
2008-09-04 18:07:01,084 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Cache hit in table locations for row <> and tableName .META.: location server XX.XX.XX.253:60020, location region name .META.,,1
2008-09-04 18:07:01,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 1 time(s).
2008-09-04 18:07:02,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 2 time(s).
2008-09-04 18:07:03,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 3 time(s).
2008-09-04 18:07:04,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 4 time(s).
2008-09-04 18:07:05,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 5 time(s).
2008-09-04 18:07:06,038 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of shroomz_062108,a8XltuT_bfDh6RCYKWEf9-==,1215120916399
2008-09-04 18:07:06,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 6 time(s).
2008-09-04 18:07:07,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 7 time(s).
2008-09-04 18:07:08,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 8 time(s).
2008-09-04 18:07:09,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 9 time(s).
2008-09-04 18:07:10,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: aa0-004-19.u.powerset.com/XX.XX.XX.253:60020. Already tried 10 time(s).
2008-09-04 18:07:11,218 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: Connection refused
2008-09-04 18:08:09,779 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 1917, Num Servers: 69, Avg Load: 28.0
2008-09-04 18:08:11,238 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:09:11,248 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:09:43,328 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.185:60020 lease expired
2008-09-04 18:09:43,348 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.183:60020 lease expired
2008-09-04 18:09:43,368 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.231:60020 lease expired
2008-09-04 18:09:43,438 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.127:60020 lease expired
2008-09-04 18:09:43,528 INFO org.apache.hadoop.hbase.master.ServerManager: XX.XX.XX.68:60020 lease expired
2008-09-04 18:10:11,258 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:11:11,278 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:12:11,298 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:13:11,318 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:14:11,338 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:15:11,358 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:16:11,368 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:17:11,378 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:18:11,388 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:19:11,398 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:20:11,408 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:21:11,418 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:22:11,428 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:23:11,438 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
2008-09-04 18:23:28,291 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 1805, Num Servers: 65, Avg Load: 28.0
2008-09-04 18:24:11,458 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: timed out waiting for rpc response
....
{code}

Attached are thread dumps taking around this time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1006,"Here is the OOME:

{code}
#
2008-11-17 17:04:18,812 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown
#
org.apache.hadoop.hbase.DroppedSnapshotException: region: streamitems,^@^@^@^@^A茂驴陆?茂驴陆,1226968617756
#
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:865)
#
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:761)
#
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:179)
#
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushSomeRegions(MemcacheFlusher.java:232)
#
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.reclaimMemcacheMemory(MemcacheFlusher.java:213)
#
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdates(HRegionServer.java:1312)
#
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
#
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
#
        at java.lang.reflect.Method.invoke(Method.java:597)
#
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:634)
#
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
#
Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded
#
        at org.apache.hadoop.hbase.util.Bytes.readByteArray(Bytes.java:62)
#
        at org.apache.hadoop.hbase.HStoreKey.readFields(HStoreKey.java:589)
#
        at org.apache.hadoop.io.MapFile$Writer.checkKey(MapFile.java:213)
#
        at org.apache.hadoop.io.MapFile$Writer.append(MapFile.java:192)
#
        at org.apache.hadoop.hbase.io.BloomFilterMapFile$Writer.append(BloomFilterMapFile.java:201)
#
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:674)
#
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:627)
#
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:852)
#
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:852)
{code}

Looking in heap, the resevoir had not been released.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-915,"From AlphaOmega: 

{code}
   1.
      Caused by: java.lang.NullPointerException
   2.
              at java.lang.String.<init>(String.java:516)
   3.
              at org.apache.hadoop.hbase.util.Bytes.toString(Bytes.java:75)
   4.
              at org.apache.hadoop.hbase.client.RetriesExhaustedException.getMessage(RetriesExhaustedException.java:50)
   5.
              at org.apache.hadoop.hbase.client.RetriesExhaustedException.<init>(RetriesExhaustedException.java:40)
   6.
              at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)
   7.
              at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:56)
   8.
              at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:30)
   9.
              at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.listTables(HConnectionManager.java:297)
  10.
              at org.apache.hadoop.hbase.client.HBaseAdmin.listTables(HBaseAdmin.java:117)
  11.
              at com.company.app.manager.util.TableUtils.createHBaseTable(TableUtils.java:113)
  12.
              at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  13.
              at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
  14.
              at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
  15.
              at java.lang.reflect.Method.invoke(Method.java:597)
  16.
              at org.springframework.util.MethodInvoker.invoke(MethodInvoker.java:276)
  17.
              at org.springframework.beans.factory.config.MethodInvokingFactoryBean.doInvoke(MethodInvokingFactoryBean.java:160)
  18.
              at org.springframework.beans.factory.config.MethodInvokingFactoryBean.afterPropertiesSet(MethodInvokingFactoryBean.java:150)
  19.
              at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1368)
  20.
              at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1334)
  21.
              ... 65 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-724,"When deleting a row, that row seems to be deleted and everything to be normal but some time afterwards that row somehow reappears (HTable.get() and scanners find it again). Looking at the log files it seems like deleted rows reappear after a flush of the memcache or after the compaction...",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-713,"Internally, i'm trying to offline a 512 region table.  All but 30 offline.  If I try to online it, all but 2 go online.  Second time I try it, all but 41 offline.  Enabling, all but 2 online.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-673,"getRow often returns no results, even when a scanner returned results for the same row.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-594,"We are running HBase TRUNK (updated yesterday) and Hadoop TRUNK (updated a few days ago) on a 15 node cluster. One node doubles as master and region server. The remainder are region servers. 

I have been trying to use the HBase shell to drop tables for quite a few minutes now. 

The master schedules the table for deletion and the region server processes the deletion:

08/04/18 16:57:29 INFO master.HMaster: deleted table: content.20b16c29
08/04/18 16:57:34 INFO master.ServerManager: 10.30.94.35:60020 no longer serving regionname: content.20b16c29,,1208549961323, startKey: <>, endKey: <>, encodedName: 385178593, tableDesc: {name: content.20b16c29, families: {content:={name: content, max versions: 1, compression: RECORD, in memory: false, block cache enabled: true, max length: 2147483647, bloom filter: none}, info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: true, maxlength: 2147483647, bloom filter: none}}}
08/04/18 16:57:34 INFO master.ProcessRegionClose$1: region closed: content.20b16c29,,1208549961323

but then a META scan happens and the table is reassigned to another server to live on as a zombie:

08/04/18 16:57:48 INFO master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: <>, server: 10.30.94.37:60020}
08/04/18 16:57:48 INFO master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: <>, server: 10.30.94.37:60020} complete
08/04/18 16:57:48 INFO master.BaseScanner: all meta regions scanned
08/04/18 16:57:49 INFO master.RegionManager: assigning region content.20b16c29,,1208549961323 to server 10.30.94.39:60020
08/04/18 16:57:52 INFO master.BaseScanner: RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: <>, server: 10.30.94.31:60020}
08/04/18 16:57:52 INFO master.BaseScanner: RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: <>, server: 10.30.94.31:60020} complete
08/04/18 16:57:52 INFO master.ServerManager: 10.30.94.39:60020 serving content.20b16c29,,1208549961323
08/04/18 16:57:52 INFO master.ProcessRegionOpen$1: regionname: content.20b16c29,,1208549961323, startKey: <>, endKey: <>, encodedName: 385178593, tableDesc: {name: content.20b16c29, families: {content:={name: content, max versions: 1, compression: RECORD, in memory: false, block cache enabled: true, max length: 2147483647, bloom filter: none}, info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: true, max length: 2147483647, bloom filter: none}}} open on 10.30.94.39:60020
08/04/18 16:57:52 INFO master.ProcessRegionOpen$1: updating row content.20b16c29,,1208549961323 in table .META.,,1 with startcode 1208552149355 and server 10.30.94.39:60020

Approximately 50 META region scans then happen, then the following occurs and reoccurs over many many subsequent META scans:

08/04/18 17:26:48 INFO master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: <>, server: 10.30.94.37:60020}
08/04/18 17:26:48 WARN master.HMaster: info:regioninfo is empty for row: content.20b16c29,,1208549961323; has keys: [info:server, info:serverstartcode]
08/04/18 17:26:48 WARN master.BaseScanner: Found 1 rows with empty HRegionInfo while scanning meta region .META.,,1
08/04/18 17:26:48 WARN master.HMaster: Removed region: content.20b16c29,,1208549
961323 from meta region: .META.,,1 because HRegionInfo was empty
08/04/18 17:26:48 INFO master.BaseScanner: RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: <>, server: 10.30.94.37:60020} complete
08/04/18 17:26:48 INFO master.BaseScanner: all meta regions scanned

yet finally the table disappears for a reason that does not appear in the logs... at least for this particular example. There is another table that is simply refusing to die...

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-499,"I'm afraid to touch the thing (No mention of the test in process listing).  Asking nigel how to kill the test.

It looks like the old problem where test was over but we'd hang on shutdown.... as though TTI is no longer doing the shutdown in the ordained sequence.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-445,"We've been dealing with a problem where regions go offline for no apparent reason.  Usually restarting the whole system clears things up, but that's not a desired workaround.  After some digging on one of the region servers with a region that is offline that should not be I found the following:

2008-02-13 17:43:31,357 INFO org.apache.hadoop.hbase.HRegion: starting compaction on region webdb,com.geocities.www/Paris/1685/,1202919182718
2008-02-13 17:45:09,004 INFO org.apache.hadoop.hbase.HRegionServer: Rolling hlog. Number of entries: 30006
2008-02-13 17:45:09,071 INFO org.apache.hadoop.hbase.HLog: new log writer created at hdfs://node-3-34.isc.swlabs.org:9000/u01/hbase-data/hbase/log_10.2
.3.32_1202914711919_60020/hlog.dat.010
2008-02-13 17:47:51,606 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region webdb,com.geocities.www/Paris/1685/,1202919182718. Took 4m
ins, 20sec
2008-02-13 17:48:20,273 INFO org.apache.hadoop.hbase.HRegionServer: Rolling hlog. Number of entries: 30007
2008-02-13 17:48:20,315 INFO org.apache.hadoop.hbase.HLog: new log writer created at hdfs://node-3-34.isc.swlabs.org:9000/u01/hbase-data/hbase/log_10.2
.3.32_1202914711919_60020/hlog.dat.011
2008-02-13 17:48:20,315 INFO org.apache.hadoop.hbase.HLog: removing old log file hdfs://node-3-34.isc.swlabs.org:9000/u01/hbase-data/hbase/log_10.2.3.3
2_1202914711919_60020/hlog.dat.008 whose highest sequence/edit id is 1286138
2008-02-13 17:48:34,959 ERROR org.apache.hadoop.hbase.HRegionServer: Cache flush failed for region webdb,com.geocities.www/Paris/1685/,1202919182718
java.lang.NullPointerException
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.close(DFSClient.java:2262)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:51)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:67)
        at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:932)
        at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:172)
        at org.apache.hadoop.hbase.HStore.internalFlushCache(HStore.java:1117)
        at org.apache.hadoop.hbase.HStore.flushCache(HStore.java:1081)
        at org.apache.hadoop.hbase.HRegion.internalFlushcache(HRegion.java:939)
        at org.apache.hadoop.hbase.HRegion.flushcache(HRegion.java:837)
        at org.apache.hadoop.hbase.HRegionServer$Flusher.run(HRegionServer.java:417)
2008-02-13 17:51:02,705 INFO org.apache.hadoop.hbase.HRegionServer: Rolling hlog. Number of entries: 30006
2008-02-13 17:52:07,221 INFO org.apache.hadoop.hbase.HRegion: starting compaction on region webdb,,1202919182716
2008-02-13 17:56:19,028 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region webdb,,1202919182716. Took 4mins, 11sec
2008-02-13 17:56:19,167 INFO org.apache.hadoop.hbase.HRegion: Splitting webdb,com.geocities.www/Paris/1685/,1202919182718 because largest aggregate siz
e is 264.7m and desired size is 256.0m
2008-02-13 17:57:36,060 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020, call batchUpdate(webdb,com.geocities.www/Paris/1685/,12029191
82718, 1202921443000, org.apache.hadoop.hbase.io.BatchUpdate@7262b6) from 10.2.3.34:43471: error: org.apache.hadoop.hbase.NotServingRegionException: we
bdb,com.geocities.www/Paris/1685/,1202919182718
org.apache.hadoop.hbase.NotServingRegionException: webdb,com.geocities.www/Paris/1685/,1202919182718
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1610)
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1582)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1431)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)
2008-02-13 17:57:46,082 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate(webdb,com.geocities.www/Paris/1685/,12029191
82718, 1202921443000, org.apache.hadoop.hbase.io.BatchUpdate@cac02f) from 10.2.3.34:43476: error: org.apache.hadoop.hbase.NotServingRegionException: we
bdb,com.geocities.www/Paris/1685/,1202919182718
org.apache.hadoop.hbase.NotServingRegionException: webdb,com.geocities.www/Paris/1685/,1202919182718
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1610)
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1582)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1431)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)

...

And so on.  The region has been offline for 2-3 hours now...so it's not a split that just taking too long.

I'm not much of a java developer, tho I'll attempt to dig into the code myself.  Please, any help here would really be appreciated. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-411,"Currently, hadoop jar must be first on the CLASSPATH.  If its not found first, on startup we get complaint that the hadoop webapps can't be found.  Has to do w/ fact that the webapp is supposed to be in the jar thats doing the class loading (There was a fix up in core but needs fixup/cleanup).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-177,"This error happened after a region tried to split before a complete compaction could be done on the region from the first split
I thank we should que up a compaction on loading of a region on a region server this should help keep this from happening but also we should have the split thread check to see if the region safe to split.


{code}
2008-01-30 00:07:34,250 ERROR org.apache.hadoop.hbase.HRegionServer: Split failed for region webdata,,1201671207519
java.io.FileNotFoundException: File hdfs://10.0.0.1:9000/gfs_storage/hadoop-root/hbase/webdata/1080614411/size/mapfiles/5351268197296217146/data does not exist.
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:341)
        at org.apache.hadoop.hbase.HStoreFile.length(HStoreFile.java:456)
        at org.apache.hadoop.hbase.HStore.loadHStoreFiles(HStore.java:876)
        at org.apache.hadoop.hbase.HStore.<init>(HStore.java:731)
        at org.apache.hadoop.hbase.HRegion.<init>(HRegion.java:286)
        at org.apache.hadoop.hbase.HRegion.splitRegion(HRegion.java:597)
        at org.apache.hadoop.hbase.HRegionServer$Splitter.split(HRegionServer.java:303)
        at org.apache.hadoop.hbase.HRegionServer$Splitter.run(HRegionServer.java:263)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-692,"I see two tables of same name in an hbase instance.  The first was made with column familes 1, 2, 3.  I then dropped that table and made a new one with column family 4.  I notice now -- or rather Jim Firby noticed --  that two tables are showing in the UI, both named the same; one with familes 1, 2, and 3 with the other showing column family 4.

Scanning etc., seems to work properly.  Looking on disk, I see one subdir named for the table with all column families under it.

Haven't tried to reproduce.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-634,"On our internal cluster, noticed hung regionserver.  Hang manifest itself in log as thousands of lines of:

{code}
Call queue overflow discarding oldest call batchUpdate
{code}

Thread dumping, a bunch of threads are waiting to append to HLog:

{code}
     41 ""IPC Server handler 8 on 60020"" daemon prio=1 tid=0x00002aab40226770 nid=0x3890 waiting for monitor entry [0x0000000042d7d000..0x0000000042d7db00]
     42         at org.apache.hadoop.hbase.HLog.append(HLog.java:370)
     43         - waiting to lock <0x00002aaab7815d38> (a java.lang.Integer)
     44         at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1624)
     45         at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1427)
     46         at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1554)
     47         at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
     48         at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
     49         at java.lang.reflect.Method.invoke(Unknown Source)
     50         at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
     51         at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)
{code}

... but they can't because another thread is stuck trying to write the HLog:

{code}
     16 ""IPC Server handler 9 on 60020"" daemon prio=1 tid=0x00002aab402278d0 nid=0x3891 in Object.wait() [0x0000000042e7e000..0x0000000042e7eb80]
     17         at java.lang.Object.wait(Native Method)
     18         at java.lang.Object.wait(Unknown Source)
     19         at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:2131)
     20         - locked <0x00002aaab7ee5038> (a java.util.LinkedList)
     21         at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:141)
     22         at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:100)
     23         at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:86)
     24         - locked <0x00002aaab7ee4cb0> (a org.apache.hadoop.dfs.DFSClient$DFSOutputStream)
     25         at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:41)
     26         at java.io.DataOutputStream.write(Unknown Source)
     27         - locked <0x00002aaab7e73ea8> (a org.apache.hadoop.fs.FSDataOutputStream)
     28         at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:990)
     29         - locked <0x00002aaab7ee5200> (a org.apache.hadoop.io.SequenceFile$Writer)
     30         at org.apache.hadoop.hbase.HLog.append(HLog.java:387)
     31         - locked <0x00002aaab7815d38> (a java.lang.Integer)
     32         at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1624)
     33         at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1427)
     34         at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1554)
     35         at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
     36         at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
     37         at java.lang.reflect.Method.invoke(Unknown Source)
     38         at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
     39         at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)
{code}

Looking in code, the above sleep will be woken when we get response from datanode -- a response that never comes in this case.  The Responder thread itself is stuck trying to read a long from the datanode:

{code}
      3 ""ResponseProcessor for block blk_3392187502501092232"" daemon prio=1 tid=0x00002aab38cd8ba0 nid=0x7700 runnable [0x0000000043080000..0x0000000043080c80]
      4         at java.net.SocketInputStream.socketRead0(Native Method)
      5         at java.net.SocketInputStream.read(Unknown Source)
      6         at java.io.DataInputStream.readFully(Unknown Source)
      7         at java.io.DataInputStream.readLong(Unknown Source)
      8         at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:1734)
{code}

Related is the DFSClient DataStreamer, itself is in a sleep

{code}
     10 ""DataStreamer for file /hbase/aa0-005-2.u.powerset.com/log_208.76.44.96_1211224091595_60020/hlog.dat.004"" daemon prio=1 tid=0x00002aab38a34920 nid=0x6e1b in Object.wait() [0x0000000043484000..0x0000000043484b00]
     11         at java.lang.Object.wait(Native Method)
     12         at java.lang.Object.wait(Unknown Source)
     13         at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1656)
     14         - locked <0x00002aaab7ee5060> (a java.util.LinkedList)
{code}

The hang doesn't change after 5 or 6 thread dumps nor does it change though I shutdown the regionserver.

Would need to figure why the datanode stopped responding, why we haven't timedout our read at least.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-386,All regression tests should close any open HTables to speed up test exit.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-155,hbase.Leases has problems with concurrency because it's data structures are not volatile. Changing them so the are makes leases more reliable.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21722,submit-patch.py now requries the future module,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9559,"See also HBASE-9503. Unless I'm missing something, getRowKeyAtOrBefore does not handle cross-file deletes correctly. It also doesn't handle timestamps between two candidates of the same row if they are in different file (latest by ts is going to be returned).
It is only used for meta, so it might be working due to low update rate, lack of anomalies and the fact that row values in meta are reasonably persistent, new ones are only added in split.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15355,"After [HBASE-10569|https://issues.apache.org/jira/browse/HBASE-10569], master is also a regionserver and it will serve regions of system tables. The meta region info could be viewed on master at the address such as : http://localhost:16010/region.jsp?name=1588230740. The real path of region.jsp for the request will be hbase-webapps/master/region.jsp on master, however, the region.jsp is under the directory hbase-webapps/regionserver, so that can not be found on master.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13676,"{noformat}
Running org.apache.hadoop.hbase.regionserver.TestRegionServerHostname
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 14.543 sec <<< FAILURE! - in org.apache.hadoop.hbase.regionserver.TestRegionServerHostname
testInvalidRegionServerHostnameAbortsServer(org.apache.hadoop.hbase.regionserver.TestRegionServerHostname)  Time elapsed: 6.845 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.testInvalidRegionServerHostnameAbortsServer(TestRegionServerHostname.java:57)


Results :

Failed tests: 
  TestRegionServerHostname.testInvalidRegionServerHostnameAbortsServer:57 null
{noformat}

The exception message is not what the test expects. We want a string containing ""Failed resolve of "" + invalidHostname. What I have is ""java.net.BindException: Problem binding to hostAddr.invalid/198.105.244.228:0 : Cannot assign requested address."" 

This is because my ISP is ""helpfully"" providing A records for invalid hostnames.

{noformat}
apurtell@aspire ~ $ dig hostAddr.invalid

; <<>> DiG 9.9.5-3ubuntu0.2-Ubuntu <<>> hostAddr.invalid
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 49027
;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;hostAddr.invalid.		IN	A

;; ANSWER SECTION:
hostAddr.invalid.	10	IN	A	198.105.244.228
hostAddr.invalid.	10	IN	A	198.105.254.228

;; Query time: 27 msec
;; SERVER: 127.0.1.1#53(127.0.1.1)
;; WHEN: Tue May 12 13:34:21 PDT 2015
;; MSG SIZE  rcvd: 66
{noformat}

The test should be made more general to capture this kind of failure too.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12154,"It doesn't make sense to run a load test on a shared box where other tests are being run. We should probably move this to integration tests and make sure its covered. In cases where the jenkins machines are shared across several projects which are doing disk IO, I have observed that this test runs into slow syncs and eventually times out. And that being said, we can't increase the timeout on this test, since its already 3 minutes. This test being disk sensitive, might have better coverage on IT.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11087,"If you try to import eclipse you will get some import errors about maven plugins. [1] So, in order to avoid the exceptions in Eclipse, looks like one needs to simply enclose all the plugin tags inside a <pluginManagement> tag. I create a patch for this problem. 

[1] http://mail-archives.apache.org/mod_mbox/hbase-dev/201404.mbox/%3CCAEz%2Byv-hMdjpue91TSh%2B1YdGW8oqo5TXPeH09Y4dntvtPro2bQ%40mail.gmail.com%3E",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10977,"On our internal rig, ran into this failure:

{code}
java.lang.AssertionError: expected:<2> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.doQuarantineTest(TestHBaseFsck.java:1737)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testQuarantineMissingHFile(TestHBaseFsck.java:1781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}

This is what is failing:

      assertEquals(hfcc.getMissing().size(), missing);

The file remove has not run yet or, else, this complaint is related:

{code}
2014-04-12 23:24:57,638 WARN  [IPC Server handler 4 on 50919] security.UserGroupInformation(1551): PriviledgedActionException as:jenkins (auth:SIMPLE) cause:java.io.FileNotFoundException: File does not exist: /user/jenkins/hbase/data/default/testQuarantineMissingHFile/63cdcba1fc55ae6463463ae16f4e454e/fam/57a07eaac97e4acd8dc04e08d1950adc
{code}

Below is full log.  Will come back and add logging....

{code}
Regression

org.apache.hadoop.hbase.util.TestHBaseFsck.testQuarantineMissingHFile

Failing for the past 1 build (Since Failed#3 )
Took 10 ms.
add description
Error Message

expected:<2> but was:<1>
Stacktrace

java.lang.AssertionError: expected:<2> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.doQuarantineTest(TestHBaseFsck.java:1737)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testQuarantineMissingHFile(TestHBaseFsck.java:1781)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Standard Output

Allow checking/fixes for table: testQuarantineMissingHFile
Checked 4 hfile for corruption
  HFiles corrupted:                  0
    HFiles successfully quarantined: 0
    HFiles failed quarantine:        0
    HFiles moved while checking:     2
      hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/63cdcba1fc55ae6463463ae16f4e454e/fam/57a07eaac97e4acd8dc04e08d1950adc
      hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/d383980be98665b638fd56bfac97a351/fam/9dd79f30f29e4cfeaa46f6e20b32e078
Summary: OK => OK
Version: 0.96.1.1-cdh5.0.1-SNAPSHOT
---- Table 'testQuarantineMissingHFile': region split map
:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/63cdcba1fc55ae6463463ae16f4e454e, deployed =>  }, A]	
A:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/a8a68d998d21b00499aca60887ae5aef, deployed =>  }, B]	
B:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/d383980be98665b638fd56bfac97a351, deployed =>  }, C]	
C:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/f9c185520bca999a753ee3ce0a244f6d, deployed =>  }, ]	
null:	
---- Table 'testQuarantineMissingHFile': overlap groups
There are 0 overlap groups with 0 overlapping regions
---- Table 'hbase:meta': region split map
:	[ { meta => null, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/hbase/meta/1588230740, deployed =>  }, ]	
null:	
---- Table 'hbase:meta': overlap groups
There are 0 overlap groups with 0 overlapping regions
Number of live region servers: 3
  p0419.mtv.cloudera.com,41017,1397370264982
  p0419.mtv.cloudera.com,39010,1397370264935
  p0419.mtv.cloudera.com,32877,1397370265023
Number of dead region servers: 0
Master: p0419.mtv.cloudera.com,33001,1397370264247
Number of backup masters: 0
Average load: 2.0
Number of requests: 655
Number of regions: 6
Number of regions in transition: 0
RegionServer: p0419.mtv.cloudera.com,32877,1397370265023 number of regions: 0
RegionServer: p0419.mtv.cloudera.com,39010,1397370264935 number of regions: 0
RegionServer: p0419.mtv.cloudera.com,41017,1397370264982 number of regions: 1
  hbase:meta,,1.1588230740 id: 1 encoded_name: 1588230740 start:  end: 
Number of empty REGIONINFO_QUALIFIER rows in hbase:meta: 0
Number of Tables: 0
Number of Tables in flux: 1
---- Table 'hbase:meta': region split map
:	[ { meta => hbase:meta,,1.1588230740, hdfs => hdfs://localhost:50919/user/jenkins/hbase/data/hbase/meta/1588230740, deployed => p0419.mtv.cloudera.com,41017,1397370264982;hbase:meta,,1.1588230740 }, ]	
null:	
---- Table 'hbase:meta': overlap groups
There are 0 overlap groups with 0 overlapping regions
Summary:
  testQuarantineMissingHFile is okay.
    Number of regions: 0
    Deployed on: 
  hbase:meta is okay.
    Number of regions: 1
    Deployed on:  p0419.mtv.cloudera.com,41017,1397370264982
0 inconsistencies detected.
Status: OK
Standard Error

2014-04-12 23:24:54,802 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: util.TestHBaseFsck#testQuarantineMissingHFile Thread=410, OpenFileDescriptor=691, MaxFileDescriptor=32768, SystemLoadAverage=422, ProcessCount=485, AvailableMemoryMB=3139, ConnectionCount=5
2014-04-12 23:24:54,809 INFO  [RpcServer.handler=0,port=33001] master.HMaster(1748): Client=jenkins//172.29.122.11 create 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2014-04-12 23:24:54,886 DEBUG [RpcServer.handler=0,port=33001] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/testQuarantineMissingHFile/write-master:330010000000000
2014-04-12 23:24:54,960 INFO  [MASTER_TABLE_OPERATIONS-p0419:33001-0] handler.CreateTableHandler(148): Create table testQuarantineMissingHFile
2014-04-12 23:24:55,060 INFO  [IPC Server handler 6 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,061 INFO  [IPC Server handler 3 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,062 INFO  [IPC Server handler 5 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741867_1043 size 305
2014-04-12 23:24:55,185 DEBUG [MASTER_TABLE_OPERATIONS-p0419:33001-0] util.FSTableDescriptors(640): Wrote descriptor into: hdfs://localhost:50919/user/jenkins/hbase/.tmp/data/default/testQuarantineMissingHFile/.tabledesc/.tableinfo.0000000001
2014-04-12 23:24:55,188 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(3969): creating HRegion testQuarantineMissingHFile HTD == 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://localhost:50919/user/jenkins/hbase/.tmp Table name == testQuarantineMissingHFile
2014-04-12 23:24:55,188 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(3969): creating HRegion testQuarantineMissingHFile HTD == 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://localhost:50919/user/jenkins/hbase/.tmp Table name == testQuarantineMissingHFile
2014-04-12 23:24:55,188 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(3969): creating HRegion testQuarantineMissingHFile HTD == 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://localhost:50919/user/jenkins/hbase/.tmp Table name == testQuarantineMissingHFile
2014-04-12 23:24:55,188 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(3969): creating HRegion testQuarantineMissingHFile HTD == 'testQuarantineMissingHFile', {NAME => 'fam', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://localhost:50919/user/jenkins/hbase/.tmp Table name == testQuarantineMissingHFile
2014-04-12 23:24:55,378 INFO  [IPC Server handler 2 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,379 INFO  [IPC Server handler 0 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,379 INFO  [IPC Server handler 1 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,386 INFO  [IPC Server handler 9 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,387 INFO  [IPC Server handler 2 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,388 INFO  [IPC Server handler 1 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741868_1044 size 61
2014-04-12 23:24:55,410 INFO  [IPC Server handler 9 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,410 INFO  [IPC Server handler 2 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-80866ac4-36df-41f3-a856-da7636fa89a3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-45b6fa92-7966-4203-8e5a-f8115f53e1ae:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-34a4a47f-8a95-461c-8633-2a7fd583b8d9:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,411 INFO  [IPC Server handler 4 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741871_1047 size 61
2014-04-12 23:24:55,418 INFO  [IPC Server handler 8 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53997 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,418 INFO  [IPC Server handler 9 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33353 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-0cf6df80-0db5-43f5-bbc4-a7092d736c08:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b2725947-b15b-4c3a-be84-aedc2a57e25f:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a192707c-27de-4afa-9948-d58a0f0df6bf:NORMAL|RBW]]} size 0
2014-04-12 23:24:55,419 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,419 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(988): Closing testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.: disabling compactions & flushes
2014-04-12 23:24:55,419 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(1010): Updates disabled for region testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,419 INFO  [IPC Server handler 4 on 50919] blockmanagement.BlockManager(2339): BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49422 is added to blk_1073741870_1046 size 60
2014-04-12 23:24:55,419 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-3] regionserver.HRegion(1068): Closed testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,458 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.
2014-04-12 23:24:55,458 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,459 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(988): Closing testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.: disabling compactions & flushes
2014-04-12 23:24:55,459 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(988): Closing testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.: disabling compactions & flushes
2014-04-12 23:24:55,459 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(1010): Updates disabled for region testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.
2014-04-12 23:24:55,459 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(1010): Updates disabled for region testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,459 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-1] regionserver.HRegion(1068): Closed testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.
2014-04-12 23:24:55,459 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-2] regionserver.HRegion(1068): Closed testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,460 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.
2014-04-12 23:24:55,461 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(988): Closing testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.: disabling compactions & flushes
2014-04-12 23:24:55,461 DEBUG [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(1010): Updates disabled for region testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.
2014-04-12 23:24:55,461 INFO  [RegionOpenAndInitThread-testQuarantineMissingHFile-4] regionserver.HRegion(1068): Closed testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.
2014-04-12 23:24:55,502 INFO  [MASTER_TABLE_OPERATIONS-p0419:33001-0] catalog.MetaEditor(278): Added 4
2014-04-12 23:24:55,503 INFO  [MASTER_TABLE_OPERATIONS-p0419:33001-0] master.AssignmentManager(2506): Bulk assigning 4 region(s) across 3 server(s), round-robin=true
2014-04-12 23:24:55,503 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] master.AssignmentManager(1451): Assigning 1 region(s) to p0419.mtv.cloudera.com,32877,1397370265023
2014-04-12 23:24:55,503 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] master.AssignmentManager(1451): Assigning 1 region(s) to p0419.mtv.cloudera.com,39010,1397370264935
2014-04-12 23:24:55,503 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.AssignmentManager(1451): Assigning 2 region(s) to p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,504 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] zookeeper.ZKAssign(175): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Async create of unassigned node a8a68d998d21b00499aca60887ae5aef with OFFLINE state
2014-04-12 23:24:55,504 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] zookeeper.ZKAssign(175): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Async create of unassigned node d383980be98665b638fd56bfac97a351 with OFFLINE state
2014-04-12 23:24:55,503 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] zookeeper.ZKAssign(175): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Async create of unassigned node 63cdcba1fc55ae6463463ae16f4e454e with OFFLINE state
2014-04-12 23:24:55,503 DEBUG [MASTER_TABLE_OPERATIONS-p0419:33001-0] master.GeneralBulkAssigner(177): Timeout-on-RIT=152000
2014-04-12 23:24:55,504 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] zookeeper.ZKAssign(175): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Async create of unassigned node f9c185520bca999a753ee3ce0a244f6d with OFFLINE state
2014-04-12 23:24:55,510 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(310): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2014-04-12 23:24:55,510 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback(69): rs={a8a68d998d21b00499aca60887ae5aef state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,39010,1397370264935
2014-04-12 23:24:55,511 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback(69): rs={d383980be98665b638fd56bfac97a351 state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,518 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback(69): rs={63cdcba1fc55ae6463463ae16f4e454e state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,32877,1397370265023
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback(69): rs={f9c185520bca999a753ee3ce0a244f6d state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback$ExistCallback(106): rs={a8a68d998d21b00499aca60887ae5aef state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,39010,1397370264935
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback$ExistCallback(106): rs={d383980be98665b638fd56bfac97a351 state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,519 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] master.AssignmentManager(1502): p0419.mtv.cloudera.com,39010,1397370264935 unassigned znodes=1 of total=1
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback$ExistCallback(106): rs={63cdcba1fc55ae6463463ae16f4e454e state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,32877,1397370265023
2014-04-12 23:24:55,519 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] master.RegionStates(316): Transitioned {a8a68d998d21b00499aca60887ae5aef state=OFFLINE, ts=1397370295504, server=null} to {a8a68d998d21b00499aca60887ae5aef state=PENDING_OPEN, ts=1397370295519, server=p0419.mtv.cloudera.com,39010,1397370264935}
2014-04-12 23:24:55,519 DEBUG [pool-1-thread-1-EventThread] master.OfflineCallback$ExistCallback(106): rs={f9c185520bca999a753ee3ce0a244f6d state=OFFLINE, ts=1397370295502, server=null}, server=p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,519 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] master.AssignmentManager(1502): p0419.mtv.cloudera.com,32877,1397370265023 unassigned znodes=1 of total=1
2014-04-12 23:24:55,520 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.AssignmentManager(1502): p0419.mtv.cloudera.com,41017,1397370264982 unassigned znodes=2 of total=2
2014-04-12 23:24:55,520 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] master.RegionStates(316): Transitioned {63cdcba1fc55ae6463463ae16f4e454e state=OFFLINE, ts=1397370295503, server=null} to {63cdcba1fc55ae6463463ae16f4e454e state=PENDING_OPEN, ts=1397370295520, server=p0419.mtv.cloudera.com,32877,1397370265023}
2014-04-12 23:24:55,520 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.RegionStates(316): Transitioned {d383980be98665b638fd56bfac97a351 state=OFFLINE, ts=1397370295504, server=null} to {d383980be98665b638fd56bfac97a351 state=PENDING_OPEN, ts=1397370295520, server=p0419.mtv.cloudera.com,41017,1397370264982}
2014-04-12 23:24:55,520 INFO  [Priority.RpcServer.handler=1,port=39010] regionserver.HRegionServer(3513): Open testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,520 INFO  [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.RegionStates(316): Transitioned {f9c185520bca999a753ee3ce0a244f6d state=OFFLINE, ts=1397370295504, server=null} to {f9c185520bca999a753ee3ce0a244f6d state=PENDING_OPEN, ts=1397370295520, server=p0419.mtv.cloudera.com,41017,1397370264982}
2014-04-12 23:24:55,521 INFO  [Priority.RpcServer.handler=1,port=32877] regionserver.HRegionServer(3513): Open testQuarantineMissingHFile,,1397370294808.63cdcba1fc55ae6463463ae16f4e454e.
2014-04-12 23:24:55,521 INFO  [Priority.RpcServer.handler=1,port=41017] regionserver.HRegionServer(3513): Open testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,525 DEBUG [RS_OPEN_REGION-p0419:39010-1] zookeeper.ZKAssign(832): regionserver:39010-0x14559c215740001, quorum=localhost:53570, baseZNode=/hbase Transitioning a8a68d998d21b00499aca60887ae5aef from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,526 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-1] master.AssignmentManager(1626): Bulk assigning done for p0419.mtv.cloudera.com,39010,1397370264935
2014-04-12 23:24:55,526 DEBUG [RS_OPEN_REGION-p0419:41017-0] zookeeper.ZKAssign(832): regionserver:41017-0x14559c215740002, quorum=localhost:53570, baseZNode=/hbase Transitioning d383980be98665b638fd56bfac97a351 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,526 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-0] master.AssignmentManager(1626): Bulk assigning done for p0419.mtv.cloudera.com,32877,1397370265023
2014-04-12 23:24:55,526 INFO  [Priority.RpcServer.handler=1,port=41017] regionserver.HRegionServer(3513): Open testQuarantineMissingHFile,C,1397370294808.f9c185520bca999a753ee3ce0a244f6d.
2014-04-12 23:24:55,526 DEBUG [RS_OPEN_REGION-p0419:32877-0] zookeeper.ZKAssign(832): regionserver:32877-0x14559c215740003, quorum=localhost:53570, baseZNode=/hbase Transitioning 63cdcba1fc55ae6463463ae16f4e454e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,527 DEBUG [RS_OPEN_REGION-p0419:41017-2] zookeeper.ZKAssign(832): regionserver:41017-0x14559c215740002, quorum=localhost:53570, baseZNode=/hbase Transitioning f9c185520bca999a753ee3ce0a244f6d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,527 DEBUG [p0419.mtv.cloudera.com,33001,1397370264247-GeneralBulkAssigner-2] master.AssignmentManager(1626): Bulk assigning done for p0419.mtv.cloudera.com,41017,1397370264982
2014-04-12 23:24:55,527 DEBUG [MASTER_TABLE_OPERATIONS-p0419:33001-0] master.GeneralBulkAssigner(153): bulk assigning total 4 regions to 3 servers, took 23ms, with 4 regions still in transition
2014-04-12 23:24:55,527 INFO  [MASTER_TABLE_OPERATIONS-p0419:33001-0] master.AssignmentManager(2513): Bulk assigning done
2014-04-12 23:24:55,535 DEBUG [RS_OPEN_REGION-p0419:39010-1] zookeeper.ZKAssign(907): regionserver:39010-0x14559c215740001, quorum=localhost:53570, baseZNode=/hbase Transitioned node a8a68d998d21b00499aca60887ae5aef from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,535 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(310): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/a8a68d998d21b00499aca60887ae5aef
2014-04-12 23:24:55,536 DEBUG [RS_OPEN_REGION-p0419:39010-1] regionserver.HRegion(4153): Opening region: {ENCODED => a8a68d998d21b00499aca60887ae5aef, NAME => 'testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.', STARTKEY => 'A', ENDKEY => 'B'}
2014-04-12 23:24:55,536 DEBUG [RS_OPEN_REGION-p0419:39010-1] regionserver.MetricsRegionSourceImpl(64): Creating new MetricsRegionSourceImpl for table testQuarantineMissingHFile a8a68d998d21b00499aca60887ae5aef
2014-04-12 23:24:55,536 DEBUG [RS_OPEN_REGION-p0419:39010-1] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,A,1397370294808.a8a68d998d21b00499aca60887ae5aef.
2014-04-12 23:24:55,577 DEBUG [pool-1-thread-1-EventThread] zookeeper.ZooKeeperWatcher(310): master:33001-0x14559c215740000, quorum=localhost:53570, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/d383980be98665b638fd56bfac97a351
2014-04-12 23:24:55,577 DEBUG [RS_OPEN_REGION-p0419:41017-0] zookeeper.ZKAssign(907): regionserver:41017-0x14559c215740002, quorum=localhost:53570, baseZNode=/hbase Transitioned node d383980be98665b638fd56bfac97a351 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-04-12 23:24:55,578 DEBUG [RS_OPEN_REGION-p0419:41017-0] regionserver.HRegion(4153): Opening region: {ENCODED => d383980be98665b638fd56bfac97a351, NAME => 'testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.', STARTKEY => 'B', ENDKEY => 'C'}
2014-04-12 23:24:55,578 DEBUG [RS_OPEN_REGION-p0419:41017-0] regionserver.MetricsRegionSourceImpl(64): Creating new MetricsRegionSourceImpl for table testQuarantineMissingHFile d383980be98665b638fd56bfac97a351
2014-04-12 23:24:55,579 DEBUG [RS_OPEN_REGION-p0419:41017-0] regionserver.HRegion(542): Instantiated testQuarantineMissingHFile,B,1397370294808.d383980be98665b638fd56bfac97a351.
2014-04-12 23:24:55,594 INFO  [StoreOpener-a8a68d998d21b00499aca60887ae5aef-1] compactions.CompactionConfiguration(85): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2014-04-12 23:24:55,598 DEBUG [RS_OPEN_REGION-p0419:39010-1] regionserver.HRegion(2822): Found 0 recovered edits file(s) under hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/a8a68d998d21b00499aca60887ae5aef
2014-04-12 23:24:55,600 INFO  [RS_OPEN_REGION-p0419:39010-1] regionserver.HRegion(637): Onlined a8a68d998d21b00499aca60887ae5aef; next sequenceid=1
2014-04-12 23:24:55,600 DEBUG [RS_OPEN_REGION-p0419:39010-1] zookeeper.ZKAssign(644): regionserver:39010-0x14559c215740001, quorum=localhost:53570, baseZNode=/hbase Attempting to retransition opening state of node a8a68d998d21b00499aca60887ae5aef
2014-04-12 23:24:55,644 INFO  [StoreOpener-d383980be98665b638fd56bfac97a351-1] compactions.CompactionConfiguration(85): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2014-04-12 23:24:55,648 DEBUG [RS_OPEN_REGION-p0419:41017-0] regionserver.HRegion(2822): Found 0 recovered edits file(s) under hdfs://localhost:50919/user/jenkins/hbase/data/default/testQuarantineMissingHFile/d383980be98665b638fd56bfac97a351
2014-04-12 23:24:55,650 INFO  [RS_OPEN_REGION-p0419:41017-0] regionserver.HRegion(637): Onlined d383980be98665b638fd56bfac97a351; next sequenceid=1
2014-04-12 23:24:55,650 DEBUG [RS_OPEN_REGION-p0419:41017-",,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11829,"Test fails with an exception:
java.lang.Exception: Unexpected exception, expected<org.apache.hadoop.hbase.regionserver.RegionServerStoppedException> but was<junit.framework.AssertionFailedError>
	at org.junit.internal.runners.statements.ExpectException.evaluate(ExpectException.java:28)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)

Note: the failure usually reproduces on the machines where openvpn is installed. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21037,"In certain cases, hbck issues a RS.closeRegion() to close a region from RS. It does not clean up in-memory state from master for the offlined region and balancer will bring back the closed region, causing region inconsistency. certain codes needs to be reexamined to see a Master.offlineRegion() is needed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11653,"Due to a bug in {{HRegion.internalPut()}}, any modifications that a {{RegionObserver}} makes to a Put's family map in the {{prePut()}} hook are lost.

This prevents coprocessors from modifying the values written by a {{Put}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19466,"I think we just need to increase the timeout interval to deal with occasional slowdowns on test executors. 1998 ms is a pretty short timeout.

By the way ""rpcTimetout"" in the exception message is a misspelling.

[ERROR] Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 37.412 s <<< FAILURE! - in org.apache.hadoop.hbase.regionserver.TestScannerCursor
[ERROR] testHeartbeatWithSparseFilter(org.apache.hadoop.hbase.regionserver.TestScannerCursor)  Time elapsed: 35.604 s  <<< ERROR!
org.apache.hadoop.hbase.client.RetriesExhaustedException: 
Failed after attempts=36, exceptions:
Thu Dec 07 22:27:16 UTC 2017, null, java.net.SocketTimeoutException: callTimeout=4000, callDuration=4108: Call to ip-172-31-47-35.us-west-2.compute.internal/172.31.47.35:35690 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=52, waitTime=2002, rpcTimetout=1998 row '' on table 'TestScannerCursor' at region=TestScannerCursor,,1512685598567.1d4e59215a881d6ccbd0b5b5bdec5587., hostname=ip-172-31-47-35.us-west-2.compute.internal,35690,1512685593244, seqNum=2

        at org.apache.hadoop.hbase.regionserver.TestScannerCursor.testHeartbeatWithSparseFilter(TestScannerCursor.java:154)
Caused by: java.net.SocketTimeoutException: callTimeout=4000, callDuration=4108: Call to ip-172-31-47-35.us-west-2.compute.internal/172.31.47.35:35690 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=52, waitTime=2002, rpcTimetout=1998 row '' on table 'TestScannerCursor' at region=TestScannerCursor,,1512685598567.1d4e59215a881d6ccbd0b5b5bdec5587., hostname=ip-172-31-47-35.us-west-2.compute.internal,35690,1512685593244, seqNum=2
Caused by: java.io.IOException: Call to ip-172-31-47-35.us-west-2.compute.internal/172.31.47.35:35690 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=52, waitTime=2002, rpcTimetout=1998
Caused by: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=52, waitTime=2002, rpcTimetout=1998
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18100,"https://builds.apache.org/job/HBASE-Flaky-Tests/lastCompletedBuild/testReport/org.apache.hadoop.hbase.client/TestBlockEvictionFromClient/testBlockRefCountAfterSplits/
{code}
java.lang.AssertionError: expected:<0> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.iterateBlockCache(TestBlockEvictionFromClient.java:1215)
	at org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.testBlockRefCountAfterSplits(TestBlockEvictionFromClient.java:607)
{code}
The test failed on May 16th as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19854,"Many a times, users want to have an offline copy of Ref Guide.聽 Some people prefer to save HTML, and some people prefer it in PDF format.聽 Hence, Apache HBase team generates PDF version of document periodically and keeps it available at: [https://hbase.apache.org/apache_hbase_reference_guide.pdf]

It would be good if a link to this URL is available in the online guide so that users would become aware that there is a PDF version.聽 Right now, unless some one explicitly looks for it using Google/Bing search, they would not know.

聽

As the PDF URL is fixed for latest documentation, it can be a static href.聽 However, I don't have any clues about how to make sure to get ""version-relevant"" PDF link for archived ref guides.

聽",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19662,"In recent trunk builds, there were the following errors:
{code}
[ERROR] src/main/java/org/apache/hadoop/hbase/metrics/MetricRegistriesLoader.java:[31] (imports) ImportOrder: Wrong order for 'org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting' import.
[ERROR] src/test/java/org/apache/hadoop/hbase/metrics/TestMetricRegistriesLoader.java:[28] (imports) ImportOrder: Wrong order for 'org.apache.hbase.thirdparty.com.google.common.collect.Lists' import.
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18858,"{code}
  public static void tearDownAfterClass() throws Exception {
    htable2.close();
    htable1.close();
    admin.close();
    utility2.shutdownMiniCluster();
    utility1.shutdownMiniCluster();
  }
{code}
If the setUpBeforeClass() fail, some members will be NULL. We need to ensures all resources are closed at the end of tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19161,"For system tables, if config 'hbase.systemtables.compacting.memstore.type' is not specified then code default 'NONE' is used which causes instantiation of DefaultMemStore class. That means for everyone to use  CompactingMemStore they need to specify this config value. Reversing it will help i.e. if user explicitly specifies 'hbase.systemtables.compacting.memstore.type' to 'NONE' then only DefaultMemStore class is used.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-19517,"When running test against hadoop-3, I observe the following:
{code}
org.apache.hadoop.hbase.zookeeper.TestZKMulti  Time elapsed: 1.327 sec  <<< ERROR!
java.lang.RuntimeException: Could not create  interface org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource Is the hadoop compatibility jar on the classpath?
	at org.apache.hadoop.hbase.zookeeper.TestZKMulti.setUpBeforeClass(TestZKMulti.java:71)
Caused by: java.util.ServiceConfigurationError: org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSource: Provider org.apache.hadoop.hbase.zookeeper.MetricsZooKeeperSourceImpl could not be instantiated
	at org.apache.hadoop.hbase.zookeeper.TestZKMulti.setUpBeforeClass(TestZKMulti.java:71)
Caused by: java.lang.NoClassDefFoundError: org/apache/commons/beanutils/DynaBean
	at org.apache.hadoop.hbase.zookeeper.TestZKMulti.setUpBeforeClass(TestZKMulti.java:71)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.beanutils.DynaBean
	at org.apache.hadoop.hbase.zookeeper.TestZKMulti.setUpBeforeClass(TestZKMulti.java:71)
{code}
I used hadoop-3.0 profile",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18841,"If I run the below out of a built checkout, it fails unable to find the main in named LoadTestTool class:

./bin/hbase ltt

Ditto for:

./bin/hbase pe

The main classes are in *-test.jars which we do not include in our cached_classpath.txt file that is our trick for making stuff work in dev context.

Investigate.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14242,"Flaked tests: 
org.apache.hadoop.hbase.security.access.TestAccessController.testMergeRegions(org.apache.hadoop.hbase.security.access.TestAccessController)
  Run 1: TestAccessController.testMergeRegions:687->SecureTestUtil.verifyAllowed:176->SecureTestUtil.verifyAllowed:168 Expected action to pass for user 'owner' but was denied
  Run 2: PASS

{noformat}
java.lang.AssertionError: Expected action to pass for user 'owner' but was denied
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hbase.security.access.SecureTestUtil.verifyAllowed(SecureTestUtil.java:168)
	at org.apache.hadoop.hbase.security.access.SecureTestUtil.verifyAllowed(SecureTestUtil.java:176)
	at org.apache.hadoop.hbase.security.access.TestAccessController.testMergeRegions(TestAccessController.java:687)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16137,"From stack:

""Lads. This patch makes for a new findbugs warning: https://builds.apache.org/job/PreCommit-HBASE-Build/2390/artifact/patchprocess/branch-findbugs-hbase-server-warnings.html
If you are good w/ the code, i can fix the findbugs warning... just say.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13944,"When using any DBE other than Prefix_Tree when the internal scanners seek to a key greater than the last key in the file, when we do scanner.getKeyValue() we get the last key in the file, whereas PrefixTree seeks to null.  This is a behaviour change.  May be in the actual scan case we may not end up in this scenario, need to check with a testcase.  But the test in TestSeekTo.testSeekTo() has a clear illustration of this problem. 
Will take this up after the current activities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4738,"Ambiguous invocations of varargs methods with non-varargs arguments relied on the compiler to implicitly cast the arguments to Object[]. Some compilers apparently do not make this implicit cast, but instead wrap the arguments in another Object[] causing them to be interpreted incorrectly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8249,"Provide a Context object for all the HBase API call, which contains the Row, CF, Region, RegionServer, RetryNumbers and LastPotentialExceptions",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7903,Need to add configuration support for large rows/ scan prefetching for the hadoop hbase streaming. Modifications are in the TableInputFormat,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7732,"we found a bug in the latest HBase code which ""hfile.io.bytes.per.checksum"" does not take effect. Because we have never call HFile.getBytesPerChecksum()  when creating a HFile.

Fix this issue by calling the correct bytes/checksum (from HFile.getBytesPerChecksum) for HFile creating ?
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8467,"Add an API to blacklist a region server. The master should not assign any new regions to the blacklisted region server. This will help in Rolling Restart of HBase, where one can blacklist a regionserver, drain all the regions(which should be fast), restart the regionserver, assign the regions backs and then remove the region server from the blacklist",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8223,"The RegionServer was performing a shutdown as it got YouAreDeadException. It closed the HLog and was waiting to close all the regions where it got stuck.

The reason region close is stuck because it's trying to obtain a lock which is occupied by the put op, which in turn is waiting for append to HLog to complete.

There is race condition here is between append/sync and HLog.close() work flow. 

Scenario:

Thread 1 => doing the append
Thread 2 => doing HregionServer shutdown

Timeline:

t1> 1: Verifies that LogSyncer is not shutting down and HLog is not closed and calls sync()
t2> 2: HRegionServer issued HLog.close()
t3> 2: In HLog.close(), it joins the LogSyncer thread, which signals all the threads waiting on syncDone and exits.
t4> 1: In sync, it sees that the sync has not complete until its txd, hence adds itself to the syncDone.await queue.

Note: at t4, it does not check whether the LogSyncer Thread is alive or not, which caused this hang.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8371,"RegionException was derived from IOError to capture the backoff timeout,
information required by the thrift clients to reduce the load on the
overloaded region servers. The exception was derived from IOError to
make it compatible with thrift. When this change was ported to neptune,
it created a new dependency on the thrift package.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13627,"Noticed while testing the 1.1.0RC0 bits. It seems we're issuing a redundant close RPC during shutdown. This results in a logging warning for each region.

{noformat}
2015-05-06 00:07:19,214 INFO  [RS:0;ndimiduk-apache-1-1-dist-6:56371] regionserver.HRegionServer: Received CLOSE for the region: 19cbe4fe2fe5335e7aace05e10e36ede, which we are already trying to CLOSE, but not completed yet
2015-05-06 00:07:19,214 WARN  [RS:0;ndimiduk-apache-1-1-dist-6:56371] regionserver.HRegionServer: Failed to close cluster_test,66666666,1430869443384.19cbe4fe2fe5335e7aace05e10e36ede. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 19cbe4fe2fe5335e7aace05e10e36ede was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2769)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2695)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2327)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:937)
	at java.lang.Thread.run(Thread.java:745)
{noformat}

1. launch a standalone cluster from tgz (./bin/start-hbase.sh)
2. load some data (ie, run bin/hbase ltt)
3. terminate cluster (./bin/stop-hbase.sh)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9764,"In PerformanceEvaluation, htable AutoFlush option is hardcoded as false

{code:title=PerformanceEvaluation.java|borderStyle=solid}

    void testSetup() throws IOException {
      this.admin = new HBaseAdmin(conf);
      this.table = new HTable(conf, tableName);
      this.table.setAutoFlush(false);
      this.table.setScannerCaching(30);
    }
{code}
This makes the write performace unreal. 

Should we add an autoflush option in PerformanceEvaluation?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10540,"{code}
public void createTable(final HTableDescriptor desc, byte [][] splitKeys)
  throws IOException {
    HTableDescriptor.isLegalTableName(desc.getName());
    try {
      createTableAsync(desc, splitKeys);
    } catch (SocketTimeoutException ste) {
      LOG.warn(""Creating "" + desc.getNameAsString() + "" took too long"", ste);
    }
{code}
crateTable calls isLegalTableName and few lines after, createTableAsync. However, createTableAsync also calls isLegalTableName which results to a double call.

Therefor, we can remove the call to isLegalTableName from crateTable.
Trunk does'nt call isLegalTableName (Should it?).  Nor is 0.96.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7456,"Please allow the Configuration to override the hard-coded maxSize of 10 for its HTablePool.  Under high loads, 10 is too small.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10145,"HBASE-7600 fixed a race condition where concurrent attempts to create the same table could succeed.
An unfortunate side effect is that it is now impossible to create a table as long as the table's znode is around, which is an issue when a cluster was wiped at the HDFS level.

Minor issue as we have discussed this many times before, but it ought to be possible to check whether the table directory exists and if not either create it or remove the corresponding znode.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14609,"The offpeak hours is [startHour, endHour) and endhour is exclusive. But endHour is not valid when config as 24, so we can't config all day as OffPeakHours.
{code}
  private static boolean isValidHour(int hour) {
    return 0 <= hour && hour <= 23; 
  }
{code}
Let endHour=24 is valid or  enable startHour==endHour can fix this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16295,"The column family exists and is actually deleted, the regions are also reopened. But, the following exception is thrown in the shell:

{code}
alter 't1', 'delete' => 'cf'

ERROR: org.apache.hadoop.hbase.InvalidFamilyOperationException: Family 'cf' does not exist, so it cannot be deleted
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)
	at org.apache.hadoop.hbase.util.ForeignExceptionUtil.toIOException(ForeignExceptionUtil.java:45)
	at org.apache.hadoop.hbase.procedure2.RemoteProcedureException.fromProto(RemoteProcedureException.java:114)
	at org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.waitForProcedureToComplete(ProcedureSyncWait.java:85)
	at org.apache.hadoop.hbase.master.HMaster.deleteColumn(HMaster.java:1916)
	at org.apache.hadoop.hbase.master.MasterRpcServices.deleteColumn(MasterRpcServices.java:474)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:55658)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2170)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:137)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:112)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hbase.InvalidFamilyOperationException): Family 'cf' does not exist, so it cannot be deleted
	at org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.prepareDelete(DeleteColumnFamilyProcedure.java:281)
	at org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.executeFromState(DeleteColumnFamilyProcedure.java:93)
	at org.apache.hadoop.hbase.master.procedure.DeleteColumnFamilyProcedure.executeFromState(DeleteColumnFamilyProcedure.java:48)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:119)
	at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:465)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1061)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:856)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:809)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$400(ProcedureExecutor.java:75)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$2.run(ProcedureExecutor.java:495)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6675,"On trunk, as of today:

Running org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 652.393 sec

Target beeing less than 3 minutes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5024,"There is no cleanup function in hbase.io.hfile.CacheConfig. The cache is a singleton, shared by all cluster if we launch more than one cluster on a test.

Related code is:

{noformat}
  /**
   * Static reference to the block cache, or null if no caching should be used
   * at all.
   */
  private static BlockCache globalBlockCache;

  /** Boolean whether we have disabled the block cache entirely. */
  private static boolean blockCacheDisabled = false;

  /**
   * Returns the block cache or <code>null</code> in case none should be used.
   *
   * @param conf  The current configuration.
   * @return The block cache or <code>null</code>.
   */
  private static synchronized BlockCache instantiateBlockCache(){
     // initiate globalBlockCache
{noformat}


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4947,"Using CopyTable with two clusters, test01 and test02.

cluster cluster01 has a table called 'table' which has a little bit of data in it.
cluster cluster02 has a table called 'table2' which have the same schema as cluster01's 'table'

Here's the command line used from a machine in cluster01
{code}
$ hbase org.apache.hadoop.hbase.mapreduce.CopyTable --peer.adr=cluster02:2181:/hbase --new.name=table2 table
{code}

Job succeeds, but gives a scary extraneous warning:
{code}
11/12/04 10:26:10 WARN client.HConnectionManager$HConnectionImplementation: Encountered problems when prefetch META table:
org.apache.hadoop.hbase.TableNotFoundException: Cannot find row in .META. for table: table2, row=table2,,99999999999999
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:136)
        at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:95)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:649)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:703)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:594)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:559)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:173)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:147)
        at org.apache.hadoop.hbase.mapreduce.TableOutputFormat.setConf(TableOutputFormat.java:198)
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:869)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:833)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Unknown Source)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1127)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:833)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:476)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:506)
        at org.apache.hadoop.hbase.mapreduce.CopyTable.main(CopyTable.java:201)
11/12/04 10:26:10 ERROR mapreduce.TableOutputFormat: org.apache.hadoop.hbase.TableNotFoundException: table2
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14276,"If an insecure client contacts a secure cluster we can get an NPE when setting up the stub for the master connection. We should throw an IOException with a clear message, and not retry if possible to distinguish this case.

Found in 0.98 but might be relevant for later branches

{noformat}
Aug 20, 2015 12:04:31 AM org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper <init>
INFO: Process identifier=hconnection-0x3c1e23ff connecting to ZooKeeper ensemble=x.x.x.x:2181,x.x.x.x:2181,x.x.x.x:2181
Aug 20, 2015 12:04:31 AM org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation makeStub
INFO: getMaster attempt 1 of 35 failed; retrying after sleep of 100, exception=com.google.protobuf.ServiceException: java.lang.NullPointerException
Aug 20, 2015 12:04:31 AM org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation makeStub
INFO: getMaster attempt 2 of 35 failed; retrying after sleep of 200, exception=com.google.protobuf.ServiceException: java.io.IOException: Call to xxxx/x.x.x.x:60000 failed on local exception: java.io.EOFException
Aug 20, 2015 12:04:31 AM org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation makeStub
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14792,"For releasing 0.98 we typically copy back the latest docs from master and then build.

When I try generating the latest docs, I get:
{noformat}
[INFO] >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[INFO] Forking Apache HBase - Assembly 0.98.16-hadoop2
[INFO] >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[INFO] 
[INFO] --- maven-enforcer-plugin:1.0.1:enforce (enforce) @ hbase-assembly ---
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.3:create-timestamp (default) @ hbase-assembly ---
[INFO] 
[INFO] <<< maven-javadoc-plugin:2.9.1:aggregate (report:aggregate) < generate-sources @ hbase <<<
[INFO] configuring report plugin org.apache.maven.plugins:maven-checkstyle-plugin:2.13
[INFO] Parent project loaded from repository: org.apache:apache:pom:12
[INFO] Relativizing decoration links with respect to project URL: http://hbase.apache.org
[INFO] Rendering site with org.apache.maven.skins:maven-fluido-skin:jar:1.4 skin.
[INFO] Skipped ""About"" report, file ""index.html"" already exists for the English version.
[INFO] Skipped ""Source Xref"" report, file ""xref/index.html"" already exists for the English version.
[INFO] Skipped ""Test Source Xref"" report, file ""xref-test/index.html"" already exists for the English version.
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.3:site (default-site) on project hbase: Error during page generation: Could not find the template 'META-INF/maven/site.vm: Encountered ""source"" at META-INF/maven/site.vm[line 1162, column 52]
[ERROR] Was expecting one of:
[ERROR] "","" ...
[ERROR] "")"" ...
[ERROR] <WHITESPACE> ...
{noformat}

Do I need to make POM updates?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11441,"jenkinsEnv paths are off.

We moved to jdk1.7 for master branch.  Though we'd set hadoopqa to run with java 1.7, the jenkinsEnv overrides what jenkins sets for JAVA_HOME so we've been running 1.6 java over this last couple of months rather than 1.7.

Trying to work around jenkinsEnv settings reveals that there is no 1.7 at the location jenkins goes to find it at (""Latest JDK 7"" option):

{code}
ls: cannot access /home/hudson/tools/java/latest1.7/..: No such file or directory
{code}

Messing w/ the options in the jenkins UI and then putting script in text box to expose paths, almost none of the advertised options are available.

Something changed.

I got a 1.7 working by setting jdk7-u51 explicitly and then setting PATH and JAVA_HOME just before our test script runs (it downloaded it)
{code}
...
ls $JAVA_HOME/..
which java
java -version
echo $JAVA_HOME
saveJavaHome=$JAVA_HOME
$JAVA_HOME/bin/java -version
ulimit -a
set +x
source ${WORKSPACE}/dev-support/jenkinsEnv.sh
export JAVA_HOME=""$saveJavaHome""
export PATH=$JAVA_HOME/bin:$PATH
which java
java -version
echo ""Resetting java_home -- FIX jenkinsEnv.sh!!! $JAVA_HOME""
....
{code}

HBase builds on hadoop1||hadoop2||hadoop3||hadoop8

I ain't sure how this stuff is supposed to be set.  Asking Andrew Bayer on our end (He said 'credits' needed refresh last night but that doesn't seem to have helped here).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12855,"IntegrationTestsDriver gets unhappy if you pass in ChaosMonkey options via -m:
{code}
sudo -u hbase hbase org.apache.hadoop.hbase.IntegrationTestsDriver -r 'IntegrationTestIngest$' -m calm
15/01/14 06:44:06 ERROR util.AbstractHBaseTool: Error when parsing command-line arguemnts
org.apache.commons.cli.UnrecognizedOptionException: Unrecognized option: -m
	at org.apache.commons.cli.Parser.processOption(Parser.java:363)
	at org.apache.commons.cli.Parser.parse(Parser.java:199)
	at org.apache.commons.cli.Parser.parse(Parser.java:85)
	at org.apache.hadoop.hbase.util.AbstractHBaseTool.parseArgs(AbstractHBaseTool.java:135)
	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:94)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.hbase.IntegrationTestsDriver.main(IntegrationTestsDriver.java:46)
usage: bin/hbase org.apache.hadoop.hbase.IntegrationTestsDriver <options>
Options:
 -h,--help          Show usage
 -r,--regex <arg>   Java regex to use selecting tests to run: e.g. .*TestBig.*
                    will select all tests that include TestBig in their name.
                    Default: .*IntegrationTest.*
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7010,"Currently a PrefixFilter will happily scan all KVs < prefix.
If should seek forward to the prefix if the current KV < prefix.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9876,"The main benefit brought by HBASE-4285 was removing the dependency on a symlink. Instead, it sets the partitions file path explicitly. Would be nice to have on 0.94.

(cc [~alexandre.normand])",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15790,"When a user different than ""hbase"" bulkload files, in general we end up with files owned by a user different than hbase. sometimes this causes problems with hbase not be able to move files around archiving/deleting.

A simple solution is probably to change the ownership of the files to ""hbase"" during bulkload.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14279,"{{ConcurrentIndex.put}} and {{remove}} are in race condition. It is possible to remove a non-empty set, and to add a value to a removed set. Also {{ConcurrentIndex.values}} is vague in sense that the returned set sometimes trace the current state and sometimes doesn't.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12733,"When ingesting with the WAL bypassed, the RegionServer will log the following at every flush:
{noformat}
2014-12-19 16:58:24,630 WARN  [MemStoreFlusher.0] wal.FSHLog: Couldn't find oldest seqNum for the region we are about to flush: [86fc8c1374ebc29cc4a39a78966d48e0]
{noformat}

The WAL won't find a seqnum for the region until the first edit which does not bypass the WAL. That might not be for hundreds or thousands of flushes. This shouldn't be at WARN level since ingest with WAL bypass is legal if a bit unusual. It's concerning that the FSHLog code that emits that warning has a TODO above suggesting the warning should instead be an assertion.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11299,"Our javadoc generation is taking a long time.  Also, when we go to update our site, the javadoc changes are so many -- the date has changed on generated doc -- that it takes for ever to commit (it is frighteningly long and noobs can only think they've done something wrong).

I have been trying various tricks to get javadoc tool to ignore the generated protobuf classes but am not having much success (it is a background process and the distractions don't help).  Stashing here changes I have so far to the javadoc pom which excludes some of the unneeded files.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10578,"When multiple scanners have the same KV, HBase should pick the ""newest"" one.
i.e. pick the KV from the store file with the largest seq id.

In the KeyValueHeap generalizedSeek implementation, we seem to prefer the ""current""
scanner over the scanners in the heap -- THIS IS WRONG.

The diff adds a unit test to make sure that bulk loads correctly. And fixes the issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11528,"We take a snapshot: ""rollbackSnapshot"" prior to doing a restore such that if the restore fails we can revert the table back to its pre-restore state.  If we are successful in restoring the table, we should delete the ""rollbackSnapshot"" when the restoreSnapshot operation successfully completes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13972,"I was looking at https://builds.apache.org/job/PreCommit-HBASE-Build/14576/console and found that findHangingTests.py didn't report any hanging / failing test.
{code}
Running org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker
Killed
{code}
It turns out that findHangingTests.py didn't distinguish the state for tests that were killed.
Patch coming shortly which allows printing of killed test(s)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5929,"I have been noticing that calls to HBaseAdmin.majorCompact throws exceptions randomly for some regions.  I could not find a pattern to these exception.  The code I have simply does this admin.majorCompact(region.getRegionNameAsString()).  admin is an instance of HBaseAdmin and region is an instance of HRegionInfo.  The exception I get is 

org.apache.hadoop.hbase.TableNotFoundException: -ROOT-,,0
        at org.apache.hadoop.hbase.client.HBaseAdmin.tableNameString(HBaseAdmin.java:1473) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.compact(HBaseAdmin.java:1235) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.majorCompact(HBaseAdmin.java:1209) ~[hbase-0.92.1.jar:0.92.1]
        at com.stumbleupon.hbaseadmin.HBaseCompact.compactAllServers(Unknown Source) [hbase_compact.jar:na]


In this case it's the root region, but I get similar exceptions for other tables, like this.


2012-05-03 19:03:42,994 WARN  [main] HBaseCompact: Could not compact:
org.apache.hadoop.hbase.TableNotFoundException: ad_daily,49842:2009-07-10,1269763588508.1997607018
        at org.apache.hadoop.hbase.client.HBaseAdmin.tableNameString(HBaseAdmin.java:1473) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.compact(HBaseAdmin.java:1235) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.majorCompact(HBaseAdmin.java:1209) ~[hbase-0.92.1.jar:0.92.1]
        at org.apache.hadoop.hbase.client.HBaseAdmin.majorCompact(HBaseAdmin.java:1196) ~[hbase-0.92.1.jar:0.92.1]
        at com.stumbleupon.hbaseadmin.HBaseCompact.compactAllServers(Unknown Source) [hbase_compact.jar:na]
        at com.stumbleupon.hbaseadmin.HBaseCompact.main(Unknown Source) [hbase_compact.jar:na]


I see this on hbase shell as well.  However, I don't see these exceptions if I use admin.majorCompact(region.getRegionName()), so it looks like something gets lost when I use getRegionNameAsString().

Let me know if I can provide more information.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5752,"When creating a new table with the hbase shell, and specifying a SPLITS_FILE with a blank line in it will cause the master to crash.

Uploading a sample splits file, here are the commands to test the split.

create 'testTable', {NAME => 'a', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', MIN_VERSIONS => '3', TTL => '2147483647', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {SPLITS_FILE => '/tmp/test.txt'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5247,"The ColumnPaginationFilter doesn't return the correct number of columns when the limit is less than the total number of columns.  I don't know much about the internals of Hbase, but it appears that the problem is more re-producible when a table is split accross at least 2 regions.  I have created a unit test which can re-produce the issue which is now attached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4543,"major_compact '.META.' has no effect, although major_compact 'any_other_table' works fine from the shell.

This issue seems to only affect 0.89. The apache-trunk seems to handle this case properly.


The issue is that getTableRegions() in HMaster.java only works if the tableName given is a ""normal"" table.
The methodology (using a MetaScanner to look through the .META. table for the tableName) does not work if
the tableName is .META.

The fix modifies getTableRegions() to check if the tableName is .META.; and if so, handle it accordingly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6456,"The command I ran is as below:
""bin/hbase org.apache.hadoop.hbase.mapreduce.Driver export t1 ./t1""

And I got the following exceptions:

attempt_201207261322_0002_m_000000_0, Status : FAILED
Error: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.util.Bytes
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
        at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:150)
        at org.apache.hadoop.hbase.mapreduce.TableInputFormat.setConf(TableInputFormat.java:100)
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:767)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:371)
        at org.apache.hadoop.mapred.Child$4.run(Child.java:266)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.au
...

This exception can be resolved by adding hbase common jar into HADOOP_CLASSPATH. But this is an extra step for users and not so convenient. 

We could add Bytes.class into dependency Jars of the MapReduce job.  

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11336,Show region sizes in table page of master info server,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13220,set_quota command to should throw exception to user when trying to set quota on a non-existing table or namespace same like grant command.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9790,"'Alter' was issued with wrong (negative) max_file_size. At some moment regionservers begin to split regions producing zero size regions. Table won't to delete, even can't disable it.

Solution: stop cluster, delete table from hdfs, use with care  
{{hbase org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12284,"This test seems to be failing occassionaly, like once in 30 times. Maybe the test needs some love ?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6753,"I'm a newbie to HBase.

I implemented a coprocessor which is pretty nice with Cloudera version 4.0.1.


Testing my copressor evolved a problem, because everytime I inserted logging into my prePut-method, the Put object was not stored anymore into HBase.

I analyzed the code and could reduce the problem to the fact, that calling the toString-method on the Put object alone, is the reason for this behaviour.

There seems to be a problem with the serialization of the object.

Serialization seems to modifiy the object with the result, that it is not inserted in HBase anymore.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4567,"When doing a rolling split of existing regions using RegionSplitter, a divide by zero exception occurs.

I'll be posting a junit test soon that reproduces the problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5299,"RSA, RS B and RS C are 3 region servers.
RS A -> META
RS B -> ROOT
RS C -> NON META and NON ROOT

Kill RS B and wait for server shutdown handler to start.  
Start RS B again before assigning ROOT to RS C.
Now the cluster will try to assign new regions to RS B.  
But as ROOT is not yet assigned the OpenRegionHandler.updateMeta will fail to update the regions just because ROOT is not online.
{code}
a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:23:25,126 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Attempting to transition node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:23:25,159 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Successfully transitioned node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:23:35,385 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Attempting to transition node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:23:35,449 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Successfully transitioned node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:24:16,666 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Attempting to transition node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:24:16,701 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x1352e27539c0009 Successfully transitioned node a87109263ed53e67158377a149c5a7be from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING
2012-01-30 16:24:20,788 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Interrupting thread Thread[PostOpenDeployTasks:a87109263ed53e67158377a149c5a7be,5,main]
2012-01-30 16:24:30,699 WARN org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Exception running postOpenDeployTasks; region=a87109263ed53e67158377a149c5a7be
org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException: Interrupted
	at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMetaServerConnectionDefault(CatalogTracker.java:439)
	at org.apache.hadoop.hbase.catalog.MetaEditor.updateRegionLocation(MetaEditor.java:142)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1382)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:221)
{code}

So we need to wait for TM to assign the regions again. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8310,"There are a few timeout values and defaults being used by HBase snapshot.
DEFAULT_MAX_WAIT_TIME (60000 milli sec, 1 min) for client response
TIMEOUT_MILLIS_DEFAULT (60000 milli sec, 1 min) for Procedure timeout
SNAPSHOT_TIMEOUT_MILLIS_DEFAULT (60000 milli sec, 1 min) for region server subprocedure  

There is also other timeout involved, for example, 
DEFAULT_TABLE_WRITE_LOCK_TIMEOUT_MS (10 mins) for TakeSnapshotHandler#prepare()

We could have this case:
The user issues a sync snapshot request, waits for 1 min, and gets an exception.
In the meantime the snapshot handler is blocked on the table lock, and the snapshot may continue to finish after 10 mins.
But the user will probably re-issue the snapshot request during the 10 mins.
This is a little confusing and messy when this happens.
To be more reasonable, we should either increase the DEFAULT_MAX_WAIT_TIME or decrease the table lock waiting time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12594,With this fix one behavior change a non-super user will notice is that he/she will be able to see only tables to which they have create/admin permissions,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6142,"The javadoc on some of the filter is somewhat confusing.
The main Filter interface has methods that behave like a sieve; when filterRowKey returns true, that means that the row is filtered _out_ (not included).

Many of the Filter implementations work the other way around. When the condition is met the value passes (ie, the row is returned).

Most Filters make it clear when a values passes (passing through the filter meaning the values are returned from the scan).
Some are less clear in light of how the Filter interface works: WhileMatchFilter and SingleColumnValueFilter are examples.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10832,"IntegrationTestIngestStripeCompactions timed out when executing in local mode, failed to shut down cleanly (LoadTestTool worker threads were trying to finish, master's catalog scanner was trying to scan a meta table that had gone away, etc.), and became a zombie. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11313,"RpcClient.getPoolType check the pool choice against ThreadLocal and RoundRobin. However, we have a 3rd pooltype already in, Reusable. We should allow in this getPoolType check.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3123,"The constructor in ZooKeeperWatcher does too much.  It does things like create the layout in ZK.  It's probably not harmful but it's unnecessary.  It should ensure that the basenode is created.  Other stuff should at least be stuffed into an initializeNodes() method or the like and only called by the first active master on cluster startup.

Other components in HBase that want to also access ZK, things like rest, should be able to reuse ZKW and ZKUtil easily.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2229,"what we are doing right now is wonky, we should use jopt simple, which attempts to emulate ye olde classic opt parsers from C in their brevity and terseness.

http://jopt-simple.sourceforge.net/",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7138,"The 'splitCount' in this line is zero in some scenario, then throw ArithmeticException: / by zero, and the '_balancedSplit' file was not deleted:
{code:java}
      LOG.debug(""Avg Time / Split = ""
          + org.apache.hadoop.util.StringUtils.formatTime(tDiff / splitCount));
{code}

Steps to reproduce:

{code}
shell> create 'test2', 'i'
shell> for i in 'a'..'z' do for j in 'a'..'z' do put 'test2', ""#{i}#{j}"", ""i:#{j}"", ""#{j}"" end end
{code}

{noformat}
$ bin/hbase org.apache.hadoop.hbase.util.RegionSplitter -r -o 2 test2 HexStringSplit
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.3-1240972, built on 02/06/2012 10:48 GMT
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:host.name=dev-vm0
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.version=1.6.0_29
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/jdk1.6.0_29/jre
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/usr/lib/jvm/default-java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../hbase-0.94.1.jar:/opt/hbase/bin/../hbase-0.94.1-tests.jar:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.5.3.jar:/opt/hbase/bin/../lib/avro-ipc-1.5.3.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.4.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.1.jar:/opt/hbase/bin/../lib/commons-lang-2.5.jar:/opt/hbase/bin/../lib/commons-logging-1.1.1.jar:/opt/hbase/bin/../lib/commons-math-2.1.jar:/opt/hbase/bin/../lib/commons-net-1.4.1.jar:/opt/hbase/bin/../lib/core-3.1.1.jar:/opt/hbase/bin/../lib/guava-11.0.2.jar:/opt/hbase/bin/../lib/hadoop-core-1.0.3.jar:/opt/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/opt/hbase/bin/../lib/httpclient-4.1.2.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/opt/hbase/bin/../lib/jackson-xc-1.8.8.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/jaxb-api-2.1.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jersey-core-1.8.jar:/opt/hbase/bin/../lib/jersey-json-1.8.jar:/opt/hbase/bin/../lib/jersey-server-1.8.jar:/opt/hbase/bin/../lib/jettison-1.1.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.5.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.10-HBASE-1.jar:/opt/hbase/bin/../lib/libthrift-0.8.0.jar:/opt/hbase/bin/../lib/log4j-1.2.16.jar:/opt/hbase/bin/../lib/metrics-core-2.1.2.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/protobuf-java-2.4.0a.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/slf4j-api-1.4.3.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.4.3.jar:/opt/hbase/bin/../lib/snappy-java-1.0.3.2.jar:/opt/hbase/bin/../lib/stax-api-1.0.1.jar:/opt/hbase/bin/../lib/velocity-1.7.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/zookeeper-3.4.3.jar:/opt/hbase/bin/../libextra/mybk-commons-cc.jar:/opt/hbase/bin/../libextra/hbase.jar:/opt/hbase/bin/../libextra/sfdcloud-hbase.jar:
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hbase/bin/../lib/native/Linux-i386-32
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:os.name=Linux
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:os.arch=i386
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:os.version=2.6.32-33-generic
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:user.name=pcer
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:user.home=/home/pcer
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase-0.94.1
12/11/08 19:20:40 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=dev-vm0:2181 sessionTimeout=60000 watcher=hconnection
12/11/08 19:20:40 INFO zookeeper.ClientCnxn: Opening socket connection to server /172.16.20.140:2181
12/11/08 19:20:40 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 28728@dev-vm0
12/11/08 19:20:40 WARN client.ZooKeeperSaslClient: SecurityException: java.lang.SecurityException: Unable to locate a login configuration occurred when trying to find JAAS configuration.
12/11/08 19:20:40 INFO client.ZooKeeperSaslClient: Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration.
12/11/08 19:20:40 INFO zookeeper.ClientCnxn: Socket connection established to dev-vm0/172.16.20.140:2181, initiating session
12/11/08 19:20:40 INFO zookeeper.ClientCnxn: Session establishment complete on server dev-vm0/172.16.20.140:2181, sessionid = 0x13ad3e9ba700150, negotiated timeout = 40000
12/11/08 19:20:40 DEBUG client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a; serverName=dev-vm0,46871,1352175042380
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for .META.,,1.1028785192 is dev-vm0:46871
12/11/08 19:20:41 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=10 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for test2,,1352373607304.8341524d6c8b105b1722961ebda3a048. is dev-vm0:46871
12/11/08 19:20:41 DEBUG util.RegionSplitter: No _balancedSplit file.  Calculating splits...
12/11/08 19:20:41 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=2147483647 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 DEBUG util.RegionSplitter: Table test2 has 1 regions that will be split.
12/11/08 19:20:41 DEBUG util.RegionSplitter: Will Split [00000000 , ffffffff) at 7fffffff
12/11/08 19:20:41 DEBUG util.RegionSplitter: Bucketing regions by regionserver...
12/11/08 19:20:41 DEBUG util.RegionSplitter: Done with bucketing.  Split time!
12/11/08 19:20:41 DEBUG util.RegionSplitter: 1 RS have regions to splt.
12/11/08 19:20:41 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=2147483647 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 DEBUG util.RegionSplitter: Finding a region on dev-vm0:46871
12/11/08 19:20:41 DEBUG util.RegionSplitter: Splitting at 7fffffff
12/11/08 19:20:41 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=dev-vm0:2181 sessionTimeout=60000 watcher=catalogtracker-on-org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 INFO zookeeper.ClientCnxn: Opening socket connection to server /172.16.20.140:2181
12/11/08 19:20:41 WARN client.ZooKeeperSaslClient: SecurityException: java.lang.SecurityException: Unable to locate a login configuration occurred when trying to find JAAS configuration.
12/11/08 19:20:41 INFO client.ZooKeeperSaslClient: Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration.
12/11/08 19:20:41 INFO zookeeper.ClientCnxn: Socket connection established to dev-vm0/172.16.20.140:2181, initiating session
12/11/08 19:20:41 INFO zookeeper.ClientCnxn: Session establishment complete on server dev-vm0/172.16.20.140:2181, sessionid = 0x13ad3e9ba700151, negotiated timeout = 40000
12/11/08 19:20:41 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 28728@dev-vm0
12/11/08 19:20:41 DEBUG catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@29c58e
12/11/08 19:20:41 DEBUG client.ClientScanner: Creating scanner over .META. starting at key 'test2,,'
12/11/08 19:20:41 DEBUG client.ClientScanner: Advancing internal scanner to startKey at 'test2,,'
12/11/08 19:20:41 DEBUG client.ClientScanner: Creating scanner over .META. starting at key 'test2,,'
12/11/08 19:20:41 DEBUG client.ClientScanner: Advancing internal scanner to startKey at 'test2,,'
12/11/08 19:20:41 DEBUG client.ClientScanner: Finished with scanning at {NAME => '.META.,,1', STARTKEY => '', ENDKEY => '', ENCODED => 1028785192,}
12/11/08 19:20:41 DEBUG catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@29c58e
12/11/08 19:20:41 INFO zookeeper.ZooKeeper: Session: 0x13ad3e9ba700151 closed
12/11/08 19:20:41 INFO zookeeper.ClientCnxn: EventThread shut down
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a; serverName=dev-vm0,46871,1352175042380
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for .META.,,1.1028785192 is dev-vm0:46871
12/11/08 19:20:41 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=10 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:20:41 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for test2,,1352373607304.8341524d6c8b105b1722961ebda3a048. is dev-vm0:46871
12/11/08 19:20:41 DEBUG util.RegionSplitter: Split Scan: 0 finished / 1 split wait / 0 reference wait
12/11/08 19:21:11 DEBUG client.HConnectionManager$HConnectionImplementation: Looked up root region location, connection=org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a; serverName=dev-vm0,46871,1352175042380
12/11/08 19:21:11 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for .META.,,1.1028785192 is dev-vm0:46871
12/11/08 19:21:11 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,7fffffff,00000000000000 for max=10 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:21:11 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for test2,7fffffff,1352373641571.d56fbb146b77bbc87c294766fabcb3c4. is dev-vm0:46871
12/11/08 19:21:11 DEBUG client.MetaScanner: Scanning .META. starting at row=test2,,00000000000000 for max=10 rows using org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation@ba5c7a
12/11/08 19:21:11 DEBUG client.HConnectionManager$HConnectionImplementation: Cached location for test2,,1352373641571.4e805892dd68d69ba02f72303973ee0e. is dev-vm0:46871
12/11/08 19:21:12 DEBUG util.RegionSplitter: Split Scan: 1 finished / 0 split wait / 0 reference wait
12/11/08 19:21:12 DEBUG util.RegionSplitter: All regions have been successfully split!
12/11/08 19:21:12 DEBUG util.RegionSplitter: TOTAL TIME = 30sec
12/11/08 19:21:12 DEBUG util.RegionSplitter: Splits = 0
Exception in thread ""main"" java.lang.ArithmeticException: / by zero
	at org.apache.hadoop.hbase.util.RegionSplitter.rollingSplit(RegionSplitter.java:576)
	at org.apache.hadoop.hbase.util.RegionSplitter.main(RegionSplitter.java:349)

{noformat}

The attached patch was tested and worked well.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10816,"In reviewing patch for HBASE-10569, Stack pointed out some existing issue with CatalogTracker. I looked into it and I think the abortable usage can be improved.

* If ZK is null, when a new one is created, the abortable could be null. We need consider this.
* The throwableAborter is to abort the process in case some ZK exception in MetaRegionTracker. In case the tracker is in a server, we don't need to do this, we can use the server as the abortable. In case the tracker is in a client, we can just abort the connection. Right?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10617,"When post following json data to rest server, it return 200, but the value is null in HBase
{code}
{""Row"": { ""key"":""cjI="", ""Cell"": {""$"":""ZGF0YTE="", ""column"":""ZjE6YzI=""}}}
{code}

From rest server log, we found the length of value is null after the server paste the json to RowModel object
{code}
14/02/26 17:52:14 DEBUG rest.RowResource: PUT {""totalColumns"":1,""families"":{""f1"":[{""timestamp"":9223372036854775807,""qualifier"":""c2"",""vlen"":0}]},""row"":""r2""}
{code}

When the order is that ""column"" before ""$"",  it works fine.
{code}
{""Row"": { ""key"":""cjI="", ""Cell"": {""column"":""ZjE6YzI="", ""$"":""ZGF0YTE="" }}}
{code}

DIfferent json libs may have different order of this two elements even if ""column"" is put before ""$"".

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10509,"Seen with IBM JDK 7:

{noformat}
Caused by: com.google.protobuf.UninitializedMessageException: Message missing required fields: row_processor_result
	at com.google.protobuf.AbstractMessage$Builder.newUninitializedMessageException(AbstractMessage.java:770)
	at org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos$ProcessResponse$Builder.build(RowProcessorProtos.java:1301)
	at org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos$ProcessResponse$Builder.build(RowProcessorProtos.java:1245)
	at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:5482)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10444,"hbase RS logs show an NPE in shutdown; no other info

{code}
14/01/30 14:18:25 INFO ipc.RpcServer: Stopping server on 57186
Exception in thread ""regionserver57186"" java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:897)
	at java.lang.Thread.run(Thread.java:744)
14/01/30 14:18:25 ERROR regionserver.HRegionServerCommand
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5000,"With block caching, when one client starts reading a block and another one comes around asking for the same block, the second client waits for the first one to finish reading and returns the block from cache. This is achieved by locking on the block offset using IdLock, a ""sparse lock"" primitive allowing to lock on arbitrary long numbers. However, in case there is no block caching, there is no reason to wait for other clients that are reading the same block. One challenge optimizing this that we don't necessary have accurate information about whether other HFile API clients interested in the block would cache it.

Setting priority as minor, as it is very unusual to turn off block caching.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6476,"There are still some areas where System.currentTimeMillis() is used in HBase. In order to make all parts of the code base testable and (potentially) to be able to configure HBase's notion of time, this should be generally be replaced with EnvironmentEdgeManager.currentTimeMillis().

How hard would it be to add a maven task that checks for that, so we do not introduce System.currentTimeMillis back in the future?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9781,"Each time I use HRegion.merge(HRegion a, HRegion b) method to merge some regions, it makes crazy that there would always be some temporary directories left on hdfs because of merging's ""Files have same sequenceid"" exceptions. I have to clean them by hand.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6487,"Tried to assign a region already assigned somewhere from hbase shell, the region is assigned to a different place but the previous assignment is not closed.  So it causes double assignments.  In such a case, it's better to issue a warning instead.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6755,"I was looking at HBase's implementation of locks and saw that is unnecessarily uses an AtomicInteger to obtain a unique lockid.
The observation is that we only need a unique one and don't care if we happen to skip one.
In a very unscientific test I saw the %system CPU reduced when the AtomicInteger is avoided.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7140,"seems like building hadoop-one-snapshot is failing.  See error log

[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] HBase
[INFO] HBase - Common
[INFO] HBase - Hadoop Compatibility
[INFO] HBase - Hadoop One Compatibility
[INFO] HBase - Server
[INFO] HBase - Hadoop Two Compatibility
[INFO] HBase - Integration Tests
[INFO] HBase - Examples
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase 0.95-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase >>>
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.1:process (default) @ hbase ---
[INFO] Setting property: classpath.resource.loader.class => 'org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader'.
[INFO] Setting property: velocimacro.messages.on => 'false'.
[INFO] Setting property: resource.loader => 'classpath'.
[INFO] Setting property: resource.manager.logwhenfound => 'false'.
[INFO] 
[INFO] <<< maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase <<<
[INFO] 
[INFO] --- maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase ---
[INFO] Not running eclipse plugin goal for pom project
[INFO] Using Eclipse Workspace: null
[INFO] Adding default classpath container: org.eclipse.jdt.launching.JRE_CONTAINER
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase - Common 0.95-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-common >>>
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.1:process (default) @ hbase-common ---
[INFO] 
[INFO] <<< maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-common <<<
[INFO] 
[INFO] --- maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-common ---
[INFO] Using Eclipse Workspace: null
[INFO] Adding default classpath container: org.eclipse.jdt.launching.JRE_CONTAINER
[INFO] File /Users/sujee/dev/hadoop/hbase-src/hbase-common/.project already exists.
       Additional settings will be preserved, run mvn eclipse:clean if you want old settings to be removed.
[INFO] Wrote Eclipse project for ""hbase-common"" to /Users/sujee/dev/hadoop/hbase-src/hbase-common.
[INFO] 
       Sources for some artifacts are not available.
       Please run the same goal with the -DdownloadSources=true parameter in order to check remote repositories for sources.
       List of artifacts without a source archive:
         o com.google.guava:guava:12.0.1
         o junit:junit:4.10-HBASE-1
         o org.apache.hadoop:hadoop-core:1.1.0
         o commons-io:commons-io:2.4
         o commons-httpclient:commons-httpclient:3.0.1
         o commons-codec:commons-codec:1.7
         o commons-lang:commons-lang:2.6
         o commons-net:commons-net:1.4.1
         o org.mortbay.jetty:jsp-api-2.1:6.1.14
         o org.mortbay.jetty:servlet-api-2.5:6.1.14
         o org.mortbay.jetty:jsp-2.1:6.1.14
         o org.apache.hadoop:hadoop-test:1.1.0
         o org.apache.ftpserver:ftplet-api:1.0.0
         o org.apache.mina:mina-core:2.0.0-M5
         o org.slf4j:slf4j-api:1.4.3
         o org.apache.ftpserver:ftpserver-core:1.0.0
         o org.apache.ftpserver:ftpserver-deprecated:1.0.0-M2
         o org.mockito:mockito-all:1.9.0
         o org.slf4j:slf4j-log4j12:1.4.3

       Javadoc for some artifacts is not available.
       Please run the same goal with the -DdownloadJavadocs=true parameter in order to check remote repositories for javadoc.
       List of artifacts without a javadoc archive:
         o com.google.guava:guava:12.0.1
         o com.google.code.findbugs:jsr305:1.3.9
         o commons-logging:commons-logging:1.1.1
         o junit:junit:4.10-HBASE-1
         o org.apache.hadoop:hadoop-core:1.1.0
         o commons-cli:commons-cli:1.2
         o xmlenc:xmlenc:0.52
         o commons-io:commons-io:2.4
         o commons-httpclient:commons-httpclient:3.0.1
         o commons-codec:commons-codec:1.7
         o org.apache.commons:commons-math:2.1
         o commons-configuration:commons-configuration:1.6
         o commons-collections:commons-collections:3.2.1
         o commons-lang:commons-lang:2.6
         o commons-digester:commons-digester:1.8
         o commons-beanutils:commons-beanutils:1.7.0
         o commons-beanutils:commons-beanutils-core:1.8.0
         o commons-net:commons-net:1.4.1
         o org.mortbay.jetty:jetty:6.1.26
         o org.mortbay.jetty:jetty-util:6.1.26
         o tomcat:jasper-runtime:5.5.23
         o commons-el:commons-el:1.0
         o tomcat:jasper-compiler:5.5.23
         o org.mortbay.jetty:jsp-api-2.1:6.1.14
         o org.mortbay.jetty:servlet-api-2.5:6.1.14
         o org.mortbay.jetty:jsp-2.1:6.1.14
         o org.codehaus.jackson:jackson-mapper-asl:1.8.8
         o org.codehaus.jackson:jackson-core-asl:1.8.8
         o org.apache.hadoop:hadoop-test:1.1.0
         o org.apache.ftpserver:ftplet-api:1.0.0
         o org.apache.mina:mina-core:2.0.0-M5
         o org.slf4j:slf4j-api:1.4.3
         o org.apache.ftpserver:ftpserver-core:1.0.0
         o org.apache.ftpserver:ftpserver-deprecated:1.0.0-M2
         o org.mockito:mockito-all:1.9.0
         o org.slf4j:slf4j-log4j12:1.4.3
         o log4j:log4j:1.2.17

[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase - Hadoop Compatibility 0.95-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-hadoop-compat >>>
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.1:process (default) @ hbase-hadoop-compat ---
[INFO] 
[INFO] <<< maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-hadoop-compat <<<
[INFO] 
[INFO] --- maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-hadoop-compat ---
[INFO] Using Eclipse Workspace: null
[INFO] Adding default classpath container: org.eclipse.jdt.launching.JRE_CONTAINER
[INFO] File /Users/sujee/dev/hadoop/hbase-src/hbase-hadoop-compat/.project already exists.
       Additional settings will be preserved, run mvn eclipse:clean if you want old settings to be removed.
[INFO] Wrote Eclipse project for ""hbase-hadoop-compat"" to /Users/sujee/dev/hadoop/hbase-src/hbase-hadoop-compat.
[INFO] 
       Sources for some artifacts are not available.
       Please run the same goal with the -DdownloadSources=true parameter in order to check remote repositories for sources.
       List of artifacts without a source archive:
         o junit:junit:4.10-HBASE-1
         o org.mockito:mockito-all:1.9.0

       Javadoc for some artifacts is not available.
       Please run the same goal with the -DdownloadJavadocs=true parameter in order to check remote repositories for javadoc.
       List of artifacts without a javadoc archive:
         o commons-logging:commons-logging:1.1.1
         o junit:junit:4.10-HBASE-1
         o org.mockito:mockito-all:1.9.0

[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase - Hadoop One Compatibility 0.95-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-eclipse-plugin:2.8:eclipse (default-cli) @ hbase-hadoop1-compat >>>
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.1:process (default) @ hbase-hadoop1-compat ---
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] HBase ............................................. SUCCESS [1.534s]
[INFO] HBase - Common .................................... SUCCESS [1.173s]
[INFO] HBase - Hadoop Compatibility ...................... SUCCESS [0.058s]
[INFO] HBase - Hadoop One Compatibility .................. FAILURE [0.098s]
[INFO] HBase - Server .................................... SKIPPED
[INFO] HBase - Hadoop Two Compatibility .................. SKIPPED
[INFO] HBase - Integration Tests ......................... SKIPPED
[INFO] HBase - Examples .................................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 4.894s
[INFO] Finished at: Fri Nov 09 14:49:27 PST 2012
[INFO] Final Memory: 17M/81M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.1:process (default) on project hbase-hadoop1-compat: Failed to resolve dependencies for one or more projects in the reactor. Reason: Missing:
[ERROR] ----------
[ERROR] 1) org.apache.hbase:hbase-hadoop-compat:jar:0.95-SNAPSHOT
[ERROR] 
[ERROR] Try downloading the file manually from the project website.
[ERROR] 
[ERROR] Then, install it using the command:
[ERROR] mvn install:install-file -DgroupId=org.apache.hbase -DartifactId=hbase-hadoop-compat -Dversion=0.95-SNAPSHOT -Dpackaging=jar -Dfile=/path/to/file
[ERROR] 
[ERROR] Alternatively, if you host your own repository you can deploy the file there:
[ERROR] mvn deploy:deploy-file -DgroupId=org.apache.hbase -DartifactId=hbase-hadoop-compat -Dversion=0.95-SNAPSHOT -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id]
[ERROR] 
[ERROR] Path to dependency:
[ERROR] 1) org.apache.hbase:hbase-hadoop1-compat:jar:0.95-SNAPSHOT
[ERROR] 2) org.apache.hbase:hbase-hadoop-compat:jar:0.95-SNAPSHOT
[ERROR] 
[ERROR] 2) org.apache.hbase:hbase-hadoop-compat:test-jar:tests:0.95-SNAPSHOT
[ERROR] 
[ERROR] Try downloading the file manually from the project website.
[ERROR] 
[ERROR] Then, install it using the command:
[ERROR] mvn install:install-file -DgroupId=org.apache.hbase -DartifactId=hbase-hadoop-compat -Dversion=0.95-SNAPSHOT -Dclassifier=tests -Dpackaging=test-jar -Dfile=/path/to/file
[ERROR] 
[ERROR] Alternatively, if you host your own repository you can deploy the file there:
[ERROR] mvn deploy:deploy-file -DgroupId=org.apache.hbase -DartifactId=hbase-hadoop-compat -Dversion=0.95-SNAPSHOT -Dclassifier=tests -Dpackaging=test-jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id]
[ERROR] 
[ERROR] Path to dependency:
[ERROR] 1) org.apache.hbase:hbase-hadoop1-compat:jar:0.95-SNAPSHOT
[ERROR] 2) org.apache.hbase:hbase-hadoop-compat:test-jar:tests:0.95-SNAPSHOT
[ERROR] 
[ERROR] ----------
[ERROR] 2 required artifacts are missing.
[ERROR] 
[ERROR] for artifact:
[ERROR] org.apache.hbase:hbase-hadoop1-compat:jar:0.95-SNAPSHOT
[ERROR] 
[ERROR] from the specified remote repositories:
[ERROR] cloudbees netty (http://repository-netty.forge.cloudbees.com/snapshot/, releases=true, snapshots=true),
[ERROR] apache release (https://repository.apache.org/content/repositories/releases/, releases=true, snapshots=true),
[ERROR] java.net (http://download.java.net/maven/2/, releases=true, snapshots=false),
[ERROR] codehaus (http://repository.codehaus.org/, releases=true, snapshots=false),
[ERROR] repository.jboss.org (http://repository.jboss.org/nexus/content/groups/public-jboss/, releases=true, snapshots=false),
[ERROR] ghelmling.testing (http://people.apache.org/~garyh/mvn/, releases=true, snapshots=true),
[ERROR] apache.snapshots (http://repository.apache.org/snapshots, releases=false, snapshots=true),
[ERROR] central (http://repo1.maven.org/maven2, releases=true, snapshots=false)
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hbase-hadoop1-compat
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7713,"build fails with following error message ""org.codehaus.plexus.resource.loader.ResourceNotFoundException: Could not find resource 'dev-support/findbugs-exclude.xml'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7638,See HBASE-7268. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6988,"Thru the cycle of restarting HBase and shell, I was somehow able to get into this state (on trunk):

{noformat}
hbase(main):020:0> describe 'test'
DESCRIPTION                                                                                ENABLED                                          
 'test', {METHOD => 'table_att', CONFIG => {'Key' => 'Value2', 'Key2' => 'Value2'}}, {NAME true                                             
  => 'cf', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0',                                                  
  COMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_D                                                  
 ELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'fa                                                  
 lse', BLOCKCACHE => 'true'}                                                                                                                
1 row(s) in 0.0420 seconds

hbase(main):021:0> disable 'test'

ERROR: Table test does not exist.'

Here is some help for this command:
Start disable of named table: e.g. ""hbase> disable 't1'""


hbase(main):022:0> create 'test', 'cf2'
0 row(s) in 1.0900 seconds

=> Hbase::Table - test
hbase(main):023:0> describe 'test'
DESCRIPTION                                                                                ENABLED                                          
 'test', {METHOD => 'table_att', CONFIG => {'Key' => 'Value2', 'Key2' => 'Value2'}}, {NAME true                                             
  => 'cf', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0',                                                  
  COMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_D                                                  
 ELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'fa                                                  
 lse', BLOCKCACHE => 'true'}                                                                                                                
1 row(s) in 0.0440 seconds

hbase(main):024:0> disable 'test'
0 row(s) in 7.0590 seconds

hbase(main):026:0> alter 'test', METHOD => 'table_att', CONFIG => { 'Key' => 'Value3' }, MAX_FILESIZE => 1234567
Updating all regions with the new schema...
1/1 regions updated.
Done.
0 row(s) in 1.1210 seconds

hbase(main):027:0> describe 'test'
DESCRIPTION                                                                                ENABLED                                          
 'test', {METHOD => 'table_att', MAX_FILESIZE => '1234567', CONFIG => {'Key' => 'Value3',  false                                            
 'Key2' => 'Value2'}}, {NAME => 'cf', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE'                                                  
 , REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647',                                                   
 MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK                                                   
 => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'true'}                                                                                     
1 row(s) in 0.0400 seconds

hbase(main):029:0> enable 'test'
0 row(s) in 7.0710 seconds

hbase(main):030:0> put 'test', 'row1', 'cf:foo', 'bar'
0 row(s) in 0.0240 seconds

hbase(main):031:0> put 'test', 'row1', 'cf2:foo', 'bar'

ERROR: org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family cf2 does not exist in region test,,1350063293064.7867533297035efe96611b5bcc54f332. in table 'test', {METHOD => 'table_att', MAX_FILESIZE => '1234567', CONFIG => {'Key' => 'Value3', 'Key2' => 'Value2'}}, {NAME => 'cf', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5845,"In HBASE-5824, attempt was made to handle single Put execution separately. Put has two exception paths thereafter. It's better to keep one exception for easy exception handling.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6878,"The code in SplitLogManager# getDataSetWatchSuccess is:
{code}
if (slt.isDone()) {
      LOG.info(""task "" + path + "" entered state: "" + slt.toString());
      if (taskFinisher != null && !ZKSplitLog.isRescanNode(watcher, path)) {
        if (taskFinisher.finish(slt.getServerName(), ZKSplitLog.getFileName(path)) == Status.DONE) {
          setDone(path, SUCCESS);
        } else {
          resubmitOrFail(path, CHECK);
        }
      } else {
        setDone(path, SUCCESS);
      }
{code}

          resubmitOrFail(path, CHECK);

should be 
          resubmitOrFail(path, FORCE);

Without it, the task won't be resubmitted if the delay is not reached, and the task will be marked as failed.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14,"Running a simple, fairly large job on the cluster, a few of the reduce steps failed; all that did are effectively hung.  Looking at failures, I see this strange output:

{code}
2007-11-13 02:09:09,606 DEBUG org.apache.hadoop.hbase.HTable: reloading table servers because: java.io.IOException: Region triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610 closed
	at org.apache.hadoop.hbase.HRegion.startUpdate(HRegion.java:1142)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1239)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

2007-11-13 02:09:19,778 DEBUG org.apache.hadoop.hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.NotServingRegionException: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1325)
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1297)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1238)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

2007-11-13 02:09:30,039 DEBUG org.apache.hadoop.hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.NotServingRegionException: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1325)
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1297)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1238)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

2007-11-13 02:09:40,275 DEBUG org.apache.hadoop.hbase.HTable: reloading table servers because: org.apache.hadoop.hbase.NotServingRegionException: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1325)
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1297)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1238)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

2007-11-13 02:09:55,379 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1325)
	at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1297)
	at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1238)
	at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1113)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
	at org.apache.hadoop.hbase.HTable.commit(HTable.java:734)
	at org.apache.hadoop.hbase.HTable.commit(HTable.java:706)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter.write(TableOutputFormat.java:89)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat$TableRecordWriter.write(TableOutputFormat.java:63)
	at org.apache.hadoop.mapred.ReduceTask$2.collect(ReduceTask.java:308)
	at TriplesTest$TestReducer.reduce(TriplesTest.java:66)
	at TriplesTest$TestReducer.reduce(TriplesTest.java:51)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:326)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1935)
{code}

Why is the reducer client being pig-headed trying to go against a region that has been closed?  Why not recalibrate?

Here is master log from around same time on the problem region:

{code}
...
2007-11-13 02:10:17,867 INFO org.apache.hadoop.hbase.HMaster: region triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610 split. New regions are: triples,http://purl.org/dc/terms/bibliographicCitation,1194919707661, triples,http://purl.org/dc/terms/references,1194919707661
...
2007-11-13 02:11:47,313 DEBUG org.apache.hadoop.hbase.HMaster: HMaster.metaScanner scanner: -3075797136896920808 regioninfo: {regionname: triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610, startKey: <http://purl.org/dc/terms/bibliographicCitation>, offline: true, split: true, tableDesc: {name: triples, families: {triples:={name: triples, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}}}}, server: 208.76.44.140:60010, startCode: -647590197693256616
...
2007-11-13 02:11:47,317 INFO org.apache.hadoop.hbase.HMaster: Deleting region triples,http://purl.org/dc/terms/bibliographicCitation,1194919500610 because daughter splits no longer hold references
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3546,"There are possibilities of XSS in the WebUI.

If ColumnFamily or Region splitting keys are like

Bytes.toBytes(""<script>alert('js')</script>"")

then browsers run the JavaScript code.
I tested on HBase-0.90.0 .
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6159,"ZK connection count always goes up by one when running shell command:

{code}
hbase(main):001:0> truncate 'table'
{code}

This can be fixed with the change in admin.rb:

{code}
- h_table = org.apache.hadoop.hbase.client.HTable.new(table_name)
- table_description = h_table.getTableDescriptor()
+ table_description = @admin.getTableDescriptor(table_name.to_java_bytes)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6467,"After restart a cluster, all region servers checked into master but the master stuck in assigning forever.

Master log shows it keeps trying connect to one region server for ROOT table, while that region server's log shows it keeps printing out NotServingRegionException.

After restart the master, things are ok now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2073,"After a regionserver went down last night, I checked its logs and found the following exception:

2009-12-29 00:17:27,663 INFO org.apache.hadoop.hbase.regionserver.HLog: Roll /hbase/amsterdam_factory/.logs/factory05.lab.mtl,60020,1262042255724/hlog.dat.1262060247637, entries=1830, calcsize=22946017, filesize=22758899. New hlog /hbase/amsterdam_factory/.logs/factory05.lab.mtl,60020,1262042255724/hlog.dat.1262063847659
2009-12-29 00:34:36,210 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
java.lang.IllegalArgumentException
	at java.nio.Buffer.position(Buffer.java:218)
	at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1114)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:58)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:189)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:106)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.nextInternal(HRegion.java:1776)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.next(HRegion.java:1719)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1944)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:648)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
2009-12-29 00:34:36,214 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 0 on 60020, call next(4170645244799815171, 1) from 192.168.1.108:53401: error: java.io.IOException: java.lang.IllegalArgumentException
java.io.IOException: java.lang.IllegalArgumentException
	at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:869)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:859)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1965)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:648)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
Caused by: java.lang.IllegalArgumentException
	at java.nio.Buffer.position(Buffer.java:218)
	at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1114)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:58)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:189)
	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:106)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.nextInternal(HRegion.java:1776)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.next(HRegion.java:1719)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1944)
	... 5 more

Looks like this bug was encountered before at https://issues.apache.org/jira/browse/HBASE-1495 and spanned a few JIRAs. It's supposed to be resolved as of 0.20.0, but we're running 0.20.2 and it took down one of our regionservers.

I'm also attaching more of the log.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1559,"IllegalThreadStateException during LocalHBaseCluster shutdown if more than one regionserver is started:

{noformat}
Thread [RegionServer:1] (Suspended (exception IllegalThreadStateException))
    FileSystem$ClientFinalizer(Thread).start() line: 595
    HRegionServer.runThread(Thread,long) line: 691
    HRegionServer.run() line: 675
    LocalHBaseCluster$RegionServerThread(Thread).run() line: 691
{noformat}

If started with only one region server, shut down is clean.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4178,"ScannerIds are currently assigned by getting a random long. While it would be a rare occurrence that two scanners received the same ids on the same region server the results would seem to be... Bad.
A client scanner would get results from a different server scanner, and maybe only from some of the region servers.

A safer approach would be using an AtomicLong. We do not have to worry about running of numbers: If we got 10000 scanners per second it'd take > 2.9m years to reach 2^63.

Then again the same reasoning would imply that this collisions would be happening too rarely to be of concern (assuming a good random number generator). So maybe this is a none-issue.

AtomicLong would also imply a minor performance hit on multi core machines, as it would force a memory barrier.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2102,We are hard coding the package version in src/contrib/build-contrib.xml and it has been out of sync with the package version in the top level build.xml file since 0.20.0. Maybe it would be better to keep the package version in a single separate file (/version.xml?) and include it from all build files?,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1475,"This does not happen every time I run a cluster test, but probably 75% of the time.

{noformat}
2009-06-02 09:58:32.365::INFO:  Logging to STDERR via org.mortbay.log.StdErrLog
2009-06-02 09:58:32.425::INFO:  jetty-6.1.14
2009-06-02 09:58:32.454::WARN:  Web application not found file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/hdfs
2009-06-02 09:58:32.454::WARN:  Failed startup of context org.mortbay.jetty.webapp.WebAppContext@7ed75415{/,file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/hdfs}
java.io.FileNotFoundException: file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/hdfs
	at org.mortbay.jetty.webapp.WebAppContext.resolveWebApp(WebAppContext.java:959)
	at org.mortbay.jetty.webapp.WebAppContext.getWebInf(WebAppContext.java:793)
	at org.mortbay.jetty.webapp.WebInfConfiguration.configureClassLoader(WebInfConfiguration.java:62)
	at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:456)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
	at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
	at org.mortbay.jetty.Server.doStart(Server.java:222)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:453)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:246)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:202)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:279)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:955)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:275)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:119)
	at org.apache.hadoop.hbase.HBaseClusterTestCase.setUp(HBaseClusterTestCase.java:122)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
2009-06-02 09:58:32.497::INFO:  Started SelectChannelConnector@localhost:34719
Starting DataNode 0 with dfs.data.dir: /home/jgray/src/hbase-0.20.0-1304/hbase/build/hbase/test/dfs/data/data1,/home/jgray/src/hbase-0.20.0-1304/hbase/build/hbase/test/dfs/data/data2
2009-06-02 09:58:32.678::INFO:  jetty-6.1.14
2009-06-02 09:58:32.683::WARN:  Web application not found file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/datanode
2009-06-02 09:58:32.683::WARN:  Failed startup of context org.mortbay.jetty.webapp.WebAppContext@6f7cf6b6{/,file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/datanode}
java.io.FileNotFoundException: file:/home/jgray/src/hbase-0.20.0-1304/hbase/bin/webapps/datanode
	at org.mortbay.jetty.webapp.WebAppContext.resolveWebApp(WebAppContext.java:959)
	at org.mortbay.jetty.webapp.WebAppContext.getWebInf(WebAppContext.java:793)
	at org.mortbay.jetty.webapp.WebInfConfiguration.configureClassLoader(WebInfConfiguration.java:62)
	at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:456)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
	at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
	at org.mortbay.jetty.Server.doStart(Server.java:222)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:453)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:375)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:216)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1283)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1238)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:414)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:119)
	at org.apache.hadoop.hbase.HBaseClusterTestCase.setUp(HBaseClusterTestCase.java:122)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
2009-06-02 09:58:32.688::INFO:  Started SelectChannelConnector@localhost:47838
{noformat}

It holds there for about 30 seconds.  If I rerun the test, the delay usually goes away.  Even when there is no delay, I still get this error at the beginning of the cluster spin up.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-568,"I have a very simple table named 'titles' that I'm playing around with.
After entering

	hql > DELETE * FROM titles;

I get the following output:

08/04/07 15:09:15 INFO hbase.HBaseAdmin: Disabled table titles
Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.hadoop.io.Text.set(Text.java:181)
        at org.apache.hadoop.io.Text.<init>(Text.java:76)
        at
org.apache.hadoop.hbase.hql.DeleteCommand.getColumnList(DeleteCommand.java:106)
        at
org.apache.hadoop.hbase.hql.DeleteCommand.execute(DeleteCommand.java:67)
        at
org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)

Every succeeding attempt to query the table results in the following output:

Exception in thread ""main"" java.lang.IllegalStateException: region
offline: titles,,1207564179189
        at
org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:438)
        at
org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:350)
        at
org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:313)
        at org.apache.hadoop.hbase.HTable.<init>(HTable.java:91)
        at
org.apache.hadoop.hbase.hql.SelectCommand.execute(SelectCommand.java:90)
        at
org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)


Deleting a specific column on the other hand, as in:

	hql> DELETE document:title FROM titles;

is no problem - I get this output:

08/04/07 17:08:02 INFO hbase.HBaseAdmin: Disabled table titles
08/04/07 17:08:02 INFO hbase.HBaseAdmin: Enabled table titles

and everything's all right ever after.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-503,"Master is stuck trying to shutdown.  It gets confused if its not running the shutdown.  Scenario is cluster is being monitored by a watcher process.  When a server goes down, its restarted.  In this environment, all hbase was updated then each server was restarted.  The regionservers bounced fine but the master won't go down.  Its stuck servicing reports of newly started regionservers to whom it sends a shutdown.... but cluster is of such a size that the master hasn't gone down by the time the regionserver starts again.  Here is how the master log looks for one server:

{code}
2008-03-11 20:47:08,198 INFO org.apache.hadoop.hbase.HMaster: Cancelling lease for XX.XX.XX.122:60020
2008-03-11 20:47:08,198 INFO org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- lease cancelled
2008-03-11 20:47:08,398 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
2008-03-11 20:47:16,421 INFO org.apache.hadoop.hbase.HMaster: received start message from: XX.XX.XX.122:60020
2008-03-11 20:47:20,163 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
2008-03-11 20:47:20,163 INFO org.apache.hadoop.hbase.HMaster: Cancelling lease for XX.XX.XX.122:60020
2008-03-11 20:47:20,163 INFO org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- lease cancelled
2008-03-11 20:47:20,393 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
2008-03-11 20:47:28,374 INFO org.apache.hadoop.hbase.HMaster: received start message from: XX.XX.XX.122:600
202008-03-11 20:47:32,095 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
2008-03-11 20:47:32,095 INFO org.apache.hadoop.hbase.HMaster: Cancelling lease for XX.XX.XX.122:60020
2008-03-11 20:47:32,095 INFO org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- lease cancelled
2008-03-11 20:47:32,274 DEBUG org.apache.hadoop.hbase.HMaster: Region server XX.XX.XX.122:60020: MSG_REPORT_EXITING -- cancelling lease
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1103,"hbase.client.rpc.maxattempts is defined as configurable in HConnectionManager , but is not present in the hbase-default.xml",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-520,"Build fails due to invalid output by saveVersion.sh:

user=`whoami` results in the string ""domain\user"" which is an invalid escape sequence down the line (or something else bad). I tried to figure out how to use sed to escape the backslash, but failed miserably and just removed the whoami altogether to workaround.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18,"Marking as minor issue since its a concurrency issue in admin function.  Though that said, this is a guaranteed way to generate rows in META that are without their regioninfo (Looks like we might add startcode and servername after a row has had its regioninfo removed).

Issue was found by Dave Simpson running a create/delete/create sequence.  Attaching log.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-723,"cachedRegionLocation stores region locations of tables whenever new region is looked up. However, the enties are deleted only when TableServers object is closed or locateRegion is called with false useCache argument. Therefore, it seems to grow without limit and cause out of memory exception. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13,"I got this this evening:

{code}
08/01/17 05:57:06 ERROR hbase.PerformanceEvaluation: Failed
org.apache.hadoop.hbase.WrongRegionException: org.apache.hadoop.hbase.WrongRegionException: Requested row out of range for HRegion TestTable,0000103481,1200548919843, startKey='0000103481', getEndKey()='0000163328', row='0000163328'
        at org.apache.hadoop.hbase.HRegion.checkRow(HRegion.java:1491)
        at org.apache.hadoop.hbase.HRegion.obtainRowLock(HRegion.java:1536)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1231)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1497)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:908)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
        at org.apache.hadoop.hbase.HTable.commit(HTable.java:968)
        at org.apache.hadoop.hbase.HTable.commit(HTable.java:939)
        at org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest.testRow(PerformanceEvaluation.java:461)
        at org.apache.hadoop.hbase.PerformanceEvaluation$Test.test(PerformanceEvaluation.java:329)
        at org.apache.hadoop.hbase.PerformanceEvaluation.runOneClient(PerformanceEvaluation.java:525)
        at org.apache.hadoop.hbase.PerformanceEvaluation.runNIsOne(PerformanceEvaluation.java:546)
        at org.apache.hadoop.hbase.PerformanceEvaluation.runTest(PerformanceEvaluation.java:568)
        at org.apache.hadoop.hbase.PerformanceEvaluation.doCommandLine(PerformanceEvaluation.java:663)
        at org.apache.hadoop.hbase.PerformanceEvaluation.main(PerformanceEvaluation.java:682)
..
{code}

We seem to be asking for the endkey on a region rather than asking for the next region, the one that has the asked-for row as its start key.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-705,"I get a RegionOfflineException error when trying to use the list command with a region offline

{code}
hbase(main):005:0* list
08/06/25 02:43:30 DEBUG client.HConnectionManager$TableServers: Cache hit in table locations for row <> and tableName .META.: location server 64.69.33.211:60020, location region name .META.,,1
08/06/25 02:43:30 DEBUG client.HConnectionManager$TableServers: reloading table servers because: region offline: webdata,,1214377950920
08/06/25 02:43:30 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of webdata,,99999999999999
08/06/25 02:43:30 DEBUG client.HConnectionManager$TableServers: Found ROOT REGION => {NAME => '-ROOT-,,0', STARTKEY => '', ENDKEY => '', ENCODED => 70236052, TABLE => {NAME => '-ROOT-', FAMILIES => [{NAME => 'info', VERSIONS => 1, COMPRESSION => 'NONE', IN_MEMORY => false, BLOCKCACHE => false, LENGTH => 2147483647, TTL => FOREVER, BLOOMFILTER => NONE}]}
08/06/25 02:43:40 DEBUG client.HConnectionManager$TableServers: reloading table servers because: region offline: webdata,,1214377950920
08/06/25 02:43:40 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of webdata,,99999999999999
08/06/25 02:43:40 DEBUG client.HConnectionManager$TableServers: Found ROOT REGION => {NAME => '-ROOT-,,0', STARTKEY => '', ENDKEY => '', ENCODED => 70236052, TABLE => {NAME => '-ROOT-', FAMILIES => [{NAME => 'info', VERSIONS => 1, COMPRESSION => 'NONE', IN_MEMORY => false, BLOCKCACHE => false, LENGTH => 2147483647, TTL => FOREVER, BLOOMFILTER => NONE}]}
NativeException: org.apache.hadoop.hbase.client.RegionOfflineException: region offline: webdata,,1214377950920
        from org/apache/hadoop/hbase/client/HConnectionManager.java:446:in `locateRegionInMeta'
        from org/apache/hadoop/hbase/client/HConnectionManager.java:377:in `locateRegion'
        from org/apache/hadoop/hbase/client/HConnectionManager.java:338:in `locateRegion'
        from org/apache/hadoop/hbase/client/MetaScanner.java:68:in `metaScan'
        from org/apache/hadoop/hbase/client/MetaScanner.java:32:in `metaScan'
        from org/apache/hadoop/hbase/client/HConnectionManager.java:295:in `listTables'
        from org/apache/hadoop/hbase/client/HBaseAdmin.java:127:in `listTables'
        from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0'
        from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke'
        from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke'
        from java/lang/reflect/Method.java:597:in `invoke'
        from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling'
        from org/jruby/javasupport/JavaMethod.java:219:in `invoke'
        from org/jruby/javasupport/JavaClass.java:416:in `execute'
        from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call'
        from org/jruby/internal/runtime/methods/DynamicMethod.java:70:in `call'
... 128 levels...
        from ruby.hbase_minus_671438.bin.hirbInvokermethod__23$RUBY$startOpt:-1:in `call'
        from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call'
        from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call'
        from org/jruby/runtime/CallSite.java:123:in `cacheAndCall'
        from org/jruby/runtime/CallSite.java:298:in `call'
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:340:in `__file__'
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:-1:in `__file__'
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:-1:in `load'
        from org/jruby/Ruby.java:512:in `runScript'
        from org/jruby/Ruby.java:432:in `runNormally'
        from org/jruby/Ruby.java:312:in `runFromMain'
        from org/jruby/Main.java:144:in `run'
        from org/jruby/Main.java:89:in `run'
        from org/jruby/Main.java:80:in `main'
        from /hbase/bin/hirb.rb:227:in `list'
        from (hbase):6:in `binding'hbase(main):006:0>
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-400,"HQL commands have been implemented through the issue 
[HADOOP-1720|https://issues.apache.org/jira/browse/HADOOP-1720]. Unit tests that test these newly 
implemented HQL commands  are needed to make sure that those commands 
are correctly implemented. 

In this issue, we are going to provide unit tests that set up a minibase cluster, 
execute various commands, and verify the results, as Stack suggested in the issue
HADOOP-1720 as follows:

Stack said:
{quote}
This is a large amount of new functionality but it is without unit tests. Regression in something as complicated as a shell is a real danger. Do you have any objection to adding at least a basic test that does a setup of a minihbasecluster adding a table using your create command (with assertion that add was successful, and that all options specified were enabled, perhaps using your describe command), and then disable, enable, input, select, and drop asserting each of the steps has happened as you go? (I can help out if you'd like).
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-385,"In the past, the lock id returned by HTable.startUpdate was a real lock id from a remote server. However, that has been superceeded by the BatchUpdate process, so now the lock id is just an arbitrary value. More, it doesn't actually add any value, because while it implies that you could start two updates on the same HTable and commit them separately, this is in fact not the case. Any attempt to do a second startUpdate throws an IllegalStateException. 

Since there is no added functionality afforded by the presence of this parameter, I suggest that we overload all methods that use it to ignore it and print a deprecation notice. startUpdate can just return a constant like 1 and eventually turn into a boolean or some other useful value.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-359,"There are a number of deprecated APIs in HRegionInterface (the interface used by the client to communicate with the HRegionServer). Although none of the APIs are used by the current client classes or by other HBase code, we do know that some HBase users have subclassed both the client and HRegionServer. What we do not know is if their changes make use of the deprecated APIs.

In addition, we would like to make an incompatible change to HRegionInterface.batchUpdate in order to support HADOOP-1724. (It would return either an enum or boolean instead of void).

If these changes would effect you, please let us know and also give us a time frame when this change could be implemented. Thanks!
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-341,"Profiling, we create a bunch of short-lived objects in hbase around lease creation, renewal and release by doing 'new Text(Long.toString(someLong)))'.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-330,"
It would be better if 'ant clean' does not remove build directory. Many projects do not remove this dir. One advantage of not removing is that, I can symlink the build to another place (e.g. /mnt/scratch/) and keep the source code in more reliable place. I will submit a patch if this sounds ok.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-321,TableMapRunnable for Multi-Threaded HBase Map Jobs,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-262,"Watching hudson, I happened to catch a hung TestCleanRegionServerExit.  The test had done a join onto the server it'd asked shutdown only the server wasn't going down because it was stuck trying to get a memcache write lock so it could finish the last flush on regions before close.  Somehow, a read (or write) lock is not being cleaned up.  Scanners are the suspect but looking at the code, scanners should be getting closed on expiration of their lease.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-157,"Watching the hbase webUI, the request counter in the load column reported in the list of regionservers doesn't make sense.  Refreshing, the request count will tend to rise for a while as you'd expect but then they'll start to fall and will often drop to zero.  This is on regionservers with constant count of regions (I'd expect load to be zero on a new region after a split).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-126,Holger Stenzhorn has been having issues running a mapreduce job that dumps into a 'local' mode hbase.  Use this issue to figure whats going on.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-86,"From the list this morning from Josh Wills:

{code}
Date: Mon, 22 Oct 2007 12:04:01 -0500
From: ""Josh Wills"" ....
To: hadoop-user@lucene.apache.org
Subject: Re: A basic question on HBase

...

> >
> > 2)  I was running one of these batch-style uploads last night on an
> > HTable that I configured w/BloomFilters on a couple of my column
> > families.  During one of the compaction operations, I got the
> > following exception--
> >
> > FATAL org.apache.hadoop.hbase.HRegionServer: Set stop flag in
> > regionserver/0:0:0:0:0:0:0:0:60020.splitOrCompactChecker
> > java.lang.ArrayIndexOutOfBoundsException
> >         at java.lang.System.arraycopy(Native Method)
> >         at sun.security.provider.DigestBase.engineUpdate(DigestBase.jav=
a:102)
> >         at sun.security.provider.SHA.implDigest(SHA.java:94)
> >         at sun.security.provider.DigestBase.engineDigest(DigestBase.jav=
a:161)
> >         at sun.security.provider.DigestBase.engineDigest(DigestBase.jav=
a:140)
> >         at java.security.MessageDigest$Delegate.engineDigest(MessageDig=
est.java:531)
> >         at java.security.MessageDigest.digest(MessageDigest.java:309)
> >         at org.onelab.filter.HashFunction.hash(HashFunction.java:125)
> >         at org.onelab.filter.BloomFilter.add(BloomFilter.java:99)
> >         at org.apache.hadoop.hbase.HStoreFile$BloomFilterMapFile$Writer=
.append(HStoreFile.java:895)
> >         at org.apache.hadoop.hbase.HStore.compact(HStore.java:899)
> >         at org.apache.hadoop.hbase.HStore.compact(HStore.java:728)
> >         at org.apache.hadoop.hbase.HStore.compactHelper(HStore.java:632=
)
> >         at org.apache.hadoop.hbase.HStore.compactHelper(HStore.java:564=
)
> >         at org.apache.hadoop.hbase.HStore.compact(HStore.java:559)
> >         at org.apache.hadoop.hbase.HRegion.compactStores(HRegion.java:7=
17)
> >         at org.apache.hadoop.hbase.HRegionServer$SplitOrCompactChecker.=
checkForSplitsOrCompactions(HRegionServer.java:198)
> >         at org.apache.hadoop.hbase.HRegionServer$SplitOrCompactChecker.=
chore(HRegionServer.java:188)
> >         at org.apache.hadoop.hbase.Chore.run(Chore.java:58)
> >
> > Note that this wasn't the first compaction that was run (there were
> > others before it that ran successfully) and that the region hadn't
> > been split at this point.  I defined the BloomFilterType.BLOOMFILTER
> > on a couple of the columnfamilies, w/the largest one having ~100000
> > distinct entries.  I don't know which of these caused the failure, but
> > I noticed that 100000 is quite a bit larger than the # of entries used
> > in the testcases, so I'm wondering if that might be the problem.
...
{code}

Poking around, could be a concurrency issue -- see http://forum.java.sun.com/thread.jspa?threadID=700440&messageID=4117706 -- but Jim and I chatting can't figure how since there should be one thread only running at compaction time....

Plan is to try and reproduce on local cluster....",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20994,Remove for loops adding to collections.  (Style),,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7737,"There is a serious bug in HServerAddress, who depends on the stringValue [class variable] for comparison. This variable is supposed to be host_ip_address:port. 

However, there is one constructor which allows user to pass a string as host_ip_address directly. This constructor is buggy because some caller may pass the host name instead of host ip address. And we found out one case in the HBase client.

The fix is to normalize the stringValue generation by calling the existing function getHostAddressWithPort.

For example:
this.stringValue = getHostAddressWithPort();
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16346,"{code:title=Increment.java|borderStyle=solid}
 // Is it necessary to prevent the null qualifier
  public Increment addColumn(byte [] family, byte [] qualifier, long amount) {
    if (family == null) {
      throw new IllegalArgumentException(""family cannot be null"");
    }
    if (qualifier == null) {
      throw new IllegalArgumentException(""qualifier cannot be null"");
    }
    List<Cell> list = getCellList(family);
    KeyValue kv = createPutKeyValue(family, qualifier, ts, Bytes.toBytes(amount));
    list.add(kv);
    familyMap.put(CellUtil.cloneFamily(kv), list);
    return this;
  }
{code}

I use the add(Cell) method to add the cell with null qualifier and it works fine.
It seems to me that the check should be removed
any command? thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13272,"Via [~larsgeorge]

Get.setClosestRowBefore() is breaking a specific Get that specifies a column. If you set the latter to ""true"" it will return the _entire_ row!",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12530,"TestStatusResource can fail if run in parallel with other tests, fix this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4202,"We added a new node to a 44 node cluster starting the datanode, mapred and regionserver processes on it. The Unix filesystem was configured incorrectly, i.e. /tmp was not writable to processes. All three processes had issues with this. Datanode and mapred shutdown on exception.
Regionserver did not stop, in fact reported to master that its up without regions. So master assigned regions to it. Regionserver would not accept them, resulting in a constant assign, reject, reassign cycle, that put many regions into a state of not being available. There are no logs about this, but we could observer the regioncount fluctuate by hundredths of regions and the application throwing many NotServingRegion exceptions.  

In fact to the master process the regionserver looked fine, so it was trying to send regions its way. Regionserver rejected them. So the master/balancer was going into a assign/reassign cycle destabilizing the cluster. Many puts and gets simply failed with NotServingRegionExceptions and took a long time to complete.

Exception from regionserver:
2011-08-06 23:57:13,953 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: SyncConnected, type: NodeCreated, path: /hbase/master
2011-08-06 23:57:13,957 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Telling master at 17.1.0.1:60000 that we are up
2011-08-06 23:57:13,957 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Telling master at 17.1.0.1:60000 that we are up
2011-08-07 00:07:39.648::INFO:  Logging to STDERR via org.mortbay.log.StdErrLog
2011-08-07 00:07:39.712::INFO:  jetty-6.1.14
2011-08-07 00:07:39.742::WARN:  tmpdir
java.io.IOException: Permission denied
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.checkAndCreate(File.java:1704)
        at java.io.File.createTempFile(File.java:1792)
        at java.io.File.createTempFile(File.java:1828)
        at org.mortbay.jetty.webapp.WebAppContext.getTempDirectory(WebAppContext.java:745)
        at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:458)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
        at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
        at org.mortbay.jetty.Server.doStart(Server.java:222)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.apache.hadoop.http.HttpServer.start(HttpServer.java:461)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.startServiceThreads(HRegionServer.java:1168)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:792)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:430)
        at java.lang.Thread.run(Thread.java:619)

Exception from datanode:
2011-08-06 23:37:20,444 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50075
2011-08-06 23:37:20,444 INFO org.mortbay.log: jetty-6.1.14
2011-08-06 23:37:20,469 WARN org.mortbay.log: tmpdir
java.io.IOException: Permission denied
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.checkAndCreate(File.java:1704)
        at java.io.File.createTempFile(File.java:1792)
        at java.io.File.createTempFile(File.java:1828)
        at org.mortbay.jetty.webapp.WebAppContext.getTempDirectory(WebAppContext.java:745)
        at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:458)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
        at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
        at org.mortbay.jetty.Server.doStart(Server.java:222)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.apache.hadoop.http.HttpServer.start(HttpServer.java:463)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:384)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:225)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1309)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1264)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1272)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1394)
2011-08-06 23:37:20,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hdp1122/17.1.0.22
************************************************************/

Exception from tasktracker:
2011-08-06 23:33:50,380 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50060
2011-08-06 23:33:50,380 INFO org.mortbay.log: jetty-6.1.14
2011-08-06 23:33:50,415 WARN org.mortbay.log: tmpdir
java.io.IOException: Permission denied
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.checkAndCreate(File.java:1704)
        at java.io.File.createTempFile(File.java:1792)
        at java.io.File.createTempFile(File.java:1828)
        at org.mortbay.jetty.webapp.WebAppContext.getTempDirectory(WebAppContext.java:745)
        at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:458)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
        at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
        at org.mortbay.jetty.Server.doStart(Server.java:222)
        at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
        at org.apache.hadoop.http.HttpServer.start(HttpServer.java:463)
        at org.apache.hadoop.mapred.TaskTracker.<init>(TaskTracker.java:935)
        at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:2837)
2011-08-06 23:33:50,416 INFO org.apache.hadoop.mapred.TaskTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down TaskTracker at hdp1122/17.1.0.22
************************************************************/


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6678,"In TestMergeTool, we pick an ""unlikely"" port for zookeeper to be on.  Perhaps it would be better if this was a privileged port < 1024.

{code}
    // Make it so we try and connect to a zk that is not there (else we might
    // find a zk ensemble put up by another concurrent test and this will
    // mess up this test.  Choose unlikely port. Default test port is 21818.
    // Default zk port is 2181.
    this.conf.setInt(HConstants.ZOOKEEPER_CLIENT_PORT, 10001);
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2894,"{code:title=MultiPut.java}
public class MultiPut implements Writable {
  public HServerAddress address; // client code ONLY                                              
        
  // map of regions to lists of puts for that region.                                             
  public Map<byte[], List<Put> > puts = new TreeMap<byte[], List<Put>>(Bytes.BYTES_COMPARATOR);
[...]
{code}
I don't see any reason for those fields to be public.  Let's make sure this doesn't leak to a stable release, otherwise it becomes part of the API.

Fixing this issue may be pointless if this ever happens: http://su.pr/1SG7fB

_edit:_ Similarly, {{MultiPutResponse}} has two fields that are {{protected}}, but need not to be:
{code:title=MultiPutResponse.java}
public class MultiPutResponse implements Writable {
                
  protected MultiPut request; // used in client code ONLY
                  
  protected Map<byte[], Integer> answers = new TreeMap<byte[], Integer>(Bytes.BYTES_COMPARATOR);
[...]
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5559,"HBASE-4440 adds a 'presplit' option to PerformanceEvaluation utility.

when the splits are generated, the first split has row-end-key=0 (zero).  Hence this split doesn't get any data.

For example, 
if total keyspace is 100, and splits requested are 5, 
generated splits => [0, 20, 40, 60, 80]
it should be => [20, 40, 60, 80, 100]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7640,"ERROR: Found lingering reference file
hdfs://node3:9000/hbase/entry_proposed/fbd1735591467005e53f48645278b006/recovered.edits/0000000000091843039.temp

recovered.edits is not a column family.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10515,"Here is related code:
{code}
    if (tableDir == null || regionDir == null) {
      LOG.error(""No archive directory could be found because tabledir ("" + tableDir
          + "") or regiondir ("" + regionDir + ""was null. Deleting files instead."");
      deleteRegionWithoutArchiving(fs, regionDir);
{code}
When regionDir is null, calling deleteRegionWithoutArchiving() would lead to NPE in FileSystem.delete().",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5285,"#On YCSB client machine:
/usr/local/bin/java -cp ""build/ycsb.jar:db/hbase/lib/*:db/hbase/conf/"" com.yahoo.ycsb.Client -load -db com.yahoo.ycsb.db.HBaseClient -P workloads/workloada -p columnfamily=family1 -p recordcount=5000000 -s > load.dat

loaded 5mil records, that created 8 regions. (balanced all onto the same RS)

/usr/local/bin/java -cp ""build/ycsb.jar:db/hbase/lib/*:db/hbase/conf/"" com.yahoo.ycsb.Client -t -db com.yahoo.ycsb.db.HBaseClient -P workloads/workloada -p columnfamily=family1 -p operationcount=5000000 -threads 10 -s > transaction.dat



#On RS that was holding the 8 regions above. 
2012-01-25 23:23:51,556 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x134f70a343101a0 Successfully transitioned node 162702503c650e551130e5fb588b3ec2 from RS_ZK_REGION_SPLIT to RS_ZK_REGION_SPLIT
2012-01-25 23:23:51,616 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer:
java.lang.RuntimeException: Cached an already cached block
at org.apache.hadoop.hbase.io.hfile.LruBlockCache.cacheBlock(LruBlockCache.java:268)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:276)
at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:487)
at org.apache.hadoop.hbase.io.HalfStoreFileReader$1.seekTo(HalfStoreFileReader.java:168)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:181)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:111)
at org.apache.hadoop.hbase.regionserver.StoreScanner.<init>(StoreScanner.java:83)
at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1721)
at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.<init>(HRegion.java:2861)
at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1432)
at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1424)
at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1400)
at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3688)
at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3581)
at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1771)
at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)
at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1325)
2012-01-25 23:23:51,656 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x134f70a343101a0 Attempting to transition node 162702503c650e551130e5fb588b3ec2 from RS_ZK_REGION_SPLIT to RS_ZK_REGION_SPLIT",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1037,"I've been running tests under Windows/Cygwin while on the road. Meanwhile they are not failing on Hudson. 

* TestInfoServers and TestTableMapReduce fail with timeout.

* TestThriftServer fails with an assertion failure related to timestamps.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9657,"In FSHLog#syncer(), we have this comment:
{code}
      // TODO: preserving the old behavior for now, but this check is strange. It's not
      //       protected by any locks here, so for all we know rolling locks might start
      //       as soon as we enter the ""if"". Is this best-effort optimization check?
      if (!this.logRollRunning) {
        checkLowReplication();
{code}
The implication is that checkLowReplication() may be running when FSHLog#rollWriter() is also running.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9,"I got this exception using a post-0.15.0 hbase trunk:

Caused by: java.io.IOException: java.io.IOException: java.lang.ArrayIndexOutOfBoundsException

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
	at java.lang.reflect.Constructor.newInstance(Unknown Source)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
	at org.apache.hadoop.hbase.HTable.commit(HTable.java:904)
	at org.apache.hadoop.hbase.HTable.commit(HTable.java:875)
	at xxx.PutHbase$HbaseUploader.writeHbaseNoRetry(PutHbase.java:107)


Where writeHbaseNoRetry looks like:

    private void writeHbaseNoRetry(HTable table, String column, String row, File contents) throws IOException {
      long lockid = table.startUpdate(new Text(row));
      try {
        table.put(lockid, new Text(column), FileUtil.readFile(contents));
        table.commit(lockid);
      } finally {
        table.abort(lockid);
      }
    }

I found this in my error logs -- it is rare, and I am not sure how to reproduce it.  Contents could be 1kb-100kb long.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3667,"Last night on one of our clusters I ran into the strange problem where metrics were showing in jmx, all but request rate seemingly.  Then, I restarted a single cluster member and it started reporting requests/second.  I did a few others and they started working.  Its strange.  Gary was helping out and noted that requests is only metric to use new MetricsRate otherwise, its not clear why it'd go wonky.  This issue is placeholder for figuring out whats up here.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-22,"Here's a couple of exceptions thrown by hql that should be fixed as we go:

{code}
08/01/24 10:39:42 INFO hbase.HConnectionManager$TableServers: Attempt 3 of 5 failed with <java.net.ConnectException: Connection refused>. Retrying after sleep of 10000 
08/01/24 10:39:52 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 1 time(s).08/01/24 10:39:53 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 2 time(s).
08/01/24 10:39:54 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 3 time(s).08/01/24 10:39:55 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 4 time(s).
08/01/24 10:39:56 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 5 time(s).08/01/24 10:39:57 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 6 time(s).
08/01/24 10:39:58 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 7 time(s).08/01/24 10:39:59 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 8 time(s).
08/01/24 10:40:00 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 9 time(s).
08/01/24 10:40:02 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:60000. Already tried 10 time(s).
08/01/24 10:40:03 WARN hbase.HConnectionManager$TableServers: Testing for table existence threw exception
org.apache.hadoop.hbase.MasterNotRunningException
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.getMaster(HConnectionManager.java:202)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRootRegion(HConnectionManager.java:691)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:329)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.relocateRegion(HConnectionManager.java:311)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:476)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:339)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.relocateRegion(HConnectionManager.java:311)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.listTables(HConnectionManager.java:291)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.tableExists(HConnectionManager.java:227)
        at org.apache.hadoop.hbase.hql.CreateCommand.execute(CreateCommand.java:49)
        at org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)
Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.hadoop.hbase.hql.BasicCommand.extractErrMsg(BasicCommand.java:62)
        at org.apache.hadoop.hbase.hql.BasicCommand.extractErrMsg(BasicCommand.java:68)
        at org.apache.hadoop.hbase.hql.CreateCommand.execute(CreateCommand.java:67)
        at org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)
{code}

or


{code}
Hbase> create table log(uname, uid);
Creating table... Please wait.
Exception in thread ""main"" java.lang.StringIndexOutOfBoundsException: String index out of range: -1
        at java.lang.String.substring(String.java:1938)
        at org.apache.hadoop.hbase.shell.BasicCommand.extractErrMsg(BasicCommand.java:60)
        at org.apache.hadoop.hbase.shell.BasicCommand.extractErrMsg(BasicCommand.java:64)
        at org.apache.hadoop.hbase.shell.CreateCommand.execute(CreateCommand.java:61)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:96)
[hadoop@latewhatgrow-lx bin]$ 
{code}
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15,"I've spent some time looking into this issue but there are not enough clues in the logs to tell where the problem is. Here's what I know.

Two region servers went down last night, a minute apart, during Paul Saab's 6hr run inserting 300million rows into hbase. The regionservers went down to force rerun of hlog and avoid possible data loss after a failure writing memory flushes to hdfs.

Here is the lead up to the failed flush:

...
2007-11-28 22:40:02,231 INFO  hbase.HRegionServer - MSG_REGION_OPEN : regionname: postlog,img149/4699/133lm0.jpg,1196318393738, startKey: <img149/4699/133lm0.jpg>, tableDesc: {name: postlog, families: {cookie:={name: cookie, max versions: 1, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, ip:={name: ip, max versions: 1, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}}}
2007-11-28 22:40:02,242 DEBUG hbase.HStore - starting 1703405830/cookie (no reconstruction log)
2007-11-28 22:40:02,741 DEBUG hbase.HStore - maximum sequence id for hstore 1703405830/cookie is 29077708
2007-11-28 22:40:03,094 DEBUG hbase.HStore - starting 1703405830/ip (no reconstruction log)
2007-11-28 22:40:03,852 DEBUG hbase.HStore - maximum sequence id for hstore 1703405830/ip is 29077708
2007-11-28 22:40:04,138 DEBUG hbase.HRegion - Next sequence id for region postlog,img149/4699/133lm0.jpg,1196318393738 is 29077709
2007-11-28 22:40:04,141 INFO  hbase.HRegion - region postlog,img149/4699/133lm0.jpg,1196318393738 available
2007-11-28 22:40:04,141 DEBUG hbase.HLog - changing sequence number from 21357623 to 29077709
2007-11-28 22:40:04,141 INFO  hbase.HRegionServer - MSG_REGION_OPEN : regionname: postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739, startKey: <img149/7512/dscn4444lightenedfi3.jpg>, tableDesc: {name: postlog, families: {cookie:={name: cookie, max versions: 1, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, ip:={name: ip, max versions: 1, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}}}
2007-11-28 22:40:04,145 DEBUG hbase.HStore - starting 376748222/cookie (no reconstruction log)
2007-11-28 22:40:04,223 DEBUG hbase.HStore - maximum sequence id for hstore 376748222/cookie is 29077708
2007-11-28 22:40:04,277 DEBUG hbase.HStore - starting 376748222/ip (no reconstruction log)
2007-11-28 22:40:04,353 DEBUG hbase.HStore - maximum sequence id for hstore 376748222/ip is 29077708
2007-11-28 22:40:04,699 DEBUG hbase.HRegion - Next sequence id for region postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739 is 29077709
2007-11-28 22:40:04,701 INFO  hbase.HRegion - region postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739 available
2007-11-28 22:40:34,427 DEBUG hbase.HRegionServer - flushing region postlog,img143/1310/yashrk3.jpg,1196317258704
2007-11-28 22:40:34,428 DEBUG hbase.HRegion - Not flushing cache for region postlog,img143/1310/yashrk3.jpg,1196317258704: snapshotMemcaches() determined that there was nothing to do
2007-11-28 22:40:55,745 DEBUG hbase.HRegionServer - flushing region postlog,img142/8773/1001417zc4.jpg,1196317258703
2007-11-28 22:40:55,745 DEBUG hbase.HRegion - Not flushing cache for region postlog,img142/8773/1001417zc4.jpg,1196317258703: snapshotMemcaches() determined that there was nothing to do
2007-11-28 22:41:04,144 DEBUG hbase.HRegionServer - flushing region postlog,img149/4699/133lm0.jpg,1196318393738
2007-11-28 22:41:04,144 DEBUG hbase.HRegion - Started memcache flush for region postlog,img149/4699/133lm0.jpg,1196318393738. Size 74.7k
2007-11-28 22:41:04,764 DEBUG hbase.HStore - Added 1703405830/ip/610047924323344967 with sequence id 29081563 and size 53.8k
2007-11-28 22:41:04,902 DEBUG hbase.HStore - Added 1703405830/cookie/3147798053949544972 with sequence id 29081563 and size 41.3k
2007-11-28 22:41:04,902 DEBUG hbase.HRegion - Finished memcache flush for region postlog,img149/4699/133lm0.jpg,1196318393738 in 758ms, sequenceid=29081563
2007-11-28 22:41:04,902 DEBUG hbase.HStore - compaction for HStore postlog,img149/4699/133lm0.jpg,1196318393738/ip needed.
2007-11-28 22:41:04,903 DEBUG hbase.HRegion - 1703405830/ip needs compaction
2007-11-28 22:41:04,903 INFO  hbase.HRegion - starting compaction on region postlog,img149/4699/133lm0.jpg,1196318393738
2007-11-28 22:41:04,903 DEBUG hbase.HStore - started compaction of 4 files in /hbase/compaction.dir/hregion_1703405830/ip
2007-11-28 22:41:04,905 DEBUG hbase.HRegionServer - flushing region postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739
2007-11-28 22:41:04,906 DEBUG hbase.HRegion - Started memcache flush for region postlog,img149/7512/dscn4444lightenedfi3.jpg,1196318393739. Size 133.1k
2007-11-28 22:41:05,087 DEBUG hbase.HStore - Added 376748222/ip/8686640221458382286 with sequence id 29081604 and size 95.8k
2007-11-28 22:41:05,419 FATAL hbase.HRegionServer - Replay of hlog required. Forcing server restart
org.apache.hadoop.hbase.DroppedSnapshotException: java.io.IOException: Could not complete write to file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data by DFSClient_-1010714652
	at org.apache.hadoop.dfs.NameNode.complete(NameNode.java:323)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

	at org.apache.hadoop.hbase.HRegion.internalFlushcache(HRegion.java:920)
	at org.apache.hadoop.hbase.HRegion.flushcache(HRegion.java:807)
	at org.apache.hadoop.hbase.HRegionServer$Flusher.run(HRegionServer.java:451)
...

Over in the namenode, I see the following related to the deleted file:

2007-11-28 22:40:48,546 DEBUG dfs.StateChange - *DIR* NameNode.mkdirs: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,546 DEBUG dfs.StateChange - DIR* NameSystem.mkdirs: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,546 DEBUG dfs.StateChange - DIR* FSDirectory.mkdirs: created directory /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,552 DEBUG dfs.StateChange - *DIR* NameNode.create: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652 at XX.XX.XX.29
2007-11-28 22:40:48,552 DEBUG dfs.StateChange - DIR* NameSystem.startFile: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652 at XX.XX.XX.29
2007-11-28 22:40:48,552 DEBUG dfs.StateChange - DIR* FSDirectory.addFile: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data is added to the file system
2007-11-28 22:40:48,552 DEBUG dfs.StateChange - DIR* NameSystem.startFile: add /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data to namespace for DFSClient_-1010714652
2007-11-28 22:40:48,557 DEBUG dfs.StateChange - *DIR* NameNode.create: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/index for DFSClient_-1010714652 at XX.XX.XX.29
2007-11-28 22:40:48,557 DEBUG dfs.StateChange - DIR* NameSystem.startFile: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/index for DFSClient_-1010714652 XX.XX.XX.29
2007-11-28 22:40:48,558 DEBUG dfs.StateChange - DIR* FSDirectory.addFile: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/index is added to the file system
2007-11-28 22:40:48,558 DEBUG dfs.StateChange - DIR* NameSystem.startFile: add /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/index to namespace for DFSClient_-1010714652
2007-11-28 22:40:48,573 DEBUG dfs.StateChange - *BLOCK* NameNode.addBlock: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652
2007-11-28 22:40:48,573 DEBUG dfs.StateChange - BLOCK* NameSystem.getAdditionalBlock: file /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652
2007-11-28 22:40:48,573 DEBUG dfs.StateChange - DIR* FSDirectory.addFile: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data with blk_-6398846109350112398 block is added to the in-memory file system
2007-11-28 22:40:48,573 INFO  dfs.StateChange - BLOCK* NameSystem.allocateBlock: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data. blk_-6398846109350112398
.....
2007-11-28 22:40:48,717 DEBUG dfs.StateChange - *DIR* NameNode.delete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,717 DEBUG dfs.StateChange - DIR* NameSystem.delete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,717 DEBUG dfs.StateChange - DIR* FSDirectory.delete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411
2007-11-28 22:40:48,717 DEBUG dfs.StateChange - DIR* FSDirectory.unprotectedDelete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411 is removed
....
2007-11-28 22:40:48,826 DEBUG dfs.StateChange - *DIR* NameNode.complete: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652
2007-11-28 22:40:48,826 DEBUG dfs.StateChange - DIR* NameSystem.completeFile: /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data for DFSClient_-1010714652
2007-11-28 22:40:48,827 WARN  dfs.StateChange - DIR* NameSystem.completeFile: failed to complete /hbase/hregion_376748222/cookie/mapfiles/3557442410867103411/data because dir.getFileBlocks() is null  and pendingFile is null

Only delete I see is on compaction completion but reading code doesn't look like its possible for deletes to be confused.

Will add extra logging to see if I can figure how the delete is coming about.

(We've fixed a similar problem before when compactions were done at region level)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-235,"I dropped a table with 121 regions, ans read from the web UI. Afterwards, most of the regions went away, but 6 remained counted and listed in the web UI. select * from .META. shows no rows, so in reality the regions are gone. This inconsistency gives a poor sense of the consistency of HBase.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-404,"Before HADOOP-2738, it was impossible to subclass Text and have it obey the ISA semantics because Text instances would directly access other instances private members. Now that this has been fixed, fix TextSequence so it really can be used wherever a Text can be used.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-26,"See 'stack - 30/Oct/07 09:51 PM' comment over in HADOOP-2083 for description of an error or see here: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/970/testReport/org.apache.hadoop.hbase.mapred/TestTableIndex/testTableIndex/

Seems like its a rare occurrence.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6966,"This jira will address the port of the compressed RPC implementation to trunk. I am expecting the patch to be significantly different due to the PB stuff in trunk, and hence filed a separate jira.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13459,"We have done quite a bit of data center migration work in the past year.  We modified verify replication a bit to help us out.

Things like:
Ignoring timestamps when comparing Cells
More detailed counters when discrepancies are reported between rows added the following counters: 
SOURCEMISSINGROWS,TARGETMISSINGROWS,SOURCEMISSINGKEYS, TARGETMISSINGKEYS
Also added the ability to run this job on any pair of tables and clusters.

If folks are interested I can put up the patch and backport.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13031,"Posted on the mailing list and seems like some people are interested.  A little background for everyone.

We have a very large table, we would like to snapshot and transfer the data to another cluster (compressed data is always better to ship).  Our problem lies in the fact it could take many weeks to transfer all of the data and during that time with major compactions, the data stored in dfs has the potential to double which would cause us to run out of disk space.

So we were thinking about allowing the ability to snapshot a specific key range.  

Ideally I feel the approach is that the user would specify a start and stop key, those would be associated with a region boundary.  If between the time the user submits the request and the snapshot is taken the boundaries change (due to merging or splitting of regions) the snapshot should fail.

We would know which regions to snapshot and if those changed between when the request was submitted and the regions locked, the snapshot could simply fail and the user would try again, instead of potentially giving the user more / less than what they had anticipated.  I was planning on storing the start / stop key in the SnapshotDescription and from there it looks pretty straight forward where we just have to change the verifier code to accommodate the key ranges.  

If this design sounds good to anyone, or if I am overlooking anything please let me know.  Once we agree on the design, I'll write and submit the patches.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5338,"It'd be nice to have support for ""SKIP"" mappings so that you can omit columns from the TSV during the import. For example

{code}
-Dimporttsv.columns=SKIP,HBASE_ROW_KEY,cf1:col1,cf1:col2,SKIP,SKIP,cf2:col1...
{code}

Or maybe HBASE_SKIP_COLUMN to be less ambiguous. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5585,"From IRC 

{noformat}
sulabhc	St^Ack: that fixed most of the issue, just one last question, I removed some META entries how do I put it back ?
sulabhc	St^Ack: putting from Hbase-shell does not seem to be possible
St^Ack	sulabhc: it is but the content in .META. is serialized Writable of HRegionInfo.
St^Ack	Can you find the region in the fs that you want to put back?
St^Ack	If so, cat its .regioninfo
St^Ack	it has binary format of the HRegionInfo that needs to be in .META. and a txt version.
St^Ack 	You'll need to create an HRegionInfo, serialize it as bytes, and then put that into .META.
St^Ack	Look around in the catalog package, the MetaEditor class, for how to do this from java.
St^Ack	We should really make this easier to do in shell...
St^Ack	or look in bin to see how we do some of this via (j)ruby
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5993,"HBASE-4102 added an atomic append.  For high performance situations, it would be helpful to be able to do appends that don't actually require a read of the existing value.  This would be useful in building a growing set of values.  Our original use case was for implementing a form of search in HBase where a cell would contain a list of document ids associated with a particular keyword for search.  However it seems like it would also be useful to provide substantial performance improvements for most Append scenarios.

Within the client API, the simplest way to implement this would be to leverage the existing Append api.  If the Append is marked as setReturnResults(false), use this code path.  If result return is requested, use the existing Append implementation.  

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7890,Add an index number before each region would make it easier to locate a region on the page.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7891,Adding an index number for each table region in table.jsp would make it easier to locate a region or to count regions.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2325,"In order to run jcarder on the unit tests, it's handy to be able to add jvm args to the junit test runner. This trivial patch adds a hook for this. Unfortunately I don't know much about maven, someone will have to help me for trunk.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2143,This was discussed in HBASE-2021. The compaction queue details is only exposed on RegionServer level but should be aggregated to the master metrics so that the total current status can be graphed. Since we change the RPC version anyways it is easy to add the to HServerLoad.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5268,"This is another part missing in the ""wide row challenge"".
Currently entire families of a row can be deleted or individual columns or versions.
There is no facility to mark multiple columns for deletion by column prefix.

Turns out that be achieve with very little code (it's possible that I missed some of the new delete bloom filter code, so please review this thoroughly). I'll attach a patch soon, just working on some tests now.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13879,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1990,"Consider the following client code...

	byte b[] = result.getValue( Bytes.toBytes(""family""), Bytes.toBytes(""qualifier"") );
        put.add( Bytes.toBytes(""family""), Bytes.toBytes(""qualifer""), Bytes.toBytes( ""value"")  );

... the requirement to supply family and qualifiers as bytes causes code to get cluttered and verbose.  At worst, it scares peoples un-necessarily about HBase development, and at best, developers inevitably will get tired of doing all this casting and then add their own wrapper classes around the HBase client to make their code more readable.

I would like to see something like this in the API...

	byte b[] = result.getValue( ""family""), ""qualifier"" );
        put.add( ""family"", ""qualifer"", Bytes.toBytes( ""value"")  );

... where the Hbase client can perform the required Bytes.toBytes() conversion behind the scenes.




",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12494,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3157,"New Increment class from HBASE-2946 is not exactly the same as the existing ICV call.  It does not iterate the snapshot and check for existing columns with the same version number.  Instead we rely on correct ordering from our read operations.

Should add a good unit test to verify this works as advertised.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14356,Parent issue added a timeout rule. The rule needs to be mentioned in all tests to take effect. Add it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3616,"HBASE-3507 added per region request count.
We should utilize this information so that HServerLoad can provide moving average of request counts to load balancer.
We can update this method in HRegionServer:
{code}
  private HServerLoad buildServerLoad() {
{code}
The above method can aggregate request counts from HRegions and store it in HServerLoad.RegionLoad",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5601,In addition to the overall block cache hit ratio it would be extremely useful to have per-column-family data block cache hit ratio metrics.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3840,"A common user error (and even hbase dev error) is to pass a vanilla Hadoop Configuration into HBase methods that expect to see all of the relevant hbase defaults from hbase-default.xml. This often results in NPE or issues locating ZK.

We should add a method like HBaseConfiguration.verify(conf) which ensures that the conf has incorporated hbase-default.xml. We can do this by checking for existence of hbase.defaults.for.version.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12889,We use the copy table job to ship data between clusters.  Sometimes we have very wide rows and it is nice to be able to set the batching and caching.  I'll attach trivial patches for you guys.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2434,"An option of number of rows to fetch every time we hit a region server should be added to mapreduce.Export so that createSubmittableJob() calls s.setCaching() with the specified value.

Also, an option of write buffer size should be added to mapreduce.Import so that we can set write buffer. Sample calls:
+    table.setAutoFlush(false);
+    table.setWriteBufferSize(desired_buffer_size);
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5512,"This came up from HBASE-2038
From Anoop:

- What we wanted from the filter is include a row and then seek to the next row which we are interested in. I cant see such a facility with our Filter right now. Correct me if I am wrong. So suppose we already seeked to one row and this need to be included in the result, then the Filter should return INCLUDE. Then when the next next() call happens, then only we can return a SEEK_USING_HINT. So one extra row reading is needed. This might create even one unwanted HFileBlock fetch (who knows).
Can we add reseek() at higher level?

From Lars:
Yep, for that we'd need to add INCLUDE_AND_SEEK_USING_HINT (similar to the INCLUDE_AND_SEEK_NEXT_ROW that we already have). Shouldn't be hard to add, I'm happy to do that, if that's the route we want to go with this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15175,"Currently JavaHBaseContext has methods for bulkPut, bulkDelete, etc

It is desirable to add support for checkAndPut, checkAndMutate, checkAndDelete as well.

See related thread:
http://search-hadoop.com/m/YGbbt3Szd24Vtpr&subj=Re+HBase+atomic+update

Thanks [~zzhan] for offline discussion",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7846,"Currently org.apache.hadoop.hbase.util.Merge needs 2 region names to be explicitly specified to perform a merge.  This can be cumbersome.
One idea for improvement is to have Merge to figure out all the adjacent regions and perform the merges.  

For example:
regions before merge: row-10, row-20, row-30, row-40, row-50
regions after merge: row-10, row-30, row-50

In the above example, region names of ""row-10"" and ""row-20"" are merged to become a new bigger region of ""row-10"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2991,"-refreshNodes capabilities should be added to bin/hbase (or to a new script called `hbaseadmin`, if we want to maintain command name consistency) with cluster exclusion functionality similar to the capabilities of dfsadmin and mradmin. For ease of adminis",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7358,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-765,"Spring can configure classes/object graphs via xml.  I am pretty much able to configure the entire MR object graph to launch MR jobs via spring except class IndexConfiguration.java. So instead of only using addFromXML() to configure IndexConfiguration, it would be nice to add support so Spring could set all class variables needed for initialization in IndexConfiguration without invoking addFromXML().  

Since the class IndexConfiguration already has setters and getters for almost all its members, it's almost compliant for a spring configuration bean except one issue: no ability to configure columnMap outside of calling addFromXML().  The easiest way i can figure is to allow a setter for the column map and put any logic for checking the map integrity there.  By adding a few methods to IndexConfiguration.java , it should solve the issue.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7169,"HTableMultiplexer is a useful client library for isolating regionserver failures, especially for clients that talk to several regionservers at a high throughput. It exposes useful metrics to the client on how many puts failed per regionserver. This patch adds average/max latency counters as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-470,"{code}
Problem 1.

hql > help enable;
Syntax error : Type 'help;' for usage.
hql > help disable;
Syntax error : Type 'help;' for usage.
..... ???

Added Feature 1.

hql > disable all;
hql > enable all;
hql > drop all;
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4612,"When having a lot of columns grouped by name I've found that it would be very useful to be able to scan them using multiple prefixes, allowing to fetch specific groups in one scan, without fetching the entire row. This is impossible to achieve using a FilterList, so I've added such support to the existing ColmnPrefixFilter while keeping backward compatibility.
The attached patch is based on 0.90.4, I noticed that the 0.92 branch has a new method to support instantiating filters using Thrift. I'm not sure how the serialization works there so I didn't implement that, but the rest of my code should work in 0.92 as well.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10681,"pom.xml in hbase write as

 <distributionManagement>
    <site>
      <id>hbase.apache.org</id>
      <name>HBase Website at hbase.apache.org</name>
      <!-- On why this is the tmp dir and not hbase.apache.org, see
               https://issues.apache.org/jira/browse/HBASE-7593?focusedCommentId=13555866&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13555866
               -->
      <url>file:///tmp</url>
    </site>

We expect pom.xml in hbase like hadoop can be:

 <distributionManagement>
  <repository>
      <id>${distMgmtStagingId}</id>
      <name>${distMgmtStagingName}</name>
      <url>${distMgmtStagingUrl}</url>
    </repository>
    <snapshotRepository>
      <id>${distMgmtSnapshotsId}</id>
      <name>${distMgmtSnapshotsName}</name>
      <url>${distMgmtSnapshotsUrl}</url>
    </snapshotRepository>
    <site>
      <id>hbase.apache.org</id>
      <name>HBase Website at hbase.apache.org</name>
      <!-- On why this is the tmp dir and not hbase.apache.org, see
               https://issues.apache.org/jira/browse/HBASE-7593?focusedCommentId=13555866&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13555866
               -->
      <url>file:///tmp</url>
    </site>
  </distributionManagement>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5475,"Currently importtsv (and now also Import with HBASE-5440) support using HFileOutputFormat for later bulk loading.
However, currently that cannot be without having access to the table we're going to import to, because both importtsv and Import need to lookup the split points, and find the compression setting.
It would be nice if there would be an offline way to provide the split point and compression setting.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5311,"Just like we periodically compact the StoreFiles we should also periodically compact the MemStore.
During these compactions we eliminate deleted cells, expired cells, cells to removed because of version count, etc, before we even do a memstore flush.

Besides the optimization that we could get from this, it should also allow us to remove the special handling of ICV, Increment, and Append (all of which use upsert logic to avoid accumulating excessive cells in the Memstore).

Not targeting this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5954,At least get recommendation into 0.96 doc and some numbers running w/ this hdfs feature enabled.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15075,"During the process of improving region normalization feature, I found that if region split request triggered by the execution of SplitNormalizationPlan fails, there is no way of knowing whether the failed split originated from region normalization.

The association of particular split request with outcome of split would give RegionNormalizer information so that it can make better normalization decisions in the subsequent invocations.

One approach is to embed metadata, such as a UUID, in SplitRequest which gets passed through RegionStateTransitionContext when RegionServerServices#reportRegionStateTransition() is called.
This way, RegionStateListener can be notified with the metadata (id of the requester).

See discussion on dev mailing list
http://search-hadoop.com/m/YGbbCXdkivihp2",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2817,"Right now we have a single HBASE_HEAPSIZE configuration. This isn't that great, since the HMaster doesn't really need much ram compared to the region servers. We should allow different java options and heapsize for the different daemon types.

Probably worth breaking out THRIFT, REST, AVRO, etc, as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3150,"We have this unique requirement where some column families hold data that is indexed from other existing column families. The index data is very large, and we end up writing these inserts into the WAL and then into the store files. In addition to taking more iops, this also slows down splitting files for recovery, etc.

Creating this task to have an option to suppress WAL logging on a per CF basis.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3779,"Currently daughter regions are placed on the same region server where the parent region was.
Stanislav Barton mentioned the idea that load information should be considered when placing the daughter regions.
The rationale is that the daughter regions tend to receive more writes. So it would be beneficial to place at least one daughter region on a different region server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10947,To extend functionality of HTable and HBaseAdmin we may need to subclass them. This JIRA allows to add a default constructor and probably remove the final variables in them so that we could subclass them.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-610,"HBASE-609 has an example of clock skew making it so master scanner missed edits placed there by a regionserver whose clock was in advance of the masters.  There may be other cases lurking where this kind of issue -- two servers are updating a particular row with off-clocks -- may bite us.  Could a regionserver that has a clock a long ways behind the running master's clock enter a split record that went in behind the current inforegion cell's version?  If so, the master wouldn't see the split.

One fix would be a new feature where cells had a version that autoincremented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21150,"After HBASE-15728 is integrated, the lazy table metrics registration results in penalty for the first flushes.
Excerpt from log shows delay (note the same timestamp 08:18:23,234) :
{code:java}
2018-09-02 08:18:23,232 DEBUG [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-2] regionserver.MetricsTableSourceImpl(124): Creating new                      MetricsTableSourceImpl for table 'testtb-1535901500805'
2018-09-02 08:18:23,233 DEBUG [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-2] regionserver.MetricsTableSourceImpl(137): registering metrics for testtb-   1535901500805
2018-09-02 08:18:23,234 INFO  [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-1] regionserver.HRegion(2822): Finished flush of dataSize ~2.29 KB/2343,       heapSize ~5.16 KB/5280, currentSize=0 B/0 for fa403f6a4fb8dbc1a1c389744fce2d58 in 280ms, sequenceid=5, compaction requested=false
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52758,1535901497238)-snapshot-pool11-thread-1] regionserver.MetricsTableAggregateSourceImpl(84): it took 6 ms to register  testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52758,1535901497238)-snapshot-pool11-thread-1,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-1] regionserver.MetricsTableAggregateSourceImpl(84): it took 0 ms to register  testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-1,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52762,1535901497314)-snapshot-pool9-thread-1] regionserver.MetricsTableAggregateSourceImpl(84): it took 6 ms to register   testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52762,1535901497314)-snapshot-pool9-thread-1,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52762,1535901497314)-snapshot-pool9-thread-2] regionserver.MetricsTableAggregateSourceImpl(84): it took 6 ms to register   testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52762,1535901497314)-snapshot-pool9-thread-2,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52758,1535901497238)-snapshot-pool11-thread-2] regionserver.MetricsTableAggregateSourceImpl(84): it took 5 ms to register  testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52758,1535901497238)-snapshot-pool11-thread-2,5,FailOnTimeoutGroup]
2018-09-02 08:18:23,234 DEBUG [rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-2] regionserver.MetricsTableAggregateSourceImpl(84): it took 6 ms to register  testtb-1535901500805 Thread[rs(hw13463.attlocal.net,52760,1535901497280)-snapshot-pool10-thread-2,5,FailOnTimeoutGroup]
{code}
This is a regression in that there were multiple (6 ms) delays before the flush can finish, waiting for the metrics table to be registered.

When first region of the table is opened on region server, we can proactively register table metrics.
This would avoid the penalty on first flushes for the table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16888,"a) If the delta has tags and the mutation doesn鈥檛 apply the TTL, we shouldn鈥檛 create the TagRewriteCell.
{noformat}

    List<Tag> tags = TagUtil.carryForwardTags(delta);
    long ts = now;
    Cell newCell = null;
    byte [] row = mutation.getRow();
    if (currentValue != null) {
     ...
    } else {
      // Append's KeyValue.Type==Put and ts==HConstants.LATEST_TIMESTAMP
      CellUtil.updateLatestStamp(delta, now);
      newCell = delta;
      tags = TagUtil.carryForwardTTLTag(tags, mutation.getTTL());
      if (tags != null) {
        newCell = CellUtil.createCell(delta, tags);
      }
    }

{noformat}

b) If the cell has tags, the ShareableMemoryTagRewriteCell will make duplicate copy of tags. 
{noformat}

      Cell clonedBaseCell = ((ShareableMemory) this.cell).cloneToCell();
      return new TagRewriteCell(clonedBaseCell, this.tags);

{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10174,"On user mailing list under the thread 'Guava 15', Kristoffer Sj枚gren reported NoClassDefFoundError when he used Guava 15.

The issue has been fixed in 0.96 + by HBASE-9667

This JIRA ports the fix to 0.94 branch",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13017,Lets backport that feature to branch-1.0 adapting HBASE-12035 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14289,"The default HBase load balancer (the Stochastic load balancer) is cost function based. The cost function weights are tunable but no visibility into those cost function results is directly provided.

This issue backports HBASE-13965 to 0.98 branch to provide visibility via JMX into each cost function of the stochastic load balancer, as well as the overall cost of the balancing plan.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18029,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5231,This JIRA backports per-table load balancing to 0.90,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8752,"0.94 already supports multi-thread compaction. It will be good it also supports multi-thread memstore flush, so that users can tune the number of threads for both compaction and flushing when running a heavy-write load.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10071,"Users tend to run hbase shell to query hbase quickly. The result will be shown as binary format which may not look clear enough when users write columns using specified types, such as long/int/short. Therefore, it may be helpful if the results could be shown as specified format. We make a patch to extend get/scan in hbase shell in which user could specify the data type in get/scan for each column as:
{code}
scan 'table', {COLUMNS=>['CF:QF:long']}
get 'table', 'r0', {COLUMN=>'CF:QF:long'}
{code}
Then, the result will be shown as Long type. The result of above get will be:
{code}
COLUMN                                        CELL                                                                                                           
 CF:QF                                timestamp=24311261, value=24311229
{code}
This extended format is compatible with previous format, if users do not specify the data type, the command will also work and output binary format.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17145,Is there any plan to backport the fix for hbase-6721 to any future 1.1.x releases. Is there a patch available for the same?,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9830,"Backport HBASE-9605 which is about ""Allow AggregationClient to skip specifying column family for row count aggregate""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1456,"Since so much in thrift has changed between the ancient version used in this branch and thrift 0.1.0, it will be useful to have a backport patch of all the changes so far.
There are some api tweaks. Like, gets returning lists, and just being empty when nothing was found instead of throwing NotFound.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3645,"Dmitriy was getting whack responses from his shell... NoSuchMethodException, etc., and it turned out that it was a long running shell that had run over a cluster restart.  We should at least fail if we've lost our zk session or reconnect.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9679,"It's not a top priority issue, seems to me.
Right now hbase do a linear scan to search a key within a hfile block on interst, in special case, e.g. 100% read scenario or high read/write ratio scanario, it's useful to do a binary search improvement to reduce the CPU cost and response time,  i think the biggest benefit should be the cpu:)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12259,"HydraBase ( https://code.facebook.com/posts/321111638043166/hydrabase-the-evolution-of-hbase-facebook/ ) Facebook's implementation of HBase with Raft for consensus will be going open source shortly. We should pull in the parts of that fb-0.89 based implementation, and offer it as a feature in whatever next major release is next up. Right now the Hydrabase code base isn't ready to be released into the wild; it should be ready soon ( for some definition of soon).

Since Hydrabase is based upon 0.89 most of the code is not directly applicable. So lots of work will probably need to be done in a feature branch before a merge vote.

Is this something that's wanted?

Is there anything clean up that needs to be done before the log implementation is able to be replaced like this?

What's our story with upgrading to this? Are we ok with requiring down time ?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3288,HBASE-3287 introduced two new configuration parameters.  These should both be optionally configurable at the family level.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3014,"I see a lot of UnknownScannerException messages in the log at ERROR level when I'm running a MapReduce job that scans an HBase table.  These messages are logged under normal conditions, and according to [~jdcryans], should probably be logged at a less severe log level like WARN.  

Example error message:
{code}
2010-09-16 09:20:52,398 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
org.apache.hadoop.hbase.UnknownScannerException: Name: -8711007779313115048
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1880)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:657)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
{code}

Reference to the HBase users mailing list thread where this was originally discussed:
http://markmail.org/thread/ttzbi6c7et6mrq6o

This is a simple, change, so I didn't include a formal patch.  If one is required, I will gladly create and attach one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6976,"As JD and Elliot mentioned, turning off ZKAssign logging can improve AM performance a lot.  During the testing, I also noticed that: after all regions are already opened, master UI still shows lots of regions in transition. It is because AM hasn't finished the ZK event processing yet.

Changing the logging level from debug to trace will improve AM performance. With HBASE-6611, I think AM is getting stable and reliable. I hope we don't need to see these logging any more.

The logging is still available after turning trace logging level on for AM and ZKAssign class.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1619,"While working on the HBase tap and scheme for Cascading I came across a situation where you want to add a bunch of KeyValues to a Put object.
Looking at the code for putting KeyValues in put we copy the family from the KeyValue and use that as a key. So I was thinking that it might be a good idea to just ""point""
into the KV by using a ImmutableBytesWritable and use that as the key instead. This is going to be good when working with MR jobs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9265,Could we simplify the installation process for Windows users by providing a Chocolatey package?,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20995,Clean up manual array copies in code.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7794,"Currently the CompactionTool requires an HStore to run the compaction, 
but with the StorageEngine (HBASE-7678) in place we can cleanup this code
{code}
return new HStore(tmpDir, region, hcd, fs, conf) {
  @Override
  public FileStatus[] getStoreFiles() throws IOException {
    return this.fs.listStatus(getHomedir());
  }

  @Override
  Path createStoreHomeDir(FileSystem fs, Path homedir) throws IOException {
    return storeDir;
  }
};
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4631,"There were some good comments in the review of HBASE-4460.

Cleanup the code and look at potential optimizations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1095,"There is no facility for tracking clients and their use of HRS, tables, etc. other entities of interest over time. Would be useful to track down heavy users, periodic spikes, and the like. Could be implemented as per-user (need concept and definition of user/session) metrics collected by HRS and periodically entered into a history table. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12338,"Since server side prefetching was not proved to be a good way to prefetch, we need to do it on client side.
This is a wrapper class that takes any instance of `ResultScanner` as the underneath scanning component. The class will schedule the scanning in a background thread. There is a buffering queue storing prefetched results, whose's length is configurable. The prefetcher will release the thread if the queue is full and wait for results to be consumed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-823,"Over in HBASE-745, Luo Ning profiling found that the number of open Readers has direct impact on memory used.  This issue is about putting an upper bound on the number of open Readers doing something like a bounded pool w/ a LRU eviction policy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18708,"Currently heap allocations for RS memory structures like {{memstore}} and {{lruCache}} are configured as percentage of total RS heap size. Since on-heap bucketCache uses RS heap, configuring it as a percentage of heap size will improve usability. Currently this can be configured either as a percentage of heap or a memory size in MiB and we can remove the latter option which is applicable to external or off-heap bucketCache.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-606,"Many user problems can be traced back to misconfiguring either Hadoop or HBase. Create a ""wizard"" script that helps them get off the ground.

Once a base configuration is generated, users can customize appropriately.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2751,"Having a lot of regions per region server could be considered harmless if most of them aren't used, but that's not really true at the moment. We keep all files opened all the time (except for rolled HLogs). I'm thinking of 2 solutions

 # Lazy open the store files, or at least close them down after we read the file info. Or we could do this for every file except the most recent one.
 # Close files when they're not in use. We need some heuristic to determine when is the best moment to declare that a file can be closed. 

Both solutions go hand in hand, and I think it would be a huge gain in order to lower the ulimit and xceivers-related issues.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10113,"DoubleBlockCache is a BlockCache that combines the LruBlockCache and SlabCache. CombinedBlockCache that combines LruBlockCache and BucketCache. These behaviors are (almost entirely) redundant. Consolidate the implementations into a single implementation, or reduce code duplication.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16078,"This ticket is result of discussion in [HBASE16044|https://issues.apache.org/jira/browse/HBASE-16044] to avoid ""hbase shell"" output parsing hacks. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3730,"The current DEFAULT_VERSIONS (in HColumnDescriptor) is 3, but there is no particular reason for this.  Many uses require only 1, and having a default that is different makes people confused (e.g., ""Do I need multiple versions to support deletes properly?"").

Reasonable values for the default are 1 and max int.  1 is the better choice.

Discussion on the mailing list suggests that the current value of 3 may have been derived from an example in the Bigtable paper.  The example does not suggest that there is anything special about 3, it's just an illustration.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3754,There's a number of unit tests that implement their own Server just to pass it to some other class without implementing anything specific except getting the Configuration. We should define one that all could use and refactor the others out.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8635,"Currently ""hbase.hregionserver.prefetcher.resultsize.max"" defines global limit for prefetching.
The default value is 256MB.

It would be more flexible to define this measure as a percentage of the heap.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8721,"this fix aims for bug mentioned in http://hbase.apache.org/book.html 5.8.2.1:

""Deletes mask puts, even puts that happened after the delete was entered. Remember that a delete writes a tombstone, which only disappears after then next major compaction has run. Suppose you do a delete of everything <= T. After this you do a new put with a timestamp <= T. This put, even if it happened after the delete, will be masked by the delete tombstone. Performing the put will not fail, but when you do a get you will notice the put did have no effect. It will start working again after the major compaction has run. These issues should not be a problem if you use always-increasing versions for new puts to a row. But they can occur even if you do not care about time: just do delete and put immediately after each other, and there is some chance they happen within the same millisecond.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2472,Yesterday it was suggested that we ship with a directory laden with the ordained patches needed for hdfs.  Assigning myself.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11504,"today we flush the socket buffer after each response.

The server maintains a queue of the calls to write. If this queue is not empty, we should not flush. We should do that only when the queue is empty. This will save some packets when nagle is disabled and we have a list of small responses to send (for example responses to puts, or small gets). This is linked to HBASE-11492.

The client has a queue as well, so we could do the same thing there.

There could be some drawbacks (if the server is overloaded between multiple channel for example writing the next response may take time), but it seems a good thing to do. For example, if the server if overloaded saving on buffer flush seems to be a nice thing to do.

Any opinion?
It's something I plan to do if I don't find a major drawback.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3281,"On cluster here, I see a log replay on a region taking about 28 seconds.  It does a replay of approximately 750,000 edits.  Since this can run for a while, we have a Progress By default we have:

{noformat}
      int interval = this.conf.getInt(""hbase.hstore.report.interval.edits"", 2000);
{noformat}

This led to about 300 ZK node re-transitions (from OPENING to OPENING) in about 30 seconds.  I haven't measured the operation in ZK but it's certainly several millis.

Seems like we could be adding a significant amount of overheard here (5ms * 300 = 1.5 seconds = 5%).  But I think some of these could be >5ms so we could be adding 10% or more.

One way to address this would be to do it based on size not entries (this region only had increments, so lots of small edits).  Another way would be to do it based on time instead of entries (check-in every 5 seconds, for example).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6940,I think we should enable gc by default.  Its pretty frictionless apparently and could help in the case where folks are getting off the ground.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3786,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11356,"When using uniform splitter to create a table, the start/endKey and region names can contain characters that break HTML, like <j, or "" .",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16370,"Getting this message trying to do a build with -Prelease:

{noformat}
[INFO] Restricted to JDK 1.7 yet jdk.tools:jdk.tools:jar:1.8:system contains org/relaxng/datatype/DatatypeLibrary.class targeted to JDK 1.8
[WARNING] Rule 3: org.apache.maven.plugins.enforcer.EnforceBytecodeVersion failed with message:
HBase has unsupported dependencies.
  HBase requires that all dependencies be compiled with version 1.7 or earlier
  of the JDK to properly build from source.  You appear to be using a newer dependency. You can use
  either ""mvn -version"" or ""mvn enforcer:display-info"" to verify what version is active.
  Non-release builds can temporarily build with a newer JDK version by setting the
  'compileSource' property (eg. mvn -DcompileSource=1.8 clean package).
Found Banned Dependency: jdk.tools:jdk.tools:jar:1.8
Use 'mvn dependency:tree' to locate the source of the banned dependencies.
[INFO] ------------------------------------------------------------------------
{noformat}

My JDK is 1.8.  But I wanted to build to target 1.7.  So I didn't' have the -DcompileSource=1.8.

The enforcer checks the jdk tools.jar and causes the error because the system JDK is 1.8.

This is a valid build/release use case as long as we support both 1.8 and 1.7.

We should exclude jdk tools.jar from the enforcer.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20654,"Currently only the count of regions in transition is exposed thru JMX.
Here is a sample snippet of the /jmx output:
{code}
{
  ""beans"" : [ {
...
  }, {
    ""name"" : ""Hadoop:service=HBase,name=Master,sub=AssignmentManager"",
    ""modelerType"" : ""Master,sub=AssignmentManager"",
    ""tag.Context"" : ""master"",
...
    ""ritCount"" : 3
{code}
It would be desirable to expose region name, state for the regions in transition as well.
We can place configurable upper bound on the number of entries returned in case there're a lot of regions in transition.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11993,"TableStateManager has the full set of TableNames already in memory,
we should expose the set of table names and use it instead of going to query the fs descriptors.

(Is there any reason why we don't have the descriptors in-memory too? saving memory with tons of tables? do we even support tons of tables?)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4058,"We should have a unit test that launches a minicluster and constructs a few tables, then deletes META files on disk, then bounces the master, then recovers the result with HBCK. Perhaps it is possible to extend TestHBaseFsck to do this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1590,"As discussed in HBASE-1554 there is a bit of a disconnect between how ClassSize calculates the heap size and how we need to calculate heap size in our implementations.

For example, the LRU block cache can be sized via ClassSize, but it is a shallow sizing.  There is a backing ConcurrentHashMap that is the largest memory consumer.  However, ClassSize only counts that as a single reference.  But in our heapSize() reporting, we want to include *everything* within that Object.

This issue is to resolve that dissonance.  We may need to create an additional ClassSize.estimateDeep(), we may need to rethink our HeapSize interface, or maybe just leave it as is.  The two primary goals of all this testing is to 1) ensure that if something is changed and the sizing is not updated, our tests fail, and 2) ensure our sizing is as accurate as possible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2512,2414 made RSOQueue.  Need to continue work of making it so I can do testing of this component independent of a live cluster.  Need to remove master from RSO instances and make it so RegionServerOperations are not responsible for puttint themselves back on the queue.  In involution is hard to follow.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3129,"Currently RegionServer FS latency metrics are a little deceiving.  Because fs*Latency is only updated during RegionServerMetrics::doUpdates, you are really getting the min/max of the latency average over 'hbase.period' instead of the actual min/max outliers.  We should refactor the code so we can display these outliers and reset them every 'hbase.period'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3682,"We currently make source jars for the main artifact, but not the test artifact.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17249,"Going through the code, found For Get/Scan's setTimeRange/setColumnFamilyTimeRange, it can use  TimeRange as reference instead of creating a new one.

Reference:
https://github.com/apache/hbase/blob/master/hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java#L500

https://github.com/apache/hbase/blob/master/hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java#L506

We can implement this in a similar way as filter:

https://github.com/apache/hbase/blob/master/hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/ProtobufUtil.java#L510

I checked it is same with branch-1.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17382,"Pointed out by [~tedyu] that 'Locate' is a verb and usually we need a noun here. 'Locating' or 'Location'?

Suggestion are welcomed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2681,"stack's word: ""Fellas have complained about the way broke lzo manifests itself. HBase will actually take on writes. Its only when it goes to flush that it drops the edits and in a way that is essentially hidden to the client - exceptions are thrown in the regionserver log. So, i'd say, make another issue if you don't mind but its not for you to fix, not unless you are inclined. It'd be about better user experience around choosing a compression that is not supported or not properly installed.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1843,"The ability to set the number of retries and the pause length between them on the HBaseClient through HBaseConfiguration.

I am working on an application that utilizes Hbase for real-time queries.  The dependency on Hbase is not critical so if HBase is not available for any reason the application should continue on doing its job without the data from Hbase.  Essentially I want HBase Client to fail quickly if the request to Hase is going to fail or take a long time to respond.  I have tested various scenarios with Zookeeper running/not running and the master running/not running.
 
Configuration:
Hbase 0.20.0 & Hadoop 0.20.1
Pseudo distributed mode
Java client using HTablePool
 
 
When ZK, Master, Regionserver and my app are running, I stop the Hbase master/regionserver.  The HBaseClient then begins to complain:
16:26:51,273 INFO [HBaseClient] Retrying connect to server: /192.168.1.55:44808. Already tried 0 time(s).
16:26:53,274 INFO [HBaseClient] Retrying connect to server: /192.168.1.55:44808. Already tried 1 time(s).
...already tried 9 time(s)....
16:27:10,294 INFO [HbaseRPC] Server at /192.168.1.55:44808 not available yet, Zzzzz...

**** This is despite the fact that I set hbase.pause to be 25 ms and the retries.number = 2.  ****

I restart the Master and RegionServer and then send more client requests through HTablePool.  It has the same ""Retrying to connect to server:"" messages.  I noticed that the port number it is using is the old port for the region server and not the new one assigned after the restart.  The HbaseClient does not seem to recover unless I restart the client app.  When I do not use HTablePool and only Htable it works fine.

Issue:
Setting and using hbase.client.pause and hbase.client.retries.number parameters.  I have rarely gotten them to work.  It seems to default to 2 sec and 10 retries no matter if I overwrite the defaults on the client and the server.  Yes, I made sure my client doesn't have anything in the classpath it might pick-up.
<property>
<name>hbase.client.pause</name>
<value>20</value>
</property>
<property>
<name>hbase.client.retries.number</name>
<value>2</value>
</property>",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4818,"As many HBase users use binary row keys rather than strings to optimize memory consumption displaying an escaped string in the HBase shell isn't useful (and takes a lot of screen space)
Allowing user to provide a row key formatter as part of the scan\get commands would allow developers to display the row key in a way thats makes sense for them.

Example:
scan 'stats', { ROWFORMATTER => MyRowFormatter.new }

The row formatter simply gets the bytes array key and formats it to a string.
Its an easy change tomake with simple monkey-patching of the shell commands but I would be happy to see it as part of the shell itself.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8777,"HBase currently determines which server to go to, then creates delayed callable with pre-determined server and goes there. For later 16-32-... second retries this approach is suboptimal, the cluster could have seen massive changes in the meantime, so retry might be completely useless.
We should re-locate regions after the delay, at least for longer retries. Given how grouping is currently done it would be a bit of a refactoring.

The effect of this is alleviated (to a degree) on trunk by server-based retries (if we fail going to the pre-delay server after delay and then determine the server has changed, we will go to the new server immediately, so we only lose the failed round-trip time); on 94, if the region is opened on some other server during the delay, we'd go to the old one, fail, then find out it's on different server, wait a bunch more time because it's a late-stage retry and THEN go to the new one, as far as I see. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2921,"When you start the HBase shell from bash, you see the following prompt:

hbase(main):001:0>

And typing in ""conf"" as the command yields the following prompt-related information:

conf.prompt_c=""%N(%m):%03n:%i* ""
conf.prompt_i=""%N(%m):%03n:%i> ""
conf.prompt_mode=:DEFAULT
conf.prompt_n=""%N(%m):%03n:%i> ""
conf.prompt_s=""%N(%m):%03n:%i%l ""

On the other hand, opening the HBase shell as python subprocess yields an empty string as the prompt string. Furthermore, sending it the ""conf"" command through a pipe yields the following output:

conf.prompt_c=nil
conf.prompt_i=nil
conf.prompt_mode=:NULL
conf.prompt_n=nil
conf.prompt_s=nil

This occurs because irb checks if stdout is a tty and changes the prompt configuration in case it is.  It would be very useful for the hbase shell to have a --force-tty option that overrides this check.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8193,Currently HBaseAdmin.isTableAvailable() only checks in META to say if a  table is available or not. It should also check with the zkTable state if it is ENABLED before returning true.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4448,"Setting up and tearing down HBaseTestingUtility instances in unit tests is very expensive.  On my MacBook it takes about 10 seconds to set up a MiniCluster, and 7 seconds to tear it down.  When multiplied by the number of test classes that use this facility, that's a lot of time in the build.

This factory assumes that the JVM is being re-used across test classes in the build, otherwise this pattern won't work. 

I don't think this is appropriate for every use, but I think it can be applicable in a great many cases - especially where developers just want a simple MiniCluster with 1 slave.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3504,The HLog.updateLock protects the rolling of logs with concurrent writes to the HDFS log file. This is a scalability bottleneck for a workload that comprises mostly of counter-increments.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10424,"Often there are cases of a region not getting assigned due to timeouts (while others do go through). In this case, the Master does appear to enter a never-ending retry operation where it retries each chosen server several times before moving to another.

For debugging in such a scenario, where the master is best aware of the situation, it could use that to its advantage and help capture issues better if it probably setup an N retry threshold (for # of servers tried) and run a HTTP GET on the current timing out RS's info port, to capture its /stacks end point and dump the output in its logs for investigation later.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2465,"On startup, in verifyClusterState, the master contacts each region server serially. If a region server is down it will retry for several minutes (if the client retry setting is high). During this period, the master cannot be shut down, and also isn't processing real work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6273,"This JIRA is in reference to JD's comments regarding the clean up needed in isMasterRunning().  Refer to 
https://issues.apache.org/jira/browse/HBASE-6240?focusedCommentId=13400772&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13400772",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3886,"This is an interesting one.  HServerInfo is deprecated in TRUNK and replaced effectively by a new class ServerName.  Both equate instances of HSI or SN if the two instances have the same hostname and port.  Well, thats well and good but what if we are getting signals from a server whose IP has changed?  In this case, we'll see the server in its new location come in but we'll treat it as though we'd seen it already, thought its IP had changed.  We don't want this.

This facility is needed for rare case where a server is moved from one IP to another.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7085,"An HTableInterface with isAutoFlush()==false does not currently automatically flushCommits when unlockRow is is called.  

In our system this means that we must issue the flushCommits when we run in isAutoFlush()==false mode. 

The API will automatically flush when closing the table interface but since it unlocks before flushing we have a problem.  

I can't see any logic in releasing locks without first flushing the commits and as such suggest that including an automatic flush before unlocking would improve the API.   ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7292,"The class description javadoc for HTablePool contains a sentence that makes no sense in the context (it appears to be part of an incorrectly-applied patch from the past). The sentence references the correct way of returning HTables to the pool, but it actually makes it more difficult to understand what the correct way of returning tables to the pool actually is.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3692,"A user on IRC yesterday had an issue with RejectedExecutionException coming out of HTable sometimes. Apart from being very confusing to the user as it comes with no message at all, it exposes the HTable internals. 

I think we should handle it and instead throw something like DontUseHTableInMultipleThreadsException or something more clever. In his case, the user had a HTable leak with the pool that he was able to figure out once I told him what to look for.

It could be an unchecked exception and we could consider adding in 0.90 but marking for 0.92 at the moment.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4198,"As I mentioned on the mailing list, the way HBA.flush behaves is different from what is used to be. Right now here's how flush and compact work:

 - When calling HBA.flush it will fetch the list of regions then will contact their owners directly one by one and the flush will be done inline. The major issue here is flushing a big table will take a *long* time, but it does give some guarantee that all the flushes are done. The old behavior was that all flushes were done async.

 - For compactions it also calls every regions' owners one by one and instead of being inline the compactions are queued. This is not very different from the old behavior, except that the master has nothing to do now.

What I believe we need to do:

 - Both methods should have the same guarantees, either they return when everything is flushed/compacted or they don't.
 - If we do inlining, we should issue the requests in parallel a la HTable.batch.
 - We definitely need to offer an async version.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1863,"o.a.h.h.i.HbaseObjectWritable does not support read/write of unknown Writable object (will throw UnsupportedIoerationException); 
in addition, writing a known Writable object, e.g., HColumnDescriptor, will write the code twice.
furthermore, it may be useful to change addToMap from private to public.

not causing any problem with hbase, but will be nice to have the above corrected, especially part of the code is already there.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2816,"Implementing Object.equals() and hashCode() for Get, Put, etc, would be handy. The particular use case is using Mockito to verify operations on mock HTable objects.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2689,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1388,"It would be useful to have a suite of performance tests so that HBase can be compared to other similar projects. This could then be automated on the same hardware (perhaps even EC2?).

There is a project called Vpork, developed by Jon Travis to test Voldemort that would be a good starting point. It is written in Groovy and can use the Java client libs. This version has been slightly refactored and also supports Cassandra:
http://github.com/johanoskarsson/vpork/tree/master",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3718,"The regionserver uses a ConcurrentSkipList to store the KVs in the memstore. Although the order complexity of a lookup is O(n), still the latency to lookup a specific key in the memstore is very large, especially when the memstore is large and the KV.compare() method is costly.

One optimization is to investigate using a ConcurrentHashMap (instead of ConcurrentSkipList). The lookup and insertion cost is minimized. We can do it only for column-families that are marked as ""do not support rangescans"". ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-975,"Keeping a MapFile's start and end key in cache would save us some seeks, see if it can be done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10932,"The typical use case of RowCounter is to do some kind of data integrity checking, like after exporting some data from RDBMS to HBase, or from one HBase cluster to another, making sure the row(record) number matches. Such check commonly won't require much on response time.
Meanwhile, based on current impl, RowCounter will launch one mapper per region, and each mapper will send one scan request. Assuming the table is kind of big like having tens of regions, and the cpu core number of the whole MR cluster is also enough, the parallel scan requests sent by mapper would be a real burden for the HBase cluster.
So in this JIRA, we're proposing to make rowcounter support an additional option ""--maps"" to specify mapper number, and make each mapper able to scan more than one region of the target table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15630,"Trying to verify latest release (1.2.1), and I found it a bit inconvenient to parse the *.mds checksum file. The line wrapping, white space, and the general format of the file does not lend itself for easy verification.

I suggest using the standard ""coreutils"" format for md5sum, sha*sum, etc., instead: <lowercase-hash><space><asterisk(binary-flag)><filename>
{code}
# md5
3d66c0dd4f38fa881046fe64dd680a7a *hbase-1.2.1-src.tar.gz
# sha1
3666a4829d9a8d9285173bfa8e8d0ff5423a22d6 *hbase-1.2.1-src.tar.gz
# rmd160
#fb318e84b6256492cfb990aec2238a64c2da21ad *hbase-1.2.1-src.tar.gz
# sha224
89d341a55069e4875f9e6859737062fd7a4c11596811731c4ba95ca0 *hbase-1.2.1-src.tar.gz
# sha256
e8000a65e98d4c5db7bab54da99a57209fe4ea777ab41e91ae8ccf7bfa2d50dd *hbase-1.2.1-src.tar.gz
# sha384
49aa0620bf0fbe20bbde66cecabb76b22defb9ee609936edc3952889e6484e55c88f1c93d6258a2eaab4a9d5188b6170 *hbase-1.2.1-src.tar.gz
# sha512
28956a35a01ae87e9f733664c52c6fd25f9a60a1ff7047bbf306cd433c2a5b863c9bf05aba1d58792b86eec9943ae00e772c4b76fb81c5d210cf256cd074189b *hbase-1.2.1-src.tar.gz
{code}
(comment lines added for humans, but ignored by tools; commented out rmd160, because not a coreutils supported algorithm; binary flag optional, could use another space instead... probably only matters for some dos tools)

This makes it very easy to verify multiple files and hashes using: {{shasum -c file.mds}} or {{sha1sum -c file.mds}} or {{md5sum -c file.mds}}.

In addition to the file format change, I suggest these two additional changes:

1. Drop rmd160. It's not nearly as popular as the others, and it doesn't lend itself to easy verification (no coreutils equivalent command like md5sum, sha1sum, etc.)
2. Concatenate hashes from all files into a single file. This makes it easier to verify all downloads at once.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2165,"Improve by 

- moving the ""blocking"" FS scan into a thread so that the UI loads fast and initially displays ""n/a"" but once it has completed the scan it displays the proper numbers
- explaining what fragmentation means to the user (better hints or help text in UI)
- Switch -ROOT- (and maybe even .META.?) to simply say ""Yes"" or a tick that it is fragmented as it only has 0% or 100% available (since it has only a single region)
- also computing the space occupied by each table and the total and - if easily done - add a graph to display it (Google Pie Chart would be nice but is an external link)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21066,"聽
{code:java}
public boolean isTableState(TableName tableName, TableState.State... states) {
 try {
 TableState tableState = getTableState(tableName);
 return tableState.isInStates(states);
 } catch (IOException e) {
 LOG.error(""Unable to get table "" + tableName + "" state"", e);
 // XXX: is it safe to just return false here?
 return false;
 }
 }
聽
{code}
聽

When cannot get table state, returning false is not always safe or correct.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17383,"Currently we get this log
{code}
2016-12-28 21:11:14,349 INFO  [RpcServer.deafult.FPBQ.Fifo.handler=39,queue=9,port=16041] regionserver.MemStoreFlusher: Blocking updates on stobdtserver5,16041,1482938527980: the global offheap memstore size 12.6 G + global memstore heap overhead 4.0 G is >= than blocking 12.6 G size
{code}
Here the global offheap memstore size is greater than the blocking size. The memstore heap overhead need not be included in this log unless the higher water mark breach is only due to the heap overhead.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5826,"HBASE-5782 solved the correctness issue for the sync of HLog edits.
Todd provided a patch that would achieve higher throughput.

This JIRA is a continuation of Todd's work submitted there.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3055,"Working on the failed hbase-3019 some improvements were made to bulk assignment:

1. Temporarily disabling timeout on regions in transition
2. A executor service running assignments per server rather than a thread for every server (if big cluster thread-per could be OTT).

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1158,"If we do not take the startcode into consideration when recovering from a server death, then we cannot know if the data in ROOT or META pertains to the the current instance or the previous one.

With ZK this should be easier if we modify HServerAddress to contain the startCode of a HRegionServer instance. It would be immediately visible whether or not the region was on the dead server or the new server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12713,"I find that the policy of region split which in IncreasingToUpperBoundRegionSplitPolicy will be use the value of ""maxfilesize"" when the count of region is greater than 100. But sometimes 100 regions is not too much for a cluster that has 50 or more regionservers.
So i think this policy should consider the density of the regions but not the total count of the regions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-635,"Currently, the TableMap spawns a number of Map tasks matching the number of regions being served. However, each task reports 0% complete until the task is fully complete and jumps to 100%. It would be ideal if each task accurately reported it's percentage complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7349,The javadoc check should look for an increase in the number of warnings. It can do so by running javadoc against trunk before running it for the patch. This will increase build times.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17392,"When user misconfigures 'hbase.hstore.engine.class', region server complains ""Class not found"" and gives up. In this case, we need to load the DefaultStoreEngine to avoid that. Sanity check needs to be done to prevent user from misconfiguration as well.

https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreEngine.java#L121",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3945,"Keeping a region on the same region server would give good stability for active scanners.
We shouldn't reassign the same region in two successive calls to balanceCluster().",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3551,"I hung with a user Marc and we were looking over configs and his cluster profile up on ec2.  One thing we noticed was that his 100+ 1G regions of two families had ~2.5G of heap resident.  We did a bit of math and couldn't get to 2.5G so that needs looking into.  Even still, 2.5G is a bunch of heap to give over to indices (He actually OOME'd when he had his RS heap set to just 3G; we shouldn't OOME, we should just run slower).  It sounds like he needs the indices loaded but still, for some cases we should drop indices for unaccessed files.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-17926,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-20837,"While working on HBASE-20557 contribution, we figured out that the checkstyle build target (ImportOrder's `groups` [http://checkstyle.sourceforge.net/config_imports.html] ) was different from the development supported IDE (e.g. IntelliJ and Eclipse) formatter, we would provide a fix here to sync between聽[dev-support/hbase_eclipse_formatter.xml|https://github.com/apache/hbase/blob/master/dev-support/hbase_eclipse_formatter.xml] and [hbase/checkstyle.xml|https://github.com/apache/hbase/blob/master/hbase-checkstyle/src/main/resources/hbase/checkstyle.xml]

This might need to backport the changes of master to branch-1 and branch-2 as well.

Before this change, this is what checkstyle is expecting for import order

聽
{code:java}
import com.google.common.annotations.VisibleForTesting;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.classification.InterfaceAudience;
import org.apache.hadoop.hbase.conf.ConfigurationObserver;{code}
聽

And the proposed import order with the respect to HBASE-19262 and HBASE-19552 should be

聽
聽聽 !IDEA import layout.png!",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16803,"HBASE-16773 fixed a case where PriorityRpcServer handler threads are all occupied accessing hbase:acl table.

However, the fix relies on the fact that there is single region in hbase:acl table so that the access can be local.

As discussed at the end of HBASE-16773, we should disable split of hbase:acl table as well.
hbase:meta is normally much larger than hbase:acl table and it has only one region.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12463,"By default Memstore uses MSLAB. For each of the Cell added to memstore, we will allocate area in MSLAB and return the area in BR wrapper. So each time a new BR object is created. Instead of this we can have ThreadLocal level BR instance and each time when allocate() API return the BR, we can set the byte[], offset, length on this ThreadLocal level BR instance. So totally only those many objects as the threads count (max handler count)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7978,"I would like to discuss the possibility of merging the prefix tree module into the hbase-server module. 

Ideally, I think we should have hbase-mapreduce and hbase-storage modules, the latter one containing most of HFile code. hbase-mapreduce depends on hbase-storage so that it knows how to encode hfiles. prefix-tree belongs to hbase-storage. 

prefix tree is just another DBE, although a big one, and it rightfully belongs with her sisters. The fact that the code is independent from the rest of the code base does not mean that it should have it's own module. We should keep the number of modules manageable, and stay away from hadoop trunk's one-module-per-package policy. 

Related: HBASE-7936",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2970,"Bloom filters are currently using the LRU block cache.  They are being treated as normal data blocks, however, it would be advantageous if we could treat me separately and give them their own portion of the LRU.

What we've seen in practice is that some blooms get very big and are accessed frequently.  This leads to blooms consuming a majority of the cache so lots of churn on data blocks.

In any case, I think it is desirable in general to be able to control how much memory is used for blooms and other meta data.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6841,"I got myself into a situation where I needed to truncate a massive table while it was getting hits and surprisingly the clients were not recovering. What I see in the logs is that every time we prefetch .META. we setup a new HConnection because we close it on the way out. It's awfully slow.

We should just turn it off or make it useful. jstacks coming up.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11334,"Migrating to new log implementations is underway as in HBASE-10092. 
Next step would be to abstract them so that the hadoop community can standardize on a logging layer that is easy for end users to tune.

Simplest way to do this is use SLF4j APIs as the main interface and binding/ implementation details in the docs as necessary.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3361,"There's a few reasons to break tests out into their own module:
1. Allowing maven users to easily re-consume test utilities as part of a ""test"" package which doesn't pollute the runtime classpath
2. Putting integration tests (tests that create or require a cluster) in their own module allows users to easily rebuild and test the core of HBase without running long-running tests, reducing the developer iteration loop

After some discussions with Stack on IRC, it sounds like there was some historic investigation of this which was abandoned because the module system was becoming too complex. I'd suggest that rather than trying to break out components all at once into their modules, evaluate creation of modules on a case-by-case basis and only create them when there's a significant use case justification.

I created a sample of what I'm thinking about (based on the current trunk) and posted it on github
git://github.com/ekohlwey/modularized-hbase.git",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2598,As described in the TODOs in HConstants.java,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21664,"When trying to minimize the number of methods in ClusterConnection, I found that QuotaStatusCalls uses several methods in ClusterConnection, and it is not under the client package. And finally I found that, only QuotaTableUtil uses it, and all the methods which reference it is used for testing.

 So let's move these methods to the test code base, so we are free to move it anywhere, so we do not need to declare the methods in ClusterConnection any more.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1846,Move thrift to contrib,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2814,"Hello, i have create small patch for thrift interface to increament many columns in many rows in many tables, but im not a hbase or even java developer so if someone want to look at this and create somethink better i would be appreciate.

thanks
S.Bauer

PS. sorry for my bad english ;) ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1521,"There are some additional optimizations in the specialized StoreScanner and also in HFile for minor compactions.  For example, there is some KV disassembling and sanity checking in HFile even though in a minor compaction these checks have already been run during the flush.

Another area to discuss is whether we should actually process deletes during minor compactions.  It's not especially expensive (ScanDeleteTracker is quite simple) but it requires looking at both the row and the qualifier value of every single KV.  Removing this would drop our axiom that ""Deletes only apply to later storefiles"", which is used during Get processing to have more efficient delete handling.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11601,"Although HBASE-11185 exists, it is geared towards the snapshot manifest code.  We have used snapshots to ship our two largest tables across the country and while doing so found a few potential optimizations where doing things in parallel helped quite a bit.  I can attach a patch containing changes I've made and we can discuss if these are changes worth getting pushed to 0.94.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1255,"Current Process command-line args is very simple in master and Region Server.
There is a comment
    // Process command-line args. TODO: Better cmd-line processing
    // (but hopefully something not as painful as cli options).

So we still can use CLI http://commons.apache.org/cli/usage.html or someone from list of alternatives http://jopt-simple.sourceforge.net/

What is disadvantage of CLI ?

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6744,"Per table balancing just balances regions based on tables.  However, overall, regions could be seriously unbalanced.

For example, if you shutdown all most all region serves in a cluster, then create tons of new tables (no region pre-split), then start up all region servers.  You will see the regions won't move to other region servers since they are balanced per table (only one region for a table at this moment).

If we can make the balance algorithm sophisticated enough, we don't need the configuration hbase.master.loadbalance.bytable.  We can do the regular and bytable balancing at the same time.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18370,"Currently once a region goes into FAILED_OPEN state this requires operator intervention. With some underlying causes, this is necessary. With others, the master could eventually successfully deploy the region without humans in the loop. The master should optionally attempt automatic resolution of FAILED_OPEN states with a strategy of: delay, unassign, reassign. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8196,"There has been some interest in porting region merge (HBASE-7403), and making splits more stable in 0.94. For online merge, we depend on HBASE-7721, thus we might need the backport. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-21011,"There is a corner case when cleaner chore for HFiles and oldwals is disabled, admin/user needs to manually execute admin command {{cleaner_chore_run}} to clean the old HFiles and oldwals. Existing logic of {{cleaner_chore_run}} is to [firstly trigger the HFiles cleaner and then oldwals cleaner|https://github.com/taklwu/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java#L1414-L1420], and only return succeed if both completes.聽

but when running this {{cleaner_chore_run}} command, there is a potential use case that admin would like trigger the cleaner for only oldwals or hfiles but still keep the automatic cleaner chore disabled. So, this change aims to provide support for this corner case, and provide flexibility for those user with cleaner chore disabled by default to execute admin CLI to run oldwals and HFiles cleaning procedure individually.

NOTE that {{cleaner_chore_run}} was introduced in HBASE-17280, this patch added options 'hfiles' and 'oldwals' to it. Also fix default behavior of {{cleaner_chore_run}} will be only ran when cleaner chore is set to disabled, e.g. the proposed admin CLI options are
{noformat}
hbase> cleaner_chore_run               # this was introduced in HBASE-17280, but changed the behavior to only ran when cleaner chore is set to disabled

hbase> cleaner_chore_run 'hfiles'      # added, ran when cleaner chore is set to disabled
hbase> cleaner_chore_run 'oldwals'     # added, ran when cleaner chore is set to disabled
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5273,"While reworking on the coprocessor blog, I start to realize that we should have a template of coprocessor that helps users to quickly start to develop, test a customized coprocessors. Currently there are some built-in coprocessors but all over the code base, and a user has to search around the code to see how to develop a new one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12890,We have a very large cluster and we frequently add remove quite a few regionservers from our cluster.  Whenever we do this the balancer moves thousands of regions at once.  Instead we provide a configuration parameter: hbase.balancer.max.regions.  This limits the number of regions that are balanced per iteration.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4991,"See discussion titled 'Able to control routing to Solr shards or not' on lily-discuss
User may want to quickly dispose of out of date records by deleting specific regions. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5341,"Hbase 0.92.0 was released with two artifacts, plain and security. The security code is built with -Psecurity. There are two tarballs, but only the plain jar in maven repo at repository.a.o. 

I see no reason to do a separate artifact for the security related code, since 0.92 already depends on secure Hadoop 1.0.0, and all of the security related code is not loaded by default. In this issue, I propose, we merge the code under /security to src/ and remove the maven profile. 

Edit: after some discussion, and the plans for modularizing the build to include a security module, we changed the issue description to push the security jars in 0.92.1 to maven repo. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1755,Moving to 0.22.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4274,"If you restart HDFS underneath HBase, when HBase isn't taking any write load, the region servers won't ""notice"" that there's any problem until the next time they take a write, at which point they will abort (because the pipeline is gone from beneath them). It would be better if they wrote some garbage to their HLog once every few seconds as a sort of keepalive, so they will aggressively abort as soon as there's an issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1839,"Currently, the methods are misnamed.  Fix for 0.21.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1406,"The current HRS implementation is a mess, especially after ZooKeeper additions to handle Session Expired events. See HBASE-1311.
It contains logic to restart itself which caused a lot of fields to be non-final that can be. It should be split out to two separate class, one that runs HRS duties and one that watches over the first in a join/restart loop. Using this means a special event like a ZooKeeper Session Expired wouldn't require special restart code, just an abort. The new wrapper class will handle restarting.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7449,"we encountered a hung issue, the thread dump shows:
most of threads waiting to a lock but there isn't lock holder be found

We know there were some discuss before, e.g:
https://issues.apache.org/jira/browse/HBASE-3622
http://bugs.sun.com/view_bug.do?bug_id=6822370
http://cs.oswego.edu/pipermail/concurrency-interest/2012-August/009635.html
https://blogs.oracle.com/dave/entry/a_race_in_locksupport_park

My point is that the JVM bug is still not fixed(at least for latest 1.6.0_37, the hotspot version: 20.12-b01), it's not just a old JVM issue, let's update the trouble shooting document firstly if possible. I'm trying to reproduce with a debug openjdk version in-house.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5517,"Originated from the discussion under HBASE-2038 [Coprocessor based IHBase]

Currently preNext() and postNext() will be called once for a next() call into HRegionServer.
But if the next() is being called with nbRows>1, co processor should provide a chance to do some operation before, after every next() calls into region as part of call next(int scannerId, int nbRows).

In case of usage of coprocessor with IHBase, before making any calls of next() into a Region, we need to make a reseek() to a row based on the index information.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10270,"When a block is added to the BlockCache its DataBlockEncoding is stored on the BlockCacheKey. This block encoding is used in the calculation of the hashCode and as such matters when cache lookups are done. Because the keys differ for encoded and unencoded (data) blocks, there is a potential for caching them twice or missing the cache. This happens for example when using Scan preloading as AbstractScannerV2.readNextDataBlock() does a read without knowing the block type or the encoding.

This patch removes the block encoding from the key and forces the caller of HFileReaderV2.readBlock() to specify the expected BlockType as well as the expected DataBlockEncoding when these matter. This allows for a decision on either of these at read time instead of cache time, puts responsibility where appropriate, fixes some cache misses when using the scan preloading (which does a read without knowing the type or encoding), allows for the BlockCacheKey to be re-used by the L2 BucketCache and sets us up for a future CompoundScannerV2 which can read both un-encoded and encoded data blocks.

A gotcha here: ScannerV2 and EncodedScannerV2 expect BlockType.DATA and BlockType.ENCODED_DATA respectively and will throw when given a block of the wrong type. Adding the DataBlockEncoding on the cache key caused a cache miss if the block was cached with the wrong encoding, implicitly defining the BlockType and thus keeping this from happening. It is now the scanner's responsibility to specify both the expected type and encoding (which is more appropriate).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6492,"In 0.96 we now have the Hadoop1-compat and Hadoop2-compat projects.
The reflection we're using to deal with different versions of Hadoop should be removed in favour of using the compact projects.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1001,If a delete cell has been entered but there is no corresponding deleted item -- or the deleted item has been expunged because > VERSIONS -- then there is no reason keeping the delete cell when compacting.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5587,"Are the {{hbase.*.dns.interface}} configuration options used or needed?  Per HBASE-4109 it looks like these never really worked, at least in cases where the hostname with a trailing dot doesn't resolve. The reason I asked is that while these were introduced in Hadoop, I don't think they're actually used, nor am I convinced bypassing the host for DNS lookups is a good idea (leads to painful bugs where default Java DNS lookups differ with these lookups). HBase started using these via a similar feature in HBASE-1279 and HBASE-1279.

I filed HADOOP-8156 to remove the API which HBase uses, which is obviously an incompatible change and would need to be worked around here if you wanted to keep this functionality in HBase, ie *if* that were to get checked into Hadoop we'd first need to get you on your own DNS class. Either way I'll update DNS' InterfaceAudience annotation to indicate HBase is a user.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1465,"Eclipse on my Mac is showing some errors when an @Override is used when a class implements an interface rather than extends.

Not a big deal but I want to keep this patch around anyways for personal use.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3274,See HBASE-2721 for details. We have fixed the default values in HBASE-3272 but we should also follow Hadoop to remove all hardcoded strings that refer to configuration properties and move them to HConstants. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12602,"Currently, we can't call hasNext() from ResultScanner directly. I think It is convenient that ResultScanner implements Iterator.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16410,"Currently when copyService.copy() returns non-zero return value, we throw exception:
{code}
        throw new IOException(""Failed of Hadoop Distributed Copy from ""+
            StringUtils.join(incrBackupFileList, "","") +"" to ""
          + backupContext.getHLogTargetDir());
{code}
We should retry distcp job when the return value is non-zero instead of throwing IOException immediately.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2888,"HBase publishes a bunch of metrics, some useful some wasteful, that should be improved to deliver a better ops experience. Examples:

 - Block cache hit ratio converges at some point and stops moving
 - fsReadLatency goes down when compactions are running
 - storefileIndexSizeMB is the exact same number once a system is serving production load

We could use new metrics too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2462,"Anything that improves our i/o profile makes hbase run smoother.  Over in HBASE-2457, good work has been done already describing the tension between minimizing compactions versus minimizing count of store files.  This issue is about following on from what has been done in 2457 but also, breaking the hard-to-read compaction code out of Store.java out to a standalone class that can be the easier tested (and easily analyzed for its performance characteristics).

If possible, in the refactor, we'd allow specification of alternate merge sort implementations. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3178,"Stack recommended in HBASE-3126 that: ""We should kill all inheritance in our scripts (except JAVA_HOME?)""

This jira is about doing that.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2375,"Currently we will make the decision to split a region when a single StoreFile in a single family exceeds the maximum region size.  This issue is about changing the decision to split to be based on the aggregate size of all StoreFiles in a single family (but still not aggregating across families).  This would move a check to split after flushes rather than after compactions.  This issue should also deal with revisiting our default values for some related configuration parameters.

The motivating factor for this change comes from watching the behavior of RegionServers during heavy write scenarios.

Today the default behavior goes like this:
- We fill up regions, and as long as you are not under global RS heap pressure, you will write out 64MB (hbase.hregion.memstore.flush.size) StoreFiles.
- After we get 3 StoreFiles (hbase.hstore.compactionThreshold) we trigger a compaction on this region.
- Compaction queues notwithstanding, this will create a 192MB file, not triggering a split based on max region size (hbase.hregion.max.filesize).
- You'll then flush two more 64MB MemStores and hit the compactionThreshold and trigger a compaction.
- You end up with 192 + 64 + 64 in a single compaction.  This will create a single 320MB and will trigger a split.
- While you are performing the compaction (which now writes out 64MB more than the split size, so is about 5X slower than the time it takes to do a single flush), you are still taking on additional writes into MemStore.
- Compaction finishes, decision to split is made, region is closed.  The region now has to flush whichever edits made it to MemStore while the compaction ran.  This flushing, in our tests, is by far the dominating factor in how long data is unavailable during a split.  We measured about 1 second to do the region closing, master assignment, reopening.  Flushing could take 5-6 seconds, during which time the region is unavailable.
- The daughter regions re-open on the same RS.  Immediately when the StoreFiles are opened, a compaction is triggered across all of their StoreFiles because they contain references.  Since we cannot currently split a split, we need to not hang on to these references for long.

This described behavior is really bad because of how often we have to rewrite data onto HDFS.  Imports are usually just IO bound as the RS waits to flush and compact.  In the above example, the first cell to be inserted into this region ends up being written to HDFS 4 times (initial flush, first compaction w/ no split decision, second compaction w/ split decision, third compaction on daughter region).  In addition, we leave a large window where we take on edits (during the second compaction of 320MB) and then must make the region unavailable as we flush it.


If we increased the compactionThreshold to be 5 and determined splits based on aggregate size, the behavior becomes:
- We fill up regions, and as long as you are not under global RS heap pressure, you will write out 64MB (hbase.hregion.memstore.flush.size) StoreFiles.
- After each MemStore flush, we calculate the aggregate size of all StoreFiles.  We can also check the compactionThreshold.  For the first three flushes, both would not hit the limit.  On the fourth flush, we would see total aggregate size = 256MB and determine to make a split.
- Decision to split is made, region is closed.  This time, the region just has to flush out whichever edits made it to the MemStore during the snapshot/flush of the previous MemStore.  So this time window has shrunk by more than 75% as it was the time to write 64MB from memory not 320MB from aggregating 5 hdfs files.  This will greatly reduce the time data is unavailable during splits.
- The daughter regions re-open on the same RS.  Immediately when the StoreFiles are opened, a compaction is triggered across all of their StoreFiles because they contain references.  This would stay the same.

In this example, we only write a given cell twice (instead of 4 times) while drastically reducing data unavailability during splits.  On the original flush, and post-split to remove references.  The other benefit of post-split compaction (which doesn't change) is that we then get good data locality as the resulting StoreFile will be written to the local DataNode.  In another jira, we should deal with opening up one of the daughter regions on a different RS to distribute load better, but that's outside the scope of this one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3866,"When a new region server is brought online, the current balancer kicks off a whole bunch of region moves and causes a lot of regions to be un-available right away.  A slower balancer that gradually balances the cluster is probably a good script to have.  I have an initial version that mooches off the region_mover script to do this.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-633,Compacting into local fs and then copying the resulting file up into hdfs rather than writing compacted file directly to hdfs may run faster.  Try it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3649,"In this thread on user@hbase: http://search-hadoop.com/m/WUnLM6ojHm1 J-D conjectures that compressing flush files leads to a suboptimal situation where ""the puts are sometimes blocked on the memstores which are blocked by the flusher thread which is blocked because there's too many files to compact because the compactor is given too many small files to compact and has to compact the same data a bunch of times.""

We have a separate compression setting already for major compaction vs store files written during minor compaction, for background/archival apps. Add a separate compression setting for flush files, default to none, to avoid the above condition.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3917,"The Avro schema files are in the src/main/java path, but should be in /src/main/resources just like the Hbase.thrift is. Makes the separation the same and cleaner.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-14040,Move distributed log roll procedure call to BackupHandler.call from IncrementalBackupManager.getLogFilesForNewBackup.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2480,Balancer is really basic; it just looks at counts of regions at the moment.  It also as it currently works has loads of issues (See the linked issues) including a lack of testibility.  This issue acts as the umbrella issue to collect all balancer improvements under.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-484,"Right now we keep our HRegionInfos stored as a stream of bytes in a single column in the META and ROOT tables. This is convenient to build and write in code under normal circumstances, and we've made the shell deserialize the binary into human readable data for display purposes.

However, we really don't have much flexibility to edit the info through the shell since it's binary. This means that when we need some latitude to reach in and tweak some stuff because of bugs or just for experimental purposes, we have to go and write custom tools in Java to achieve anything.

One way to mitigate this problem would be to stop storing HRIs as binary data and start putting each field into separate first-class columns in META and ROOT. This would let us do whatever we want in terms of single-row operations in the shell. We wouldn't have to make a special case for reading the data in those circumstances then, either.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6704,"StoreScanner#next tries to ensure that the KVs are pulled from the heap in-order. The prevKV is used for this and is compared with the latest KV pulled from the heap. Since copyKV can be modified by ScanQueryMatcher, prevKV should track the KV pulled from the heap, and not copyKV. This is a one-line fix.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-3700,"I once had an issue of ""Too many connections"" in ZooKeeper while running a MapReduce job where tables are used in my own classes instead of the interface provided by HBase (e.g. TableInputFormat and TableOutputFormat etc).  Investigation suggests this is due to many ZooKeeper's connection slots are occupied by remaining connections after clients exit, so that the free slots are not enough.

Discussed with Lars George, I suggest we note the need of explicit close of connections (to ZooKeepers) in HBase book.  Lars also suggests we improve TableOutputFormat by adding explicit calls to close methods.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-18360,{{Table}} doesn't have {{flushCommits}} method to explicitly flush mutations which is required for certain scenarios. This was a method available to users when {{HTable}} was accessible to users. Can we add {{flushCommits}} to {{Table}}. I can provide a patch if there are no objections to include this method.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5847,The Thrift API does not allow a user to create a table with multiple split keys.  This is needed for a handful of new internal projects that are written in PHP/C++.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2841,"HBASE-1511 added psuedo-distributed support for RegionServers and backup Masters, however there were some obstacles preventing the last piece: psuedo-distributed ZooKeeper clients (HQuorumPeer).  No major obstacles, just enough that I don't have time to work on them immediately.  This would be a great noob task to get familiar with how our ZooKeeper code works and make minor changes that will greatly help us test this product.  Note that if you're feeling extra ambitious, you could work on adding startZkCluster(int), killZkPeer(int), and restartZkPeer(int) to HBaseTestingUtility.java for JUnit test goodness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2608,"There are 2 compelling reasons to switch from log4j to slf4j:
* HBase provides a client library that is going to be embedded in another application.  Using SLF4J lets the application chose whatever logging library it wants instead of imposing log4j.
* When using SLF4J, we should use logback by default as it is basically a better, faster, stronger log4j.  Same author, new design / new code.  See http://logback.qos.ch/reasonsToSwitch.html",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8309,"Currently the lock timeout values and defaults are set and shared at the TableLockManager level.
One TableLockManager is shared on the master. We should allow the lock timeout to be set at individual lock level when we instantiate the lock. Components using the locks may have different timeout preferences. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8124,"When users invoke TableMapReduceUtils#addDependencyJars, directly or indirectly, the discovered jars are added to the jobconf via the configuration point ""tmpjars"". That means that, if I want to use one jobconf as the basis of another, and I blanket copy all ""hbase.*"" confs, the dependency jar list will be missed. Since the dependency jars are critical for successful execution of the job, and not an internal API passed between different MR components, this config point should be renamed to something starting with ""hbase.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6627,"org.apache.hadoop.hbase.TestMultiVersions.testGetRowVersions


Shutting down

Stacktrace

java.io.IOException: Shutting down
	at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:229)
	at org.apache.hadoop.hbase.MiniHBaseCluster.<init>(MiniHBaseCluster.java:92)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:688)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster(HBaseTestingUtility.java:661)
	at org.apache.hadoop.hbase.TestMultiVersions.testGetRowVersions(TestMultiVersions.java:143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:47)
	at org.junit.rules.RunRules.evaluate(RunRules.java:18)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1307,"I created this issue to be the overall issue for threading to increase read and write performance in HBase and to keep it as a discussion place about threading of these elements in general. Today we are doing batching of  writes and from 0.20 you will be able to do that for reads too. The thing is that the batching procedure doesn't use the ability to run these different queries at the same time, but more like a series of queries. I think that after getting a good stable 0.20 system down we should try to add threading to increase throughput for both reading and writing. At the top level of these calls I don't think that is is goin gto be to hard to do this in parallel, where it gets a little bit more complicated is when you get down to running a get query on memcache and all the storefiles at the same time, but above that I don't see it being to hard. I do think that this should not be a part of 0.20 but rather an optimization in 0.21 or so.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2623,"I witnessed a case last night where a region open got stuck -- it was an idx hbase region running on 0.20.5, seems like this combo doesn't work -- and it prevented our opening other regions behind it.  We never recovered.  Both the table that had the stuck region and all tables that had regions that were in the queue behind this stuck region were now borked.  There was no way out.

Add a timeout on region open.  If a region open fails N times, put it aside.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16327,Bufferchain is nothing but a collection of Bytebuffers. We already have MultiBytebuff. May be we can unify both and add the Bufferchain#write() to ByteBuff abstract class. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12002,The feature introduced in HBASE-11990 should be reflected in the HBase book.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-11808,We should update the jdiffHBasePublicAPI script in hbase/dev-support to be a bit more user-friendly.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-13689,Try to bring down the time on our post-commit tests using [the parallel test executor plugin|https://wiki.jenkins-ci.org/display/JENKINS/Parallel+Test+Executor+Plugin] for jenkins.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2597,"We've got a lot of objects that have a ton of different constructors with a huge number of parameters. Whenever we add a new parameter, existing callers break, and it's sometimes difficult to keep track of which booleans/nulls correspond to which parameter.

I'd like to consider moving to the ""Builder"" pattern in some of these cases. See http://guava-libraries.googlecode.com/svn/trunk/javadoc/com/google/common/collect/MapMaker.html for an example of this pattern in action. Another good example is the builder API generated by protocol buffers (search for ""builder"" on http://code.google.com/apis/protocolbuffers/docs/javatutorial.html )

I think this pattern makes code more readable and also allows us to more easily change around the number of arguments in our constructors.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6058,"We use async API today. This is already much much faster than the sync API. Still, it makes sense to use the 'multi' function: this will decrease the network & zookeeper load at startup/rolling restart.

On a 500 nodes cluster, we see 3 that 3 seconds are spent on updating ZK per bulk assignment. This should cut it in half (+ the benefits on the network/zk load).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2459,"Currently we synchronize within HConnectionManager.locateRegionInMeta() when looking up the cached location (and querying meta if not cached).  We use the same lock for every user-space region.

We really only need per-region synchronization here.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10938,"In case the namespace table is assigned to the master, TableNamespaceManager should use the shortcut connection.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2895,"I'd love to use some annotations to document some common things. In particular I'd love to see @ThreadSafe and @NotThreadSafe. If not for all classes it would at least be nice to have this for all the client classes that a user might see.

http://jcip.net/annotations/doc/index.html
Those can be easily pulled in via Maven.

Should we do it?

Hadoop common also started using  InterfaceAudience and InterfaceStability annotations which might be nice.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16506,"Currently for SNAPSHOT_TABLES stage, we loop through the tables and take snapshot for each table.
If the master restarts in the middle of this stage, we would restart taking snapshot from the first table.

This issue would use subprocedure for each snapshot so that we don't need to take snapshot for the table(s) whose snapshot is complete before the master restart.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-9416,"Nasty & hacky patch on top of the 0.96 to get some feedback on adding this third party.
I ran a test doing ""gets"" on an empty region.
With the current implementation, we're spending time in the LinkedBlockingQueue#put. I was able to do 150K operations per second.

Using the disruptor allowed me to go to 190 ops/s, i.e. a little be more than a 25% improvement.

Likely there are other improvements in this class as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6128,Thanks to HBASE-5739 we can now specify a max weight instead of a maximum number of blocks in the DoubleBlockCache. This will give a more accurate control over its memory usage.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7623,"Sometimes, some non-IOException prevents User.getCurrent() to get a username.  It makes it impossible to create a HConnection.  We should catch all exception here:

{noformat}
      try {
        User currentUser = User.getCurrent();
        if (currentUser != null) {
          username = currentUser.getName();
        }
      } catch (IOException ioe) {
        LOG.warn(""Error obtaining current user, skipping username in HConnectionKey"",
            ioe);
      }
{noformat}

Not just IOException, so that client can move forward.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7015,"Having major_compact --force would have some advantages:

1.) Changing compression type and making sure all storefiles are written with the new value

2.) Can help with TTL and expiring all old data

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-59,"mapreduce has a configuration property called ""mapred.system.dir"" which determines where in the DFS a jobtracker stores its data.  Similarly, hbase has a configuration property called ""hbase.rootdir"" which does something very similar.

These should have the same name, eg. ""hbase.system.dir"" and ""mapred.system.dir""
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-16817,"Current we write length header before KeyValueUtil#oswrite, it is more efficient to  write length header inside it, so we only to calculate the length only once.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7348,"DFSClient actually collected a number of useful statistics such as bytesLocalRead, bytesLocalRackRead and so on. So this diff is going to merge these metrics into the RegionServerMetrics.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10784,"For adding/querying rowcol and deleteColumn BF, there are multiple unnecessary memory copy operations. This jira is to address the concern and avoid creating these dummy bloom keys as much as possible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10083,"When RegionServer failed to load a bloom block from HDFS due to any timeout or other reasons, it threw out the exception and disable the entire bloom filter for this HFile. This behavior does not make too much sense, especially for the compound bloom filter. 

Instead of disabling the bloom filter for the entire file, it could just return a potentially false positive result (true) and keep the bloom filter available.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8083,"Currently, HBaseClient would throw retry_exhausted_exception to the client, which is not very informative to debug the reliability issues. So the plan is the HBaseClient could expose more details information in these exceptions. For example, what's the region server or region for the exception ? What's the server side exception in details ?

Most the information might be already there but we need to expose them in a uniform format.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10360,"HTable.getHRegionInfo() will return all the RegionServer address for each HRegion by scanning the META table. Actually, the HConnectionManger could cache these data and refresh the client location cache directly. Also, HTable could expose another API to return these cached HRegionLocation directly without scanning the META table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7106,"In JDK7, it will throw out NPE if put a NULL into a TreeSet. And in the unit tests, user can add a NULL as qualifier into the family map for GET or SCAN. 
So we shall do the followings: 

1) Make sure the semantics of NULL column qualifier is equal to that of the EMPYT_BYTE_ARRAY column qualifier.

2) An easy fix is to use the EMPYT_BYTE_ARRAY qualifier to replace NULL qualifier in the family map for the GET or SCAN objects, and everything else shall be backward compatible.

3) Add a jdk option in the pom.xml (Assuming user installed the fb packaged jdk)
eg: mvn test -Dtest=TestFromClientSide -Pjdk7",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-12280,"This change allows us to change the number of blocking store files on-line. This is already done, and should appear in the 89-fb branch soon. For context, see: HBASE-8544, HBASE-8576, HBASE-8805",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7276,"In HBase, each RegionServer will host a set of Regions and both of them keep track of the read/write requests metrics. So total number of read/write requests among all the Regions shall be equal to the total number from the RegionServer. We shall optimize the code to remove the redundant metrics in the RegionServer level, and merge the Region level metrics into the RegionServer level.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7193,"The hbase client only prints the name of exception for the RetriesExhaustedException logging purpose, which failed to provide any useful debug information.

So this jira is to enhance the logging to print the entire stack track of the exception to help on issue investigation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6911,It is too much logging for each row-location cache hit in the hbase client. So set it as the trace level. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7266,"There are 2 kinds of read operations in HBase: pread and seek+read.
Pread, positional read, is stateless and create a new connection between the DFSClient and DataNode for each operation. While seek+read is to seek to a specific postion and prefetch blocks from data nodes. The benefit of seek+read is that it will cache the prefetch result but the downside is it is stateful and needs to synchronized.

So far, both compaction and scan are using seek+read, which caused some resource contention. So using the pread for the scan request can avoid the resource contention. In addition, the region server is able to do the prefetch for the scan request (HBASE-6874) so that it won't be necessary to let the DFSClient to prefetch the data any more.

I will run through the scan benchmark (with no block cache) with verify the performance.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2239,"One of the requirements of IHBase is that the a filter should be provided that at least matches the index expression hint.  The IHBase expression classes could easily be used to generate a filter that can be used on the scan...

For example: 
{code}
Expression expression = Expression
    .or(
        Expression.comparison(columnName1, qualifer1, operator1, value1)
    )
    .or(
        Expression.and()
            .and(Expression.comparison(columnName2, qualifer2, operator2, value2))
            .and(Expression.comparison(columnName3, qualifer3, operator3, value3))
    );

Filter filter  = expression.toFilter();
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8682,The data ingestion integration test almost always fails on us due to region is not available.  I'd like to add some information before killing a region server so that we have a better idea about what's going on.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2367,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-685,"Over in HBASE-684, LN suggests that we should find alternative to synchronized sortedmap; its used all over the place in hbase so a faster alternative should improve thoughput.  That synchronized sortedmap is less than perfect has been known from earliest days (see cafarella comment at head of HStore#internalGet in 0.1 branch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-15453,"In HBASE-10015 back then I found that intrinsic locks (synchronized) in StoreScanner are slower that explicit locks.

I was surprised by this. To make sure I added a simple perf test and many folks ran it on their machines. All found that explicit locks were faster.

Now... I just ran that test again. On the latest JDK8 I find that now the intrinsic locks are significantly faster:
(OpenJDK Runtime Environment (build 1.8.0_72-b15))

Explicit locks:
10 runs  mean:2223.6 sigma:72.29412147609237

Intrinsic locks:
10 runs  mean:1865.3 sigma:32.63755505548784

I confirmed the same with timing some Phoenix scans. We can save a bunch of time by changing this back 

Arrghhh... So maybe it's time to revert this now...?

(Note that in trunk due to [~ram_krish]'s work, we do not lock in StoreScanner anymore)

I'll attach the perf test and a patch that changes lock to synchronized, if some folks could run this on 0.98, that'd be great.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-72,"Region server and client logs will have lots of the following when a cluster is being loaded:
{code}
org.apache.hadoop.hbase.NotServingRegionException: hbaserepository,,7144829661993961256
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1208)
        at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1180)
        at org.apache.hadoop.hbase.HRegionServer.startUpdate(HRegionServer.java:1122)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:985)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:340)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:566)
{code}

The NotServingRegionException exception is thrown when the remote server is no longer serving the asked-for region (usually because its been split).  The server throws the exception to provoke the client into making a new interrogation of region locations.

It would be an improvement if such 'normal' operation was not built atop exceptions.  For example, commits might return a 'region moved' message.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-80,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-73,"As is, generated code goes into o.a.h.h.thrift.generated, o.a.h.h.hql.generated, etc.  Rather, have it all go into the one package, o.a.h.h.generated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-69,"When flusher runs -- its triggered when the sum of all Stores in a Region > a configurable max size -- we flush all Stores though a Store memcache might have but a few bytes.

I would think Stores should only dump their memcache disk if they have some substance.

The problem becomes more acute, the more families you have in a Region.

Possible behaviors would be to dump the biggest Store only, or only those Stores > 50% of max memcache size.  Behavior would vary dependent on the prompt that provoked the flush.  Would also log why the flush is running: optional or > max size.

This issue comes out of HADOOP-2621.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1306,"There are multiple places where we can make an update run in parallel when inserting into HBase. Two of these points are making every row get it's own thread and then every family, store, get it's own thread when you are in the right region.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-4044,"    We found that the hlog flush to disk would block other write threads. When one thread exec ""doWrite(info, logKey, edit);"", the others wait for ""updateLock"" in HLog.java.

    Why not the others add their edits into a list and wait. When sync's time, the whole list sync to disk once. I think it will decrease the IO calls. 

    So Maybe we will make two lists for edits. Each thread write to the ""waledits"" and wait for ""updateLock"". Each thread can copy the ""waledits"" to ""flushedits"" and flush the ""flushedits"" to disk once it gets ""updateLock"".

    In my test, it can increase the write speed of 100% when I set ""hbase.regionserver.handler.count""=100.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2910,"I am working on the Hue based front end called the ""HBase Explorer"". It would be good to be able to also display the current cluster configuration.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1690,"Support a simple access control mechanism via HTTP basic authentication.  Allow definition of authorized users and assignment of ACLs to those users backed by an HBase table. A first cut might just be to control table accesses -- a user will either be allowed any access to a table or nothing. Subsequently, supporting the granting or revocation of various combinations of create, update, read, and delete privileges on tables or column families can be considered. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1113,"I think there was a reason for why closes' were not recorded but can't remember what it was.

We should try and figure a way of adding it because its disorientating looking at a regions history seeing it opened multiple times with a close in between.  Would be sweet if could record too why closed; e.g. load balancing.

W/o the recording of 'close', I find I have to go to master logs to get a regions history.  I'd like to not have to.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10886,"Once htrace-zipkin was removed from depencencies in HBASE-9700. Because all of the depencencies of htrace-zipkin is bundled with HBase now, it is good to add it for the ease of use.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-8220,"In HTablePool, we have a method getCurrentPoolSize(...) to get how many opened HTable has been pooled. However, we don't know ConcurrentOpenedHTable which means the count of HTable get from HTablePool.getTable(...) and don't return to HTablePool by PooledTable.close(). The ConcurrentOpenedHTable may be meaningful because it indicates how many HTables should be opened for the application which may help us set the appropriate MaxSize of HTablePool. Therefore, we can and a ConcurrentOpenedHTable as a counter in HTablePool.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-6045,In discussion of HBASE-6013 it was suggested that we change --peer.adr to the more english centric --peer.addr.  We would keep the old value present in 0.90/0.92/0.94 and remove from 0.96/trunk.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7708,"We noticed high CPU utilization while using region_mover.rb to unload regions.  Consulted with Stack, who suggested changing a line in region_mover.rb from (the deprecated):
{code}
  table = getTable(admin.getConfiguration(), r.getTableDesc().getName())
{code}
to:
{code}
  table = getTable(admin.getConfiguration(), r.getTableName())
{code}
In our tests this dropped CPU utilization from ~200% over the course of the unload to ~0.5% after startup, and allowed unload of ~200 regions to complete in ~7 minutes instead of the original ~18 minutes, so the change seems to fix the CPU utilization issue with no untoward side effects we could find.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-2170,"As a wish - it would be nice to have a hbase client library (subset of the current hbase distribution) that needs to be present at the hbase client level to interact with the master/region servers. 

From an app integration - users of hbase can just link against the client library as opposed to getting the entire library to link against. 





",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-1814,"as per #hbase:

12:22 < larsgeorge> you gueys should not be allowed in the same car - ever
12:22 < larsgeorge> *guys
12:22 < dj_ryan> yeah
12:22 < larsgeorge> too dangerous for the project
12:22 < dj_ryan> it was pretty much some of the core hbase braintrust in 1 car
12:22 < rpaddock> I'd file a jira about that

The risk is clearly too great. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-749,"a patch, for anyone need 0.1.x running on hadoop 0.17.x

only 0.1.3 with hadoop 0.17.1 tested.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10096,"As [https://issues.apache.org/jira/browse/HBASE-6942] introduced, BulkDeleteEndpoint provides 'delete' method which performs like sql : ""delete from table where ..."". BulkDeleteEndpoint is efficient because it can complete scan and delete in one rpc and also could be implemented parallelly in different regions using coprocessor. BulkDeleteResponse is represents the result of BulkDeleteEndpoint.delete and will be serialized using a standard java serializable way. However, the serialized length of BulkDeleteResponse will be longer than one hundred byte length and may be not efficient enough to pass  on the network. Therefore, is it better to make BulkDeleteResponse implement Writable interface and provide more efficient serialize method?",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10790,"Now to compile a HBase tar release package, we should use
the cmd: 
{code}
 mvn clean package assembly:single
{code}, which is not convenient. We can make assembly:single as a default option and run the assembly plugin in maven package phase. Then we can just use the cmd {code} mvn clean package {code} to get a release package.

Other suggestions are welcomed.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-775,Currently we compact all map files with no upper limit this could cause a regionserver to OOME if the compaction get behind and the number of mapfiles build up.,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-7922,"Removed several warnings in eclipse editor.  no new test cases be added, since no semantics changed",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-10468,"Followup for HBASE-10277.
Further work can be done, as discussed in comments, such as moving ""global"" error management for streaming use case from AsyncProcess to HTable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
HBASE-5075,"regionserver crashed,it is too long time to notify hmaster.when hmaster know regionserver's shutdown,it is long time to fetch the hlog's lease.
hbase is a online db, availability is very important.
i have a idea to improve availability, monitor node to check regionserver's pid.if this pid not exsits,i think the rs down,i will delete the znode,and force close the hlog file.
so the period maybe 100ms.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,
